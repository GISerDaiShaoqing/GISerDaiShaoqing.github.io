<!doctype html>



  


<html class="theme-next muse use-motion" lang="en">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0" />






<meta property="og:type" content="website">
<meta property="og:title" content="GISerDaiShaoqing's Blog">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="GISerDaiShaoqing's Blog">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="GISerDaiShaoqing's Blog">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/"/>





  <title> GISerDaiShaoqing's Blog </title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  














  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">GISerDaiShaoqing's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Urban·Ecology·GIS</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            Search
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocapitalize="off" autocomplete="off" autocorrect="off"
             placeholder="Searching..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/06/21/应用统计学与R语言实现学习笔记（十）——聚类分析/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Dai Shaoqing">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GISerDaiShaoqing's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/06/21/应用统计学与R语言实现学习笔记（十）——聚类分析/" itemprop="url">
                  应用统计学与R语言实现学习笔记（十）——聚类分析
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-06-21T00:00:00+08:00">
                2017-06-21
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/统计与模型/" itemprop="url" rel="index">
                    <span itemprop="name">统计与模型</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/2017/06/21/应用统计学与R语言实现学习笔记（十）——聚类分析/" class="leancloud_visitors" data-flag-title="应用统计学与R语言实现学习笔记（十）——聚类分析">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">Visitors </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="chapter-10-cluster-analysis"><a href="#Chapter-10-Cluster-Analysis" class="headerlink" title="Chapter 10 Cluster Analysis"></a>Chapter 10 Cluster Analysis</h1><p>本篇是第十章，内容是聚类分析。由于之后的几章是典型的分析方法。而且在14章的案例里面可能不会体现，所以内容里会渗透较多的R语言操作。</p>
<h3 id="1-多元分布基本概念"><a href="#1-多元分布基本概念" class="headerlink" title="1 多元分布基本概念"></a>1 多元分布基本概念</h3><p>在研究实际问题的时候，我们经常遇到的是多变量的问题，由于指标间相互不独立，单独割裂开来分别研究分析，不能从整体上把握所研究问题的实质。所以我们必须对多元变量及其分布进行统计和分析，在地学领域这种问题比比皆是，这里就不展开阐述了，接下来是一堆纯数学概念，数学恐惧者慎入，这部分的重点应该是关于协方差矩阵。一般来说，假设所研究的问题有p个指标，进行了n次独立观测，得到了np个数据。那么对于单次独立观测，我们定义随机向量（Random Vector）为：<br>$$ x=(x_1,x_2,\cdots,x_p)’ $$<br>其概率分布函数定义为<br>$$ F(a_1,a_2,\cdots,a_p)=P(x_1\le a_1,x_2\le a_2,\cdots,x_p\le a_p) $$<br><strong>分布函数的性质</strong></p>
<blockquote>
<ul>
<li>非降的右连续函数</li>
<li>分布函数的取值范围为[0，1]，即<br>$$ 0\le F(a_1,a_2,\cdots,a_p)\le 1 $$</li>
<li>分布函数当变量取值为无穷大时，函数值收敛到1，即<br>$$ F(\infty,\infty,\cdots,\infty)=1 $$</li>
</ul>
</blockquote>
<p><strong>多元概率密度函数</strong><br>随机向量$x=(x_1,x_2,\cdots,x_p)’$的分布函数可以表示为<br>$$F(a_1,a_2,\cdots,a_p)=P(x_1\le a_1,x_2\le a_2,\cdots,x_p\le a_p)=\int_{-\infty}^{a_1}\cdots\int_{-\infty}^{a_p}f(x_1,x_2,\cdots,x_p)dx_1\cdots dx_p $$<br>则称$ x=(x_1,x_2,\cdots,x_p)’ $为连续型随机变量，称$f(x_1,x_2,\cdots,x_p)$为其多元概率密度函数。若$F(a_1,a_2,\cdots,a_p)$在点$(x_1,x_2,\cdots,x_p)$连续，则$f(x_1,x_2,\cdots,x_p)=\frac{\partial^p}{\partial x_1\partial x_2\cdots\partial x_p}F(x_1,x_2,\cdots,x_p)$且有$1\ge F(x_1,x_2,\cdots,x_p)\ge 0$，$\int_{-\infty}^{a_1}\cdots\int_{-\infty}^{a_p}f(x_1,x_2,\cdots,x_p)dx_1\cdots dx_p=1$。<br><strong>数学期望</strong><br>定义<br>$$ \begin{bmatrix} x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1q} \ x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2q} \ \vdots &amp; \vdots &amp;  &amp; \vdots \ x_{p1} &amp; x_{p2} &amp; \cdots &amp; x_{pq} \end{bmatrix}$$<br>是由随机变量构成的随机矩阵，定义X的数学期望为<br>$$ \begin{bmatrix} E(x_{11}) &amp; E(x_{12}) &amp; \cdots &amp; E(x_{1q}) \ E(x_{21}) &amp; E(x_{22}) &amp; \cdots &amp; E(x_{2q}) \ \vdots &amp; \vdots &amp;  &amp; \vdots \ E(x_{p1}) &amp; E(x_{p2}) &amp; \cdots &amp; E(x_{pq}) \end{bmatrix}$$<br>特别当q=1时，便可得到随机向量$(x_1,x_2,\cdots,x_p)’$的数学期望为$E(x)=(E(x_1),E(x_2),\cdots,E(x_p))’$<br><strong>协方差矩阵</strong><br>设$x=(x_1,x_2,\cdots,x_p)’$和$y=(y_1,y_2,\cdots,y_q)’$分别为p维和q维随机向量，则其协方差矩阵为<br>$$ E\begin {bmatrix} \begin {pmatrix} x-E(x_1) \ x-E(x_2) \ \vdots \ x-E(x_p) \end{pmatrix} (y-E(y_1),(y-E(y_2),\cdots,(y-E(y_q) \end {bmatrix}$$</p>
<p>$$=\begin {pmatrix} cov(x_1,y_1) &amp; cov(x_1,y_2) &amp; \cdots &amp; cov(x_1,y_q) \ cov(x_2,y_1) &amp; cov(x_2,y_2) &amp; \cdots &amp; cov(x_2,y_q) \ \vdots &amp; \vdots &amp;  &amp; \vdots \ cov(x_p,y_1) &amp; cov(x_p,y_2) &amp; \cdots &amp; cov(x_p,y_q) \end {pmatrix}=cov(X,Y) $$<br>$x=(x_1,x_2,\cdots,x_p)’$的协方差矩阵为<br>$$\Sigma=Var(x)=\begin {pmatrix} var(x_1) &amp; cov(x_1,x_2) &amp; \cdots &amp; cov(x_1,x_p) \ cov(x_2,x_1) &amp; var(x_2) &amp; \cdots &amp; cov(x_2,x_p) \ \vdots &amp; \vdots &amp;  &amp; \vdots \ cov(x_p,x_1) &amp; cov(x_p,x_2) &amp; \cdots &amp; var(x_p) \end {pmatrix}$$<br>随机向量X的协方差矩阵Σ是非负定矩阵。设A是常数矩阵，b为常数向量，则<br>$$ Var(AX+b)=AV(X)A’=A\Sigma A’ $$<br>若$(x_1,x_2,\cdots,x_p)’$的分量相互独立，则协方差矩阵除主对角线上的元素外均为零，即<br>$$\Sigma=Var(x)=\begin {pmatrix} var(x_1) &amp; 0 &amp; \cdots &amp; 0 \ 0 &amp; var(x_2) &amp; \cdots &amp; 0 \ \vdots &amp; \vdots &amp;  &amp; \vdots \ 0 &amp; 0 &amp; \cdots &amp; var(x_p) \end {pmatrix} $$<br><strong>相关系数矩阵</strong><br>若$x=(x_1,x_2,\cdots,x_p)’$和$y=(y_1,y_2,\cdots,y_q)’$分别是p维和q维随机向量，则其相关系数矩阵为<br>$$ \rho (x,y)=\begin {pmatrix} \rho (x_1,y_1) &amp; \rho (x_1,y_2) &amp; \cdots &amp; \rho (x_1,y_q) \ \rho (x_2,y_1) &amp; \rho (x_2,y_2) &amp; \cdots &amp; \rho (x_2,y_q) \ \vdots &amp; \vdots &amp;  &amp; \vdots \ \rho (x_p,y_1) &amp; \rho (x_p,y_2) &amp; \cdots &amp; \rho (x_p,y_q) \end {pmatrix} $$<br>若$\rho (x,y)=0$，两随机向量相互独立。</p>
<h3 id="2-数据的变换处理"><a href="#2-数据的变换处理" class="headerlink" title="2 数据的变换处理"></a>2 数据的变换处理</h3><p>数据变换是将原始数据矩阵中的每个元素按照某种特定的运算把它变成为一个新值，而且数值的变化不依赖于原始数据集合中其它数据的新值。事实上多元数据的变换处理通常是为了消除不同量纲的差异。<br>较常用的数据变换如下：</p>
<blockquote>
<ul>
<li>中心化变换<br>中心化变换是一种坐标轴平移处理方法，它是先求出每个变量的样本平均值，再从原始数据中减去该变量的均值，就得到中心化变换后的数据。设原始观测数据矩阵为：<br>$$ X= \begin{bmatrix} x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1q} \ x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2q} \ \vdots &amp; \vdots &amp;  &amp; \vdots \ x_{n1} &amp; x_{n2} &amp; \cdots &amp; x_{nq} \end{bmatrix} $$<br>$$ x_{ij}^*=x_{ij}-\bar x_j (i=1,2,\cdots,n;j=1,2,\cdots,p) $$<br>中心化变换的结果是使每列数据之和均为0，即每个变量的均值为0，而且每列数据的平方和是该列变量样本方差的(n-1)倍，任何不同两列数据之交叉乘积是这两列变量样本协方差的(n-1)倍，所以这是一种很方便地计算方差与协方差的变换。</li>
<li>极差规格化变换<br>极差规格化变换是从数据矩阵的每一个变量中找出其最大值和最小值，这两者之差称为极差，然后从每个变量的每个原始数据中减去该变量中的最小值，再除以极差，就得到规格化数据。<br>$$ x_{ij}^<em>=\frac{x_{ij}-min_{k=1,2,\cdots,n} (x_{kj})}{R_j} (i=1,2,\cdots,n;j=1,2,\cdots,p) $$<br>$$ R_j= max_{i=1,2,\cdots,n} (x_{ij})-min_{i=1,2,\cdots,n} (x_{ij})，0\le  x_{ij}^</em>\le 1 $$<br>经过极差规格化变换后，数据矩阵中每列即每个变量的最大数值为1，最小数值为0，其余数据取值均在0和1之间；并且变换后的数据都不再具有量纲，便于不同的变量之间的比较。</li>
<li>标准化变换<br>标准化变换首先对每个变量进行中心化变换，然后用该变量的标准差进行标准化。<br>$$ x_{ij}^*=\frac{(x_{ij}-\bar x)}{S_j} (i=1,2,\cdots,n;j=1,2,\cdots,p) $$<br>$$ S_j=\sqrt{\frac{1}{n-1}\sum_{i=1}^n(x_{ij}-\bar x_j)^2} $$<br>经过标准化变换处理后，数据矩阵中每列数据即每个变量的平均值为0，方差为1，且不再具有量纲，便于不同变量之间的比较。变换后，数据矩阵中任何两列数据乘积之和是所对应的两个变量相关系数的（ n-1）倍，所以这是一种很方便地计算相关矩阵的变换。</li>
<li>对数变换<br>对数变换是将各个原始数据取对数，将原始数据的对数值作为变换后的新值。<br>$$ x_{ij}^*=log(x_{ij}) $$</li>
</ul>
</blockquote>
<h3 id="3-聚类分析"><a href="#3-聚类分析" class="headerlink" title="3 聚类分析"></a>3 聚类分析</h3><p>聚类分析是一种分类技术。与多元分析的其他方法相比，该方法较为粗糙，理论上还不完善，但应用方面取得了很大成功。与回归分析、判别分析一起被称为多元分析的三大方法。<br><strong>聚类的目的</strong>——根据已知数据（ 一批观察个体的许多观测指标） ， 按照一定的数学公式计算各观察个体或变量（指标）之间亲疏关系的统计量（距离或相关系数等）。 根据某种准则（ 最短距离法、最长距离法、中间距离法、重心法等），使同一类内的差别较小，而类与类之间的差别较大，最终将观察个体或变量分为若干类。<br><strong>聚类的种类</strong>——<br>根据分类的方法可将聚类分析分为：系统聚类、快速聚类、有序聚类。<br>根据分类的对象可将聚类分析分为：Q型——样品聚类clustering for individuals；R型——指标聚类clustering for variables。<br><strong>数据结构</strong><br>|individuals|$X_1$|$X_2$|$\cdots$|$X_l$|$|cdots$|$X_p$|<br>|–|:–:|:–:|:–:|–:|<br>|1|28|1.0|$\cdots$|114|$\cdots$|0.15|<br>|2|29|2.0|$\cdots$|117|$\cdots$|0.20|<br>|$\cdots$|$\cdots$|$\cdots$|$\cdots$|$\cdots$|$\cdots$|$\cdots$|<br>|i|$x_{i1}$|$x_{i2}$|$\cdots$|$x_{il}$|$\cdots$|$x_{ip}$|<br>|$\cdots$|$\cdots$|$\cdots$|$\cdots$|$\cdots$|$\cdots$|$\cdots$|<br>|47|15|8|$\cdots$|64|$\cdots$|0.51|<br>|48|16|7.5|$\cdots$|65|$\cdots$|0.50|<br>|$\cdots$|$\cdots$|$\cdots$|$\cdots$|$\cdots$|$\cdots$|$\cdots$|<br>|n|$x_{n1}$|$x_{n2}$|$\cdots$|$x_{nl}$|$\cdots$|$x_{np}$|</p>
<h3 id="4-样品间亲疏程度的测度"><a href="#4-样品间亲疏程度的测度" class="headerlink" title="4 样品间亲疏程度的测度"></a>4 样品间亲疏程度的测度</h3><p><strong>样品间亲疏程度的测度</strong><br>研究样品或变量的亲疏程度的数量指标有两种，一种叫相似系数，性质越接近的变量或样品，它们的相似系数越接近于1，而彼此无关的变量或样品它们的相似系数则越接近于0，相似的为一类，不相似的为不同类；另一种叫距离，它是将每一个样品看作p维空间的一个点，并用某种度量测量点与点之间的距离，距离较近的归为一类，距离较远的点属于不同的类。<br>变量之间的聚类即R型聚类分析，常用相似系数来测度变量之间的亲疏程度。而样品之间的聚类即Q型聚类分析，则常用距离来测度样品之间的亲疏程度。<br><strong>距离</strong><br>假使每个样品有p个变量，则每个样品都可以看成p维空间中的一个点， n个样品就是p维空间中的n个点，则第i样品与第j样品之间的距离记为$d_{ij}$。<br><strong>定义距离的准则</strong><br>定义距离要求满足第i个和第j个样品之间的距离如下四个条件（距离可以自己定义，只要满足距离的这四个条件）</p>
<blockquote>
<ul>
<li>$d_{ij}\ge 0$对一切的i和j成立;</li>
<li>$d_{ij}=0$当且仅当$x_i=x_j$成立;</li>
<li>$d_{ij}=d_{ji}$对一切的i和j成立;</li>
<li>$d_{ij}\le d_{ik}+d_{kj}$对于一切的i和j成立。<br><strong>常用距离</strong></li>
<li>明氏距离(Minkowski)<br>设$x_i=(x_{i1},x_{i1},\cdots,x_{ip})’$和$x_j=(x_{j1},x_{j1},\cdots,x_{jp})’$是第i和j个样品的观测值，则二者之间的距离。<br>明氏距离：<br>$$ d_{ij}=(\sum_{k=1}^p \left |x_{ik}-x_{jk}|^q\right)^{\frac{1}{q}} $$<br>欧氏距离：<br>$$ d_{ij}=\sqrt{\sum_{k=1}^p(x_{ik}-x_{jk})^2} $$<br>绝对距离：<br>$$ d_{ij}=\sum_{k=1}^p|x_{ik}-x_{jk}| $$<br>Chebychev距离：<br>$$ d_{ij}=max_{k=1}^p|x_{ik}-x_{jk}| $$<br><strong>明氏距离主要有以下两个缺点</strong><br>明氏距离的值与各指标的量纲有关，而各指标计量单位的选择有一定的人为性和随意性，各变量计量单位的不同不仅使此距离的实际意义难以说清，而且，任何一个变量计量单位的改变都会使此距离的数值改变从而使该距离的数值依赖于各变量计量单位的选择。<br>明氏距离的定义没有考虑各个变量之间的相关性和重要性。实际上，明氏距离是把各个变量都同等看待，将两个样品在各个变量上的离差简单地进行了综合。</li>
<li>兰氏距离(Lance &amp; Williams)<br>这是兰思和维廉姆斯(Lance &amp; Williams)所给定的一种距离，其计算公式为：<br>$$ d_{ij}(L)=\sum_{k=1}^p\frac{|x_{ik}-x_{jk}|}{x_{ik}+x_{jk}} $$<br>这是一个自身标准化的量，由于它对大的奇异值不敏感，这样使得它特别适合于高度偏倚的数据。虽然这个距离有助于克服明氏距离的第一个缺点，但它也没有考虑指标之间的相关性。</li>
<li>马氏距离(Mahalanobis)<br>这是印度著名统计学家马哈拉诺比斯(P.C． Mahalanobis)所定义的一种距离，其计算公式为：<br>$$ d_{ij}^2=(x_i-x_j)’\Sigma^{-1}(x_i-x_j) $$<br>Σ表示观测变量之间的协方差短阵。在实践应用中，若总体协方差矩阵Σ未知，则可用样本协方差矩阵作为估计代替计算。马氏距离又称为广义欧氏距离。显然，马氏距离与上述各种距离的主要不同就是马氏距离考虑了观测变量之间的相关性。如果假定各变量之间相互独立，即观测变量的协方差矩阵是对角矩阵，则马氏距离就退化为用各个观测指标的标准差的倒数作为权数进行加权的欧氏距离。因此，马氏距离不仅考虑了观测变量之间的相关性，而且也考虑到了各个观测指标取值的差异程度。</li>
<li>斜交空间距离<br>由于各变量之间往往存在着不同的相关关系，用正交空间的距离来计算样本间的距离易变形，所以可以采用斜交空间距离。<br>$$ d_{ij}=[\frac{1}{p^2}\sum_{h=1}^p\sum_{k=1}^p(x_{ih}-x_{jh})(x_{ik}-x_{jk})r_{hk}]^{\frac{1}{2}} $$<br>当各变量之间不相关时，斜交空间退化为欧氏距离。</li>
<li>配合距离<br>$$ X_1=(V,Q,S,T,K) X_2=(V,M,S,F,K)$$<br>$$ d_{12}=\frac{m_1}{m_1+m_2}=\frac{不配合数}{配合数+不配合数}=\frac{2}{2+3}=\frac{2}{5} $$<br>适用于分类变量，尤其是名义尺度变量。<br><strong>相似系数</strong><br>研究样品间的关系常用距离，研究指标间的关系常用相似系数。相似系数常用的有夹角余弦和相关系数。</li>
<li>夹角余弦(Cosine)<br>夹角余弦是从向量集合的角度所定义的一种测度变量之间亲疏程度的相似系数。设在n维空间的向量。<br>$$ x_i=(x_{1i},x_{2i},\cdots,x_{ni})’，x_j=(x_{1j},x_{2j},\cdots,x_{nj})’ $$<br>$$ c_{ij}=\cos \alpha_{ij}=\frac{\sum_{k=1}^nx_{ki}x_{kj}}{\sqrt{\sum_{k=1}^nx_{ki}^2\sum_{k=1}^nx_{kj}^2}}，d_{ij}^2=1-c_{ij}^2$$</li>
<li>相关系数是将数据标准化后的夹角余弦<br>$$ x_i=(x_{1i},x_{2i},\cdots,x_{ni})’，x_j=(x_{1j},x_{2j},\cdots,x_{nj})’ $$<br>$$ c_{ij}=\frac{\sum_{k=1}^n(x_{ki}-\bar x_i)(x_{kj}-\bar x_j)}{\sqrt{\sum_{k=1}^n(x_{ki}-\bar x_i)^2\sum_{k=1}^n(x_{kj}-\bar x_j)^2}} $$<br><strong>距离和相似系数选择的原则</strong><br>一般说来，同一批数据采用不同的亲疏测度指标，会得到不同的分类结果。产生不同结果的原因，主要是由于不同的亲疏测度指标所衡量的亲疏程度的实际意义不同，也就是说，不同的亲疏测度指标代表了不同意义上的亲疏程度。因此我们在进行聚类分析时，应注意亲疏测度指标的选择。通常，选择亲疏测度指标时，应注意遵循的基本原则主要有：所选择的亲疏测度指标在实际应用中应有明确的意义。如在经济变量分析中，常用相关系数表示经济变量之间的亲疏程度。适当地考虑计算工作量的大小。如对大样本的聚类问题，不适宜选择斜交空间距离，因采用该距离处理时，计算工作量太大。<br>亲疏测度指标的选择要综合考虑已对样本观测数据实施了的变换方法和将要采用的聚类分析方法。如在标准化变换之下，夹角余弦实际上就是相关系数；又如若在进行聚类分析之前已经对变量的相关性作了处理，则通常就可采用欧氏距离，而不必选用斜交空间距离。此外，所选择的亲疏测度指标，还须和所选用的聚类分析方法一致。如聚类方法若选用离差平方和法，则距离只能选用欧氏距离。<br>样品间或变量间亲疏测度指标的选择是一个比较复杂且带主观性的问题，我们应根据研究对象的特点作具体分析，以选择出合适的亲疏测度指标。实践中，在开始进行聚类分析时，不妨试探性地多选择几个亲疏测度指标，分别进行聚类，然后对聚类分析的结果进行对比分析，以确定出合适的亲疏测度指标。</li>
</ul>
</blockquote>
<h3 id="5-类与类之间的距离"><a href="#5-类与类之间的距离" class="headerlink" title="5 类与类之间的距离"></a>5 类与类之间的距离</h3><blockquote>
<ul>
<li>最短距离法(Nearest Neighbor)</li>
<li>最长距离法(Furthest Neighbor)</li>
<li>重心法(Centroid method)</li>
<li>类平均法(average linkage)——组间连接法(Between-groups Linkage)和组内连接法(Within-groups Linkage)</li>
<li>Ward离差平方和法(Ward’s minimumvariance method)</li>
</ul>
</blockquote>
<h3 id="6-系统聚类hierarchical-clustering-method"><a href="#6-系统聚类-hierarchical-clustering-method" class="headerlink" title="6 系统聚类(hierarchical clustering method)"></a>6 系统聚类(hierarchical clustering method)</h3><p><strong>系统聚类的步骤</strong></p>
<blockquote>
<p>（1） 开始将n个样品各作为一类。<br>（2） 根据样品的特征，选择合适的距离公式，计算n个样品两两之间的距离，构成距离矩阵。<br>（3） 选择距离矩阵中最小的非对角线元素$d_{pq}$，将相应的两类$G_p$和$G_q$合并为一新类$G_r$={$G_p, G_q$}。<br>（4） 利用递推公式计算新类与当前各类的距离。 分别删除原矩阵的第p，q行和第p，q列，并新增一行和一列添上的结果，产生新的距离矩阵。<br>（5） 再合并、计算，直至只有一类为止。<br>（6） 画聚类图，解释。</p>
<ul>
<li>最短距离法<br>定义距离：<br>$D_{pq}$=$Min${$d_{ij}：x_i\in G_p， x_j\in G_q$}<br>假设第p类和第q类合并成第r类，第r类与其它各旧类的距离按最短距离法为：<br>递推公式：$D_{rl}$=$Min${$D_{pl}，D_{ql}$} $l\neq p,q$ </li>
<li>最长距离法<br>定义距离：<br>$D_{pq}$=$Max${$d_{ij}：x_i\in G_p， x_j\in G_q$}<br>假设第p类和第q类合并成第r类，第r类与其它各旧类的距离按最长距离法为：<br>递推公式：$D_{rl}$=$Max${$D_{pl}，D_{ql}$} $l\neq p,q$ </li>
<li>中间距离法<br>递推公式：<br>$$ D_{lr}^2=\frac{1}{2}D_{lp}^2+\frac{1}{2}D_{lq}^2-\frac{1}{4}D_{pq}^2 $$<br>$$ D_{kr}^2=\frac{1}{2}D_{kp}^2+\frac{1}{2}D_{kq}^2+\beta D_{pq}^2，-\frac{1}{4}\lt \beta \lt 0 $$</li>
<li>可变方法<br>如果让中间距离法的递推公式前两项的系数也依赖于β，则递推公式为：<br>$$  D_{kr}^2=\frac{1-\beta}{2}(D_{kp}^2+D_{kq}^2)+\beta D_{pq}^2，\beta \lt 1  $$<br>用上式作为递推公式的系统聚类法称为可变法。</li>
<li>重心法<br>假设第p类和第q类合并成第r类，第r类与其它各旧类的距离按重心法为：<br>$$ D_{rl}^2=\frac{n_p}{n_r}D_{pl}^2+\frac{n_q}{n_r}D_{ql}^2-\frac{n_pn_q}{n_r^2}D_{pq}^2 $$</li>
<li>类平均方法<br>类平均法定义类间的距离是两类间样品的距离的平均数，递推公式：<br>$$ D_{rk}^2=\frac{n_pD_{kp}^2+n_qD_{kq}^2}{n_p+n_q} $$</li>
<li>可变类平均法<br>类平均法的递推公式中，没有反映$G_p$类和$G_q$类的距离有多大，进一步将其改进，加入$D_{pq}^2$，并给定系数β&lt;1， 则类平均法的递推公式改为：<br>$$ D_{rl}^2=(1-\beta)\frac{n_pD_{pl}^2+n_qD_{ql}^2}{n_p+n_q}+\beta D_{pq}^2 $$<br>用此递推公式进行聚类就是可变类平均法。递推公式由p类和q类与l类的距离的加权平均数、p类和q类的距离两项的加权和构成，β的大小根据哪项更重要而定。</li>
<li>离差平方和法<br>类似于方差分析的想法，如果类分得恰当，同类内的样品之间的离差平方和应较小，而类间的离差平方和应当较大。当k固定时，选择使SST达到最小的分类。分类可能指数级增长，寻找最优难以完成。离差平方和法的思路：先让n个样品各自成一类，然后缩小一类，每缩小一类离差平方和就要增大，选择使SST增加最小的两类合并，直到所有的样品归为一类为止（局部最优）。<br>定义距离为离差平方和的增量：<br>$$ D_{pq}=S_r^2-S_p^2-S_q^2 $$<br>其中 是由$G_p$和$G_q$合并成的$G_r$类的类内离差平方和。可以证明离差平方和的聚类公式为。<br>递推公式：<br>$$ D_{rk}^2=\frac{n_k+n_p}{n_r+n_k}D_{pk}^2+\frac{n_k+n_q}{n_r+n_k}D_{qk}^2-\frac{n_k}{n_k+n_r}D_{pq}^2 $$<br>以上聚类方法的计算步骤完全相同，仅类与类之间距离的定义不同。 Lance和Williams于1967年将其统一为：<br>$$ D_{MJ}^2=\alpha_KD_{KJ}^2+\alpha_LD_{KJ}^2+\beta D_{KL}^2+\gamma|D_{KJ}^2-D_{KJ}^2| $$</li>
</ul>
</blockquote>
<p><strong>确定类的个数</strong><br>从系统聚类的计算机结果可以得到任何可能数量的类。但是，聚类的目的是要使各类之间的距离尽可能地远，而类中点的距离尽可能的近， 并且分类结果还要有令人信服的解释。往往做系统聚类的时候，大部分情况下我们都是依靠人的主观判断确定最后分类的个数。这里给出了一些统计方法来确定类的个数。</p>
<blockquote>
<ul>
<li>给定阈值<br>通过观测聚类图， 给出一个合适的阈值T。要求类与类之间的距离要超过T值。 例如我们给定T=0.35， 当聚类时， 类间的距离已经超过了0.35， 则聚类结束。</li>
<li>统计量R²<br>总离差平方和的分解<br>$$ \begin{bmatrix} x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1p} \ x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2p} \ \vdots &amp; \vdots &amp;  &amp; \vdots \ x_{n1} &amp; x_{n2} &amp; \cdots &amp; x_{np} \end{bmatrix} $$<br>$$ 总离差平方和=(x_{11}-\bar x_1)^2+\cdots+(x_{n1}-\bar x_1)^2+\cdots+(x_{1p}-\bar x_p)^2+\cdots+(x_{np}-\bar x_p)^2 $$<br>如果这些样本被分为两类<br>$$ \begin{bmatrix} x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1p} \ x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2p} \ \vdots &amp; \vdots &amp;  &amp; \vdots \ x_{n_11} &amp; x_{n_12} &amp; \cdots &amp; x_{n_1q} \end{bmatrix} \begin{bmatrix} x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1p} \ x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2p} \ \vdots &amp; \vdots &amp;  &amp; \vdots \ x_{n_21} &amp; x_{n_22} &amp; \cdots &amp; x_{n_2p} \end{bmatrix} $$<br>$$ 一组离差平方和=(x_{11}-\bar x_1^{(1)})^2+\cdots+(x_{n_11}-\bar x_1^{(1)})^2+\cdots+(x_{1p}-\bar x_p^{(1)})^2+\cdots+(x_{n_1p}-\bar x_p^{(1)})^2 $$<br>$$ 二组离差平方和=(x_{11}-\bar x_1^{(2)})^2+\cdots+(x_{n_11}-\bar x_1^{(2)})^2+\cdots+(x_{1p}-\bar x_p^{(2)})^2+\cdots+(x_{n_1p}-\bar x_p^{(2)})^2 $$<br>可以证明：总离差平方和＝组内离差平方和＋组间离差平方和。令T为总离差平方和，令$P_G$为分为G类的组内离差平方和。<br>统计量<br>$$ R^2=1-\frac{P_G}{T} $$<br>其中T是数据的总离差平方和， 是组内离差平方和。R²比较大，说明分G个类时组内离差平方和比较小，也就是说分G类是合适的。但是，分类越多，每个类的组内离差平方和就越小，R²也就越大；所以我们只能取合适的G，使得R²足够大，而G本身很小，随着G的增加，R²的增幅不大。比如，假定分4类时，R²=0.8；下一次合并分三类时，下降了许多，R²=0.32，则分4类是合适的。</li>
<li>伪F统计量<br>伪F统计量的定义为<br>$$ F=\frac{(T-P_G)/(G-1)}{P_G/(n-G)} $$<br>伪F统计量用于评价聚为G类的效果。如果聚类的效果好，类间的离差平方和相对于类内的离差平方和大，所以应该取伪F统计量较大而类数较小的聚类水平。</li>
<li>伪t²统计量<br>伪t²统计量的定义为<br>$$ t^2=\frac{B_{KL}}{(W_K+W_L)/(N_K+N_L-2)} $$<br>其中$W_L$和$W_K$分别是类内离差平方和， $W_M$是将K和L合并为第M类的离差平方和，$B_{KL}=W_M-W_K-W_L$为合并导致的类内离差平方和的增量。用它评价合并第K和L类的效果，伪t²统计量大说明不应该合并这两类，应该取合并前的水平。</li>
</ul>
</blockquote>
<h3 id="7-快速聚类k-means-clustering-method"><a href="#7-快速聚类-k-means-clustering-method" class="headerlink" title="7 快速聚类(k-means clustering method)"></a>7 快速聚类(k-means clustering method)</h3><p><strong>系统聚类法的缺陷</strong>——系统聚类法是一种比较常用的聚类方法。然而当样本点数量十分庞大时，则是一件非常繁重的工作，聚类的计算速度也比较慢。比如在市场抽样调查中，有4万人就其对衣着的偏好作了回答，希望能迅速将他们分为几类。这时， 用系统聚类法计算的工作量极大，作出的树状图也十分复杂，不便于分析。<br><strong>quick cluster method， k-means method</strong>也叫动态聚类、逐步聚类、迭代聚类、k-均值聚类，快速聚类适用于大型数据。<br>快速聚类（K-means）流程图</p>
<p><div id="flowchart-0" class="flow-chart"></div><br>用一个简单的例子来说明快速聚类法的工作过程。<br>例如我们要把图中的点分成两类。 快速聚类的步骤：<br>1、随机选取两个点$x_1^{(1)}$和$x_2^{(1)}$作为聚核。<br>2、对于任何点$x_k$，分别计算$d(x_k,x_1^{(1)})$和$d(x_k,x_2^{(1)})$<br>3、若$d(x_k,x_1^{(1)})\lt d(x_k,x_2^{(1)})$，则将$x_k$划为第一类，否则划给第二类。于是得图（b）的两个类。<br>4、分别计算两个类的重心，则得$x_1^{(2)}$和$x_2^{(2)}$，以其为新的聚核，对空间中的点进行重新分类，得到新分类。</p>
<p><img src="http://img.blog.csdn.net/20170617221339152?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvRVNBX0RTUQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt=""></p>
<p><img src="http://img.blog.csdn.net/20170617221358031?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvRVNBX0RTUQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt=""></p>
<blockquote>
<ul>
<li>选择凝聚点<br>初始凝聚点（聚类种子、initial cluster seeds/clustercenters）就是一批有代表性的点，是欲形成类的中心。初始凝聚点的选择直接决定初始分类，对分类结果也有很大的影响，由于凝聚点的不同选择，其最终分类结果也将出现不同，故选择时要慎重。通常选择初始凝聚点的方法有：<br>人为选择，当人们对所欲分类的问题有一定了解时，根据经验，预先确定分类个数和初始分类，并从每一类中选择一个有代表性的样品作为凝聚点。<br>将数据人为地分为A类，计算每一类的重心，就将这些重心作为凝聚点。<br>用密度法选择凝聚点。以某个正数d为半径，以每个样品为球心，落在这个球内的样品数（不包括作为球心的样品）就叫做这个样品的密度。计算所有样品点的密度后，首先选择密度最大的样品作为第一凝聚点，并且人为地确定一个正数D（一般D＞d，常取D＝2d）。然后选出次大密度的样品点，若它与第一个凝聚点的距离大于D，则将其作为第二个凝聚点；否则舍去这点，再选密度次于它的样品。这样，按密度大小依次考查，直至全部样品考查完毕为止．此方法中，d要给的合适，太大了使凝聚点个数太少，太小了使凝聚点个数太多。<br>人为地选择一正数d，首先以所有样品的均值作为第一凝聚点。然后依次考察每个样品，若某样品与已选定的凝聚点的距离均大于d，该样品作为新的凝聚点，否则考察下一个样品。<br>随机地选择，如果对样品的性质毫无所知，可采用随机数表来选择，打算分几类就选几个凝聚点。或者就用前A个样品作为凝聚点（假设分A类）。这方法一般不提倡使用。</li>
<li>衡量聚类结果的合理性指标<br>设$P_i^n$表示在第n次聚类后得到的第i类集合，$i=1,2,3,\cdots,k,A_i^{(n)}$为第n次聚类所得到的聚核。定义：<br>$$ u_n\triangleq \sum_{i=1}^k\sum_{x\in P_i^n}d^2(x,A_i^{(n)}) $$<br>为所有K个类中所有元素与其重心的距离的平方和。若分类不合理时，$u_n$会很大，随着分类的过程，逐渐下降并趋于稳定。<br><strong>算法终止的标准</strong><br>定义算法终止的标准是：<br>$$ \frac{|u_{n+1}-u_n|}{u_{n+1}}\le \varepsilon $$<br>ε是事前给定的一个充分小量。<br><strong>快速聚类步骤</strong><br>第一，选择若干个观测值点为“凝聚点”；<br>第二，通过分配每个“凝聚点”最近的类来形成临时分类。每一次对一个观测值点进行归类，“凝聚点”更新<br>为这一类目前的均值；所有的观测值点分配完后，这些类的“凝聚点”用临时类的均值代替；该步骤可以一直进行直到“凝聚点”的改变很小或为零时止；<br>第三，最终的分类由分配每一个观测到最近的“凝聚点”而形成。</li>
</ul>
</blockquote>
<h3 id="8-有序聚类"><a href="#8-有序聚类" class="headerlink" title="8 有序聚类"></a>8 有序聚类</h3><p><strong>有序样本聚类法</strong></p>
<blockquote>
<p>有序样本聚类法又称为最优分段法。该方法是由费歇在1958年提出的。它主要适用于样本由一个变量描述，或者将多变量综合成为一个变量来分析的情况。对于有序样本聚类，实际上是需要找出一些分点，将它们划分为几个分段，每个分段看作一类，这样的分类又称分割。分点位置不同得到的分割不同，有序样本聚类是要找到一个分割使得各段内部样本差异很小，而各段之间样本的差异很大。有序样本聚类法常常被用于系统的评估问题，被用来对样本点进行分类划级。这种行政上的规定往往是不客观、不合理的。合理的分类应该把发展情况最近似的地区划入同一类。这就是有序样本聚类的工作思路。系统聚类开始n个样品各自自成一类，然后逐步并类，直至所有的样品被聚为一类为止。而有序聚类则相反，开始所有的样品为一类，然后分为二类、三类等，直到分成n类。每次分类都要求产生的离差平方和最小。</p>
</blockquote>
<p><strong>有序样本聚类算法步骤</strong><br>设有序样品$x_{(1)},x_{(2)},\cdots,x_{(n)}$。它们可以是从小到大排列，也可以是按时间的先后排列。</p>
<blockquote>
<ol>
<li>定义类的直径；<br>设某类G中包含的样品有<br>{$ x_{(i)},x_{(i+1)},\cdots,x_{(j)} $} $(j\gt i)$<br>该类的均值向量为<br>$$ \bar X_G=\frac{1}{j-i+1}\sum_{i=1}^jx_{(t)} $$<br>用D(i,j)表示这一类的直径，常用的直径有欧氏距离：<br>$$ D(i,j)=\sum_{t=i}^j(x_{(t)}-\bar X_G)’(x_{(t)}-\bar X_G) $$<br>当是单变量时，也可以定义直径为：<br>$$  D(i,j)=\sum_{t=i}^j|x_{(t)}-\tilde X_G|，其中\tilde X_G是中位数$$</li>
<li>定义分类的损失函数L[p(n,k)]；<br>用b(n,k)表示将n个有序的样品分为k类的某种分法($j_1$=1)：<br>$$ \begin{array}{lcl} G_1=\left{j_1,j_1+1,\cdots,j_2-1\right} \ G_2=\left{j_2,j_2+1,\cdots,j_3-1\right} \ \cdots\qquad \cdots \\G_k=\left{j_k,j_k+1,\cdots,n\right} \end{array}$$<br>定义这种分类法的损失函数为各类的直径之和。<br>$$ L[b(n,k)]=\sum_{t=1}^kD(j_t,j_{t+1}-1) $$<br>由损失函数的构造可以看出，损失函数是各类的直径之和。如果分类不好，则各类的直径之和大，否则比较小。当n和k固定时， L[b(n,k)]越小表示各类的离差平方和越小，分类是合理的。因此要寻找一种分法b(n,k)，使分类损失函数L[b(n,k)]达到最小。记该分法为p[n,k]。</li>
<li>L[p(n,k)]的递推公式；<br>$$ \begin{cases}L[p(n,2)]=\min_{2\le j\le n}\left{D(1,j-1)+D(j,n)\right} \ L[p(n,k)]=\min_{k\le j\le n}\left{L[p(j-1,k-1)]+D(j,n)\right} \end{cases} $$<br>以上的两个公式的含义是，如果要找到n个样品分为k个类的最优分割，应建立在将j-1（j＝2,3,…,n)个样品分为k-1类的最优分割的基础上。</li>
<li>寻找最优解。</li>
</ol>
</blockquote>
<h3 id="9-聚类分析的主要步骤"><a href="#9-聚类分析的主要步骤" class="headerlink" title="9 聚类分析的主要步骤"></a>9 聚类分析的主要步骤</h3><blockquote>
<p>（1）选择变量<br>和聚类分析的目的密切相关；在不同研究对象上的值有明显的差异；变量之间不能高度相关。<br>（2）计算相似性<br>相似性是聚类分析中的基本概念，它反映了研究对象之间的亲疏程度，聚类分析就是根据对象之间的相似性来分类的。<br>（3）聚类<br>选定了聚类的变量，计算出样品或指标之间的相似程度后，构成了一个相似程度的矩阵。这时主要涉及两个问题：选择聚类的方法和确定形成的类数。<br>（4）聚类结果的解释和证实<br>对聚类结果进行解释是希望对各个类的特征进行准确的描述，给每类起一个合适的名称。这一步可以借助各种描述性统计量进行分析，通常的做法是计算各类在各聚类变量上的均值，对均值进行比较，还可以解释各类差别的原因。<br>（5）有关问题<br>几种聚类方法获得的结果不一定相同，指标聚类采用相似系数，相似系数大或距离小则表示类间关系密切。为了统一，可采用以下公式变换：<br>$$ d_{ij}^2=1-r_{ij}^2 $$<br>（6）变量聚类分析<br>对于变量聚类分析，聚类分析做完之后，各类中有较多的指标。 为了达到降维的目的， 需要在每类中选出一个代表指标。 具体做法是：假设某类中有k个指标， 首先分别计算类内指标之间的相关指数， 然后计算某个指标与类内其它指标之间相关指数的平均数， 即<br>$$ \bar R_i^2=\frac{\sum_{i\neq j}r_{ij}}{k-1} $$<br>取$\bar R_i^2$最大的$x_i$，作为该类的代表。</p>
<h3 id="10-r语言中聚类分析实现"><a href="#10-R语言中聚类分析实现" class="headerlink" title="10 R语言中聚类分析实现"></a>10 R语言中聚类分析实现</h3><p>R语言自带的聚类分析函数包括了hclust和k-means。所以本篇主要介绍这两个函数的使用。<br>而首先hclust是基于距离进行的聚类分析，所以事实上在做层次聚类的时候，第一步是先计算距离。<br>当然前期说明下，这里的样例数据是北京市12个大气污染监测站点在2017年6月7日和6月8日全天的PM2.5数据（数据来自笔者自己写的代码获取而得，调用了环境云的API），样例数据连同完整的代码会在笔记写完后统一给出。<br>环境云官网：<a href="http://www.envicloud.cn/" target="_blank" rel="external">http://www.envicloud.cn/</a></p>
</blockquote>
<p>数据：<br><img src="http://img.blog.csdn.net/20170621000012294?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvRVNBX0RTUQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt=""></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">dist.pm25&lt;-dist(airnew[,-1],method=&apos;euclidean&apos;)</div><div class="line">heatmap(as.matrix(dist.pm25),labRow=stationname,labcol=F)</div></pre></td></tr></table></figure>
<p>我们做的分析是对一天内24小时下12个站点的PM2.5聚类分析。所以事实上，这类的多元变量，是不同时间段的PM2.5值，数据结构也已经成功做成矩阵形式，接下来就需要计算距离了。<br>距离矩阵在R里面是比较好求取的。dist函数。<br>dist函数的参数事实上有不少，但是其实一般重点用的就是输入矩阵的参数（代码中的airnew[,-1]，-1代表去掉第一列数据（站点名称）），还有计算距离的方式——method。这里选的是欧氏距离。这个参数的可选取值还包括maximum（最大距离）、manhattan（曼哈顿距离）、canberra（兰氏威廉姆斯距离）、binary（定性距离，其实就是配合距离）、minkowski（闵可夫斯基距离——明氏距离）。还有用得多些的参数——diag和upper。diag为TRUE的时候给出对角线上的距离。upper为TURE的时候给出上三角矩阵上的值。默认都是TRUE。<br>函数计算完之后得到的是一个距离矩阵。我们用热力图的方式进行可视化，这就是上面的第二句代码。<br>heatmap函数是个热图可视化函数，要求输入一个矩阵。labRow其实是输入列名，labcol是与labRow相关，用来映射输入的值的。结果如下图。</p>
<p><img src="http://img.blog.csdn.net/20170621005643871?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvRVNBX0RTUQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt=""></p>
<p>计算完矩阵，即可进行聚类分析了。hclust函数的必要参数与前面距离的参数类似——输入矩阵参数，方法参数（这里聚类的方法前面也有提到，这里就不赘述了，有兴趣的可以自己看官方帮助文档）。而聚类完的结果存储在model1里面，用plot即可画出聚类谱系图。事实上，plclust也是相同的作用，参数基本是统一的，labels填写我们聚类的变量。而聚类完的结果则可以用cutree来获得，输入的model1——聚类结果，k是要求的类数。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">model1=hclust(dist.pm25,method=&quot;ward&quot;)</div><div class="line">plot(model1,labels=stationname,hang=-1,las=1)</div><div class="line">plclust(model1,labels=stationname,hang=-1)</div></pre></td></tr></table></figure>
<p><img src="http://img.blog.csdn.net/20170621005711631?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvRVNBX0RTUQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt=""></p>
<p>对聚类结果做个简单可视化。以0点和1点的PM2.5值分别为x和y轴，以聚类结果做划分。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">result=cutree(model1,k=3)</div><div class="line">plot(airnew[,2],airnew[,3],col=result,pch=as.integer(result))</div></pre></td></tr></table></figure>
<p><img src="http://img.blog.csdn.net/20170621005728521?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvRVNBX0RTUQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt=""></p>
<p>接下来是K-means的方法。函数并不复杂，输入数据框或者矩阵（做聚类的数据），center就是聚类数，nstart是迭代次数。迭代次数高，聚类可信度高些。后面的这个函数是聚类可视化的函数，是fpc包下面的，使用前请先确认是否安装。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">kres&lt;-kmeans(airnew[,-1],centers=3,nstart=10)</div><div class="line">plotcluster(airnew[,-1],kres$cluster)</div></pre></td></tr></table></figure></p>
<p><img src="http://img.blog.csdn.net/20170621005751271?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvRVNBX0RTUQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt=""></p>
<p>对比了二者的分类结果，是一致的。</p>
<p><img src="http://img.blog.csdn.net/20170621005808492?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvRVNBX0RTUQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt=""></p>
<p>聚类结束后，我们就这个数据和结果做些简单的分析。事实上作为地学人员，我们就简单地画个站点分布图来对应看看具体情况。从这张图来看，PM2.5的聚类结果显示了它具有很好的空间分异性。当然下面的图有点简陋，给出一个对比的，基于leaflet和R Notebook的交互式小地图（老规矩）。</p>
<p><img src="http://img.blog.csdn.net/20170621024446772?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvRVNBX0RTUQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt=""></p>
<p><img src="http://img.blog.csdn.net/20170621024710015?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvRVNBX0RTUQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt=""><script src="https://cdnjs.cloudflare.com/ajax/libs/raphael/2.2.7/raphael.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/flowchart/1.6.5/flowchart.min.js"></script><textarea id="flowchart-0-code" style="display: none">st=>start: 选择凝聚点（聚类中心）
e=>end: 分类结果
sub=>subroutine: 分类
cond=>condition: 分类结果是否合理？
op=>operation: 调整分类
st->sub->cond(yes)->e
cond(no)->op(right)->sub</textarea><textarea id="flowchart-0-options" style="display: none">{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12}</textarea><script>  var code = document.getElementById("flowchart-0-code").value;  var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-0-options").value));  var diagram = flowchart.parse(code);  diagram.drawSVG("flowchart-0", options);</script></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/06/13/应用统计学与R语言实现学习笔记（九）——线性回归/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Dai Shaoqing">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GISerDaiShaoqing's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/06/13/应用统计学与R语言实现学习笔记（九）——线性回归/" itemprop="url">
                  应用统计学与R语言实现学习笔记（九）——线性回归
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-06-13T00:00:00+08:00">
                2017-06-13
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/统计与模型/" itemprop="url" rel="index">
                    <span itemprop="name">统计与模型</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/2017/06/13/应用统计学与R语言实现学习笔记（九）——线性回归/" class="leancloud_visitors" data-flag-title="应用统计学与R语言实现学习笔记（九）——线性回归">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">Visitors </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="chapter-9-linear-regression"><a href="#Chapter-9-Linear-Regression" class="headerlink" title="Chapter 9 Linear Regression"></a>Chapter 9 Linear Regression</h1><p>本篇是第九章，内容是回归分析（主要以线性回归为主）。回归分析是数理统计、数理分析中最基础（也可以说是最重要）的一个分析，所以这一章内容相对来说也较多。</p>
<h3 id="1-变量间的关系"><a href="#1-变量间的关系" class="headerlink" title="1 变量间的关系"></a>1 变量间的关系</h3><blockquote>
<ul>
<li>确定型关系vs不确定型关系<br>函数关系——一一对应的确定型关系设有两个变量x和y，变量y随变量x一起变化， 并完全依赖于x，当变量x取某个数值时，y依确定的关系取相应的值，则称y是x的函数，记为y=f(x)，其中x称为自变量，y称为因变量各观测点落在一条线上。<br>相关关系(correlation)——变量间关系不能用函数关系精确表达。一个变量的取值不能由另一个变量唯一确定。当变量x取某个值时， 变量y的取值可能有几个。各观测点分布在直线周围。</li>
</ul>
</blockquote>
<p>相关关系包括了线性相关（正相关、负相关）、非线性相关、完全相关（正相关、负相关）、不相关。</p>
<p><img src="http://e.hiphotos.baidu.com/image/pic/item/6159252dd42a28344880ce5551b5c9ea15cebf4e.jpg" alt=""></p>
<p>除了如上的图，可以看下面的链接——关于相同统计量不同数据的一篇外文。</p>
<blockquote>
<p><a href="https://www.autodeskresearch.com/publications/samestats" target="_blank" rel="external">https://www.autodeskresearch.com/publications/samestats</a></p>
</blockquote>
<p><strong>相关系数(correlation coefficient)</strong></p>
<blockquote>
<ul>
<li>对变量之间关系密切程度的度量（只关心密切程度，无关因果关系）；</li>
<li>对两个变量之间线性相关程度的度量称为简单相关系数；</li>
<li>若相关系数是根据总体全部数据计算的，称为总体相关系数，记为ρ；</li>
<li>若是根据样本数据计算的，则称为样本相关系数，记为 r。</li>
</ul>
</blockquote>
<p><strong>总体相关系数的计算公式</strong>：<br>$$ \rho=\frac{\sigma_{xy}}{\sigma_x\sigma_y}=\frac{E[(X-E(X))(Y-E(Y))]}{\sqrt{E(X-E(X))^2}\sqrt{E(Y-E(Y))^2}} $$<br><strong>相关系数特点</strong></p>
<blockquote>
<ul>
<li>无量纲(Unitfree)；</li>
<li>ρ的取值范围是 [-1,1]；</li>
<li>|ρ|=1，为完全相关（ρ=1为完全正相关；ρ=-1为完全负相关）；</li>
<li>ρ=0，不存在线性相关关系；</li>
<li>-1≤ρ&lt;0，为负相关，0&lt;ρ≤1，为正相关；</li>
<li>|ρ|越趋于1表示线性关系越密切；|ρ|越趋于0表示线性关系越不密切；</li>
<li>若X与Y相互独立，则ρ=0，但ρ=0，X与Y不一定相互独立；</li>
<li>若ρ= 0，且X与Y服从正态分布，则X与Y相互独立。</li>
</ul>
</blockquote>
<p><strong>样本相关系数计算公式</strong>：<br>$$ r=\frac{\sum(x_i-\bar x)(y_i-\bar y)}{\sqrt{\sum(x_i-\bar x)^2\cdot\sum(y_i-\bar y)^2}}或r=\frac{n\sum x_iy_i-\sum x_i\sum y_i}{\sqrt{n\sum x_i^2-(\sum x_i)^2}\cdot\sqrt{n\sum x_i^2-(\sum x_i)^2}} $$<br><strong>样本相关系数特点</strong></p>
<blockquote>
<ul>
<li>无量纲(Unitfree)；</li>
<li>r的取值范围是 [-1,1]；</li>
<li>|r|=1，为完全相关（r=1为完全正相关；r=-1为完全负相关）；</li>
<li>r=0，不存在线性相关关系；</li>
<li>-1≤r&lt;0为负相关，0&lt;r≤1为正相关；</li>
<li>|r|越趋于1表示线性关系越密切；|r|越趋于0表示线性关系越不密切；</li>
</ul>
</blockquote>
<p>对变量之间关系密切程度的度量，只关心密切程度，无关因果关系。<br>比如撑伞的人数和降雨量的相关系数非常高。但是我们不能说因为撑伞的人多了，所以降雨量大。</p>
<p><strong>r的抽样分布</strong><br>r的抽样分布随总体相关系数和样本容量的大小而变化。当样本数据来自服从正态分布的总体时，随着n的增大，r的抽样分布趋于正态分布，尤其是在总体相关系数ρ很小或接近0时，趋于正态分布的趋势非常明显。而当ρ远离0时，除非n非常大，否则r的抽样分布呈现一定的偏态。当ρ为较大的正值时， r呈现左偏分布；当ρ为较小的负值时， r 呈现右偏分布。只有当ρ接近于0，而样本容量n很大时，才能认为r是接近于正态分布的随机变量。<br><strong>相关系数的显著性检验步骤</strong><br>检验两个变量之间是否存在线性相关关系，等价于对回归系数$β_1$的检验。采用R. A. Fisher提出的t检验。<br>检验的步骤为：</p>
<blockquote>
<p>（1） 提出假设：$H_0：\rho=0；H_1：\rho \neq0$<br>（2） 计算检验的统计量： $t=r\sqrt{\frac{n-2}{1-r^2}}\sim t(n-2)$<br>（3） 确定显著性水平α，并作出决策。</p>
<ul>
<li>若$|t|&gt;t_{α/2}$，拒绝$H_0$。</li>
<li>若$|t|&lt;t_{α/2}$，不能拒绝$H_0$。</li>
</ul>
</blockquote>
<h3 id="2-回归分析和简单线性回归分析"><a href="#2-回归分析和简单线性回归分析" class="headerlink" title="2 回归分析和简单线性回归分析"></a>2 回归分析和简单线性回归分析</h3><h4 id="21-回归分析"><a href="#2-1-回归分析" class="headerlink" title="2.1 回归分析"></a>2.1 回归分析</h4><p><strong>什么是回归分析(Regression)?</strong></p>
<blockquote>
<p>从一组样本数据出发，确定变量之间的数学关系式。对这些关系式的可信程度进行各种统计检验，并从影响某一特定变量的诸多变量中找出哪些变量的影响显著， 哪些不显著。利用所求的关系式，根据一个或几个变量的取值来预测或控制另一个特定变量的取值， 并给出这种预测或控制的精确程度。</p>
</blockquote>
<p><strong>回归分析与相关分析的区别</strong></p>
<blockquote>
<p>相关分析中，变量x变量y处于平等的地位；回归分析中，变量y称为因变量，处在被解释的地位，x称为自变量，用于预测因变量的变化；<br>相关分析中所涉及的变量x和y都是随机变量；回归分析中，因变量y是随机变量，自变量x可以是随机变量，也可以是非随机的确定变量；<br>相关分析主要是描述两个变量之间线性关系的密切程度；回归分析不仅可以揭示变量x对变量y的影响大小，还可以由回归方程进行预测和控制。</p>
</blockquote>
<p><strong>回归模型(regression model)</strong>——回答“变量之间是什么样的关系？”方程中运用1个数值型因变量(响应变量)作为被预测的变量；1个或多个数值型或分类型自变量 (解释变量)作为用于预测的变量。主要用于预测和估计。回归模型的类型包括一元回归模型（线性和非线性）和多元回归模型（线性和非线性）。<br>接下来先从简单线性回归分析讲起。</p>
<h4 id="22-简单线性回归分析"><a href="#2-2-简单线性回归分析" class="headerlink" title="2.2 简单线性回归分析"></a>2.2 简单线性回归分析</h4><p><strong>简单线性回归(Simple Linear Regression)</strong>——涉及一个自变量的回归，因变量y与自变量x之间为线性关系。被预测或被解释的变量称为因变量(dependent variable)，用y表示；用来预测或用来解释因变量的一个或多个变量称为自变量(independent variable)，用x表示。因变量与自变量之间的关系用一个线性方程来表示。<br>描述因变量y如何依赖于自变量x和误差项ε的方程称为回归模型(Regression Model，定义如前)。<br><strong>（1）简单线性回归模型的表示形式</strong><br>$$ y=\beta_0+\beta_1 x+\varepsilon $$<br>y是x的线性函数(部分)加上误差项(residual/random error term)。线性部分反映了由于x的变化而引起的y的变化。误差项ε是随机变量。反映了除x和y之间的线性关系之外的随机因素对y的影响，是不能由x和y之间的线性关系所解释的变异性。$β_0$和$β_1$称为模型的参数(interception, slope)。<br><strong>（2）简单线性回归模型的基本假定</strong><br>误差项ε是一个期望值为0的随机变量，即E(ε)=0。对于一个给定的x值，y的期望值为<br>$$ E(y)=\beta_0+\beta_1x $$<br>对于所有的x值，ε的方差$σ^2$都相同；误差项ε是一个服从正态分布的随机变量，且相互独立。即ε~N(0,$σ^2$);独立性意味着对于一个特定的x值，它所对应的ε与其他x值所对应的ε不相关；对于一个特定的x值， 它所对应的y值与其他x所对应的y值也不相关。<br><strong>（3）简单线性回归方程(regression equation)</strong><br>描述y的平均值或期望值如何依赖于x的方程称为回归方程；简单线性回归方程的形式如下<br>$$ E(y)=\beta_0+\beta_1x $$<br>方程的图示是一条直线，也称为直线回归方程。$β_0$是回归直线在y轴上的截距(interception)，是当x=0时y的期望值。$β_1$是直线的斜率(slope)，称为回归系数，表示当x每变动一个单位时，y的平均变动值。<br><strong>（4）估计的回归方程(estimated regression equation)</strong><br>总体回归参数$β_0$和$β_1$是未知的，必须利用样本数据去估计。用样本统计量$b_0$和$b_1$代替回归方程中的未知参数$β_0$和$β_1$，就得到了估计的回归方程。<br>简单线性回归中估计的回归方程为<br>$$ \hat y=b_0+b_1x $$<br>其中：$b_0$是估计的回归直线在y轴上的截距，$b_1$是直线的斜率，也表示x每变动一个单位时，y的平均变动值，$\hat y$表示一个给定的x的值对应的y的估计值。<br><strong>（5）最小二乘估计</strong><br>使因变量的观察值与估计值之间的离差平方和达到最小来求得$b_0$和$b_1$的方法。即<br>$$ argmin \sum_{i=1}^n(y_i-\hat y_i)^2=\sum_{i=1}^n(y_i-b_0-b_ix_i)^2 $$<br>用最小二乘法拟合的直线来代表x与y之间的关系与实际数据的误差平方和比其他任何直线都小。<br>根据最小二乘法的要求，可得到如下的公式：<br>$$ \begin{cases}b_1=\frac{n\sum_{i=1}^nx_iy_i-(\sum_{i=1}^nx_i)(\sum_{i=1}^ny_i)}{n\sum_{i=1}^nx_i^2-(\sum_{i=1}^nx_i)^2}\\b_0=\bar y-b_1\bar x\end{cases} $$<br><strong>最小二乘估计的性质</strong></p>
<blockquote>
<ul>
<li>所有残差的和为0。所有残差的平方和最小；</li>
<li>回归直线经过变量X与Y的均值；</li>
<li>是$β_0和β_1$的无偏估计。</li>
</ul>
</blockquote>
<p>在r语言中，简单线性回归的代码如下：<br><figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">modele&lt;-lm(e~a)</div></pre></td></tr></table></figure></p>
<p><strong>（7）回归直线的拟合优度</strong><br><strong>变差</strong><br>因变量 y 的取值是不同的， y 取值的这种波动称为变差。 变差来源于两个方面：</p>
<blockquote>
<ul>
<li>由于自变量 x 的取值不同造成的。</li>
<li>除 x 以外的其他因素(如x对y的非线性影响、测量误差等)的影响。<br>对一个具体的观测值来说， 变差的大小可以通过该实际观测值与其均值之差$y-\bar y$来表示。</li>
</ul>
</blockquote>
<p><strong>离差平方和的分解(三个平方和的关系与意义)</strong><br>$$ \sum_{i=1}^n(y_i-\bar y)^2=\sum_{i=1}^n(\hat y_i-\bar y)^2+\sum_{i=1}^n(y_i-\hat y)^2 $$<br>从左至右分别为SST，SSR，SSE。<br>所以就有SST=SSR+SSE。<br><strong>总平方和(SST)</strong>——反映因变量的 n 个观察值与其均值的总离差；<br><strong>回归平方和(SSR)</strong>——反映自变量 x 的变化对因变量 y 取值变化的影响，或者说，是由于x与y之间的线性关系引起的y的取值变化，也称为可解释的平方和；<br><strong>残差平方和(SSE)</strong>——反映除x以外的其他因素对y取值的影响，也称为不可解释的平方和或剩余平方和。</p>
<p><strong>判定系数R²(coefficient of determination)</strong><br>回归平方和占总离差平方和的比例。<br>$$R^2=\frac{SSR}{SST}=\frac{\sum_{i=1}^n(\hat y_i-\bar y)^2}{\sum_{i=1}^n(y_i-\bar y)^2}=1-\frac{\sum_{i=1}^n(y_i-\hat y)^2}{\sum_{i=1}^n(\hat y_i-\bar y)^2}$$</p>
<blockquote>
<ul>
<li>反映回归直线的拟合程度；</li>
<li>取值范围在[0,1]之间；</li>
<li>$R^2\rightarrow1$，说明回归方程拟合的越好；$R^2\rightarrow0$，说明回归方程拟合的越差；</li>
<li>对简单线性回归，判定系数等于相关系数的平方，r=(b1的符号)sqrt(R²)。</li>
</ul>
</blockquote>
<p><strong>估计标准误差(standard error of estimate)</strong></p>
<blockquote>
<ul>
<li>实际观察值与回归估计值离差平方和的均方根；</li>
<li>反映实际观察值在回归直线周围的分散状况；</li>
<li>对误差项ε的标准差σ的估计， 是在排除了x对y的线性影响后，y随机波动大小的一个估计量；</li>
<li>反映用估计的回归方程预测y时预测误差的大小。<br>计算公式为<br>$$ s=\sqrt{\frac{\sum_{i=1}^n(y_i-\hat y_i)^2}{n-2}}=\sqrt{\frac{SSE}{n-2}}=\sqrt{MSE} $$</li>
</ul>
</blockquote>
<p><strong>显著性检验</strong></p>
<blockquote>
<ul>
<li>线性关系的显著性检验：检验自变量与因变量之间的线性关系是否显著，即检验x与y之间是否具有线性关系，或者说，检验自变量x对因变量y的影响是否显著；</li>
<li>回归系数的显著性检验：检验回归系数是否不等于0；</li>
<li>在简单线性回归中，线性关系的显著性检验等价于回归系数的显著性检验。<br><strong>线性关系的检验</strong><br>将回归均方(MSR)同残差均方(MSE)加以比较， 应用F检验来分析二者之间的差别是否显著。<br><strong>回归均方</strong>：回归平方和SSR除以相应的自由度(自变量的个数p)；<br><strong>残差均方</strong>：残差平方和SSE除以相应的自由度(n-p-1)。</li>
<li>提出假设：$H_0：\beta_1=0$ 线性关系不显著；</li>
<li>计算检验统计量F：<br>$$ F=\frac{SSR/1}{SSE/(n-2)}=\frac{MSR}{MSE}\sim F(1,n-2) $$</li>
<li>确定显著性水平α，并根据分子自由度1和分母自由度n-2找出临界值$F_\alpha$。</li>
<li>作出决策：$若F&gt;F_\alpha，拒绝H_0； 若F&lt;F_\alpha，不拒绝H_0$。<br><strong>回归系数的检验(检验步骤)</strong></li>
<li>提出假设<br>$$H_0:\beta_1=0(没有线性关系)$$<br>$$H_1:\beta_1\neq 0(有线性关系)$$</li>
<li>计算检验的统计量<br>$$ t=\frac{b_1}{s_{b_1}}\sim t(n-2) $$</li>
<li>确定显著性水平$\alpha$，并进行决策：<br>$$ \left|t\right|\gt t_{\alpha/2}，拒绝H_0；\left|t\right|\lt t_{\alpha/2}，不拒绝H_0 $$<br><strong>显著性检验的几点注意</strong><br>显著性关系的结论不意味着因果关系。显著性关系的结论也不能推出线性关系的结论，仅能说在x的样本观测之范围内，x和y是相关的，而且一个线性关系只揭示了y的变异的主要部分。当样本容量很大时，对于小的b1值也能得到统计上是显著的结果。</li>
</ul>
</blockquote>
<h3 id="3-利用回归方程进行估计和预测"><a href="#3-利用回归方程进行估计和预测" class="headerlink" title="3 利用回归方程进行估计和预测"></a>3 利用回归方程进行估计和预测</h3><p>根据自变量x的取值估计或预测因变量y的取值。<br><strong>估计或预测的类型</strong></p>
<blockquote>
<p>（1）点估计：y的平均值的点估计，y的个别值的点估计；<br>（2）区间估计：y的平均值的置信区间估计，y的个别值的预测区间估计。</p>
</blockquote>
<p><strong>（1）点估计</strong><br>对于自变量x的一个给定值$x_0$，根据回归方程得到因变量y的一个估计值$\hat y_0$。<br>点估计值有<strong>y的平均值的点估计</strong>和<strong>y的个别值的点估计</strong>。在点估计条件下，平均值的点估计和个别值的的点估计是一样的，但在区间估计中则不同。</p>
<blockquote>
<p><strong>y的平均值的点估计</strong><br>利用估计的回归方程， 对于自变量 x 的一个给定值$x_0$，求出因变量y的平均值的一个估计值$E(y_0)$，就是平均值的点估计。<br><strong>y的个别值的点估计</strong><br>利用估计的回归方程，对于自变量x的一个给定值$x_0$，求出因变量y的一个个别值的估计值$\hat y_0$，就是个别值的点估计。</p>
</blockquote>
<p><strong>（2）区间估计</strong><br>点估计不能给出估计的精度， 点估计值与实际值之间是有误差的， 因此需要进行区间估计。对于自变量x的一个给定值$x_0$，根据回归方程得到因变量y的一个估计区间。区间估计有两种类型：<strong>置信区间估计(confidence interval estimate)</strong>和<strong>预测区间估计(prediction interval estimate)</strong>。<br><strong>置信区间估计</strong><br>利用估计的回归方程，对于自变量x的一个给定值$x_0$，求出因变量y的平均值的估计区间，这一估计区间称为置信区间(confidence interval)。$E(y_0)$在$1-\alpha$置信水平下的置信区间为:<br>$$ \hat y_0\pm t_{\alpha/2}(n-2)s\sqrt{\frac{1}{n}+\frac{(x_0-\bar x)^2}{\sum_{i=1}^n(x_i-\bar x)^2}} $$<br>式中s为估计标准误差。<br>x=均值时能得到y的平均值的最精确估计。<br><strong>预测区间估计</strong><br>利用估计的回归方程,对于自变量x的一个给定值$x_0$,求出因变量y的一个个别值的估计区间，这一区间称为预测区间(prediction interval)。$E(y_0)$在$1-\alpha$置信水平下的预测区间为:<br>$$ \hat y_0\pm t_{\alpha/2}(n-2)s\sqrt{1+\frac{1}{n}+\frac{(x_0-\bar x)^2}{\sum_{i=1}^n(x_i-\bar x)^2}} $$<br><strong>影响区间宽度的因素</strong></p>
<blockquote>
<ul>
<li>置信水平(1-α)——区间宽度随置信水平的增大而增大；</li>
<li>数据的离散程度s——区间宽度随离散程度的增大而增大；</li>
<li>样本容量——区间宽度随样本容量的增大而减小；</li>
<li>用于预测的$x_p$与$\bar x$的差异程度，区间宽度随$x_p$与$\bar x$的差异程度的增大而增大。</li>
</ul>
</blockquote>
<p>其实在R语言里主要用predict.lm函数来进行区间估计。代码样例如下：<br><figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">con&lt;-predict.lm(modele,h,interval=<span class="string">"confidence"</span>,level=<span class="number">0.95</span>)</div></pre></td></tr></table></figure></p>
<p>其中interval控制是置信区间（参数填confidence）、预测区间（参数填prediction）或者是不做区间估计，level是置信水平，接着用R绘制一个简单的回归和置信区间的图，这里先给出如何绘制置信区间band的代码，完整代码还是老规矩，在这一部分笔记写完后给出。<br><figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">polygon(c(h[,<span class="number">1</span>], rev(h[,<span class="number">1</span>])), c(con[,<span class="number">3</span>], rev(con[,<span class="number">2</span>])),border=<span class="string">"red"</span>,lwd=<span class="number">1</span>,lty = c(<span class="string">"dashed"</span>, <span class="string">"solid"</span>))</div></pre></td></tr></table></figure></p>
<p><img src="http://e.hiphotos.baidu.com/image/pic/item/e1fe9925bc315c60f07e93b187b1cb1348547781.jpg" alt=""></p>
<h3 id="4-残差分析"><a href="#4-残差分析" class="headerlink" title="4 残差分析"></a>4 残差分析</h3><p><strong>残差(residual)</strong>——因变量的观测值与根据估计的回归方程求出的预测值之差，用e表示。<br>$$e_i=y_i-\hat y_i$$<br>反映了用估计的回归方程去预测而引起的误差。<br><strong>残差检验的目的</strong></p>
<blockquote>
<ul>
<li>检验线性的假设是否成立；</li>
<li>确定有关误差项ε的假定是否成立（正态分布；方差为常数；独立性）。</li>
<li>检测有影响的观测值。</li>
</ul>
</blockquote>
<p><strong>残差图(residual plot)</strong></p>
<blockquote>
<ul>
<li>表示残差的图形（关于x的残差图，关于y的残差图，标准化残差图）。</li>
<li>用直方图或正态概率图检验正态性。</li>
</ul>
</blockquote>
<p><strong>标准化残差(standardized residual)</strong></p>
<blockquote>
<ul>
<li>残差除以它的标准差后得到的数值。 计算公式为<br>$$ z_{e_i}=\frac{e_i}{s_{e_i}}=\frac{y_i-\hat y_i}{s_{e_i}} $$</li>
<li>$e_i$是第i个残差的标准差， 其计算公式为<br>$$ s_{e_i}=s_y\sqrt{1-h_i}=s_y\sqrt{1-(\frac{1}{n}+\frac{(x_i-\bar x)^2}{\sum(x_i-\bar x)^2})} $$</li>
</ul>
</blockquote>
<p><strong>标准化残差图</strong><br>用以直观地判断误差项服从正态分布这一假定是否成立。</p>
<blockquote>
<ul>
<li>若假定成立， 标准化残差的分布也应服从正态分布。</li>
<li>在标准化残差图中， 大约有95%的标准化残差在-2到+2之间。</li>
</ul>
</blockquote>
<p><strong>变换</strong><br>数据变换的问题在前面第七章拟合优度检验提过，那么什么时候做变换?<br>如果从散点图观察发现残差是自变量的函数，通过变换可能可以解决问题。<br>做什么变换？观察残差与因变量观测值的均值的关系：</p>
<blockquote>
<ul>
<li>如果残差的标准差与因变量观测值的均值有线性关系，用log变换；</li>
<li>如果残差的方差与因变量观测值的均值有线性关系，用square root变换；</li>
<li>如果残差的标准差与因变量观测值的均值的平方有线性关系，用inverse变换；</li>
<li>如果残差的标准差与因变量观测值的均值的幂有线性关系，用power变换。</li>
</ul>
</blockquote>
<p><strong>序列相关（自相关）</strong><br>当数据是按时间顺序采集的，有可能引起误差项之间的相关(Serial correlation,autocorrelation)。<br>这里介绍一个相关的杜宾-瓦特森(Durbin-Watson)检验统计量：<br>$$ d=\frac{\sum_{t=2}^n(e_t-e_{t-1})^2}{\sum_{t=1}^ne_t^2} $$<br>是否遗漏了重要的对因变量有时序影响的自变量，有时可通过引入度量观测次数的自变量解决该问题。这部分属于时间序列分析的范畴，这里就不进一步阐述了。</p>
<p>在R语言中，线性回归方程残差图绘制非常简单。模型拟合过程会自动给出四个残差可视化相关的图。绘制方法如下：<br><figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">layout(matrix(c(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>),nrow=<span class="number">2</span>,byrow=<span class="literal">T</span>))</div><div class="line">plot(modele)</div></pre></td></tr></table></figure></p>
<p>结果如图</p>
<p><img src="http://f.hiphotos.baidu.com/image/pic/item/7acb0a46f21fbe0906ef384a61600c338744ad3f.jpg" alt=""></p>
<p><strong>异常值(outlier)与识别</strong><br>如果某一个点与其他点所呈现的趋势不相吻合，这个点就有可能是异常点。</p>
<blockquote>
<ul>
<li>如果异常值是一个错误的数据， 比如记录错误造成的， 应该修正该数据， 以便改善回归的效果；</li>
<li>如果是由于模型的假定不合理， 使得标准化残差偏大， 应该考虑采用其他形式的模型，比如非线性模型；</li>
<li>如果完全是由于随机因素而造成的异常值， 则应该保留该数据。</li>
</ul>
</blockquote>
<p>在处理异常值时， 若一个异常值是一个有效的观测值， 不应轻易地将其从数据集中予以剔除。</p>
<blockquote>
<ul>
<li>异常值也可以通过标准化残差来识别；</li>
<li>如果某一个观测值所对应的标准化残差较大， 就可以识别为异常值；</li>
<li>一般情况下，当一个观测值所对应的标准化残差小于-2或大于+2时，就可以将其视为异常值。</li>
</ul>
</blockquote>
<p><strong>有影响的观测值</strong><br>如果某一个或某一些观测值对回归的结果有强烈的影响，那么该观测值或这些观测值就是有影响的观测值。<br>一个有影响的观测值可能是：一个异常值， 即有一个值远远偏离了散点图中的趋势线；对应一个远离自变量平均值的观测值；或者是这二者组合而形成的观测值。<br>如果有影响的观测值是一个错误的数据，比如记录错误造成的， 应该修正该数据，以便改善回归的效果。<br>如果有影响的观测值是一个有效的数据则应该保留它， 可以帮助我们分析模型的假定是否合理。<br><strong>杠杆率点(leverage point)</strong><br>如果自变量存在一个极端值， 该观测值则称为高杠杆率点(high leverage point)，在简单回归中，第i个观测值的杠杆率用$h_i$表示，其计算公式为：<br>$$h_i=\frac{1}{n}+\frac{(x_i-\bar x)^2}{\sum(x_i-\bar x)^2}$$<br>如果一个观测值的杠杆率$h_i&gt;n/6$，就可以将该观测值识别为有高杠杆率的点；<br>一个有高杠杆率的观测值未必是一个有影响的观测值， 它可能对回归直线的斜率没有什么影响。</p>
<h3 id="5-多元线性回归multiple-regression-model"><a href="#5-多元线性回归-multiple-regression-model" class="headerlink" title="5 多元线性回归(multiple regression model)"></a>5 多元线性回归(multiple regression model)</h3><p><strong>多元线性回归(multiple regression model)</strong></p>
<blockquote>
<ul>
<li>一个因变量与两个及两个以上自变量的回归。</li>
<li>描述因变量y如何依赖于自变量$x_1,x_2,\cdots,x_p$和误差项$\varepsilon$的方程，称为多元回归模型。</li>
<li>涉及 p 个自变量的多元回归模型可表示为<br>$$y=\beta_0+\beta_1x_1+\beta_2x_2+\cdots+\beta_px_p+\varepsilon$$</li>
<li>$\beta_0,\beta_1,\beta_2,\cdots,\beta_p$是参数。</li>
<li>$\varepsilon$是被称为误差项的随机变量。</li>
<li>y是$x_1,x_2,\cdots,x_p$的线性函数加上误差项$\varepsilon$。</li>
<li>$\varepsilon$包含在y里面但不能被p个自变量的线性关系所解释的变异性。</li>
</ul>
</blockquote>
<p><strong>多元回归模型的基本假定</strong></p>
<blockquote>
<ul>
<li>误差项ε是一个期望值为0的随机变量， 即E(ε)=0。</li>
<li>对于自变量$x_1,x_2,\cdots,x_p$的所有值，ε的方差$\sigma^2$都相同。</li>
<li>误差项ε是一个服从正态分布的随机变量，即$ε~N(0,\sigma^2)$，且相互独立。</li>
</ul>
</blockquote>
<p><strong>多元回归方程(multiple regression equation)</strong><br>描述因变量y的平均值或期望值如何依赖于自变量$x_1,x_2,\cdots,x_p$的方程。<br>多元线性回归方程的形式为<br>$$E(y)=\beta_0+\beta_1x_1+\beta_2x_2+\cdots+\beta_px_p+\varepsilon$$</p>
<blockquote>
<ul>
<li>$\beta_1,\beta_2,\cdots,\beta_p$称为偏回归系数。</li>
<li>$\beta_i$表示假定其他变量不变，当$x_i$每变动一个单位时，y的平均变动值。</li>
</ul>
</blockquote>
<p>二元回归方程的几何表达——回归面。</p>
<p><img src="http://f.hiphotos.baidu.com/image/pic/item/c995d143ad4bd11366254c6c50afa40f4afb0587.jpg" alt=""></p>
<p><strong>估计的多元回归的方程(estimated multiple regression equation)</strong><br>用样本统计量$b_0,b_1,b_2,\cdots,b_p$估计回归方程中的参数$\beta_0,\beta_1,\beta_2,\cdots,\beta_p$时得到的方程。一般形式为。<br>$$\hat y=b_0+b_1x_1+b_2x_2+\cdots+b_px_p$$<br><strong>参数的最小二乘法</strong><br>使因变量的观察值与估计值之间的离差平方和达到最小来求得$b_0,b_1,b_2,\cdots,b_p$，即：<br>$$argmin Q(b_0,b_1,b_2,\cdots,b_p)=\sum_{i=1}^n(y_i-\hat y_i)^2=\sum_{i=1}^ne_i^2$$<br>求解各回归参数的标准方程如下：<br>$$ \begin{cases}\left. \frac{\partial Q}{\partial \beta_0} \right| _{\beta_0=b_0}=0\\\left. \frac{\partial Q}{\partial \beta_i} \right| _{\beta_i=b_i}=0(i=1,2,\cdots,p)\end{cases} $$<br><strong>多重判定系数(multiple coefficient of determination)</strong><br>回归平方和占总平方和的比例，计算公式为<br>$$ R^2=\frac{\sum_{i=1}^n(\hat y_i-\bar y)^2}{\sum_{i=1}^n(y_i-\bar y)^2}=\frac{SSR}{SST}=1-\frac{SSE}{SST} $$<br>因变量取值的变差中， 能被估计的多元回归方程所解释的比例。<br><strong>修正多重判定系数(adjusted multiple coefficient of determination)</strong><br>用样本容量n和自变量的个数p去修正$R^2$得到。计算公式为<br>$$R_a^2=1-(1-R^2)\times\frac{n-1}{n-p-1}$$<br>避免增加自变量而高估$R^2$，意义与$R^2$类似，数值小于$R^2$。<br><strong>估计标准误差s</strong><br>对误差项ε的标准差σ的一个估计值。衡量多元回归方程的拟合优度。计算公式为<br>$$ s=\sqrt{\frac{\sum_{i=1}^n(y_i-\hat y_i)^2}{n-p-1}}=\sqrt{\frac{SSE}{n-p-1}}=\sqrt{MSE} $$<br><strong>线性关系检验</strong><br>检验因变量与所有自变量之间的线性关系是否显著，也被称为总体的显著性检验。检验方法是将回归均方和(MSR)同离差均方和(MSE)加以比较，应用F检验来分析二者之间的差别是否显著。</p>
<blockquote>
<ul>
<li>如果是显著的， 因变量与自变量之间存在线性关系；</li>
<li>如果不显著， 因变量与自变量之间不存在线性关系。<br>（1）提出假设：<br>$H_0：\beta_1=\beta_2=\cdots=\beta_p=0$ 线性关系不显著；<br>$H_1：\beta_1,\beta_2,\cdots,\beta_p $ 至少有一个不等于0。<br>（2）计算检验统计量F：<br>$$ F=\frac{SSR/p}{SSE/(n–p-1)}=\frac{MSR}{MSE}\sim F(p,n-p-1) $$<br>（3）确定显著性水平α，并根据分子自由度p和分母自由度n-p-1找出临界值$F_\alpha$。<br>（4）作出决策：$若F&gt;F_\alpha，拒绝H_0$。</li>
</ul>
</blockquote>
<p><strong>回归系数的检验(检验步骤)</strong></p>
<blockquote>
<ul>
<li>线性关系检验通过后，对各个回归系数进行检验。</li>
<li>对每一个自变量单独应用 t 检验统计量进行检验。<br>（1）提出假设<br>$$H_0:\beta_i=0(自变量x_i与因变量y没有线性关系)$$<br>$$H_1:\beta_i\neq 0(自变量x_i与因变量y有线性关系)$$<br>（2）计算检验的统计量<br>$$ t=\frac{b_i}{s_{b_i}}\sim t(n-p-1)，s_{b_i}=\frac{s}{\sqrt{\sum(x_i-\bar x)^2}}$$<br>（3）确定显著性水平$\alpha$，并进行决策：<br>$$ \left|t\right|\gt t_{\alpha/2}，拒绝H_0；\left|t\right|\lt t_{\alpha/2}，不拒绝H_0 $$</li>
</ul>
</blockquote>
<p><strong>回归系数的推断(置信区间)</strong><br>回归系数在(1-α)%置信水平下的置信区间为<br>$$ b_i\pm t_{\alpha/2}(n-p-1)s_{b_i} $$<br>回归系数的抽样标准差<br>$$ s_{b_i}=\frac{s}{\sqrt{\sum(x_i-\bar x)^2}}$$</p>
<h3 id="6-多重共线性multicollinearity"><a href="#6-多重共线性-multicollinearity" class="headerlink" title="6 多重共线性(multicollinearity)"></a>6 多重共线性(multicollinearity)</h3><p>回归模型中两个或两个以上的自变量彼此相关。多重共线性带来的问题有：可能会使回归的结果造成混乱， 甚至会把分析引入歧途；可能对参数估计值的正负号产生影响， 特别是各回归系数的正负号有可能同我们预期的正负号相反。<br><strong>多重共线性的识别</strong></p>
<blockquote>
<ul>
<li>检测多重共线性的最简单的一种办法是计算模型中各对自变量之间的相关系数， 并对各相关系数进行显著性检验；<br>若有一个或多个相关系数显著， 就表示模型中所用的自变量之间相关，存在着多重共线性。</li>
<li>如果出现下列情况，暗示存在多重共线性：<br>模型中各对自变量之间显著相关。<br>当模型的线性关系检验(F检验)显著时，几乎所有回归系数的t检验却不显著。<br>回归系数的正负号与预期的相反。</li>
</ul>
</blockquote>
<p><strong>检测多重共线性(Variance Inflationary Factor)</strong><br>VIF (variance inflation factor) 用以测量如果自变量相关对估计的回归系数的变异程度的影响。<br>$VIF_j$的定义:<br>$$VIF_j=\frac{1}{1-R_j^2}$$<br>$R_2^j$是第j个自变量对其它自变量进行回归的判定系数。VIF=1表示所对应自变量与其它自变量无线性关系。VIF值越大，多重共线性越严重。如果$VIF_j$&gt;5，$x_j$与其它自变量高度相关。<br><strong>多重共线性(问题的处理)</strong><br>将一个或多个相关的自变量从模型中剔除，使保留的自变量尽可能不相关。<br>如果要在模型中保留所有的自变量，则应避免根据t统计量对单个参数进行检验，对因变量值的推断(估计或预测)的限定在自变量样本值的范围内。</p>
<h3 id="7-定性自变量的回归"><a href="#7-定性自变量的回归" class="headerlink" title="7 定性自变量的回归"></a>7 定性自变量的回归</h3><p><strong>虚拟变量(dummy variable)</strong><br>定性自变量————只有两个水平的定性自变量或有两个以上水平的定性自变量。<br>虚拟变量——用数字代码表示的定性自变量。<br>虚拟变量的取值为0，1。<br><strong>虚拟变量的个数</strong><br>当定性自变量只有两个水平时，可在回归中引入一个虚拟变量。一般而言，如果定性自变量有k个水平，需要在回归中模型中引进k-1个虚拟变量。<br>当定性自变量只有两个水平并引进虚拟变量时，回归方程可写$E(y)=\beta_0+ \beta_1x$。当指定虚拟变量0，1时,$\beta_0$总是代表与虚拟变量值0所对应的那个分类变量水<br>平的平均值；$\beta_1$总是代表与虚拟变量值1所对应的那个分类变量水平的平均响应与虚拟变量值0所对应的那个分类变量水平的平均值的差值，即平均值的差值=$(\beta_0+\beta_1)-\beta_0=\beta_1$<br>当定性自变量超过两个水平（假定三个水平）并引进虚拟变量时，回归方程可写$E(y)=\beta_0+ \beta_1x_1+\beta_2x_2$。<br>方差分析同样可以通过引入虚拟变量做回归分析。</p>
<h3 id="8-非线性回归"><a href="#8-非线性回归" class="headerlink" title="8 非线性回归"></a>8 非线性回归</h3><p><strong>（1）二阶回归模型(Quadratic Regression Model)</strong>——当散点图如下所示，可考虑二次回归模型。<br>$$y_i=\beta_0+\beta_1x_i+\beta_2x_i^2+\varepsilon$$</p>
<p><img src="http://a.hiphotos.baidu.com/image/pic/item/342ac65c1038534373c8627f9913b07eca80886d.jpg" alt=""></p>
<p><strong>二阶回归模型的显著性检验</strong></p>
<blockquote>
<ul>
<li>总体显著性检验<br>$$F test statistic=\frac{MSR}{MSE}$$</li>
<li>二阶检验<br>比较二阶模型<br>$$ y=\beta_0+\beta_1x_1+\beta_2x^2+\varepsilon $$<br>线性模型<br>$$ y=\beta_0+\beta_1x_1+\varepsilon $$<br>假设：<br>$H_0:β_2=0 (没有二阶项)$<br>$H_1:β_2\neq 0 (需要二阶项)$</li>
</ul>
</blockquote>
<p><strong>（2）交互作用</strong><br>交互作用——两个自变量共同作用对因变量产生的潜在影响。</p>
<blockquote>
<p> 假设：<br>$$ y=\beta_0+\beta_1x_1+\beta_2x_2+\beta_3x_1x_2+\varepsilon $$<br>没有交互项, $x_1$对y的影响用$β_1$测量；有交互项,$x_1$对y的影响用$β_1+β_3x_2$测量。影响随$x_2$的改变而改变。</p>
</blockquote>
<p><strong>交互作用显著性检验</strong></p>
<blockquote>
<ul>
<li>交互作用模型:<br>$$ y=\beta_0+\beta_1x_1+\beta_2x_2+\beta_3x_1x_2+\varepsilon $$</li>
<li>假设：<br>$$ H_0：\beta_3=0 （x_1和x_2无交互作用）$$<br>$$ H_1：\beta_3\neq 0 （x_1和x_2有交互作用）$$</li>
</ul>
</blockquote>
<p><strong>（3）其他非线性回归</strong><br>因变量y与x之间不是线性关系，可通过变量代换转换成线性关系，用最小二乘法求出参数的估计值。但是并非所有的非线性模型都可以化为线性模型。</p>
<blockquote>
<ul>
<li><p>双曲线<br>基本形式：$y=\frac{x}{\alpha x+\beta}$<br>线性化方法：$令y’=\frac{1}{y}，x’=\frac{1}{x}，则有y’=\alpha+\beta x’$<br><img src="http://f.hiphotos.baidu.com/image/pic/item/359b033b5bb5c9ea68b6e6bddf39b6003af3b323.jpg" alt=""></p>
</li>
<li><p>幂函数曲线<br>基本形式：$y=\alpha x^\beta$<br>线性化方法：$两端取对数得：lgy=lg\alpha+\beta lgx，y’=lgy，x’=lgx，则有y’=lg\alpha+\beta x’$<br><img src="http://e.hiphotos.baidu.com/image/pic/item/faf2b2119313b07e46efb55606d7912397dd8c1a.jpg" alt=""></p>
</li>
<li><p>对数曲线<br>基本形式：$y=\alpha+\beta lnx$<br>线性化方法：$x’=lnx，则有y’=\alpha+\beta x’$<br><img src="http://a.hiphotos.baidu.com/image/pic/item/c8ea15ce36d3d53936c4ea9d3087e950342ab0f7.jpg" alt=""></p>
</li>
<li><p>指数曲线<br>基本形式：$y=\alpha^{\beta x}$<br>线性化方法：$两端取对数得：lny=ln\alpha+\beta x，y’=lny，则有y’=ln\alpha+\beta x$<br><img src="http://a.hiphotos.baidu.com/image/pic/item/b812c8fcc3cec3fd0c24432bdc88d43f87942752.jpg" alt=""></p>
</li>
<li>S型曲线<br>基本形式：$y=\frac{1}{\alpha+\beta e^{-x}}$<br>线性化方法：$令y’=1/y，x’=e^{-x}，则有y’=\alpha+\beta x’$<br><img src="http://g.hiphotos.baidu.com/image/pic/item/d62a6059252dd42a5e0ae6f5093b5bb5c9eab869.jpg" alt=""></li>
</ul>
</blockquote>
<h3 id="9-建立回归模型"><a href="#9-建立回归模型" class="headerlink" title="9 建立回归模型"></a>9 建立回归模型</h3><p>得到描述因变量与一个或一个以上自变量之间关系的估计的回归方程。目的是建立一个基于最好自变量集合的模型。找到一个适合的描述变量关系之间关系的函数。选择模型应包含的变量。</p>
<blockquote>
<ul>
<li>俭约的模型–用尽可能少的变量来提供足够精度的预测。</li>
<li>将不重要的变量除去更容易对模型进行解释。</li>
<li>发生多重共线性的可能变小。</li>
</ul>
</blockquote>
<p><strong>变量选择Variable Selection</strong></p>
<blockquote>
<p>有些变量的作用不是很大，SSE 不会随着变量个数的增加而增加，但MSE=SSE/(n-k-1) 有可能会随着变量<br>个数的增加而增加。最小的MSE可作为最优变量选择的一个准则，但需考虑所有子集 (2^p个)。</p>
</blockquote>
<p><strong>检验增加变量是否适宜的F统计</strong><br>$$F=\frac{SSE(x_1,x_2,\cdots,x_p)-SSE(x_1,x_2,\cdots,x_q,x_{q+1},\cdots,x_p)}{\frac{SSE(x_1,x_2,\cdots,x_q,x_{q+1},\cdots,x_p)}{n-p-1}}$$<br>$$ F\sim F(p-q,n-p-1) $$<br>F越大，说明增加变量减少预测误差的效果越显著。<br><strong>变量选择过程</strong></p>
<blockquote>
<ul>
<li>向前选择(Forward Selection)</li>
</ul>
<ol>
<li>从没有自变量的模型开始。</li>
<li>如果所有的F统计量的p-值大于预先设定的终止值，说明增加任一变量效果不显著，停止。</li>
<li>否则，加入具有最大F统计量值的变量。</li>
<li>重新回归， Go to Step 2。</li>
</ol>
<ul>
<li>后向消元(Backward Elimination)</li>
</ul>
<ol>
<li>从包含所有自变量的模型开始。</li>
<li>如果所有的F统计量的p-值小于预先设定的终止值，说明减少任一变量效果显著，停止。</li>
<li>否则，删除具有最小F统计量值的变量。</li>
<li>重新回归， Go to Step 2。</li>
</ol>
<ul>
<li>逐步回归(Stepwise regression procedure)<br>向前选择和后向消元的结合。<br>1.先检查是否有变量需从模型中删除。<br>2.再检查增加一个变量是否能改善模型。<br>3.重复以上过程。<br>注意： α进≤α出，否则F进&lt;F&lt;F出，会导致无限循环。</li>
<li>最佳子集回归(Best-subset approach)<br>对所有可能的自变量组合进行估计。找出具有最大的修正判定系数$adj.R^2$和最小的估计误差标准差$s_ε$。</li>
</ul>
</blockquote>
<h3 id="10-回归中的常见错误"><a href="#10-回归中的常见错误" class="headerlink" title="10 回归中的常见错误"></a>10 回归中的常见错误</h3><p>（1）没有检验线性关系假设</p>
<blockquote>
<p>画散点图。<br>如果不是线性的，检验其它非线性。<br>用线性关系描述非线性关系会引起误导。</p>
</blockquote>
<p>（2）只看结果不看图表</p>
<blockquote>
<p>要将画散点图作为回归分析的一部分。<br>检验回归直线与实际观测值间的关系。<br>对自动回归来说这一步更为重要。</p>
</blockquote>
<p>（3）用回归系数判定变量的重要性</p>
<blockquote>
<p>回归系数依赖于自变量的量纲，因此系数的大小与变量的重要性无关。<br>例如，将秒变为微秒没有改变任何事实，但是变量的系数却有所改变。</p>
</blockquote>
<p>（4）没有确定置信区间</p>
<blockquote>
<p>观察值是随机样本，所以回归结果有一定随机性。<br>不确定置信区间，不可能理解参数的真正含义。</p>
</blockquote>
<p>（5）没有计算判定系数</p>
<blockquote>
<p>没有$R^2$，很难确定多少变异是由回归解释的。<br>即使$R^2$看起来很好，安全起见还应做F-test。</p>
</blockquote>
<p>（6）错误解释相关系数</p>
<blockquote>
<p>判定系数是$R^2$。<br>相关系数是R。<br>$R^2$给出变异由回归解释的百分比，不是R。<br>如：R =0.5,$R^2$=0.25——回归解释了25%的变异，不是50%。</p>
</blockquote>
<p>（7）使用强相关的自变量</p>
<blockquote>
<p>模型同时包括两强相关的自变量会降低回归模型的显著性。<br>要尽可能的了解自变量间的关系。</p>
</blockquote>
<p>（8）用回归模型预测观测值范围之外的区域</p>
<blockquote>
<p>回归是基于某一特定观测样本的。<br>在样本观测值范围内能提供较为精确的估计。</p>
</blockquote>
<p>（9）观测值取值范围太小</p>
<blockquote>
<p>回归只有在观测值取值范围附近预测的结果比较好。<br>如果不在常用的范围内取值，回归模型用处不大。</p>
</blockquote>
<p>(10)包括太多的自变量</p>
<blockquote>
<p>变量越多的模型不一定越好。<br>有可能出现多重共线性。</p>
</blockquote>
<p>（11）认为好的预测变量是好的控制变量<br>相关关系不一定因果关系：A与B相关，并不意味着可以通过改变A来控制B。</p>
<p>（12）线性回归结果会给人以误导</p>
<blockquote>
<p>为了提供一个简练的总结，回归过程中舍弃了一些信息。<br>有时一些重要的特征也舍弃了——看图形表示可以告诉我们是否有问题。</p>
</blockquote>
<h3 id="11-logistic-回归"><a href="#11-Logistic-回归" class="headerlink" title="11 Logistic 回归"></a>11 Logistic 回归</h3><p>Logistic回归提出的目的是为了解决二值化数据的回归问题。那么为什么简单线性回归模型不适合二值化数据的回归呢？详细原因可见如下图。</p>
<p><img src="http://f.hiphotos.baidu.com/image/pic/item/6a63f6246b600c33ea0a3996104c510fd9f9a179.jpg" alt=""> </p>
<p>二值化变量是“yes”或者”no”的数据。可以被编码为1和0，也就是说不会有其他的变异数值。所以对于这种情况模型的要求是：模型的边界为0和1，模型可以输出的是一个在这类或者另一类的概率。我们想要的是一个实际值落入这类或者另一类的概率大小。而理想的模型是很好的估计0和1，或者换句话说，结果是0或1。所以解决方案就是Logistic回归。</p>
<p><img src="http://h.hiphotos.baidu.com/image/pic/item/2fdda3cc7cd98d10963de06f2b3fb80e7aec9087.jpg" alt=""></p>
<p>Logistic的基本形式为<br>$$ \pi_i’=ln(\frac{\pi_i}{1-\pi_i})=\beta_0+\beta_1x_i $$<br>通过观测值估计$n_i$的概率$p_i$，并且用$ln(\frac{p_i}{1-p_i})$估计。<br>典型案例：<br>城市增长问题，城市化预测模拟，</p>
<p><strong>常见的问题</strong></p>
<blockquote>
<ul>
<li>都有一个二值化（或分类）变量：</li>
<li>都涉及到预测的思想机会，概率，比例或百分比。</li>
<li>不像其他的预测情况，y值是有界的。</li>
</ul>
</blockquote>
<p><strong>Logistic 回归与简单线性回归</strong></p>
<blockquote>
<p>logistic回归是一种统计技术，可以用二值化变量问题中。回归虽有相似之处，但它不同于普通最小二乘法。识别重要和相似之处是两种技术的区别。</p>
</blockquote>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/06/11/应用统计学与R语言实现学习笔记（八）——方差分析/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Dai Shaoqing">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GISerDaiShaoqing's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/06/11/应用统计学与R语言实现学习笔记（八）——方差分析/" itemprop="url">
                  应用统计学与R语言实现学习笔记（八）——方差分析
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-06-11T00:00:00+08:00">
                2017-06-11
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/统计与模型/" itemprop="url" rel="index">
                    <span itemprop="name">统计与模型</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/2017/06/11/应用统计学与R语言实现学习笔记（八）——方差分析/" class="leancloud_visitors" data-flag-title="应用统计学与R语言实现学习笔记（八）——方差分析">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">Visitors </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="chapter-8-anova"><a href="#Chapter-8-ANOVA" class="headerlink" title="Chapter 8 ANOVA"></a>Chapter 8 ANOVA</h1><p>本篇是第八章，内容是方差分析。前一段考试，汇报，作业。忙不过来，停更了一段时间，现在重新开始更这一部分内容。方差分析是很多实验的基础以及很重要的分析手段，这一章内容相比较而言比较多。</p>
<h3 id="1方差分析的引论"><a href="#1-方差分析的引论" class="headerlink" title="1.方差分析的引论"></a>1.方差分析的引论</h3><p>方差分析其实对我们来说并不陌生，因为大学搞生态的那群同学，实验中无数次出现了单方差因素分析的方法。那么方差分析究竟是什么呢？从引论来说，我们举个跟地学领域相关的例子。<br>不同地貌对土壤有机质是否有影响？<br>简单地说方差分析实质适合分析的是一系列数值型数据存在某个属性（也可以是某些），然后这个属性可以按照一定的规则分成几个类别（或者叫水平），我们想了解的就是，不同类别或者不同水平的这个数值是否存在显著性差异。简单的理解，它是处理分类型数据的。<br>这里需要跟上一章提到的拟合优度检验、后面讲到的回归分析做些区别，拟合优度检验通常是分析两个分类变量的关系，回归分析则分析的是一个数值型变量（或多个数值型变量）对一个数值型变量的影响（或者说二者的关系）。而方差分析则是分析一个分类变量（或多个分类变量）对于一个数值变量的影响（或者说二者的关系）。<br>这里给出一些定义和术语（不喜好数学的同学可以跳过，但请记住我上面的内容）：<br><strong>方差分析(Analysis of Variance，ANOVA)</strong><br>研究分类型自变量对数值型因变量的影响</p>
<blockquote>
<ul>
<li>一个或多个分类型自变量<br>  两个或多个 (k 个) 处理或分类</li>
<li>一个数值型因变量</li>
</ul>
</blockquote>
<p>通过检验多个总体均值是否相等来判断是否有显著影响</p>
<blockquote>
<ul>
<li>通过分析数据的误差判断各总体均值是否相等</li>
</ul>
</blockquote>
<p>有单因子方差分析和双因子方差分析</p>
<blockquote>
<ul>
<li>单因子方差分析：涉及一个分类型自变量</li>
<li>双因子方差分析：涉及两个分类型自变量</li>
</ul>
</blockquote>
<p>方差分析 vs 假设检验<br>（1）假设检验：一次只能研究两个样本</p>
<blockquote>
<ul>
<li>需要比较的次数随因子的数量增多而增多；</li>
<li>第一类错误发生的可能性增大。</li>
</ul>
</blockquote>
<p>（2）方差分析：同时分析多个样本</p>
<blockquote>
<ul>
<li>提高检验效率；</li>
<li>将所有信息结合在一起， 增加了分析的可靠性。</li>
</ul>
</blockquote>
<h4 id="11-方差分析的部分概念"><a href="#1-1-方差分析的部分概念：" class="headerlink" title="1.1 方差分析的部分概念："></a>1.1 方差分析的部分概念：</h4><blockquote>
<ul>
<li>因子或因素 (factor)——所要检验的对象，要分析行业对投诉次数是否有影响， 行业是要检验的因子或因素。</li>
<li>水平或处理(treatment):因子的不同表现,零售业、 旅游业、 航空公司、 家电制造业就是因子的处理。</li>
<li>观察值：在每个因子处理下得到的样本数据，每个行业被投诉的次数就是观察值。</li>
<li>试验：涉及一个因子多水平， 可称为单因子多处理的试验。</li>
<li>总体：因子的每一个处理看作是一个总体。</li>
<li>样本数据：观察值可以看作是从着多个总体中抽取的样本数据</li>
</ul>
</blockquote>
<p>也就是说分类变量是因子或因素，而分的类别就可以称为水平或处理，观察值则是数值型变量。试验就是就是分类的过程，总体其实就是水平，样本数据就是观测值。<br>接下来讲讲方差分析的基本思想和原理。</p>
<h4 id="12-方差分析的基本思想和原理"><a href="#1-2-方差分析的基本思想和原理" class="headerlink" title="1.2 方差分析的基本思想和原理"></a>1.2 方差分析的基本思想和原理</h4><p>方差分析的基本思想和原理基于两类误差。也就是随机误差和系统误差。</p>
<blockquote>
<ul>
<li><strong>随机误差</strong>——因子的同一处理(总体)下， 样本各观察值之间的差异，这种差异可以看成是随机因素的影响， 称为随机误差。</li>
<li><strong>系统误差</strong>——因子的不同处理(不同总体)下， 各观察值之间的差异，这种差异可能是由于抽样的随机性所造成的， 也可能是由于行业本身所造成的， 后者所形成的误差是由系统性因素造成的， 称为系统误差。</li>
</ul>
</blockquote>
<p>所以方差分析的实质是——比较两类误差，以检验均值是否相等；比较的基础是方差比；如果系统（处理）误差明显地不同于随机误差，则均值就是不相等的；反之，均值就是相等的。<br>这里数据的误差用平方和(sum of squares)表示。</p>
<blockquote>
<ul>
<li><strong>组内平方和(within groups)</strong>——因子的同一处理(同一个总体)下样本数据的平方和。组内平方和只包含随机误差。</li>
<li><strong>组间平方和(between groups)</strong>——因子的不同处理(不同总体)下各样本之间的平方和。组间平方和既包括随机误差， 也包括系统误差。</li>
</ul>
</blockquote>
<p>所以若原假设成立， 组间平方和与组内平方和经过平均后的数值就应该很接近， 它们的比值就会接近1。</p>
<blockquote>
<ul>
<li>若原假设不成立， 组间平方和平均后的数值就会大于组内平方和平均后的数值， 它们之间的比值<br>就会大于1。</li>
<li>当这个比值大到某种程度时， 就可以说不同处理之间存在着显著差异， 也就是自变量对因变量有影响。</li>
</ul>
</blockquote>
<h4 id="13-方差分析的基本假定"><a href="#1-3-方差分析的基本假定" class="headerlink" title="1.3 方差分析的基本假定"></a>1.3 方差分析的基本假定</h4><p>（1）每个总体都应服从正态分布：</p>
<blockquote>
<ul>
<li>对于因子的每一个处理， 其观察值是来自服从正态分布总体的简单随机样本。</li>
</ul>
</blockquote>
<p>（2）各个总体的方差必须相同：</p>
<blockquote>
<ul>
<li>各组观察数据是从具有相同方差的总体中抽取的。</li>
</ul>
</blockquote>
<p>（3）观察值是独立的。<br>（4）在上述假定条件下， 判断行业对投诉次数是否有显著影响， 实际上也就是检验具有同方差的四个正态总体的均值是否相等。<br>（5）如果四个总体的均值相等， 可以期望四个样本的均值也会很接近：</p>
<blockquote>
<ul>
<li>四个样本的均值越接近， 推断四个总体均值相等的证据也就越充分；</li>
<li>样本均值越不同， 推断总体均值不同的证据就越充分。</li>
</ul>
</blockquote>
<p>这里要注意的是，往往很多人做统计的时候往往不考虑前提和假设，这是一个错误。经典统计学中很多模型都有严密的数学推导和前提假设，就笔者从事的地学领域里其实有很多现象不是太遵循经典统计学的前提，由此也衍生出了空间统计学理论，所以在做统计研究时需要考量自己数据的特征，了解统计学与模型的基本前提与假设。</p>
<p>原假设：$H_0：\mu_1=\mu_2=\mu_3=\cdots=\mu_n $</p>
<blockquote>
<ul>
<li>n个水平被投诉次数的均值都相等；</li>
<li>意味着每个样本都来自均值为$\mu$、方差为$\sigma^2$的同一正态总体。</li>
</ul>
</blockquote>
<p>若备择假设成立，即$H_1：\mu_i(i=1,2,3,\cdots,n)$不全相等</p>
<blockquote>
<ul>
<li>至少有一个总体的均值是不同的；</li>
<li>样本分别来自均值不同的多个个正态总体。</li>
</ul>
</blockquote>
<h3 id="2单因子方差分析one-way-anova"><a href="#2-单因子方差分析（One-way-ANOVA" class="headerlink" title="2.单因子方差分析（One-way ANOVA)"></a>2.单因子方差分析（One-way ANOVA)</h3><p>从这章开始后面的部分基本是典型数据分析，故我会渗透更多的数据分析的一些经验和理念。在这里因为要正式进入方差分析的具体内容里，所以我想谈的一点是我曾经说过的一句话——编程先学数据结构。数据结构的重要性可以参加下面的知乎。</p>
<blockquote>
<p><a href="https://www.zhihu.com/question/29587605" target="_blank" rel="external">https://www.zhihu.com/question/29587605</a></p>
</blockquote>
<p>当然对于R或是其他数据处理语言来说，我觉得最关键的是你在使用分析数据（调用各种包）时需要了解你所调用的包或者函数处理的是什么样的数据（你要把数据处理成你的函数可以读的形式）。<br>当然这是题外话，还是回到标题的单因子方差分析。</p>
<p>如果一个试验中，只有一个因子在变，而其它因素保持不变，称此试验为单因子试验（只涉及一个分类型自变量）。那么它的数据结构如下所示：</p>
<p><img src="http://img.blog.csdn.net/20170607211717109?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvRVNBX0RTUQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt=""></p>
<p>当然事实上在分析的时候，个人觉得R和其他数据所能读取的数据结构或者说组织方式还是2列的变量（数值型变量与分类变量）。</p>
<p>分析步骤则是统计学的经典三部曲：</p>
<blockquote>
<ul>
<li>提出假设；</li>
<li>构造检验统计量；</li>
<li>统计决策。</li>
</ul>
</blockquote>
<p>假设的提法在前面已经提过了。<br>$H_0：\mu_1=\mu_2=\mu_3=\cdots=\mu_n $（自变量对因变量没有显著影响）。<br>$H_1：\mu_1,\mu_2,\mu_3,\cdots,\mu_n不全相等$（自变量对因变量有显著影响）。</p>
<p>构造统计量需要计算<br>（1）处理的均值<br>（2）全部观察值的总均值<br>（3）平方和<br>（4）均方(MS)</p>
<p>（接下来是公式大全，公式恐惧症者请跳过）<br><strong>（1）处理的均值</strong><br>假定从第i个总体中抽取一个容量为$n_i$的简单随机样本， 第i个总体的样本均值为该样本的全部观察值总和除以观察值的个数。<br>$$ \bar x_i=\frac{\sum_{j=1}^nx_{ij}}{n_i} (i=1,2,\cdots,k)$$<br>式中： $n_i$为第 i 个总体的样本观察值个数，$x_{ij}$为第i个总体的第j个观察值。</p>
<p><strong>（2）全部观察值的总均值</strong><br>全部观察值的总和除以观察值的总个数。<br>$$ \bar x’=\frac{\sum_{i=1}^k\sum_{j=1}^nx_{ij}}{n}=\frac{\sum_{i=1}^kn_i\bar x_i}{n}$$</p>
<p><strong>（3）平方和</strong><br>方差分析需要计算三个平方和。</p>
<blockquote>
<ul>
<li>总平方和 (Sum of Squares for Total), SST。<br>全部观察值与总平均值的离差平方和，反映全部观察值的离散状况。<br>$$ SST=\sum_{i=1}^k\sum_{j=1}^n(x_{ij}-\bar x’)^2 $$</li>
<li>处理平方和 (Sum of Squares due to Treatment), SSTR，又叫组间平方和。<br>各组平均值与总平均值的离差平方和，反映各总体的样本均值之间的差异程度， 又称处理平方和或组间平方和，该平方和既包括随机误差， 也包括系统误差。<br>$$ SSTR= \sum_{i=1}^k\sum_{j=1}^n(\bar x_i-\bar x’)^2=\Sigma_{i=1}^kn_i(\bar x_i-\bar x’)^2 $$</li>
<li>误差平方和 (Sum of Squares due to Error),SSE，又叫组内平方和。<br>每个处理或组的各样本数据与其组平均值的离差平方和，反映每个样本各观察值的离散状况，又称组内平<br>方和或残差平方和，该平方和反映的是随机误差的大小。<br>$$ SSE=\sum_{i=1}^k\sum_{j=1}^n(x_ij-\bar x_i）^2 $$<br>实际上，SST=SSTR+SSE<br>SST反映全部数据总的误差程度； SSE反映随机误差的大小； SSTR反映随机误差和系统误差的大小。<br>如果原假设成立， 则表明没有系统误差， 处理平方和SSTR除以自由度后的均方与误差平方和SSE和除以自由度后的均方差异就不会太大；如果处理均方显著地大于误差均方， 说明各处理(总体)之间的差异不仅有随机误差， 还有系统误差。<br>判断因子的处理是否对其观察值有影响， 实际上就是比较处理均方与误差均方之间差异的大小。</li>
</ul>
</blockquote>
<p><strong>（4）均方——构建检验统计量</strong><br>各平方和的大小与观察值的多少有关， 为消除观察值多少对平方和大小的影响， 需要将其平均， 这就是均方， 也称为方差。计算方法是用平方和除以相应的自由度，三个平方和对应的自由度分别是： SST 的自由度为n-1， 其中n为全部观察值的个数，SSTR的自由度为k-1， 其中k为因子处理(总体)的个数，SSE 的自由度为n-k。<br>处理均方：SSTR的均方， 记为MSTR， 计算公式为:<br>$$ MSTR=\frac{SSTR}{k-1} $$<br>误差均方：SSE的均方，记为MSE， 计算公式为:<br>$$ MSE=\frac{SSE}{n-k} $$<br>计算检验统计量F：<br>将MSTR和MSE进行对比， 即得到所需要的检验统计量F，当$H_0$为真时， 二者的比值服从分子自由度为k-1、分母自由度为n-k的F分布， 即<br>$$ F=\frac{MSTR}{MSE}\sim(k-1,n-k) $$。<br>最后是统计决策将统计量的值F与给定的显著性水平$\alpha$的临界值$F_\alpha$进行比较，作出对原假设$H_0$的决策。</p>
<blockquote>
<ul>
<li>根据给定的显著性水平$\alpha$， 在F分布表中查找与第一自由度$df_1＝k-1$、 第二自由度$df_2=n-k$ 相应的临界值$F_\alpha$。</li>
<li>若F&gt;$F_\alpha$，则拒绝原假设$H_0$，表明均值之间的差异是显著的，所检验的因子对观察值有显著影响。</li>
<li>若F&lt;$F_\alpha$，则不能拒绝原假设$H_0$， 无证据支持表明所检验的因子对观察值有显著影响。</li>
</ul>
</blockquote>
<p>对前面的三部曲做一个进一步的总结：</p>
<blockquote>
<p>（1）提出假设；<br>（2）构造检验统计量；<br><strong>均值</strong>：全部观察值的总均值、处理的均值。<br><strong>平方和</strong>：总平方和SST，处理平方和SSTR，误差平方和SSE。<br><strong>均方</strong>：处理均方MSTR，误差均方MSE。<br><strong>均方比</strong>：MSTR/MSE~F分布。<br>（3） 统计决策。</p>
</blockquote>
<p>在R语言中，方差分析函数较为简单，具体应用后面再说。value为观察值，factor为因素。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">a.aov&lt;-aov(value~factor,data=a)</div><div class="line">summary(a.aov)</div></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th>误差来源（方差来源）</th>
<th style="text-align:center">平方和(SS)</th>
<th style="text-align:center">自由度(df)</th>
<th style="text-align:center">均方(MS)</th>
<th style="text-align:right">F</th>
</tr>
</thead>
<tbody>
<tr>
<td>组间（处理）</td>
<td style="text-align:center">SSTR</td>
<td style="text-align:center">k-1</td>
<td style="text-align:center">MSTR=SSTR/(k-1)</td>
<td style="text-align:right">MSTR/MSE</td>
</tr>
<tr>
<td>组内（误差）</td>
<td style="text-align:center">SSE</td>
<td style="text-align:center">n-k</td>
<td style="text-align:center">MSE=SSE/(n-k)</td>
<td style="text-align:right"></td>
</tr>
<tr>
<td>总计（合计）</td>
<td style="text-align:center">SST</td>
<td style="text-align:center">n-1</td>
</tr>
</tbody>
</table>
<p>当然仅仅证明有显著性差异，可能还不能满足我们的需求，所以需要测度方差分析的关系强度。<br><strong>关系强度的测量</strong><br>拒绝原假设表明因子(自变量)与观测值之间有关系，而处理平方和(SSTR)度量了自变量(行业)对因变量<br>(投诉次数)的影响效应。</p>
<blockquote>
<ul>
<li>当处理平方和比误差平方和(SSE)大， 而且大到一定程度时， 就意味着两个变量之间的关系显著， 大得越多， 表明它们之间的关系就越强。 反之， 就意味着两个变量之间的关系不显著， 小得越多， 表明它们之间的关系就越弱。</li>
</ul>
</blockquote>
<p>变量间关系的强度用处理平方和(SSTR)及误差平方和(SSE)占总平方和(SST)的比例大小来反映。<br>处理平方和占总平方和的比例记为$R^2$ ,即<br>$$R^2=\frac{SSTR（处理平方和）}{SST（总平方和）}$$<br>其平方根R就可以用来测量两个变量之间的关系强度。</p>
<h3 id="3方差分析中的多重比较"><a href="#3-方差分析中的多重比较" class="headerlink" title="3.方差分析中的多重比较"></a>3.方差分析中的多重比较</h3><p>多重比较（multiple comparison procedures）——通过对总体均值之间的配对比较来进一步检验到底哪些均值之间存在差异。</p>
<blockquote>
<ul>
<li>可采用Fisher提出的最小显著差异方法， 简写为LSD-least significant difference。LSD方法是对检验两个总体均值是否相等的t检验方法的总体方差估计加以修正（ 用MSE来代替） 而得到的。</li>
</ul>
</blockquote>
<p>方差分析中的多重比较分析步骤</p>
<blockquote>
<p>（1）提出假设<br>$H_0: \mu_i=\mu_j (第i个总体的均值等于第j个总体的均值)$<br>$H_1: \mu_i\neq\mu_j (第i个总体的均值不等于第j个总体的均值)$<br>（2）计算检验的统计量: $\bar x_i-\bar x_j$<br>（3）计算LSD,t分布的自由度为n-k（MSE的自由度为n-k）。<br>$$ LSD=t_{\alpha/2}\sqrt{MSE(\frac{1}{n_i}+\frac{1}{n_j})} $$<br>（4）决策：<br>若$\left|{\bar x_i-\bar x_j}\right|\gt LSD $，拒绝$H_0$；<br>若$\left|{\bar x_i-\bar x_j}\right|\lt LSD $，不拒绝$H_0$。</p>
</blockquote>
<h3 id="4双因子方差分析two-way-anova"><a href="#4-双因子方差分析（Two-way-ANOVA）" class="headerlink" title="4.双因子方差分析（Two-way ANOVA）"></a>4.双因子方差分析（Two-way ANOVA）</h3><p>前面介绍完了单因子方差分析，但是当我们的因子大于一个的时候，我们又该怎么分析呢？同样抛个样例问题出来。<br>假设现在我们想了解北京城市人口空间分布是否受不同环路（一环、二环、三环乃至四、五、六环）或新老城区的显著影响。所以该问题是一个典型的双因子问题，可以拆分为如下的情况：</p>
<table>
<thead>
<tr>
<th>因子</th>
<th style="text-align:center">新城区</th>
<th style="text-align:right">老城区</th>
</tr>
</thead>
<tbody>
<tr>
<td>一环</td>
<td style="text-align:center">人口</td>
<td style="text-align:right">人口</td>
</tr>
<tr>
<td>二环</td>
<td style="text-align:center">人口</td>
<td style="text-align:right">人口</td>
</tr>
<tr>
<td>三环</td>
<td style="text-align:center">人口</td>
<td style="text-align:right">人口</td>
</tr>
</tbody>
</table>
<p>对于该问题我们可以考虑用单因子方差分析来解决——即通过考虑两个因子间所有的组合来分析是否有显著影响。（二环+新城区，二环+老城区，三环+新城区，……，六环+老城区）通过这样组合来得到最后的单因子水平。但是这样处理的问题是，我们无法了解到底是新老城区的因素影响了人口的空间分布，或者是不同的环路影响了人口的空间分布，亦或是二者共同影响。所以我们需要新的方法来分析。这就是题目所述的双因子方差分析。</p>
<h4 id="41-双因子方差分析的基本假定"><a href="#4-1-双因子方差分析的基本假定" class="headerlink" title="4.1 双因子方差分析的基本假定"></a>4.1 双因子方差分析的基本假定</h4><blockquote>
<p>（1） 每个总体都服从正态分布（对于因素的每一个水平， 其观察值是来自正态分布总体的简单随机样本）。<br>（2） 各个总体的方差必须相同（对于各组观察数据， 是从具有相同方差的总体中抽取的）。<br>（3） 观察值是独立的。</p>
</blockquote>
<p>双因子方差分析实质是分析两个因素(行因素Row和列因素Column)对试验结果的影响。<br>如果两个因素对试验结果的影响是相互独立的， 分别判断行因素和列因素对试验数据的影响， 这时的双因素方差分析称为<strong>无交互作用的双因素方差分析</strong>或<strong>无重复双因素方差分析</strong>(Two-factor without replication)。<br>如果除了行因素和列因素对试验数据的单独影响外，两个因素的搭配还会对结果产生一种新的影响， 这<br>时的双因素方差分析称为<strong>有交互作用的双因素方差分析</strong>或<strong>可重复双因素方差分析</strong> (Two-factor with replication )。</p>
<h4 id="42-无交互作用双因子方差分析"><a href="#4-2-无交互作用双因子方差分析" class="headerlink" title="4.2 无交互作用双因子方差分析"></a>4.2 无交互作用双因子方差分析</h4><p>如果在一项试验中，有两个因子在变，而其余因子保持不变，则称之为双因子试验。</p>
<blockquote>
<p>设因子A有a个水平$A_1，A_2，···，A_a$，因子Ｂ有b个水平$B_1，B_2，···，B_b$，每组因子<br>组合进行1次试验，其结果为$x_{ij}$，$x_{ij}\sim N(\mu_{ij},\sigma^2)$,现在要研究它们对因变量X的影响。</p>
</blockquote>
<p><strong>（1）无交互作用双因子方差分析：模型</strong><br>$$ X_{ij}=\mu+\alpha_i+\beta_j+\varepsilon_{ij} $$<br>这里$\varepsilon_{ij}\sim iid$ $N(0,\sigma^2) $<br><strong>（2）无交互作用双因子方差分析：假设</strong><br>因子A<br>原假设：$H_0:α_1= α_2=… = α_a=0$<br>备择假设：$H1:至少一个α_i不等于0$<br>因子B<br>原假设：$H_0: β_1 = β_2 = … = β_b=0$<br>备择假设：$H1:至少一个β_i不等于0$<br><strong>（3）计算步骤（公式大全）</strong></p>
<blockquote>
<ul>
<li>均方：<br>$\bar x_{i.}$是A因素的第i个水平下各观察值的平均值<br>$$ \bar x_{i.}=\frac{\sum_{j=1}^bx_{ij}}{b}（i=1,2,\cdots,a） $$<br>$\bar x_{.j}$是B因素的第j个水平下各观察值的平均值<br>$$ \bar x_{.j}=\frac{\sum_{i=1}^ax_{ij}}{a}（i=1,2,\cdots,b） $$<br>$\bar x’$是B因素的第j个水平下各观察值的平均值<br>$$ \bar x’=\frac{\sum_{i=1}^a\sum_{j=1}^bx_{ij}}{ab} $$</li>
<li>平方和：<br>$$ SST=\sum_{i=1}^a\sum_{j=1}^b(x_{ij}-\bar x’)^2 $$<br>$$ SSA=b\sum_{i=1}^a(x_{i.}-\bar x’)^2 $$<br>$$ SSB=a\sum_{j=1}^b(x_{.j}-\bar x’)^2 $$<br>$$ SSE=\sum_{i=1}^a\sum_{j=1}^b(x_{ij}-x_{i.}-x_{.j}+\bar x’)^2 $$<br>$$ SST=SSA+SSB+SSE $$</li>
<li>计算均方（MS）构造检验统计量:<br>误差平方和除以相应的自由度，四个平方和的自由度分别是：<br>总离差平方和SST的自由度为 ab-1；<br>A因素的离差平方和SSA的自由度为 a-1；<br>B因素的离差平方和SSB的自由度为 b-1；<br>随机误差平方和SSE的自由度为 (a-1)×(b-1)。<br>A因素的均方，记为MSA，计算公式为：<br>$$ MSA=\frac{SSA}{a-1} $$<br>B因素的均方，记为MSB，计算公式为：<br>$$ MSB=\frac{SSB}{b-1} $$<br>随机误差项的均方，记为MSE，计算公式为：<br>$$ MSE=\frac{SSE}{(a-1)(b-1)} $$</li>
<li>计算检验统计量(F)<br>检验行因素的统计量<br>$$ F_A=\frac{MSA}{MSE}\sim F(a-1,(a-1)(b-1)) $$<br>检验列因素的统计量<br>$$ F_B=\frac{MSB}{MSE}\sim F(b-1,(a-1)(b-1)) $$</li>
<li>统计决策<br>将统计量的值F与给定的显著性水平$\alpha$的临界值$F_\alpha$进行比较， 作出对原假设$H_0$的决策：<br>根据给定的显著性水平a在F分布表中查找相应的临界值$F_\alpha$；<br>若$F_A&gt;F_\alpha$，则拒绝原假设，表明均值之间的差异是显著的， 即所检验的A因素对观察值有显著影响；<br>若$F_A&gt;F_\alpha$，则拒绝原假设，表明均值之间有显著差异，即所检验的B因素对观察值有显著影响。</li>
</ul>
</blockquote>
<table>
<thead>
<tr>
<th>误差来源（方差来源）</th>
<th style="text-align:center">平方和</th>
<th style="text-align:center">自由度</th>
<th style="text-align:center">均方</th>
<th style="text-align:right">F</th>
</tr>
</thead>
<tbody>
<tr>
<td>因子A</td>
<td style="text-align:center">SSA</td>
<td style="text-align:center">a-1</td>
<td style="text-align:center">MSA=SSA/(a-1)</td>
<td style="text-align:right">MSA/MSE</td>
</tr>
<tr>
<td>因子B</td>
<td style="text-align:center">SSB</td>
<td style="text-align:center">b-1</td>
<td style="text-align:center">MSB=SSB/(b-1)</td>
<td style="text-align:right">MSB/MSE</td>
</tr>
<tr>
<td>误差</td>
<td style="text-align:center">SSE</td>
<td style="text-align:center">(a-1)(b-1)</td>
<td style="text-align:center">MSE=SSE/(a-1)(b-1))</td>
<td style="text-align:right"></td>
</tr>
<tr>
<td>总计</td>
<td style="text-align:center">SST</td>
<td style="text-align:center">ab-1</td>
</tr>
</tbody>
</table>
<h4 id="43-有交互作用双因子方差分析"><a href="#4-3-有交互作用双因子方差分析" class="headerlink" title="4.3 有交互作用双因子方差分析"></a>4.3 有交互作用双因子方差分析</h4><p>除了上面的无交互作用双因子方差分析之外，可能存在的一种情况就是二者同时作用，这就是有交互作用的双因子方差分析。<br>即（$A_i,B_j$）下作了r个试验，所得结果记作$x_{ijk}$,$x_{ijk}$服从$N(\mu_{ij},\sigma^2)，i=1,\cdots,a,j=1,\cdots,b,k=1,\cdots,r$。且相互独立。<br><strong>（1）有交互作用双因子方差分析：模型</strong><br>$$ X_{ijk}=\mu+\alpha_i+\beta_j+(\alpha\beta)_{ij}+\varepsilon_{ijk} $$<br>这里$\varepsilon_{ijk}\sim iid$ $N(0,\sigma^2) $<br><strong>（2）交互作用双因子方差分析：假设</strong><br>因子A<br>原假设：$H_0:α_1= α_2=… = α_a=0$<br>备择假设：$H1:至少一个α_i不等于0$<br>因子B<br>原假设：$H_0: β_1 = β_2 = … = β_b=0$<br>备择假设：$H1:至少一个β_i不等于0$<br>交互作用<br>原假设：$H_0: αβ_{11} = αβ_{12} = … = αβ_{ab}=0$<br>备择假设：$H1:至少一个αβ_{ij}不等于0$<br><strong>计算步骤（公式大全）</strong></p>
<blockquote>
<ul>
<li>平方和<br>$$ SST=\sum_{i=1}^a\sum_{j=1}^b\sum_{k=1}^r(x_{ij}-\bar x’)^2 $$<br>$$ SSA=br\sum_{i=1}^a(x_{i.}-\bar x’)^2 $$<br>$$ SSB=ar\sum_{j=1}^b(x_{.j}-\bar x’)^2 $$<br>$$ SSAB=r\sum_{i=1}^a\sum_{j=1}^b(\bar x_{ij}-\bar x_{i.}-\bar x_{.j}+\bar x’)^2 $$<br>$$ SSE=\sum_{i=1}^a\sum_{j=1}^b\sum_{k=1}^r(x_{ijk}-\bar x_{ij})^2 $$<br>$$ SST=SSA+SSB+SSAB+SSE $$</li>
<li>计算检验统计量(F)<br>$$ F_A=\frac{MSA}{MSE}\sim F(a-1,ab(r-1)) $$<br>$$ F_B=\frac{MSB}{MSE}\sim F(b-1,ab(r-1)) $$<br>$$ F_{AB}=\frac{MSAB}{MSE}\sim F((a-1)(b-1),ab(r-1)) $$<br>拒绝域<br>$$ F_A\gt F_\alpha(a-1,ab(r-1)) $$<br>$$ F_B\gt F_\alpha(b-1,ab(r-1)) $$<br>$$ F_{AB}\gt F_\alpha((a-1)(b-1),ab(r-1)) $$</li>
</ul>
</blockquote>
<table>
<thead>
<tr>
<th>误差来源（方差来源）</th>
<th style="text-align:center">平方和</th>
<th style="text-align:center">自由度</th>
<th style="text-align:center">均方</th>
<th style="text-align:right">F</th>
</tr>
</thead>
<tbody>
<tr>
<td>因子A</td>
<td style="text-align:center">SSA</td>
<td style="text-align:center">a-1</td>
<td style="text-align:center">MSA=SSA/(a-1)</td>
<td style="text-align:right">MSA/MSE</td>
</tr>
<tr>
<td>因子B</td>
<td style="text-align:center">SSB</td>
<td style="text-align:center">b-1</td>
<td style="text-align:center">MSB=SSB/(b-1)</td>
<td style="text-align:right">MSB/MSE</td>
</tr>
<tr>
<td>交互作用</td>
<td style="text-align:center">SSAB</td>
<td style="text-align:center">(a-1)(b-1)</td>
<td style="text-align:center">MSB=SSAB/(a-1)(b-1)</td>
<td style="text-align:right">MSAB/MSE</td>
</tr>
<tr>
<td>误差</td>
<td style="text-align:center">SSE</td>
<td style="text-align:center">ab(r-1)</td>
<td style="text-align:center">MSE=SSE/ab(r-1))</td>
<td style="text-align:right"></td>
</tr>
<tr>
<td>总计</td>
<td style="text-align:center">SST</td>
<td style="text-align:center">abr-1</td>
</tr>
</tbody>
</table>
<h3 id="5实验设计初步"><a href="#5-实验设计初步" class="headerlink" title="5.实验设计初步"></a>5.实验设计初步</h3><p>谈完了方差分析的各种理论，回顾开头我们提到的“搞实验的同学经常使用单因素方差分析”，所以在实验设计里，方差分析的应用是非常普遍的。所以这里也谈谈实验设计的一些内容（笔者非实验设计人员，所以仅谈谈一些理念）。<br>一个实验必须施加一些处理，来观察这些处理会不会对实验结果或者测量值有影响。不同的处理是用来比较不同的总体。而好的实验，这些处理必须是随机的。所谓的随机就是指，每个样本有同等的机会（等概率事件）接收这些处理。<br>所以对于这个随机化的比喻就是，你必须闭着眼睛选，才能保证你选的水平是随机的。<br>实验相比于观察的优点也在于此，随机化使的两个比较总体尽可能相似，一切东西都是一样的除了选择处理的水平，如果实验结果存在差异的话，我们就能得出结论，这个处理是否会造成实验结果的不同。实验是我们设计的，可以控制实验的变量（很熟悉的控制变量法）——我们能保证我们比较的两个总体除了处理之外大致是一样的，而观察则无法保证我们所观察的两个总体仅仅存在某个处理上的差异，其他都是一致的。<br>从这个角度来说，实验设计的注意要点如下：</p>
<blockquote>
<p>（1） 因子数量（单因子方差分析，双因子方差分析……）；<br>（2） 因子处理的数量。<br>（3） 实验设计类型</p>
</blockquote>
<p>前两个点大家可能都很清楚了，主要谈谈第三个点。<br>实验设计类型严格来说包括如下：</p>
<blockquote>
<p>（1）完全因素位级组合（Full factorial design）</p>
<ul>
<li>完全随机化设计</li>
<li>随机化区组设计<br>（2）部分因素位级组合（Fractional factorial design）</li>
</ul>
</blockquote>
<p><strong>（1）完全因素位级组合（Full factorial design）</strong><br>顾名思义，就是讲所有因子的所有组合考虑一遍，造成的问题就是——实验规模巨大。<br>以下几个要点：</p>
<blockquote>
<ul>
<li>如果有k个因子，对于k个因子的第i个水平来说，会有$n_i$个水平的观测值：<br>$$ n=\prod_{i=1}^k n_i $$</li>
<li>必须实验每个可能的因子水平的组合。</li>
<li>必须捕获有关交互的全部信息。</li>
<li>大量的工作。</li>
</ul>
</blockquote>
<p>主要还包括两种类型。</p>
<blockquote>
<ul>
<li>完全随机化设计(completely randomized design)——“处理” 被随机地指派给试验单元的一种设计，“处理” 是指可控制的因子的各个水平 “试验单元(experiment unit)”是接受“处理”的对象或实体。</li>
<li>随机化区组设计(randomized block design)——先按一定规则将试验单元划分为若干同质组， 称为“ 区组(block)”，再将各种处理随机地指派给各个区组,分组后再将每个品种（ 处理） 随机地指派给每一<br>个区组的设计就是随机化区组设计。<strong>如果可能， 我们应选择随机化区组设计</strong>。</li>
</ul>
</blockquote>
<p><strong>（2）部分因素位级组合（Fractional factorial design）</strong></p>
<blockquote>
<ul>
<li>仅测量部分因子水平的组合的结果。</li>
<li>必须认真设计来捕获所有可能的交互作用。</li>
<li>相比而言，工作量降低了，不确定性增大了。</li>
<li>在知道一些因子不存在交互作用的前提下特别有效。</li>
</ul>
</blockquote>
<p>典型的是正交试验设计——利用“正交表”进行科学地安排与分析多因子试验的方法。其主要优点是能在很多试验方案中挑选出代表性强的少数几个试验方案，并且通过这少数试验方案的试验结果的分析，推断出最优方案，同时还可以作进一步的分析，得到比试验结果本身给出的还要多的有关各因子的信息。</p>
<blockquote>
<ul>
<li>正交表的性质（正交性）<br>每列中不同数字出现的次数是相等的。每个因子不同的水平出现的次数相同。表示：在试验安排中，所挑选出来的水平组合是均匀分布的（每个因子的各水平出现的次数相同）——<strong>整齐可比性</strong>。<br>对于任意两列，将同一行的两个数字看成有序数对时，每种数对出现的次数是相等的。任意两个因子都全面试验。表示：任意两因子的各种水平的搭配在所选试验中出现的次数相等——<strong>均衡分散性</strong>。<br>正交表的优点：各因子的各水平的搭配是均衡的。<br>试验点均衡分散在全部试验条件之中，使得它的代表性很强，能够比较全面地反映、分析出全面试验的最优点来。</li>
<li>用正交表安排试验的步骤<br>明确试验目的，确定试验指标。<br>确定要考察的（主要）因子和水平——各水平次序最好随机排列（因为正交试验不是全面试验）。<br>选用合适的正交表，安排试验计划：根据因子的水平，选择相应水平的正交表；再根据欲考察因子的个数选定正交表中因子的个数。<br>根据计划进行试验，确定试验指标。<br>对试验结果进行分析，得出合理的结论。</li>
<li>正交试验结果的分析方法<br><strong>直观分析法</strong>：简单、直观、容易操作，计算量少。<br><strong>方差分析</strong>：理论根据可靠，结果可信度高，计算量比较大。<br><strong>正交试验的直观分析法</strong><br>计算各因子各水平的综合平均值，选出各因子的最优水平。对给定因子的每个水平，其它因子对试验指标的影响是相同的，因此可用综合平均值来比较各指标对试验指标的影响（综合可比性）。<br>计算个因子综合平均值的极差，分清因子的主次（在平均值中最大数与最小数之差，称为极差。极差的大小序列，表示因子的重要性大小）。<br>选定最优组合——选定最优组合的原则：对于重要因子，一定要选最优水平，以期达到较好试验效果；对于不重要因子，由于它们的水平变动对试验结果影响不大，可根据节约、高效、简便易行等实际情况灵活选定其水平。<br><strong>正交试验的方差分析</strong><br>假定试验指标服从正态分布<br>基本思想与双因子方差分析方法一致：将总的离差平方和分解成各因子及各交互作用的离差平方和，构造F统计量，对各因子是否对试验指标具有显著影响，作F检验。</li>
</ul>
</blockquote>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/05/10/应用统计学与R语言实现学习笔记（七）——拟合优度检验/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Dai Shaoqing">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GISerDaiShaoqing's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/05/10/应用统计学与R语言实现学习笔记（七）——拟合优度检验/" itemprop="url">
                  应用统计学与R语言实现学习笔记（七）——拟合优度检验
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-05-10T00:00:00+08:00">
                2017-05-10
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/统计与模型/" itemprop="url" rel="index">
                    <span itemprop="name">统计与模型</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/2017/05/10/应用统计学与R语言实现学习笔记（七）——拟合优度检验/" class="leancloud_visitors" data-flag-title="应用统计学与R语言实现学习笔记（七）——拟合优度检验">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">Visitors </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="chapter-7-goodness-of-fit"><a href="#Chapter-7-Goodness-of-Fit" class="headerlink" title="Chapter 7 Goodness of Fit"></a>Chapter 7 Goodness of Fit</h1><p>本篇是第七章，内容是拟合优度检验。</p>
<h3 id="1多项分布"><a href="#1-多项分布" class="headerlink" title="1.多项分布"></a>1.多项分布</h3><p>拟合优度检验的第一个应用是关于多项总体。那么多项总体（或者多项分布）是什么呢？</p>
<blockquote>
<ul>
<li>多项分布是二项分布的推广。</li>
<li>总体被分为几个互不相交的类别。</li>
<li>多项分布假设：每次试验有且仅有一个结果发生；每次试验独立；每次试验概率不变。</li>
</ul>
</blockquote>
<p>拟合优度检验-多项总体步骤</p>
<blockquote>
<ul>
<li>将所观测到的数据与理论上的期望值进行比较。</li>
<li>步骤：<br>1.计算每一类实际观测到的频次$f_i$；<br>2.计算每一类理论上的期望频次$e_i$；<br>3.计算 Chi-square 统计量——$\chi^2=\sum(f_i-e_i)^2/e_i$。<br>其中自由度 (df) = k-1， k 是多项总体的类别数。</li>
</ul>
</blockquote>
<p>拟合优度检验用于多项总体检验没有直接的函数，这里用R语言的自编函数实现，体会下具体的算法（当然感觉自己写的略复杂）。代码依旧是后面放出，函数具体使用说明也会附上。</p>
<h3 id="2独立性"><a href="#2-独立性" class="headerlink" title="2.独立性"></a>2.独立性</h3><p>依旧是从问题出发——性别与购物频率是否有关系<br>独立性检验——该统计方法常用于检验两个分类变量是否有关系。那么首先要提到两个概念——独立事件和非独立事件（independent and dependent events)。</p>
<blockquote>
<ul>
<li>独立事件——一个事物发生不会对其他事物发生概率造成影响。</li>
<li>非独立事件——一个事物发生会影响其他事物发生概率。</li>
</ul>
</blockquote>
<p>接着统计学构建出了一个表来进行独立性检验。这就是联立表（Contingency Tables)。</p>
<blockquote>
<ul>
<li>解决多总体比例问题。</li>
<li>之前通常用两个或两个以上特征来对样本观测值分类。</li>
<li>也被称为交叉表。</li>
</ul>
</blockquote>
<p><img src="http://img.blog.csdn.net/20170514170656815?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvRVNBX0RTUQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p>
<p>一般在R中，使用Table函数即可生成两个特征（分类变量）的联立表，xtabs则是根据公式创立联立表，prop.table则可以直接计算出比例。<br>联立表如何做独立性检验呢？首先提出假设（这里不详述，相信大家应该懂怎么建立了），接着计算期望的联立表每个单元格的期望频次。<br>$$ e_{ij}=\frac{(i^{th} Rowtotal)(j^{th} Columtotal)}{Total SampleSize}。 $$<br>接着就可以对比实际频次和期望频次，然后我们用卡方（chi-square)统计量进行检验。<br>$$ \chi^2=\sum_{i=1}^n\sum_{j=1}^m\frac{(f_{ij}-e_{ij})^2}{e_{ij}} with, df=(n-1)(m-1)。 $$<br>n为行数，m为列数，$f_{ij}$,$e_{ij}$分别为第i行和第j列的$单元格_{ij}$实际频次和期望频次。<br>当然这个方法也可以用来检验顺序变量和分类变量。方法类似，这里不赘述。</p>
<h3 id="3概率分布"><a href="#3-概率分布" class="headerlink" title="3.概率分布"></a>3.概率分布</h3><p>拟合优度检验的最重要的应用其实是探测一个数据具体的概率分布。<br>当然探测数据分布的第一方式——是可见即可得的可视化。主要包括前面提到过的直方图和QQ图。<br>QQ图——Quantile-Quantile Plots（分位数图）：</p>
<blockquote>
<ul>
<li>适用于小数据集。</li>
<li>猜测分布的基础方法。</li>
<li>用来绘制QQ图的数据必须落在该分布内。</li>
<li>如果散点图接近直线，说明数据分布接近正态分布。</li>
</ul>
</blockquote>
<p>这里给出绘制QQ图的原理：</p>
<blockquote>
<ul>
<li>对样本容量为N的样本数据按照升序排序。</li>
<li>计算从1到N排序的百分比。</li>
<li>从百分位数得分的关系找到中心分数。</li>
<li>找到对应于中心分数的z值（标准正态分布）。</li>
<li>绘制对应z值的观测点数据。</li>
</ul>
</blockquote>
<p>接着用R语言实现<br><figure class="highlight r"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#QQ plot</span></div><div class="line"><span class="comment">#generation of random number that fall in normal distribution</span></div><div class="line">a&lt;-rnorm(<span class="number">200</span>,<span class="number">0</span>,<span class="number">1</span>)</div><div class="line"></div><div class="line"><span class="comment">#plot</span></div><div class="line">jpeg(<span class="string">"plot1.jpg"</span>,width = <span class="number">5000</span>,height = <span class="number">4000</span>,units = <span class="string">"px"</span>,res = <span class="number">1000</span>)</div><div class="line">qqnorm(a)</div><div class="line">qqline(a,col=<span class="string">"red"</span>)</div><div class="line">dev.off()</div></pre></td></tr></table></figure></p>
<p><img src="http://img.blog.csdn.net/20170510011333319?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvRVNBX0RTUQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p>
<p>除了QQ图之外，另外一类方法就是通过统计方法——拟合优度检验来探测数据是否正态分布。<br>以正态分布为例。<br>过程：</p>
<blockquote>
<ul>
<li>获取样本数据。</li>
<li>将样本结果分组（单元格）。</li>
<li>比较实际与预期值。</li>
</ul>
</blockquote>
<p>统计量如下：<br>$$ \chi^2=\sum_{i=1}^k\frac{(f_i-ei-)^2}{e_i}。 $$<br>R语言中可以用chisp.test函数进行正态分布测验。</p>
<p>此外对于有某种特定分布的非正态数据可以通过数学变换转变为正态分布数据。<br>常用的一般包括：</p>
<blockquote>
<ul>
<li>对数变换。</li>
<li>开方变换。</li>
<li>指数或平方变换。</li>
</ul>
</blockquote>
<p>这里的数学变换需要根据大家实际研究需求决定。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/05/08/应用统计学与R语言实现学习笔记（六）——假设检验/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Dai Shaoqing">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GISerDaiShaoqing's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/05/08/应用统计学与R语言实现学习笔记（六）——假设检验/" itemprop="url">
                  应用统计学与R语言实现学习笔记（六）——假设检验
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-05-08T00:00:00+08:00">
                2017-05-08
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/统计与模型/" itemprop="url" rel="index">
                    <span itemprop="name">统计与模型</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/2017/05/08/应用统计学与R语言实现学习笔记（六）——假设检验/" class="leancloud_visitors" data-flag-title="应用统计学与R语言实现学习笔记（六）——假设检验">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">Visitors </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="chapter-6-hypothesis-test"><a href="#Chapter-6-Hypothesis-Test" class="headerlink" title="Chapter 6 Hypothesis Test"></a>Chapter 6 Hypothesis Test</h1><p>本篇是第6章，内容是假设检验。</p>
<h3 id="1基本思想"><a href="#1-基本思想" class="headerlink" title="1.基本思想"></a>1.基本思想</h3><p>我们还是从问题开始讨论。这回提个接地气的问题——雄安新区批复前后对该地区房价是否有差异？<br>嗯，假设检验其实就是为了解决这类问题。<br>假设检验的基本思想——我们有样本，但是无法获得总体，需要对总体的分布形式或分布参数事先作出某种假设，然后根据样本观测值，运用统计分析的方法来检验这一假设是否正确。<br>分解开来，假设检验=假设+检验（或者假设检验）。<br>假设(hypothesis)——对总体的参数的具体数值（或分布形式）所作的陈述（总体参数包括总体均值、比例、 方差等，分析之前必需陈述）。<br>假设检验(hypothesis test)—先对总体的参数（ 或分布形式） 提出某种假设，然后利用样本信息判断假设是否成立的过程（有参数检验和非参数检验；逻辑上运用反证法， 统计上依据小概率原理）。如图。</p>
<p><img src="http://img.blog.csdn.net/20170508115209606?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvRVNBX0RTUQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p>
<p>假设检验的思想还可以去搜索Fisher 显著性检验的思想(女士品茶试验)的故事深深体会，这里就不详述了。有兴趣的同学可以点击下文的科学网链接查看。</p>
<blockquote>
<p><a href="http://blog.sciencenet.cn/blog-624263-795715.html" target="_blank" rel="external">http://blog.sciencenet.cn/blog-624263-795715.html</a></p>
</blockquote>
<h3 id="2原假设和备择假设"><a href="#2-原假设和备择假设" class="headerlink" title="2.原假设和备择假设"></a>2.原假设和备择假设</h3><p>从前面的介绍我们知道，假设检验的第一步是建立假设。那么假设分为两种（原假设和备择假设）。那么这二者具体又是什么呢？</p>
<blockquote>
<ul>
<li>原假设(null hypothesis)——原假设又称“ 0假设”，总是有符号 =， ≥ 或≤，表示为 $H_0$。是研究者想收集证据予以反对的假设（生产实践中常对应正常情形，如均值与设计一致）；一般来说，原假设是一旦拒绝便要采取行动的假设。因此， 原假设总是“受到保护的假设” ，没有充分的证据是不能拒绝原假设的。例如，对一家信誉很好的工厂的产品进行检验，原假设一般是“ 产品合格”。</li>
<li>备择假设(alternative hypothesis)——研究者想收集证据予以支持的假设， 一旦发生就要采取行动， 是与原假设对立的假设，也称“研究假设”，总是有符号 ≠， &gt; 或 &lt;，表示为 $H_1$。</li>
</ul>
</blockquote>
<p>总结起来就是，原假设是统计学史上最悲催角色——它从一开始诞生，就是为了被科学家们发好人卡拒绝而存在的一个假设。备择假设才是科学家们追求的白富美。<br>搞明白了这两个假设，下一步我们做假设检验的时候，就要先提出假设了，这里给了一些提出假设的要点：</p>
<blockquote>
<ul>
<li>原假设和备择假设是一个完备事件组， 而且相互对立（在一项假设检验中， 原假设和备择假设必有一个成立， 而且只有一个成立）。</li>
<li>先确定备择假设， 再确定原假设。</li>
<li>等号“ =” 总是放在原假设上。</li>
<li>因研究目的不同， 对同一问题可能提出不同的假设（ 也可能得出不同的结论）。</li>
</ul>
</blockquote>
<p>同时在实际应用中，我们有不同的需求，因此又有双侧检验和单侧检验的区分。</p>
<blockquote>
<ul>
<li>双侧检验——备择假设没有特定的方向性，并含有符号“=”的假设检验，称为双侧检验或双尾检验(two-tailed test)</li>
<li>单侧检验——备择假设具有特定的方向性，并含有符号“&gt;”或“&lt;”的假设检验，称为单侧检验或单尾检验(one-tailed test)。其中备择假设的方向为“&lt;”，称为左侧检验，备择假设的方向为“&gt;”，称为右侧检验。</li>
</ul>
</blockquote>
<p>原假设与备择假设形式：</p>
<blockquote>
<ul>
<li>双边检验：$ H_0: \mu=2，H_1: \mu\neq2 $。</li>
<li>单边检验：左侧检验——$ H_0: \mu\le2，H_1: \mu>2 $，右侧检验——$ H_0: \mu\ge2，H_1: \mu&lt;2 $。</li>
</ul>
</blockquote>
<p>所见即所得，用一张图来表示假设检验过程。</p>
<p><img src="http://img.blog.csdn.net/20170508122049152?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvRVNBX0RTUQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p>
<p>所以拒绝原假设的理由是假设检验中的小概率原理。那么什么是小概率？</p>
<blockquote>
<ul>
<li>在一次试验中， 一个几乎不可能发生的事件发生的概率。</li>
<li>在一次试验中小概率事件一旦发生， 我们就有理由拒绝原假设。</li>
<li>小概率由研究者事先确定。</li>
</ul>
</blockquote>
<p>所以拒绝$H_0$的理由就是</p>
<p><img src="http://img.blog.csdn.net/20170508122334492?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvRVNBX0RTUQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p>
<p><img src="http://img.blog.csdn.net/20170508122348076?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvRVNBX0RTUQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p>
<h3 id="3第一类错误和第二类错误"><a href="#3-第一类错误和第二类错误" class="headerlink" title="3.第一类错误和第二类错误"></a>3.第一类错误和第二类错误</h3><p>上文介绍了假设检验的过程，但是假设检验过程会不会出现错误呢？其实大家仔细分析拒绝原假设的理由就会发现问题了。通常情况下原假设是小概率事件，但是小概率事件≠0概率事件。小概率事件不是不发生，而是发生概率较小。就像天气预报说明天有99%的可能不下雨，结果1%的可能性成为了事实，明天下雨了。因此假设检验中会有两类错误（弃真错误和取伪错误）经常出现。<br>（1）第一类错误(弃真错误)：</p>
<blockquote>
<ul>
<li>原假设为真时拒绝原假设。</li>
<li>第一类错误的概率为α（没错，就是它，我们的好朋友，小α。咳咳咳，就是显著性水平，一般由研究者事先指定，常用的值有0.01, 0.05, 0.10）。</li>
</ul>
</blockquote>
<p>（2）第二类错误（取伪错误）：</p>
<blockquote>
<ul>
<li>原假设为假时未拒绝原假设。</li>
<li>第二类错误的概率记为β。</li>
</ul>
</blockquote>
<p><img src="http://img.blog.csdn.net/20170508123318554?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvRVNBX0RTUQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p>
<p><img src="http://img.blog.csdn.net/20170508131755305?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvRVNBX0RTUQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p>
<p>α和β的关系——α和β的关系就像翘翘板， α小β就大，α大β就小。所以两类错误不可能同时发生（第一类只在$H_0$为真时发生，第而类只在$H_0$为假时发生）。<br>影响β的因素：</p>
<blockquote>
<ul>
<li>总体参数的真值。</li>
<li>显著性水平α（当α减少时增大）。</li>
<li>总体标准差σ（当σ增大时增大）。</li>
<li>样本容量n（当n减少时增大）。</li>
</ul>
</blockquote>
<h3 id="4统计量与拒绝域"><a href="#4-统计量与拒绝域" class="headerlink" title="4.统计量与拒绝域"></a>4.统计量与拒绝域</h3><p>讲了这么多，但是还没有介绍假设检验的计算过程。假设检验的过程依赖于两个重要数学概念（统计量与拒绝域，前面已经有稍微提到了）。这里再做具体介绍。<br>检验统计量(test statistic)——根据样本观测结果计算得到的， 并据以对原假设和备择假设作出决策的某个样本统计量，是对样本估计量的标准化结果（原假设$H_0$为真，点估计量的抽样分布）。<br>标准化的检验统计量公式为：<br>$$ 标准化的检验统计量=\frac{点估计量-假设值}{点估计量的抽样标准差} $$<br>显著性水平和拒绝域的三种情况：<br>双侧检验：</p>
<p><img src="http://img.blog.csdn.net/20170508135530979?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvRVNBX0RTUQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p>
<p>左侧检验：</p>
<p><img src="http://img.blog.csdn.net/20170508135602105?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvRVNBX0RTUQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p>
<p>右侧检验：</p>
<p><img src="http://img.blog.csdn.net/20170508135615106?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvRVNBX0RTUQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p>
<p>统计量落在拒绝域时，我们就可以拒绝原假设。具体如下：</p>
<blockquote>
<ul>
<li>给定显著性水平α，查表得出相应的临界值$z_{\alpha},z_{\alpha/2},t_{\alpha},t_{\alpha/2},\cdots$。</li>
<li>将检验统计量的值与α水平的临界值进行比较。</li>
<li>作出决策：双侧检验——|统计量| &gt; 临界值，拒绝$H_0$；左侧检验——统计量 &lt; 临界值，拒绝$H_0$；右侧检验——统计量 &gt; 临界值，拒绝$H_0$。</li>
</ul>
</blockquote>
<h3 id="5利用p值进行决策"><a href="#5-利用p值进行决策" class="headerlink" title="5.利用p值进行决策"></a>5.利用p值进行决策</h3><p>如何利用假设检验解决实际问题？很重要的一个应用是在决策上。就如标题说的，利用p值进行决策。那么什么是p值?<br>p值(p-value)：在一个假设检验问题中，拒绝原假设的最小显著性水平。</p>
<blockquote>
<ul>
<li>在原假设为真的条件下，检验统计量的观察值大于或等于其计算值的概率(双侧检验为分布中检验统计量两侧面积的总和;单侧检验为分布中检验统计量相应单侧面积）。</li>
<li>反映实际观测到的数据与原假设$H_0$之间的一致程度。</li>
<li>被称为观察到的（或实测的）显著性水平。</li>
<li>决策规则： 若p值&lt;α， 拒绝$H_0$。</li>
</ul>
</blockquote>
<p>p值法步骤（以大样本均值为例）<br>将样本统计量转换成检验统计量z</p>
<blockquote>
<ul>
<li>计算p值： Z为标准正态分布随机变量（$p值=(\left|Z\right|\ge z)(双侧),p值=(Z\le z)(左侧),p值=(Z\ge z)(右侧)$）</li>
<li>比较p值和α：<br>如果α≥p值，拒绝$H_0$;<br>如果$α&lt;$p值，不能拒绝$H_0$。</li>
</ul>
</blockquote>
<p>假设检验结论的表述<br>假设检验的目的就在于试图找到拒绝原假设的证据， 而不在于证明什么是正确的。</p>
<blockquote>
<ul>
<li>拒绝原假设时结论是清楚的。</li>
<li>当不拒绝原假设时——并未给出明确的结论，不能说原假设是正确的， 也不能说它不是正确的。但也未说它不是10。 我们只能说样本提供的证据还不足以推翻原假设。</li>
</ul>
</blockquote>
<p>假设检验步骤的总结</p>
<blockquote>
<ul>
<li>陈述原假设和备择假设。</li>
<li>从所研究的总体中抽出一个随机样本。</li>
<li>确定一个适当的检验统计量， 并利用样本数据算出其具体数值。</li>
<li>确定一个适当的显著性水平， 并计算出其临界值， 指定拒绝域。</li>
<li>将统计量的值与临界值进行比较， 作出决策——统计量的值落在拒绝域，拒绝$H_0$，否则不拒绝$H_0$，也可以直接利用p值作出决策。</li>
</ul>
</blockquote>
<h3 id="6一个总体参数的检验"><a href="#6-一个总体参数的检验" class="headerlink" title="6.一个总体参数的检验"></a>6.一个总体参数的检验</h3><p>前面的理论讲的差不多了，又到了典型总体参数的检验内容的介绍了。依旧是先一个总体参数的检验（总体均值、总体比例、总体方差）。<br>总体均值的检验(大样本： n≥30)<br>使用z检验统计量：<br>$\sigma^2已知$：<br>$$ z=\frac{\bar x-\mu_0}{\sigma/\sqrt{n}}\sim N(0,1)。 $$<br>$\sigma^2未知$：<br>$$ z=\frac{\bar x-\mu_0}{s/\sqrt{n}}\sim N(0,1)。 $$</p>
<p>总体均值的检验(正态总体小样本)<br>检验统计量：<br>$\sigma^2已知$：<br>$$ z=\frac{\bar x-\mu_0}{\sigma/\sqrt{n}}\sim N(0,1)。 $$<br>$\sigma^2未知$：<br>$$ t=\frac{\bar x-\mu_0}{s/\sqrt{n}}\sim t(n-1)。$$<br>总体比例的检验<br>假定条件：</p>
<blockquote>
<ul>
<li>总体服从二项分布；</li>
<li>可用正态分布来近似(大样本)。</li>
</ul>
</blockquote>
<p>检验的Z统计量：<br>$$ z=\frac{\bar q-p_0}{\sqrt{\frac{p_0(1-p_0)}{n}}}\sim N(0,1)，p_0为假设的总体比例。 $$<br>总体方差的检验<br>检验一个总体的方差或标准差，假设总体近似服从正态分布，使用$\chi^2$分布。<br>检验统计量：<br>$$ \chi^2=\frac{(n-1)s^2}{\sigma_0^2}\sim \chi^2(n-1)。 $$</p>
<p><img src="http://img.blog.csdn.net/20170508143623860?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvRVNBX0RTUQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p>
<p>这里顺带提下作为统计推断的两大分支的区间估计和假设检验的关系。</p>
<blockquote>
<ul>
<li>过程相似：如果假设均值在95%的置信区间之外，双边检验将拒绝原假设（显著性水平为5%）。</li>
<li>逻辑不同：置信区间——不知道均值多少而要估计它；假设检验: 假定一个均值要看数据是否支持这个假设。</li>
</ul>
</blockquote>
<p>另外还是要谈一谈统计学与实际问题——这里谈的是统计显著性和实际显著性。</p>
<p>一个被拒绝的原假设意味着有统计显著性，但未必有实际显著性。这种情况常发生在大样本或精确测量场合，如Kepler的行星运行第一定律：行星轨道是椭圆的，当时吻合程度很好，100年后，仪器更高级、测量更精确，该假设被拒绝，因为行星间交互作用导致摄动。因此不要盲目使用统计显著性。此外，显著性水平α的选择也是个很关键的问题。一般来说：</p>
<blockquote>
<ul>
<li>α不宜过小，否则第二类错误概率会较大。</li>
<li>α的选择与判断发生错误时要付出的代价大小有关。</li>
<li>α的选择是决策问题。</li>
</ul>
</blockquote>
<h3 id="7两个总体参数的检验"><a href="#7-两个总体参数的检验" class="headerlink" title="7.两个总体参数的检验"></a>7.两个总体参数的检验</h3><p>讲完了一个总体参数，照例来讲就两个总体参数（两个总体均值之差，两个总体比例之差，两个总体方差比）。<br>独立大样本两总体均值之差检验<br>假定条件：</p>
<blockquote>
<ul>
<li>两个样本是独立的随机样本。</li>
<li>大样本($n_1\ge30和n_2\ge30$)。</li>
</ul>
</blockquote>
<p>检验统计量：<br>$$ \sigma_1^2，\sigma_2^2已知：z=\frac{(\bar x_1-\bar x_2)-(\mu_1-\mu_2)}{\sqrt{\frac{\sigma_1^2}{n_1}+\frac{\sigma_2^2}{n_2}}}\sim N(0,1)。 $$<br>$$ \sigma_1^2，\sigma_2^2未知：z=\frac{(\bar x_1-\bar x_2)-(\mu_1-\mu_2)}{\sqrt{\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2}}}\sim N(0,1)。 $$<br>正态总体独立小样本均值之差检验（$\sigma_1^2，\sigma_2^2已知$）<br>假定条件：</p>
<blockquote>
<ul>
<li>两个独立的小样本。</li>
<li>两个总体都是正态分布。</li>
<li>$\sigma_1^2，\sigma_2^2已知。$</li>
</ul>
</blockquote>
<p>检验统计量:<br>$$z=\frac{(\bar x_1-\bar x_2)-(\mu_1-\mu_2)}{\sqrt{\frac{\sigma_1^2}{n_1}+\frac{\sigma_2^2}{n_2}}}\sim N(0,1)。 $$<br>正态总体独立小样本均值之差检验($\sigma_1^2，\sigma_2^2$未知但$\sigma_1^2=\sigma_2^2$)<br>假定条件：</p>
<blockquote>
<ul>
<li>两个独立的小样本。</li>
<li>两个总体都是正态分布。</li>
<li>$\sigma_1^2，\sigma_2^2未知但相等，即\sigma_1^2=\sigma_2^2。$</li>
</ul>
</blockquote>
<p>检验统计量：<br>$$t=\frac{(\bar x_1-\bar x_2)-(\mu_1-\mu_2)}{s_p\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}}，其中s_p=\frac{(n_1-1)s_1^2+(n_2-1)s_2^2}{n_1+n_2-2}，自由度：n_1+n_2-2。 $$</p>
<p>两个总体均值之差的检验($\sigma_1^2，\sigma_2^2$未知且不相等$\sigma_1^2\ne\sigma_2^2$)<br>假定条件：</p>
<blockquote>
<ul>
<li>两个总体都是正态分布。</li>
<li>$\sigma_1^2，\sigma_2^2未知且不相等，即\sigma_1^2\ne\sigma_2^2。$</li>
<li>样本容量相等，$n_1=n_2=n$。</li>
</ul>
</blockquote>
<p>检验统计量：<br>$$t=\frac{(\bar x_1-\bar x_2)-(\mu_1-\mu_2)}{\sqrt{\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2}}}=\frac{(\bar x_1-\bar x_2)-(\mu_1-\mu_2)}{\sqrt{\frac{s_1^2+s_2^2}{n}}}，自由度：n_1+n_2-2=2(n-1)。 $$</p>
<p>两个总体均值之差的检验($\sigma_1^2，\sigma_2^2$未知且不相等$\sigma_1^2\ne\sigma_2^2$)<br>假定条件：</p>
<blockquote>
<ul>
<li>两个总体都是正态分布。</li>
<li>$\sigma_1^2，\sigma_2^2未知且不相等，即\sigma_1^2\ne\sigma_2^2。$</li>
<li>样本容量相等，$n_1\ne n_2$。</li>
</ul>
</blockquote>
<p>检验统计量：<br>$$t=\frac{(\bar x_1-\bar x_2)-(\mu_1-\mu_2)}{\sqrt{\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2}}}，自由度：最接近v的整数——v=\frac{(\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2})^2}{\frac{(s_1^2/n_1)^2}{n_1-1}+\frac{(s_2^2/n_2)^2}{n_2-1}}。 $$</p>
<p>两个总体均值之差的检验(匹配样本)<br>假定条件:</p>
<blockquote>
<ul>
<li>两个总体配对差值构成的总体服从正态分布。</li>
<li>配对差是由差值总体中随机抽取的。</li>
<li>数据配对或匹配(重复测量 (前/后))。</li>
</ul>
</blockquote>
<p>$$ 样本差值均值\bar d=\frac{\sum_{i=1}^n d_i}{n_d}, 样本差值标准差值 s_d=\sqrt{\frac{\sum_{i=1}^n(d_i-\bar d)^2}{n_d-1}}。 $$<br>大样本检验统计量：<br>$$ z=\frac{\bar d-d_0}{s_d/\sqrt{n_d}}\sim N(0,1)。 $$<br>小样本检验统计量：<br>$$ t=\frac{\bar d-d_0}{s_d/\sqrt{n_d}}\sim t(n-1)。 $$</p>
<p>两个总体比例之差的检验<br>假定条件：</p>
<blockquote>
<ul>
<li>两个总体都服从二项分布。</li>
<li>可以用正态分布来近似。</li>
</ul>
</blockquote>
<p>检验统计量：<br>检验$H_0$： $p_1-p_2=0$<br>$$ z=\frac{\bar p_1-\bar p_2}{\sqrt{\bar p(1-\bar p)(\frac{1}{n_1}+\frac{1}{n_2})}}，其中\bar p=\frac{x_1+x_2}{n_1+n_2}=\frac{\bar p_1n_1+\bar p_2n_2}{n_1+n_2}。 $$<br>检验$H_0$： $p_1-p_2=d_0$<br>$$ z=\frac{(\bar p_1-\bar p_2)-d_0}{\sqrt{\frac{\bar p_1(1-\bar p_1)}{n_1}+\frac{\bar p_2(1-\bar p_2)}{n_2}}}。 $$</p>
<p>两个总体方差比的检验(F检验)<br>假定条件：</p>
<blockquote>
<ul>
<li>两个总体都服从正态分布。</li>
<li>两个独立的随机样本。</li>
</ul>
</blockquote>
<p>检验统计量：<br>$$ F=\frac{s_1^2}{s_2^2}\sim F(n_1-1,n_2-1)或 F=\frac{s_2^2}{s_1^2}\sim F(n_2-1,n_1-1)。 $$</p>
<p>最后的总结就是如下图。</p>
<p><img src="http://img.blog.csdn.net/20170508152254020?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvRVNBX0RTUQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p>
<p>最后的最后，回到开头提的问题——雄安新区。该问题其实是两个总体参数的检验问题——两个总体均值之差的问题（两个总体分别是批复前的房价和批复后的房价）。所以如果要讨论该问题，可以考虑从批复前后的房价，抽取配对大样本或小样本(楼盘房价）进行假设检验，这样我们就能在统计学上证明这件事对雄安房价的显著影响啦。本篇涉及的R语言内容较少，还是老规矩，放到后面的第14章去讨论。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="Dai Shaoqing" />
          <p class="site-author-name" itemprop="name">Dai Shaoqing</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">26</span>
                <span class="site-state-item-name">posts</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">6</span>
                <span class="site-state-item-name">categories</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">17</span>
                <span class="site-state-item-name">tags</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/GISerDaiShaoqing" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://weibo.com/2884386252/profile?rightmod=1&wvr=6&mod=personinfo" target="_blank" title="微博">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  微博
                </a>
              </span>
            
          
        </div>

        
        

        
        
          <div class="links-of-blogroll motion-element links-of-blogroll-inline">
            <div class="links-of-blogroll-title">
              <i class="fa  fa-fw fa-globe"></i>
              
            </div>
            <ul class="links-of-blogroll-list">
              
                <li class="links-of-blogroll-item">
                  <a href="https://www.researchgate.net/profile/Shaoqing_Dai" title="Research Gate" target="_blank">Research Gate</a>
                </li>
              
            </ul>
          </div>
        

        


      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Dai Shaoqing</span>
</div>


<div class="powered-by">
  Powered by <a class="theme-link" href="https://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  






  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  


  




	





  





  





  






  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length == 0) {
      search_path = "search.xml";
    }
    var path = "/" + search_path;
    // monitor main search box;

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.popup').toggle();
    }
    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';
      $.ajax({
        url: path,
        dataType: "xml",
        async: true,
        success: function( xmlResponse ) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = $( "entry", xmlResponse ).map(function() {
            return {
              title: $( "title", this ).text(),
              content: $("content",this).text(),
              url: $( "url" , this).text()
            };
          }).get();
          var $input = document.getElementById(search_id);
          var $resultContent = document.getElementById(content_id);
          $input.addEventListener('input', function(){
            var matchcounts = 0;
            var str='<ul class=\"search-result-list\">';
            var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
            $resultContent.innerHTML = "";
            if (this.value.trim().length > 1) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var content_index = [];
                var data_title = data.title.trim().toLowerCase();
                var data_content = data.content.trim().replace(/<[^>]+>/g,"").toLowerCase();
                var data_url = decodeURIComponent(data.url);
                var index_title = -1;
                var index_content = -1;
                var first_occur = -1;
                // only match artiles with not empty titles and contents
                if(data_title != '') {
                  keywords.forEach(function(keyword, i) {
                    index_title = data_title.indexOf(keyword);
                    index_content = data_content.indexOf(keyword);
                    if( index_title >= 0 || index_content >= 0 ){
                      isMatch = true;
                      if (i == 0) {
                        first_occur = index_content;
                      }
                    }

                  });
                }
                // show search results
                if (isMatch) {
                  matchcounts += 1;
                  str += "<li><a href='"+ data_url +"' class='search-result-title'>"+ data_title +"</a>";
                  var content = data.content.trim().replace(/<[^>]+>/g,"");
                  if (first_occur >= 0) {
                    // cut out 100 characters
                    var start = first_occur - 20;
                    var end = first_occur + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if(start == 0){
                      end = 50;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    var match_content = content.substring(start, end);
                    // highlight all keywords
                    keywords.forEach(function(keyword){
                      var regS = new RegExp(keyword, "gi");
                      match_content = match_content.replace(regS, "<b class=\"search-keyword\">"+keyword+"</b>");
                    });

                    str += "<p class=\"search-result\">" + match_content +"...</p>"
                  }
                  str += "</li>";
                }
              })};
            str += "</ul>";
            if (matchcounts == 0) { str = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>' }
            if (keywords == "") { str = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>' }
            $resultContent.innerHTML = str;
          });
          proceedsearch();
        }
      });}

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched == false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(function(e){
      $('.popup').hide();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    });
    $('.popup').click(function(e){
      e.stopPropagation();
    });
  </script>





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script>
  <script>AV.initialize("oTblBOq0hbTxjxkvF4aCAjQ6-gzGzoHsz", "5R3loDlmeKFd1bdvCNnq065n");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
  


  

</body>
</html>
