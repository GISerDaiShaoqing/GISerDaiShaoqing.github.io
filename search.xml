<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Coding and Paper Letter（二十四）]]></title>
    <url>%2F2018%2F09%2F24%2FCoding-and-Paper-Letter%EF%BC%88%E4%BA%8C%E5%8D%81%E5%9B%9B%EF%BC%89%2F</url>
    <content type="text"><![CDATA[资源整理。这一次内容有点多，拆为两篇，这一篇主要针对Coding。 Coding：1.R语言包geex，用于估计参数的框架和来自R中的一组无偏估计方程（即M-估计）的经验夹层协方差矩阵。 geex 2.R语言包nlmixr，用于拟合一般动态模型，药代动力学（PK）模型和药代动力学 - 药效学（PKPD）模型的R包，其具有个体数据或总体数据。 nlmixr 3.开源项目modis mpf，Python语言处理的，基于MODIS观测数据的melt pond反演。 modis mpf 4.开源项目Sentinel Granules Services,这是一个Web应用程序，它在给定点，线或多边形的情况下返回Sentinel 2的UTM数据的名称。 输入是在WKT中定义的几何。 它在PostGIS中执行简单的交集。 Sentinel Granules Service 5.开源项目rhino，为数据立方体提供了一个层，允许在基于coverage的视图和基于对象的视图之间切换。 rhino 6.开源项目temaki，用于mapbox地图的图标。 temaki 7.R语言包Leaflet.glify，功能齐全，快速渲染的基于web gl的Leaflet插件。 Leaflet.glify 8.开源项目BlenderGIS，构建Blender和GIS之间数据的桥梁。 BlenderGIS 9.开源项目search playground，Mapbox地理编码器调试工具，用于测试Mapbox地理编码器v5的内部工具。 search playground 10.jutpytelab的资源。 awesome jupyterlab 11.R语言包nonlinearTseries，非线性时间序列分析的R包。 nonlinearTseries 12.开源项目r sparsepp，sparsepp的Rcpp接口。 r sparsepp 13.开源项目sparsepp，C++项目，高效哈希映射。 sparsepp 14.R语言包hunspell,用于R的高性能Stemmer，Tokenizer和Spell Checker。 hunspell 15.Shiny项目GeoMKT，地图相关的。 GeoMKT 16.开源项目sage windows，构建与Cygwin兼容的Sage构建及其可执行安装程序和辅助文件的文件和说明。 sage windows 17.R语言包ggseg，ggplot2的拓展包，用于脑图集绘图的包。 ggseg 18.Python库openrouteservice，Python的openrouteservice（ORS）API。 openrouteservice py 19.R语言包sdmTMB，使用时空GLMM拟合地底鱼的高分辨率物种分布模型并估计范围转换指标。 sdmTMB 20.R语言包namer，用于命名R Markdown文件的块。 namer 21.开源项目jupyter tips and tricks，用于数据科学的jupyter工程。 jupyter tips and tricks 22.开源项目vid2vid，Pytorch实现了我们用于高分辨率（例如2048x1024）照片级真实视频到视频转换的方法。 vi2dvid 23.开源项目task views，用于编辑CRAN任务视图的本地副本，R语言工程。 task views 24.开源项目stats tutorials，简短的统计学教程。 stats tutorials 25.开源项目inxi，inxi是一个功能齐全的CLI系统信息工具。 它可以在大多数Linux发行版存储库中使用，也可以在BSD上运行。 inxi 26.R语言包R APSIM，包含通用实用程序函数的包，用于加载和操作APSIM输出和元文件。 R APSIM 27.Python库Synonyms，中文近义词工具包。 Synonyms 28.R语言包vdiffr，vdiffr是包测试的扩展，可以轻松测试视觉回归。 它提供了一个Shiny应用程序来管理失败的测试，并在视觉上将图形与其预期输出进行比较。 vdiffr 29.R语言包usra，无交互的GIS工具用于栅格处理与可视化。 usra 30.Python库sense，SenSE是用于有源微波域中的辐射传输（RT）建模的通用社区框架。 它在相干框架中实现了不同表面的不同散射和发射的不同现有模型，以模拟作为表面生物地球物理参数的函数的SAR后向散射系数。 sense 31.Python库ray，Ray是一个灵活的高性能分布式执行框架。 ray 32.开源项目PerceptualGAN，Pytorch实现图像处理与感知鉴别器的论文。 PerceptualGAN 33.R语言包imgw，自动下载IMGW-PIB气象/水文数据集。 imgw 34.R语言包gg2v，ggplot2的拓展包，探索使用vega渲染ggplot2图形。 gg2v 35.开源项目data vis statistics geosciences，地球科学中的数据可视化与统计，该存储库包含Python的高级本科课程的实验室部分，用于地理和空间科学家的数据可视化和统计。 实验室将在1月至5月更新，与课程相同（2018年）。 data vis statistics geosciences 36.R语言包RStoolbox，R语言里的遥感分析。 RStoolbox 37.开源项目Recent SLAM Research，跟踪SLAM前沿动态。 Recent SLAM Research 38.开源项目tps stn pytorch，具有薄板样条（TPS）的空间变压器网络（STN）的PyTorch实现。 tps stn pytorch 39.开源项目HoughCircles，用于圆检测的霍夫变换。 HoughCircles 40.R语言包PointedSDMs，这是一个使用点过程公式在R中拟合SDM的R包。 它使用INLA进行拟合，因此编写了许多函数来重新格式化Spatial数据，以便INLA可以使用它。 PointedSDMs 41.R语言包htmldeps,Shiny，R Markdown，flexdashboard，htmlwidgets和leaflet的打包HTML依赖项。 htmldeps 42.R语言包SDMTools，物种分布建模工具：用于处理与物种分布建模练习相关的数据的工具 SDMTools 43.R语言包dqrng，R的快速伪随机数发生器。 dqrng 44.R语言包bs4Dash，使用AdminLTE3启动Bootstrap 4 shinydashboard。 bs4Dash 45.QGIS插件，简单快速大气校正。 simple atmospheric correction 46.一本涵盖数据可视化基础知识的书。 dataviz 47.admb的相关开源项目。admb，是AD Model Builder的简称，支持自动微分（AD）应用于非线性统计建模和优化问题的解决方案。 R2admb adstudio admb project.github.io admb examples glmmadmb]]></content>
      <categories>
        <category>Personal</category>
      </categories>
      <tags>
        <tag>Consideration of Ecology and Geography</tag>
        <tag>Summary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PostGIS学习笔记（开篇）]]></title>
    <url>%2F2018%2F09%2F21%2FPostGIS%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%BC%80%E7%AF%87%EF%BC%89%2F</url>
    <content type="text"><![CDATA[PostGIS事实上算是笔者开始写博客的第一篇内容。而事实上那篇博文的内容并不丰富，笔者对PostGIS的了解仍然不多，然而17年在OSGeo课程学习时对PostGIS又有了进一步了解，并逐步发现它的强大。刚好最近又遇上一个问题，也使我萌发了开坑PostGIS的想法。 1 PostGIS简介 PostGIS是对象关系型数据库系统PostgreSQL的一个扩展，PostGIS提供如下空间信息服务功能:空间对象、空间索引、空间操作函数和空间操作符。同时，PostGIS遵循OpenGIS的规范。PostGIS的版权被纳入到GNU的GPL中，也就是说任何人可以自由得到PostGIS的源码并对其做研究和改进。正是由于这一点，PostGIS得到了迅速的发展，越来越多的爱好者和研究机构参与到PostGIS的应用开发和完善当中。 以上引自百度百科。 下面是我的第一篇博客。 桌面GIS连接Postgresql总结 安装可以在网上搜索教程，在连接ArcGIS、QGIS拓展内容可见上文。 2 关键问题最近需要的一个工作是基于土地覆被数据和其他数据做一个简单的适宜用地提取。其实总结起来就是各种基础的空间叠加分析，但是却遇上了一个关键问题。土地覆被数据分辨率为300 m，下图即为土地覆被数据（已提取了需要的土地覆被类型）。为了面积准确性，进行栅格转矢量的时候并没有选择简化面。结果导致数据量非常巨大。 打开属性表可以发现，研究区一共有3146163条数据。 然后需要和另外一个结果做空间叠加（Intersection，相交)，得到适宜用地的空间分布。结果由于数据量太大运行时间较长。在ArcGIS平台测试结果如图。花了21分钟27秒。 笔者同时尝试着使用了ArcGIS Pro来进行大数据量的矢量相交计算。计算时间为13分钟6秒。 也有人给的建议是选用PostGIS进行计算。于是进行了测试。 需要设置SRID和geometry。接下来在PostGIS的SQL查询里运行如下的SQL查询。 12SELECT ST_Intersection(suitablewgs84.geometry, ecooutwgs84.geometry) FROM public.suitablewgs84 INNER JOIN public.ecooutwgs84 on ST_Intersects(suitablewgs84.geometry, ecooutwgs84.geometry) 可能是目前学习不够深入，速度似乎不够快。而这也是本部分学习笔记的开篇。 先放一些PostGIS的资料。 postgresql学习资料 PostGIS]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>ArcGIS</tag>
        <tag>ArcGIS Pro</tag>
        <tag>PostGIS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Coding and Paper Letter（二十三）]]></title>
    <url>%2F2018%2F09%2F21%2FCoding-and-Paper-Letter%EF%BC%88%E4%BA%8C%E5%8D%81%E4%B8%89%EF%BC%89%2F</url>
    <content type="text"><![CDATA[资源整理。 1 Coding：1.开源项目aom，基于Fotran90编写的水光学蒙特卡洛模型。可以模拟辐射量。 aomc 2.开源项目proSR，一种全新的单图像超分辨率重建方法。 proSR 3.开源项目conditional neural process，条件神经网络的jupyter notebook实现。 conditional neural process 4.如何将自己开发的R包推送到cran上，需要准备的东西。 prepare for cran 5.Python库flask ipywidgets，flask框架里的ipywidgets支持。 flask ipywidgets 6.针对生态学家的贝叶斯数据分析介绍。 bayes course 7.R中关于回归，GLM，混合效应模型和GLMM的wokrshop练习。 glmm course 8.R语言包bayesdfa，bayesdfa与Stan实施贝叶斯动态因子分析（DFA）。 bayesdfa 9.开放交通数据的资源。 opentransportdata 10.R语言包rangeModelMetadata，提供了创建与R中物种范围模型相关的元数据对象的便捷访问。 rangeModelMetadata 11.在Earth Engine IDE中转换和运行代码的工具。 ee loader 12.R语言包backyard，这个包的目标是为Bookdown项目提供可视后台。 backyard 13.R语言包binb，非常适合从LaTeX制作pdf演示文稿，并且还得到Markdown和RMarkdown的支持。 binb 14.地理空间资源链接。 coords 15.夏威夷大学马诺阿分校地质与地球物理系举办的研讨会。 tgif2018 16.R语言包unilur，帮助用rmarkdown编写教程，实践或试卷。 unilur 17.R语言包pRojects，用于创建各类不同的项目，以降低繁琐的项目设置工作。 pRojects 18.R语言包RGLUEANN，一般似然不确定性估计（GLUE）和人工神经网络（ANN）之间耦合的R实现。 RGLUEANN 19.使用开源软件的基本遥感和GIS方法教程（Python或R中的GDAL）。 open geo tutorial 20.R语言包lucCalculus，用于分析土地利用的时空演算改变轨迹。 lucCalculus 21.R语言包rmdWidgets，将Widgets插入到Rmarkdown的html/LaTex文档中。 rmdWidgets 22.R语言包revgeo，使用Google Maps API和Photon API在R中反向地理编码。 revgeo 23.Rmarkdown模板，传统邮件的R bookdown模板。 bookdown mail 24.R语言包portalr，专门从指定的portal获取数据（Chihuahuan沙漠中长期野外场地的啮齿动物，植物，蚂蚁和天气的观测数据）。 portalr 25.XGBoost功能交互和重要性。 xgbfi 26.Tidynomicon：Python程序员R简介 tidynomicon 27.Stan 2.18.0中的多线程和Map-Reduce的一个小案例。 cmdstan map rect tutorial 28.主题为地热的学习资源jupyter notebook。 geothermics 29.Generic Mapping Tools的Python接口以及Generic Mapping Tools。 gmt python gmt 30.R语言包geobench，放置数据（在发行版中）和代码（用任何语言）来测试性能。 geobench 31.正则化贪婪森林算法。集成树机器学习方法。 rgf 2 Paper:1.Estimating urban above ground biomass with multi-scale LiDAR/用多尺度激光雷达估算城市地上生物量 背景：长期以来，城市树木因提供生态系统服务（减轻“热岛”效应，抑制空气污染等）而受到重视;最近，城市森林储存大量地上生物量（AGB）的潜力也得到了认可。然而，由于树木的可塑性，高物种多样性以及异质和复杂的土地覆盖，城市地区在评估AGB时面临特殊挑战。遥感，特别是光探测和测距（LiDAR），通过直接测量树木结构，为评估城市AGB提供了独特的机会。在这项研究中，陆地LiDAR测量被用于推导出伦敦卡姆登区的新异速生长，其中包含了城市环境中典型的各种树木结构。使用从墙到墙的机载LiDAR数据集，然后使用新的个体树检测（ITD）方法在整个自治市镇中识别单个树。随后将新的异速生长应用于所识别的树木，产生自治市镇范围内的AGB估计。 结果：Camden的AGB密度估计值为51.6 Mg ha-1，其中林地口袋中的AGB密度最大;陆地LiDAR衍生的AGB估计表明这些区域与温带和热带森林相当。地球LiDAR衍生的最大高度和投影冠面积的多元线性回归解释了树体积的93％的方差，突出了这些指标用于表征不同树形结构的效用。局部推导的异速生长提供了对树木体积的准确估计，而自治市镇的异速生长倾向于过高估计林地区域的AGB。新的ITD方法成功识别了单个树木;然而，由于ITD无法解决表冠重叠，因此与陆地LiDAR相比，AGB被低估了≤25％。蒙特卡罗不确定性分析确定在估算AGB时将木材密度值指定为最大的不确定性来源。 结论：在未来一个世纪，预计全球人口将日益城市化，导致城市土地覆盖面积空前扩大。由于需要碳汇和评估这些地区碳密度的有效工具，城市地区将变得更加重要。使用多尺度激光雷达提供了实现这一目标的机会，提供了城市森林结构和AGB的空间显式图。 LiDAR对AGB的大规模测量已经在森林地区有了很多应用，而针对城市森林AGB的研究还较少，本文就是针对城市内部森林的AGB测度。 2.Global forecasts of urban expansion to 2030 and direct impacts on biodiversity and carbon pools/2000-2030年全球城市扩展过程及其对生物多样性和碳储量的直接影响 推文 该文章模拟了2000-2030年全球城市扩展过程。然后基于模拟结果，分析了城市扩展过程对自然栖息地、生物多样性以及碳储量的影响。详情可以见上面的推文，PNAS的雄文。城市扩张的模型以及造成的环境效应值得关注。]]></content>
      <categories>
        <category>Personal</category>
      </categories>
      <tags>
        <tag>Consideration of Ecology and Geography</tag>
        <tag>Summary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[科学利用谷歌云平台]]></title>
    <url>%2F2018%2F09%2F19%2F%E7%A7%91%E5%AD%A6%E5%88%A9%E7%94%A8%E8%B0%B7%E6%AD%8C%E4%BA%91%E5%B9%B3%E5%8F%B0%2F</url>
    <content type="text"><![CDATA[当今既是大数据时代，也是云计算时代。云平台构建已经成了诸多大数据平台建设第一步。于是各家互联网巨头们纷纷都开启了云平台服务。国内的以阿里云、腾讯云、百度云、华为云为首，国外的有AWS和谷歌。最近Google Cloud（谷歌云平台）有新用户注册就送300美刀的优惠，可使用时间为12个月！这也是本文的基础，关于Google Cloud注册就不介绍了。并不复杂，不过需要有信用卡。 VPS搭建1 注册注册我就不说了。在以下网址自行注册。 注册网址 2 创建项目进入控制台后，先点击左上角红框。在弹出的对话框点击右上角红框。输入名字即可 3 创建VM接着从左侧进入Computer Engine，点击VM。 点击创建。 这个时候需要选地区，建议选择台湾。asia-east1-c节点（图中没有改，貌似网上都说c节点信号较好）。 接下来是选机器类型，默认的是28美刀一个月的，这里选的最低配是$5一个月。 然后是选系统。根据自己的爱好选择，我因为已经有阿里云的Ubuntu服务器，所以我这里选的CentOS7。 接着设置身份和API访问权限，勾选允许HTTP流量和允许HTTPS流量。 需要设置网络，创建一个外部ip地址。 接着点击创建即可。 4 SSH链接接下来可以选择在浏览器上用SSH连接直接配置服务器(很不错的选择）。 输入命令。 1sudo -i 不过我还是更喜欢用Xshell来设置，Xshell连接需要先设置防火墙。按照如下找到防火墙规则。 点击创建防火墙规则。输入名称，对IP设置为0.0.0.0/0，此外目标选网络里的所有实例。 点击创建即可。 接着切换到Xshell里面。点击“工具”→“新建用户密钥生成向导”。 生成密钥参数，点击下一步。 设置一个用户名。密码看自己需求，也可以不设。 将密钥保存起来。 回到Google Cloud Platform。在实例中找到元数据，切换到SSH密钥，然后点击修改。 点击添加一项，将刚刚保存的SSH密钥复制粘贴到上面，并在密钥最后增加自己设置的用户名保存即可。 接着在Xshell里进行登录。新建一个连接，名称自己随意定义，主机填VM的外部ip（也就是创建静态IP的原因）。 接着点击用户身份验证，使用公共密钥登录，用户密钥选择刚刚创建的那个，如果有密码还需要输入密码。即可连接。 登录成功。 可以愉快地在谷歌云平台上为所欲为了。]]></content>
      <categories>
        <category>Coding</category>
      </categories>
      <tags>
        <tag>Google Cloud Platform</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[博客平台、Markdown编辑器与hexo admin简介]]></title>
    <url>%2F2018%2F09%2F19%2FHexo-Admin%E5%8D%9A%E5%AE%A2%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[今天来介绍下一些博客平台，顺带也介绍几个笔者用过的Markdown编辑器，以及最近刚刚开始使用的博客后台管理的神器hexo-admin。 1 博客平台关于如何写博客这个事情确实是一件比较有意思的事情，尽管最近网易、新浪等博客平台纷纷宣布倒台，但是感觉在程序猿界并没有多少影响。业内比较出名的博客平台实在太多，笔者目前也是多个博客平台同步更新。所以也简单提下可以使用的博客平台。 1.CSDN: CSDN (Chinese Software Developer Network) 创立于1999年，是中国的IT社区和服务平台，为中国的软件开发者和IT从业者提供知识传播、职业发展、软件开发等全生命周期服务，满足他们在职业发展中学习及共享知识和信息、建立职业发展社交圈、通过软件开发实现技术商业化等刚性需求。 2.简书: 简书是一个创作社区，任何人均可以在其上进行创作。用户在简书上面可以方便的创作自己的作品，互相交流。简书成为国内优质原创内容输出平台。 3.开源中国:开源中国成立于2008年8月，是目前国内最大的开源技术社区，拥有超过200万会员，形成了由开源软件库、代码分享、资讯、协作翻译、码云、众包、招聘等几大模块内容，为IT开发者提供了一个发现、使用、并交流开源技术的平台。 4.知乎:知乎是网络问答社区，连接各行各业的用户。用户分享着彼此的知识、经验和见解，为中文互联网源源不断地提供多种多样的信息。 5.掘金:掘金是一个帮助开发者成长的社区,是给开发者用的 Hacker News,给设计师用的 Designer News,和给产品经理用的 Medium。 6.阿里云栖社区:云栖社区是面向开发者的开放型技术平台。源自阿里云,服务于云计算技术全生态。包含博客、问答、培训、设计研发、资源下载等产品。 7.腾讯云+社区:云+社区致力于打造开发者的技术分享型社区。营造云计算技术生态圈,专注于提高开发者的技术影响力。 8.科学网:科学网是由中国科学院、中国工程院和国家自然科学基金委员会主管，科学时报社主办的综合性科学网站，主要为网民提供快捷权威的科学新闻报道、丰富实用的科学信息服务以及交流互动的网络平台，目标是建成最具影响力的全球华人科学社区。 以上均来自某度 以上的前7个应当是程序猿比较熟悉，偏向IT的博客和交流论坛，第8个属于科研学术界的博客。当然除了以上8个还有很多，如segmentfault，各个学科的各种论坛（气象家园、地信论坛、小木虫、人大经济论坛等等等）。 目前我主要在CSDN、简书、开源中国、科学网、阿里云栖社区以及自己搭载的博客平台(hexo + github)更新博客。从使用来说，CSDN作为老牌IT社区，博客对Markdown的支持十分丰富，几乎所有Markdown拓展都有，应当是之前使用最舒服的一个博客平台，简书整个网站风格不错，而且文章内容也多元化，不仅仅是技术干货，偶尔也能满足你的情怀，Markdown支持基本的拓展，不过像公式和流程图类的不支持。开源中国对markdown支持程度与简书差别不大，而且最近发现对博客文字的审核较为严格，偶然出现的一些敏感词汇也是通不过的。阿里云栖社区目前刚刚加入，直观感受跟开源中国和简书支持较为类似，是否支持公式和流程图不确定。科学网不支持Markdown编辑，还是传统的富文本编辑，毕竟科学网面对的是科研人员，并非大家都很熟悉Markdown。但是在谷歌浏览器上只需要使用Markdown Here拓展即可实现Markdown到富文本的转换非常方便。之前我在更新博客的时候，习惯在CSDN上写，然后在其他平台复制粘贴。不过后面发现CSDN的图床似乎最近有些小问题，之前图片在各个平台都能通用，现在似乎不太支持。这也是我更换了博客管理平台的原因。 2 Markdown编辑器可能讲了这么久一些人还不太了解Markdown。这里简要介绍（依旧是度娘资料）。 Markdown是一种可以使用普通文本编辑器编写的标记语言，通过简单的标记语法，它可以使普通文本内容具有一定的格式。Markdown具有一系列衍生版本，用于扩展Markdown的功能（如表格、脚注、内嵌HTML等等），这些功能原初的Markdown尚不具备，它们能让Markdown转换成更多的格式，例如LaTeX，Docbook。总结起来就是人类为了懒搞出来的一套标记语言。想进一步了解的可以自行搜索。这里推荐两篇我常用的博客，由于笔者仍在从事科研，写公式是一大特点。所以我很喜欢Markdown的LaTex拓展。下面两篇文章就是在讲述这方面的内容。 LaTeX 各种命令，符号 Markdown中编写LaTeX数学公式 接下来讲讲Markdown编辑器，笔者一共用过cutemarked，Markdownpad，Cmd Markdown和Visual Studio Code四个相关的编辑器。前两个里面Cutemarked用得比较久，支持实时预览，导出html，PDF，也支持数学公式。流程图也是支持的，但是是基于mermaid插件，而不是flowchart。语法有变化，后面有空来讲就这两个的流程图语法(下面也有篇博客讲这方面的内容）。而Markdownpad用的时间不长。似乎是导出的功能不够完善。Cmd Markdown是目前还一直在用的，几乎所有拓展都支持，各种体验还不错，强力推荐，导出方面略有不足（免费会员支持的不多，付费各种格式均支持），而且同步功能给好评。Visual Studio Code的话，其实不仅仅是为了当Markdown编辑器，只不过我尝试着做了个配置，将它配成也能适合Markdown编辑的平台。除了这些还有很多编辑器，详情见下面的文章链接。 Markdown里面的流程图 整理：几款好用的Markdown编辑器 10款流行的Markdown编辑器，总有一款适合你 最受欢迎的10个Markdown编辑器,有一个被称神的编辑器 3 hexo admin由于自己搭载的hexo github平台是完全基于Markdown的，在之前CSDN的图床出问题之后，我就将利用七牛云重新做了一个属于自己的图床。于是在思考有没有快捷的方式来写博客。在Github上搜索一番后，发现了如下两个神器。 hexo admin hexo admin qiniu hexo admin是一个基于hexo的博客管理页面。界面如下，可以用来写博客，设置各种相关内容。 而hexo admin qiniu是基于hexo admin基础上做的改进。主要增加了以七牛云作为图床的功能，这样子，利用qq截完图，直接在hexo admin界面里，粘贴即可生成图片链接，非常简洁。安装只需要如下的语句。 1npm install --save hexo-admin-qiniu 接着必须在站点配置文件（博客文件夹里的_config.yml，不是主题文件夹里的）里修改配置文件。配置内容如下。 12345678#Qiniuadmin: qiniuCfg: imageslim: true # 启动图片瘦身，仅华东区bucket可以使用 AccessKey: &apos;your qiniu AK&apos; SecretKey: &apos;your qiniu SK&apos; BucketName: &apos;your BK Name&apos; bucketHost: &apos;you BK Host&apos; 具体的安装配置也可以见官网。运行的话只需要定位到博客路径。 12hexo server -dhexo server -d -p 5000 #当4000端口被占的时候，更换为5000端口 当然也有人专门开发了一个编辑器HexoEditor。也很不错，详情链接在下面。 HexoEditor]]></content>
      <categories>
        <category>Coding</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Coding and Paper Letter（二十二）]]></title>
    <url>%2F2018%2F09%2F18%2FCoding-and-Paper-Letter%EF%BC%88%E4%BA%8C%E5%8D%81%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[资源整理。 1 Coding：1.开源项目openeo api。oponEO开发了一个开放的API，以简单统一的方式将R，python和javascript客户端连接到对地观测大数据云平台的后台。 此存储库包含此API，即oponEO（核心）API。 openeo api 2.开源项目quantized mesh viewer，在Cesium中渲染自定义量化网格瓦片并使用THREE.js渲染器调试单个瓦片。 quantized mesh viewer 3.开源项目spade，rust语言的空间数据结构。 spade 4.用TensorFlow进行机器学习书籍附带TensorFlow机器学习的源代码。有关代码说明，请参阅本书。 TensorFlow Book 5.R语言包ggsoccer，ggplot2的拓展包，用于绘制足球场及足球赛事的包。 ggsoccer 6.开源项目firspaper,关于写第一篇论文的很多东西。很切实的经验之谈。值得关注。 firspaper 7.R语言包datapasta，一个帮助在不同平台复制粘贴的包。 datapasta 8.R语言包rgeopat2，支持使用’GeoPAT’2软件处理的空间数据分析。 rgeopat2 9.开源项目weathercontext，twitter上的机器人，每天中午定时发布天气信息，同时也可以查询历史天气（来自ECMWF的ERA-interim数据）。 weathercontext 10.R语言包geojsonsf，R中GeoJSON和Simple Feature对象之间的简单，低依赖性和快速转换工具。 geojsonsf 11.R语言包adaptMCMC，通用自适应蒙特卡罗马尔可夫链采样器的R语言实现。 adaptMCMC 12.R语言包usmap，在R中创建包括阿拉斯加和夏威夷在内的美国地图。 usmap 13.R语言包s2，用于椭球体的Google s2库的R接口。 s2 14.开源项目TheGeolocationManual，R markdown组织的文件，应该跟Geolocation相关的内容。详情见仓库。 TheGeolocationManual 15.Fotran库LAPACK，用于解决数值线性代数中最常出现的问题。 lapack 16.R语言包pkgdown，用于生成R包的静态网页。 pkgdown 17.node建立的自然语言处理库，具有实体提取，情感分析，自动语言识别等功能。 nlp.js 18.开源项目KivyMD，Kivy Material Design标准的小部件的集合。 KivyMD 19.用于ODSC介绍贝叶斯工作流的幻灯片和材料。 intro bayesian workflow 20.开源项目NUTS，来自Hoffman＆Gelman的2011年无转换采样器（NUTS）的python版本。 NUTS 21.R语言包cowsay，R中有更多动物的cowsay。就是用注释画出动物的样子。 cowsay 22.R语言包lato，使用’Lato’字体的最小和灵活的’ggplot2’主题。 lato 23.QGIS的Google Earth Engine插件。 qgis earthengine plugin 2 Paper:1.Evaluating the Performance of Sentinel-2, Landsat 8 and Pléiades-1 in Mapping Mangrove Extent and Species/评估Sentinel-2，Landsat 8和Pléiades-1在红树林范围和物种制图方面的表现 绘制红树林的范围和物种对于了解它们对环境变化的反应以及观察其提供商品和服务的完整性非常重要。然而，准确绘制红树林范围和物种是遥感的持续挑战。新推出的可自由使用的Sentinel-2（S2）传感器为这些挑战提供了新的机会。本研究首次开展了一项研究，旨在研究中国东寨港第一个国家红树林自然保护区红树林范围和物种的原始条带，光谱指数和纹理信息。为了绘制红树林的范围和物种，利用和修改了基于红树林生态系统的空间结构和基于地理对象的图像分析的三级层次结构。在实验过程中，为了克服优化高维和相关特征空间的挑战，引入了递归特征消除（RFE）算法。最后，基于随机森林算法，来自RFE的所选特征被用于红树林物种鉴别。将结果与Landsat 8（L8）和Pléiades-1（P1）数据进行了比较，结果表明S2和L8可以准确地提取红树林的范围，但P1显然高估了它。关于红树林物种群落水平，S2的总体分类准确度为70.95％，低于P1图像（78.57％），略高于L8数据（68.57％）。同时，前者差异具有统计显着性，后者则不然。优势物种基本上是在S2和P1图像中提取的，这些特征对于红树林物种鉴别是最重要的。最重要的特征是红光波段，其次是短波红外，近红外，蓝光和其他可见光波段。这项研究表明S2传感器可以准确地绘制红树林的范围，并基本上区分红树林物种群落，但对于后者，由于红树林物种的复杂性，应该谨慎。遥感影像在红树林提取方面的成果。事实证明哨兵的数据在提取范围上准确度较高，而提取物种上却效果不佳。从与Landsat 8和Pléiades-1的比较来看，相信未来红树林遥感制图的关键是这几个多源卫星的信息融合。 2.National scale spatiotemporal land-use regression model for PM2.5, PM10 and NO2 concentration in China/中国PM2.5，PM10和NO2浓度的全国尺度时空土地利用回归模型 空气污染流行病学研究越来越依赖于高分辨率暴露预测模型。但是，到目前为止，很少有这种类型分辨率的数据可供在中国使用。目标：我们制定了国家土地利用回归模型（LUR），以估算中国2014年至2016年的月平均PM2.5，PM10和NO2。方法：我们使用广义加性混合模型开发了时空半参数模型。模型中包括各种预测变量：时变气象数据，Globaland 30的高分辨率土地覆盖数据，气溶胶光学深度的卫星测量和地理信息系统（GIS）衍生的预测变量。我们使用两种交叉验证（CV）方法评估模型性能，包括保持CV和10折CV。结果：在1382个监测点进行了超过22,000次月度观测，以估算空气污染暴露情况。时变空间项解释了87％，71％和69％的变异性，PM2.5，PM10和NO2模型的保持交叉验证R²分别为0.85,0.62和0.62。模型显示，气象变量，人口密度，海拔，道路距离和土地覆盖类型是空气污染暴露的重要预测因子。结论：我们开发了一种新的全国范围的模型来估算居住水平的空气污染暴露，可用于研究空气污染的慢性不利影响。LUR的全国尺度上的研究，并且涵盖了三大关键大气污染物，比较扎实的研究。且是比较高时间分辨率（月）的LUR。 3.Spatializing Segregation Measures: An Approach To Better Depict Social Relationships/空间化隔离措施：一种更好地描绘社会关系的方法 隔离涉及一个以上的人口群体，隔离措施量化了不同人口群体在空间中的分布方式。隔离研究的关键概念和方法论基础之一是考虑跨地区单位的两个或更多人口群之间空间相互作用的潜力。这个基础意味着需要一种空间方法来描绘邻居之间的空间（以及社会）互动。通常，简单的百分比（例如，黑色百分比）不是隔离的量度。由于地方空间隔离措施直到最近才出现，本文的目标有三个：（1）解释用于测量邻域（或地方）层面隔离水平的空间方法，（2）证明不足之处。使用一定比例的种族/族裔群体作为隔离措施，以及（3）澄清两种常用的不同和多样性指数的适当性。来自密苏里州圣路易斯和伊利诺伊州芝加哥的数据用于讨论这三点。一个偏向社会学的GIS应用，似乎是涉及到种族隔离方面的研究。 4.National PM2.5 and NO2 Exposure Models for China Based on Land Use Regression, Satellite Measurements, and Universal Kriging/基于土地利用回归，卫星测量和通用克里格法的中国国家PM2.5和NO2暴露模型 室外空气污染是全球的主要杀手，也是中国疾病负担的第四大因素。中国是世界上人口最多的国家，每年空气污染死亡人数最多，但中国现有国家空气污染估算的空间分辨率普遍较低。我们通过开发和评估中国的国家经验模型（包括土地利用回归（LUR），卫星测量和普遍克里金法（UK））来解决这一research gap。我们用几种方法测试得到的模型，包括（1）比较使用前向逐步回归与偏最小二乘（PLS）回归开发的模型，（2）比较使用和不使用卫星测量开发的模型，使用和不使用UK，以及（ 3）10倍交叉验证（CV），以省为单元的留一交叉验证（LOPOCV）和以城市为单元的留一交叉验证（LOCOCV）。卫星数据和克里金法在使预测更准确方面具有互补性：克里金法改进了良好采样区域的模型;卫星数据大大提高了远离监视器的位置的性能。逐步前向选择与10倍CV中的PLS类似地执行，但是优于LOPO-CV中的PLS。我们的最佳模型采用前向选择和UK，我们为中国的年平均浓度制作了第一个高分辨率国家LUR模型。模型应用于1 km网格以支持未来的研究。 2015年，超过80％的中国人口居住在超过中国国家PM2.5标准的地区，这里的结果将公开，可能对环境健康研究有用。类似于上面第二篇的土地利用回归模型。不过这篇增加了和人口相关的研究，切实地做到了暴露的研究。 5.Thermal evaluation of urbanization using a hybrid approach/使用混合方法对城市化进行热评估 城市发展增加了建筑物和路面的径流温度，这可能对水生生物有害。但是，我们根据土地利用预测径流温度的能力有限。本文探讨了可用于模拟径流温度的工具，这是一种敏感物种溪鳟（Salvelinus sp。）。明尼苏达城市热量输出工具（MINUHET）和暴雨水管理模型（SWMM）被应用于弗吉尼亚州布莱克斯堡附近的Stroubles Creek流域的14.1平方公里的部分，持续两个夏天。流量，水温和天气数据来自Virginia Tech StREAM实验室（流研究，教育和管理）监测站。 SWMM和MINUHET分别针对流量和流温度进行校准和验证。模型对不透水性（SWMM预测的流量）和露点温度（MINUHET预测的水温）敏感。虽然模型输出时间步长为15分钟，但使用Nash-Sutcliffe效率（NSE）按小时时间步长评估模拟流量流中的模型性能。 SWMM的NSE值分别为0.67和0.65，校准和验证期间的MINUHET分别为0.62和0.57，表明SWMM在流量模拟中的表现优于MINUHET。在验证期间使用MINUHET模拟流温度，NSE值为0.58，证明了令人满意的水温模拟。由于SWMM不能进行简单混合以外的温度模拟。 SWMM和MINUHET的水文和热输出以混合方式组合，强调每个相应模型的强度，即SWMM用于径流和径流，MINUHET用于水温。使用MINUHET和Hybrid模型模拟热负荷;混合模型（0.56）单独使用比MINUHET（0.45）更大的NSE。 MINUHET预测表明，在校准和验证期分别为39％和38％的情况下，水温将超过21°C的鳟鱼毒性阈值。由于观察到的温度分别超过了校准和验证期的59％和53％的毒性阈值，因此MINUHET不是温度持续时间超过毒性阈值的保守预测因子。小尺度城市化与径流温度对物种危害的研究，耦合了两个模型。 6.An Analytical Framework for Integrating the Spatiotemporal Dynamics of Environmental Context and Individual Mobility in Exposure Assessment: A Study on the Relationship between Food Environment Exposures and Body Weight/在暴露评估中整合环境背景和个体流动的时空动态的分析框架：食物环境暴露与体重之间关系的研究 在过去的研究中，个人环境暴露主要是以静态方式测量的。在这项研究中，我们开发并实施一个动态表示环境背景（环境背景立方体）的分析框架，并有效地整合个人日常运动（行为时空轨迹），以准确地推导出个人环境暴露（环境背景暴露指数）。该框架用于检查食物环境暴露与46名参与者的超重状态之间的关系，使用俄亥俄州哥伦布市的全球定位系统（GPS）收集的数据和二元逻辑回归模型。结果表明，与其他广泛使用的方法相比，所提出的框架可以对个体食物环境暴露产生更可靠的测量。考虑到个体环境暴露的复杂空间和时间动态，拟议的框架也有助于缓解不确定的地理环境问题（UGCoP）。它可用于其他环境健康研究，涉及环境影响广泛的健康行为和结果。关美宝老师团队的新文章，关注的是个体食物环境暴露与时空轨迹相关的研究。近期连续看到两篇关美宝老师团队相关的文章。食物环境暴露是一个比较新的话题，值得关注。属于环境健康方面的另一个研究，但是之前见过一些做城市代谢研究的似乎也略有涉及。 7.Integrating spatial and temporal contexts into a factorization model for POI recommendation/将空间和时间上下文集成到POI推荐的因子分解模型中 矩阵分解是推荐系统中最常用的方法之一。但是，它面临着与兴趣点（POI）建议中的登记数据相关的两个挑战：数据稀缺性和隐式反馈。为解决这些问题，本文提出了一种特征空间分离因子分解模型（FSS-FM）。该模型将POI要素空间表示为单独的切片，每个切片代表一种特征。因此，可以容易地添加空间和时间信息以及其他上下文以补偿稀缺数据。此外，将因子分解模型的两个常用目标函数（加权最小二乘和成对排序函数）组合以构建混合优化函数。对两个真实数据集进行了广泛的实验：Gowalla和Foursquare，并将结果与基线方法的结果进行比较以评估模型。结果表明，FSS-FM在两种数据集的精确度和召回率方面均优于最先进的方法。具有单独特征空间的模型可以改善推荐的性能。包含空间和时间上下文进一步利用了性能，空间上下文比时间上下文更有影响力。此外，还证明了混合优化在改进POI推荐方面的能力。推荐系统算法和VGI数据的结合，事实上POI作为关键的地图导航点，对模糊搜索之类的功能有很高的要求，因此这个研究是相对具有较大工程意义的。来自于地理所裴韬老师团队的成果。 8.Estimating spatiotemporal distribution of PM 1 concentrations in China with satellite remote sensing, meteorology, and land use information/利用卫星遥感，气象和土地利用信息估算中国PM 1浓度的时空分布 PM1可能比PM2.5（空气动力学直径≤1μm且≤2.5μm的颗粒物质）更危险。然而，由于缺乏PM1监测数据，PM1浓度及其健康影响的研究受到限制。目标：利用卫星遥感，气象和土地利用信息，估算2005 - 2014年中国PM1浓度的时空变化。两种类型的中分辨率成像光谱仪（MODIS）产品6气溶胶光学深度（AOD）数据（基于暗目标（DT）和深蓝色（DB）反演的）。开发广义相加模型（GAM）以将地面监测的PM1数据与AOD数据和其他空间和时间预测因子（例如，城市覆盖，森林覆盖和日历月）联系起来。进行10折交叉验证以评估预测能力。结果表明，PM1水平在冬季最高，而在夏季最低。总的来说，整个中国的PM1水平在过去十年中并未发生实质性变化。对于当地重污染地区，河北西南部和京津地区的PM1水平大幅上升。结论：具有卫星反演AOD，气象和土地利用信息的GAM具有较高的预测能力来估计地面PM1。在过去十年中，环境PM1在中国达到了很高的水平。估计结果可用于评估PM1的健康影响。在见惯了大量PM2.5各类反演研究后，这一篇确实耳目一新，因为做的是PM1。可以说细颗粒物将在未来对人类健康产生持续的影响，也是需要重点关注的大气污染物。]]></content>
      <categories>
        <category>Personal</category>
      </categories>
      <tags>
        <tag>Consideration of Ecology and Geography</tag>
        <tag>Summary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Coding and Paper Letter（二十一）]]></title>
    <url>%2F2018%2F09%2F16%2FCoding-and-Paper-Letter%EF%BC%88%E4%BA%8C%E5%8D%81%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[资源整理。 1 Coding：1.R语言包psychmeta，用于心理学方面的的Meta分析。 psychmeta 2.开源项目trug ggplot2， 2018年1月，Tampa的R用户会议关于ggplot2语法的ppt。 trug ggplot2 3.开源项目Residual Attention Network， Residual Attention Network 4.Python库sentinel_api，欧空局哨兵卫星数据的API接口。 esa sentinel 5.R语言开源电子书，有关创建R建模包的建议。 model implementation principles 6.书籍R for Data Sciences的附录指南。 r4ds instructors 7.Python库pyny3d，面向工程的工具，用于交互式构建，工作和执行具有3D几何的着色模拟。 pyny3d 8.R语言包geoparser，geoparser.io的R语言接口。 geoparser 9.微软开源项目nni，用于神经架构搜索和超参数调整的开源AutoML工具包。 nni 10.开源项目Open3D，开源的3D数据处理的库。 Open3D 11.开源项目jpmml sparkml lightgbm,JPMML-SparkML插件，用于将LightGBM-Spark模型转换为PMML。 jpmml sparkml lightgbm 12.D3插件，它根据Voronoi曲面细分计算树形图。 d3 voronoi treemap 13.Python库esridump，esri RESTful的API接口，将格式转换为更普遍的geojson。 pyesridump 14.R语言包googleLanguageR，谷歌翻译的R语言客户端。 googleLanguageR 15.Python的Docker镜像。 python 16.开源项目cityengine，分享一些CGA规则和代码。 cityengine 17.开源项目intro r gis，R语言里的GIS中简介。 intro r gis 18.开源项目swiss maps，从swiss top生成topojson数据。 swiss maps 19.开源项目NYTaxi,纽约出租车轨迹数据分析。基于R和Python。 NYTaxi 20.R语言包condvis，统计模型的可视化。 condvis 21.R语言包rangemap，用于构建物种分布范围图的R包。 rangemap 22.开源项目opendata，该项目包含有关使用R获取，解析，操作，创建和共享打开数据的信息。 opendata 23.R语言包grcdr，R中图形的ggplot2扩展和脚本的集合。 grcdr 24.基于Web的附录和已发布文章中使用的代码教程。 examples 25.R语言包geoplumber，从R服务地理数据并使用可扩展的前端服务。 geoplumber 26.R语言包gpuR，R语言使用GPU的接口。 gpuR 27.开源项目awesome quantum machine learning，量子机器学习基础知识，算法，学习资料，项目以及网络项目的描述。 awesome quantum machine learning 28.R语言包gbm，老的gbm包，梯度提升模型包。 gbm 29.R语言包fts，快速的时间序列库。 fts 30.开源项目FAST，通过有效的时间序列相似性搜索实现地震检测。 FAST 31.R语言包geofacet，ggplot2的拓展包，地理分面工具。 geofacet 32.R语言包terra，空间数据处理的R包。 terra 2 Paper：1.Fast Geographically Weighted Regression (FastGWR): A Scalable Algorithm to Investigate Spatial Process Heterogeneity in Millions of Observations/快速地理加权回归（FastGWR）：一种可扩展的算法，用于研究数百万次观测中的空间过程异质性 地理加权回归（GWR）是一种广泛使用的工具，用于探索地理空间上的过程的空间异质性。 GWR计算特定于位置的参数估计，这使得其校准过程计算密集。当前开源GWR软件可以处理的最大数据点数在标准桌面上大约为15,000个观测值。在大数据时代，这严重限制了GWR的使用。为了克服这一限制，我们提出了一种基于Python和消息传递接口（MPI）的高度可扩展的开源FastGWR实现，可以扩展到数百万次观察。 FastGWR优化了内存使用以及并行化，从而显着提升了性能。为了说明FastGWR的性能，从洛杉矶市的Zillow数据集中，对大约130万个单户住宅物业进行了特征房价模型的校准，这是首次将GWR应用于此大小的数据集。结果表明，随着高性能计算（HPC）环境中核心数量的增加，FastGWR呈线性扩展。它还优于目前可用的开源GWR软件包，在标准桌面上具有极快的速度降低速度 - 快达数千倍。很有幸，笔者在5月份北京的空间精度2018会议上见过作者的汇报，当时的题目是比较不同GWR的结果是否有差异性？同时也简要介绍了他开发的FastGWR软件。现在已经在IJGIS发表了，GWR算法在大数据上的扩展。之前笔者在暑期学校的时候有幸听过Fothingham的汇报，他也曾说过原来的GWR运算规模大约在8w条左右数据。因此这个FastGWR的出现将会为GWR领域的研究带来更多的活力与生机。 2.Using MAIAC AOD to verify the PM2.5 spatial patterns of a land use regression model/使用MAIAC AOD验证土地利用回归模型的PM2.5空间模式 PM2.5的准确空间信息对于空气污染控制和流行病学研究至关重要。土地利用回归（LUR）模型已被广泛用于预测地面PM2.5的空间分布。然而，由于有限的地面观测，LUR模型的预测PM2.5空间模式尚未得到充分研究。增加的气溶胶光学厚度（AOD）产品可能是大面积空间连续观测的近似值。本研究建立了北京季节1 km×1 km MAIAC AOD与观测地PM2.5之间的关系，并根据AOD预测了季节性PM2.5地图。还开发了季节性LUR模型，AOD和LUR模型均通过保持监测站点进行验证。最后，通过上述AOD PM2.5图，全面验证了LUR模型的空间模式。结果表明，单独AOD可以直接用于预测地面PM2.5浓度在季节水平的空间分布，与LUR模型的能力相当。源自这两种方法的PM2.5地图在交通道路附近显示出相似的空间趋势和协调变化。在土地利用特征变化很快的城乡过渡地区，可以观察到很大的差异。变量和缓冲区大小选择对于LUR模型至关重要，因为它们主导了预测PM2.5的空间模式。将AOD纳入LUR模型可以提高春季的模型性能，并在测试过程中提供更可靠的结果。LUR模型和AOD产品的对比研究，PM2.5的制图是当前大气遥感的一大研究重点，LUR和AOD的研究是比较普遍的两种方式。这个比较还是比较有意思的。 3.Supervised Classification of Power Lines from Airborne LiDAR Data in Urban Areas/基于机载激光雷达数据的城市电力线监督分类 使用机载LiDAR（光探测和测距）数据自动提取电力线一直是电力管理最重要的主题之一。然而，这对于复杂的城市地区来说非常具有挑战性，因为电力线靠近建筑物和树木。在本文中，我们提出了一个新的，半自动化和通用的框架，包括四个步骤：（i）电力线候选点过滤，（ii）局部邻域选择，（iii）空间结构特征提取，以及（iv）SVM分类。我们介绍了候选点过滤和多尺度斜圆柱邻域的电力线走廊方向，用于空间结构特征提取。在详细评估涉及七个尺度和四种类型的局部邻域选择，26个结构特征和两个数据集，我们证明了使用多尺度斜圆柱邻域的单个3D点显着改善了电力线分类。实验表明，电力线分类的精度，召回率和质量率分别超过98％，98％和97％。此外展示了该方法可以减少整个处理时间，同时实现高精度。激光雷达遥感的一个新应用，电力线规划。激光雷达遥感近年来的兴起，使得遥感方面有了很多新的应用。 4.URBAN-i: From urban scenes to mapping slums, transport modes, and pedestrians in cities using deep learning and computer vision/URBAN-i：从城市场景到城市中的贫民窟，交通方式和行人，使用深度学习和计算机视觉 在跨越不同科学领域的深度学习和计算机视觉的迅速发展中，在城市发展方面，深度学习和计算机视觉应用仍然局限于智能城市和自动驾驶汽车的概念。实际上，在欠发达国家的城市和城市地区出现了很大的知识差距，其中非正规性的混乱是主导方案。深度学习和人工智能（AI）如何解决非正规性的复杂性，以推进城市建模和我们对城市的理解？在人工智能和计算机视觉的范例中，可以提出关于北方和南方城市未来的各种问题和争论。在本文中，我们介绍了一种依靠深度学习和计算机视觉的多用途现实 - 动态城市建模的新方法，使用深度卷积神经网络（CNN），从空中和街景图像中感知和检测城市场景中的非正规性和贫民窟。除了检测行人和运输模式。该模型已经在全球城市的城市场景图像上进行了培训。该模型很好地验证了计划区域和非计划区域之间的各种细微差别，包括非正规区域和贫民区。我们尝试推进城市建模，以更好地了解城市发展的动态。我们还旨在举例说明人工智能在城市中的重要影响，超越了主流中智能城市的讨论和感知。 URBAN-i模型的算法在Python编程中完全编码，使用预先训练的深度学习模型，用作地球各个角落的地图和城市建模工具，包括非正式住区和贫民窟区域。计算机视觉和深度学习在城市规划中的应用。 5.Nighttime light images reveal spatial-temporal dynamics of global anthropogenic resources accumulation above ground/夜间光图像揭示了地上全球人为资源积累的时空动态 城市化和工业化在很大程度上代表了从生物圈和岩石圈到人类圈的材料转化过程。因此，了解这种人为物质库存积累的模式是评估和维持人类如何改变地球周围资源的生物物理运动的基本先决条件。然而，由于较高空间分辨率的数据缺口，以前关于这些人为种群的研究往往局限于全球和国家尺度。在此基础上，本研究基于一套新的国家材料库存数据和夜间光图像，开发了一个回归模型，用于绘制1 km×1 km水平的三种基本建筑材料（钢，混凝土和铝）的全球人为库存。 1992年至2008年，本研究发现了一种分布不均匀的模式，其中超过40％来自三条带：从英格兰穿越海峡到西欧;从中国东部沿海到韩国和日本;从美国东海岸的五大湖到佛罗里达州。较小空间尺度的全球人为种群的时空动态反映了自然地理，建筑和建筑规范以及社会经济发展的综合影响。本研究的结果提供了有用的数据，可以为区域和城市规模的政策制定者和行业提供资源效率，废物管理，城市采矿，空间规划和环境可持续性方面的支持。夜间灯光用于产业生态方面的研究，长时间序列的产业生态学人为资源积累的高分辨率制图。 6.Estimating the impacts of urban form on CO2 emission efficiency in the Pearl River Delta, China/估算城市形态对珠江三角洲二氧化碳排放效率的影响 提高二氧化碳排放效率对实现节能减排目标，实现低碳发展具有重要意义。虽然人们越来越认识到城市形态可以显着影响城市地区的二氧化碳排放，但很少有研究能够量化城市形态对二氧化碳排放效率的影响。因此，本文的目的是通过实证量化城市形态如何影响二氧化碳排放效率来为现有文献做出贡献。本研究中的二氧化碳排放效率以二氧化碳经济效率（CEE）和二氧化碳社会效率（CSE）表示。首先，本研究利用1990 - 2013年期间当地重要的社会经济变量，计算了珠江三角洲（广州，深圳，珠海，佛山，江门，肇庆，惠州，东莞和中山）九个城市的相关数据。然后，选择了七个景观指标，以便使用遥感数据量化城市形态的三个维度（扩展，不规则和紧凑）。最后，利用面板数据模型来估计城市形态与二氧化碳排放效率之间的关联。本研究发现城市扩张与CEE和CSE之间存在负相关关系，这一发现表明城市增长会降低二氧化碳的经济效率。此外，发现城市形式的不规则性增加会降低CEE和CSE-更大程度的不规则性，换句话说，导致更低的二氧化碳排放效率。相反，城市紧凑性被确定为对CEE和CSE都有显着的积极影响，这表明城市的紧凑发展实际上可以帮助提高二氧化碳排放效率。这项研究的结果对于建设中国的低碳城市具有重要意义。一直关注城市形态对于二氧化碳排放的影响，这篇文章是一篇很不错的参考论文。 7.Estimation of ground level particulate matter concentrations through the synergistic use of satellite observations and process-based models over South Korea/通过在韩国协同使用卫星观测和基于过程的模型估算地面颗粒物浓度 长时间暴露于空气动力学直径10μm（PM10）和2.5μm（PM2.5）的颗粒物质（PM）对人体健康具有负面影响。虽然在全球范围内进行了基于站点的PM监测，但在高空间分辨率下为大面积区域提供空间连续的PM信息仍然具有挑战性。卫星衍生的气溶胶信息，如气溶胶光学深度（AOD），经常被用来研究地面PM浓度。在这项研究中，我们将多个卫星衍生产品（包括AOD）与基于模型的气象参数（即露点温度，风速，表面压力，行星边界层高度和相对湿度）和排放参数（即NO，NH3， SO2，POA和HCHO）估算韩国的表面PM浓度。随机森林（RF）机器学习用于估算PM10和PM2.5浓度，2015-2016共有32个参数。结果表明，基于RF的模型产生了良好的性能，导致R10值分别为0.78和0.73，PMMS和PM2.5的RMSE分别为17.08μg/m³和8.25μg/m³。特别是，所提出的模型成功地估计了高PM浓度。 AOD被认为是估算地面PM浓度最重要的因素，其次是风速，太阳辐射和露点温度。使用来自对地静止卫星传感器（即GOCI）的气溶胶信息导致估算PM浓度的精度略高于来自极轨道传感器系统（即MODIS）的精度。所提出的RF模型产生了更好的性能，特别是在改进低估基于过程的模型（即GEOS-Chem和CMAQ）方面。融合过程模型与卫星影像的PM污染物制图，多源数据融合用在PM制图上的工作，发表在欧洲地学旗舰刊物。 8.Transferability and Upscaling of Fuzzy Classification for Shoreline Change over 30 Years/30年来海岸线变化模糊分类的可转移性和提升 地方当局要求提供有关土地使用决策的海岸线变更信息。监测海岸线变化对于更新沿海规划和管理中使用的海岸线地图非常有用。通过分析一段时间内的数据，可以确定海岸变化的位置和速度。因此，我们可以防止高风险区域的任何发展。这项研究调查了海岸线变化的模糊分类的可转移性，并向更大的区域进行了升级。使用六个子区域，使用了三种策略：（i）基于参考子集的主要土地利用/覆盖优化两个FCM（模糊c-均值）参数，（ii）采用类别平均值和由参考子集的分类以在目标子集上执行FCM，以及（iii）估计目标子集的模糊性的最佳水平。这种方法应用于一系列图像，以确定印度尼西亚中爪哇省北部一段三十年来海岸线位置发生严重变化的海岸线位置。通过覆盖海岸线图像估算海岸线变化的程度。突出显示海岸线位置以推断沿海岸的侵蚀和吸积区域，并计算海岸线的变化。从实验结果来看，我们获得了分析的7个土地利用/覆盖等级的m（模糊度）值在1.3到1.9的范围内。此外，对于本研究中使用的十个图像，我们获得了最优m = 1.8。对于类似的沿海特征，可以采用该m值，并且土地利用/覆盖与两个FCM参数之间的关系可以缩短优化参数所需的时间。所提出的用于将分类方法放大并转移到更大或不同区域的方法是有希望的，显示κ（kappa）值&gt; 0.80。结果还显示参考和目标子集之间的水隶属度值的一致性由κ&gt; 0.82表示。在研究期间，该地区表现出侵蚀和吸积。通过水的变化表明侵蚀，并且观察到从非水到海岸线的变化大约78平方公里。增加的原因是非水的变化以及从水变为海岸线的变化为19.5平方公里。研究区东段的侵蚀严重，而中段通过填海活动获得土地。这些侵蚀和吸积过程在海岸线的变化中发挥了积极作用。我们得出结论，该方法适用于当前的研究领域。可以采用土地利用/覆盖等级与本研究中产生的FCM参数值之间的关系。海岸线的遥感提取的研究，基于模糊分类的方法。近年来海平面上升一直是全球变暖关键的关注问题，海岸线的遥感提取可以快速帮助这方面的深入研究。]]></content>
      <categories>
        <category>Personal</category>
      </categories>
      <tags>
        <tag>Consideration of Ecology and Geography</tag>
        <tag>Summary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Coding and Paper Letter（二十）]]></title>
    <url>%2F2018%2F09%2F13%2FCoding-and-Paper-Letter%EF%BC%88%E4%BA%8C%E5%8D%81%EF%BC%89%2F</url>
    <content type="text"><![CDATA[资源整理。 1 Coding：1.R语言包tibbletime，处理时间数据的包。 tibbletime 2.R语言包gravity，重力模型，可以用于分析交互作用等，其实应该是模仿物理学引力模型的拓展，在经济地理中也有介绍过。 gravity 3.开源项目earth analytics fall 2018，地球分析2018秋季课程作业模板。 earth analytics fall 2018 4.开源项目GeolocatorAnalyses，地理定位数据分析，基于R语言的项目。 GeolocatorAnalyses 5.Python开源项目PyRADS，PyRADS是用于行星大气的Python逐行辐射模型。 PyRADS 6.开源项目Eco variation，论文”Spatial and temporal variation of ecosystem properties at macroscales”的数据处理脚本和代码（R）。 Eco variation 7.Python开源项目nativepython，一个基于llvm的框架，用于从Python生成和调用高性能本机代码。 nativepython 8.R语言包RGDALDB，在sf中为GDAL的ExecuteSQL提供DBI。 RGDALDB 9.DMLC开源项目xbgoost，机器学习大杀器，提供了多个语言的接口。 xgboost 10.VS code的Github pull/request插件。 vscode pull request github 11.开源项目spatialdata，目测是某论文的代码，scala语言的项目。 spatialdata 12.开源项目AtlantisNEUS R，R代码（脚本和函数）与Atlantis NEAU End-2-end海洋生态系统模型的交互和分析输出。 AtlantisNEUS R 13.Python库Panuscript，Pandoc，pandoc-citeproc和ImageMagick的轻量级Python封装，用于学术写作。 Panuscript 14.使用link2gi的教程。link2GI是R包，提供更方便的R语言与其他开源GIS软件的交互。 link2gi2018 link2GI 15.R语言包uavRmp，无人机任务规划。应该是类似于地面站那样子的规划飞行线路的功能。 uavRmp 16.亚马逊雷达数据处理。 amzn lidar 17.Python开源项目live earth desktop，连续下载向日葵8号数据，并且作为桌面背景。 live earth desktop 18.WRF-hydrology，WRF水文模型代码。 wrf hydro nwm public 19.R语言使用者研讨会上Python的材料。 python for r users workshop 20.R语言开源项目voronoiTreemap，用于voronoi树图的R包，通过shiny增加了交互性。 voronoiTreemap 21.R语言包sf，空间要素的R包。 sf 22.Python开源项目phstl，将GDAL栅格转换为STL的三维格网。 phstl 2 Paper:1.Integrating the past, present, &amp; future of Landsat: Continuity of science, applications, monitoring, and reporting/整合Landasat的前世，今生和未来：科学、应用、监测与报告的连续性 该链接其实不是论文，应该是一个ppt。Landsat科学团队在2017年夏季会议上发表的演讲。 EROS中心，Sioux Falls，SD，美国。 2017年7月12日。回顾了Landast数据近年来的应用，包括土地覆被，和激光雷达结合的生物量估算，树高估算。 2.Urbanisation and human health in China: Spatial features and a systemic perspective/中国城市化与人类健康：空间特征与系统视角 目前的研究很少关注城市空间扩展的活力及其可能的环境和健康影响，或城市化梯度不同点的城市环境快速变化对健康的影响。本研究采用公共卫生生态学方法，系统地了解中国城市化，城市环境变化与人类健康之间的关系。基于近几十年来五个不同时期的夜间灯光数据的遥感图像分析被用于确定整个城市区域的变化。通过回顾有关环境健康，城市化和健康之间关系的证据，我们推进了解释城市人类健康生态的途径框架。 Spearman等级相关系数用于衡量疾病流行率与城市化水平之间的相关性，为系统理解城市健康增加了另一个维度。近几十年来，城市地区在空间上一直在增加，但不均衡，中小城市在过去十年中也在迅速扩大。城市化和城市扩张导致土地利用/覆盖变化，城市环境和居民生活方式的变化，从而导致人类健康问题。近几十年来，城市化水平最高的地区更倾向于患慢性病。如果人类疾病不成为社会和经济发展的障碍，生态公共卫生方法可以提供对需要定期收集的多种数据的见解。较早的城市化与人类健康的论文。城市扩张导致的慢性疾病，在近年来健康城市研究越来越受重视。 3.Modeling Discrete Forest Anisotropic Reflectance Over a Sloped Surface With an Extended GOMS and SAIL Model/利用扩展的GOMS和SAIL模型在斜面上建立离散森林各向异性反射模型 地形对冠层反射率的影响在崎岖地形的地表生物物理变量的反演中起着关键作用。在本文中，我们提出了一种新的离散森林冠层各向异性反射模型，几何光学和相互遮蔽和从任意倾斜叶片散射模型与地形（GOSAILT）相结合，考虑了坡度，坡向，地下性质的影响。树木生长，多重散射和漫射天窗。使用用于坡地地形（GOST）模型的几何光学模型评估GOSAILT模拟的四个场景分量（即，阳光照射的冠，阴影冠，阳光照射的背景和阴影背景）的面积比例。通过GOSAILT模拟的冠层反射率针对两个反射率数据集进行验证。这些广泛的验证表明GOSAILT在倾斜表面上的冠层反射模拟中具有良好的性能。几何光学模型的一个新改进模型，从小文院士的四分量理论出发，针对地形对冠层反射率影响做了改进。 4.Accounting for differences in costs among sampling locations in optimal stratification/在最优分层中考虑采样位置之间的成本差异 在可到达性方面存在显着差异的区域，通过考虑采样位置选择的这些差异，可以提高用于估算总体平均值或总数的基于设计的抽样策略的成本效率。这可以通过分层随机抽样来实现。那么问题是如何构建分层。现有的最优分层方法（例如cum stratification）在采样单元中假定成本不变，因此当违反该假设时可能是次优的。在给定预期总成本的最大值的情况下，提出了模拟退火算法，用于在样本大小的最佳分配下同时优化层中断和样本大小。所提出的分层方法在中国安徽省5900平方公里的研究区进行了测试。计算最佳分层阈值以估计土壤有机质含量（SOM）的总体平均值。来自多元线性回归模型的SOM预测被用作分层变量。最佳的分层阈值与cum stratification阈值不同。使用最优分层的SOM估计平均值的方差比cum stratification小约8至29％，这取决于地层的数量。这种大的精度增益可以通过逐点成本和分层变量的适度强相关来解释。当这种相关性较弱或者单位之间的成本变化较小时，预计会有较小的增益。当没有与感兴趣的变量相关的辅助变量可用时，也可以使用所提出的算法，仅考虑采样单元之间的成本差异。在地理学中，采样位置的设计是绕不开的关键话题，如何提高采样效率，降低成本，本文提供了一个很好的范例研究。 5.Delineation of a permanent basic farmland protection area around a city centre: Case study of Changzhou City, China/划定市中心周边永久性基本农田保护区：中国常州市案例研究 划定永久性基本农田将保障中国农业发展的生产基线，确保城市周边地区易于占用优质农田，从而严格控制面临城市扩张加速的农田（特别是城市周边优质农田）的使用。本研究研究了典型地区正在进行快速城市化的永久性基本农田的划分。通过构建系统分类模型，将农田分为基质，边缘和岛屿农田，以分析农田的邻接和破碎。根据各种农田计划的指标要求，建立了评价指标体系，以建立综合农田生产力评价模型。从农地空间连续性和高效生产力的角度出发，提出了永久性基本农田划分模型，划定了城市周边优质农田的永久保护和利用边界。结果表明：（1）基质和边缘农田可以直观地显示农田的邻接特征; （2）综合耕地生产力与耕地空间格局，配套基础设施，政策管理和保护密切相关; （3）毗邻和高产农田之间存在高度的空间重叠。该模型考虑了综合农田生产力和空间聚类，以划定永久性基本农田，这是保护耕地质量和保障农田可持续利用的有利因素。它还可以作为控制线来限制城市扩张，引导城市群发展，改善经济和集约的城市土地利用。基本农田的划分模型，比较有实际意义的研究，毕竟目前为止，这个部分似乎主要靠人工。如果方法值得推广，是一个很不错的研究。 6.Effectiveness Assessment of Soil Erosion Critical Source Areas for Soil and Water Conservation/水土保持土壤侵蚀关键源区有效性评价 以严重的土壤侵蚀和高沉积物产量为特征的关键源区（CSAs）被认为是保护的重中之重。如何识别CSA并评估保护措施的有效性是特定地点流域管理的关键问题。土壤和水评估工具（SWAT）模型是用于特定地点保护实践设计的有用工具，并且一些研究试图基于流域模型识别CSA。然而，有限的研究报告了针对CSA的保护实践的有效性。本研究的目的是使用SWAT模型评估针对CSA的保护措施的有效性。首先根据每个HRU的4年平均年侵蚀来确定CSA。然后为CSA设计了适当的土壤保持措施。还建立了整个流域保护措施的情景，作为对比的对应部分方案，然后与CSA目标保护措施的结果进行比较。结果表明，SWAT可以准确模拟研究区的沉积物产量。 CSA主要位于坡耕地和陡峭的沟壑，与土地利用和坡度分布相吻合。确定的CSA覆盖了20％的HRU，平均贡献了44％的沉积物产量。针对CSA的保护措施比覆盖整个流域的保护实践具有更高的减沙效果。因此，针对CSA的保护实践比广泛的保护实践更有效。我们得出结论，以CSA为重点的土壤保持措施确实可以提高减沙效果。根据CSAs概念确定土壤保持措施的安置将有助于流域的水质控制。SWAT模型在流域管理和土壤侵蚀方面的应用。流域生态学，或者以流域为管理单元的生态学研究似乎在这几年比较火热。虽然这是篇较早的论文，也是可以回顾的。 7.Evaluation and comparison of MODIS Collection 6.1 aerosol optical depth against AERONET over regions in China with multifarious underlying surfaces/评估和比较MODIS Collection 6.1与AERONET在中国各地区的多种下垫面的气溶胶光学厚度 这是篇手稿论文。这项研究评估了MODIS C6.1 AOD产品的性能，并将其与中国地区的C6产品进行了比较，并在2001年至2016年期间对多种下垫面进行了比较。AOD反演在20个AERONET站点进行了验证，结果显示C6.1中的DT反演的R为0.946，而EE内的分数可认为相对较低，仅为54.03％。 C6.1中的DB反演具有略低的R值，但其他标准优于DT。比较C6.1中城市和植被区域的结果，DB反演的总体质量优于城市地区的DT反演。在LEV领域，DT的性能明显优于DB。对于HEV区域，DB在综合上比DT更好地执行。在C6.1的空间分布方面，大多数DB AOD值小于DT的值，DT和DB之间的关系随着不同的土地覆盖类型而变化。对于C6.1中的AOD覆盖范围，高覆盖率的DT反演主要分布在中国中东部地区。然而，高表面反射率的影响导致西南地区的AOD覆盖率低。相反，在主要土地覆盖类型为裸土的区域中，DB的AOD覆盖率往往较高，而在受雪影响的区域往往较低。就C6.1和C6之间的比较而言，C6中对城市地区的DT的过高估计得到了有效的缓解。然而，在C6.1中也发现了DT几乎系统性的下降。对于DB，观察到一致的AOD覆盖分布，仅有细微的区别。 C6.1中DB的AOD覆盖率高于中国中部，南部和东北部的C6。与C6相比，C6.1中DB回收的质量略有增加，并且对于粗气溶胶颗粒观察到最显着的改善。DT是指暗目标法，DB是指深蓝算法。在比较AOD产品过程中，可以明显发现AOD与下垫面以及海拔的密切联系。 8.An estimate of rural exodus in China using location-aware data/利用位置感知数据估算中国农村人口外流 快速发展的经济和中国日益增长的城市化创造了人类历史上最大的农村向城市迁移。因此，全面了解农村迁徙模式及其在该国的普遍程度和规模对于社会和政治问题越来越重要。由于以前从十年一次的人口普查和小规模家庭调查中得出的内部移徙数据有限，我们无法及时和一致地观察整个国家的农村人口减少动态。在本研究中，我们使用从2016年农历新年期间中国最大的社交媒体平台的移动位置请求中收集的总体位置感知数据，对中国农村人口减少进行全国性估算（就网格单元而言）基于世界上最大的旅行时期的水平流行率和幅度。我们的研究结果表明，广泛的农村飞行可能发生在网格单元级农村土地的60.2％（36.5％-81.0％，低于上限估计），覆盖约1.55（1.48-1.94）百万个村庄和村庄，中国大部分地区农村定居点。此外，我们发现估计的农村人口减少的幅度和空间范围存在明显的区域差异。这些变化可能与源群体的大小区域差异有关，主要是因为当今中国的农村飞行普遍存在。我们的估计可以为中国农村人口减少的相关调查以及人口统计研究中越来越多的人群来源数据的可能性提供见解。Social Sensing数据的典型研究，基于社交媒体大数据估算人口外流。 9.Using Individual GPS Trajectories to Explore Foodscape Exposure: A Case Study in Beijing Metropolitan Area/利用个人GPS轨迹探索Foodscape暴露：北京都市圈的案例研究 随着人们越来越关注人们获取食物环境的特征及其对个人健康的影响，人们开始关注基于GPS轨迹评估个人食物暴露。然而，现有的研究主要集中在使用短周期轨迹的整体活动空间，这忽略了人类运动的复杂性以及个体在日常生活安排中所经历的空间的异质性。在这项研究中，我们提出了一个新的框架来提取暴露区域，包括日常生活中心周围的局部活动空间和长期GPS轨迹的非机动通勤路线。新提出的框架是针对具体个体的，可以将不同地方的个体活动（空间范围，停留持续时间和时间）的内部异质性以及背景的动态结合起来。对GeoLife数据集的初步研究表明，个体暴露区域的不同部分的食物环境的大小和组成存在显着差异，并且居住环境不代表整个Foodscape。使用微软亚院的Geolife数据集进行分析，对于Foodscape的暴露评估，不同于目前已经有很多成果的污染暴露评估，还是相对较为新颖的一个方向。 10.Multiscale Measures of Population: Within- and between-City Variation in Exposure to the Sociospatial Context/多尺度人口测度：暴露于社会空间背景下的城市内和城市间变化 了解空间尺度对于理解社会空间背景至关重要。在隔离和邻里效应文献中已经开发了多尺度人口测量方法，这些文献承认了各种空间背景对个体成果和群体间联系的作用。尽管现有的关于社会空间不平等的研究越来越多地探索空间尺度的影响，但很少有系统证据表明社会空间环境的暴露如何在城市内部和城市之间的城市空间中发生变化。本文介绍了一种衡量他人潜在风险的多尺度方法。利用荷兰全体人口的个人层面登记数据和101个空间尺度的特殊详细的多尺度定居社区框架，我们测量了三个具有不同城市形态的荷兰城市的非西方少数民族比例。我们创建了种族暴露的个人和累积距离概况，绘制了种族暴露表面，并应用熵作为标量变异的度量，以比较城市内部和城市之间不同位置的其他人的潜在暴露。可以实施多尺度方法来检查各种社会过程，特别是隔离和邻域效应。偏向社会学的一个研究，主题是隔离和邻域效应。感觉是偏向种族的研究，此外，在中国可能比较难以进行，个人层面登记数据很难获取。 11.Targeted change detection in remote sensing images/遥感图像中的目标变化检测 遥感系统和图像处理的最新发展使得有可能提出一种新的方法，用于对象分类和检测一系列卫星地球图像中的特定变化（所谓的目标变化检测）。 本文中提出了一个正式的问题，允许有效地使用深度学习方法来分析时间相关的遥感图像系列。 本文还引入了一个新的框架，用于开发针对目标变化检测的深度学习模型，并演示了一些可用于业务应用的案例。基于深度学习提出的目标变化检测，变化检测一直是图像领域的热点问题，而到了遥感影像同样如此，不过相对而言，个人认为遥感的变化检测要麻烦得多。 12.Collections of Points of Interest: How to Name Them and Why it Matters/兴趣点收集：如何命名他们及其重要性 可通过网络访问大型全球覆盖的兴趣点（POI）数据库以及社会传感技术，以研究人类如何对待这些POI，即当他们访问这些POI时，他们如何撰写这些POI，他们访问这些POI的顺序，等等，导致研究人员和公司利用POI代表地区及其可供性。例如，可以通过它们包含的POI的类型以及它们的频率来表征邻域，或者尝试基于这些POI在地理空间上分布的空间模式来提取功能区域的空间足迹。然而，这些观点忽略了这些POI之间的空间和位置以及定义多种区域及其相互作用的运输基础设施。因此，退步并明确说明人们考虑POI的集合以描绘区域（例如，将其与诸如旅游业之类的活动类型相关联）通常更有益。举一个具体的例子，人们经常在纽约这样的城市拍照的地点所包围的区域可以被描述为感兴趣的区域（例如，时间广场），以区别于仅基于点的视角。不幸的是，社区尚未就这些领域的共同术语达成一致，而是使用人类地理或遥感等领域的类似术语作为代理。虽然它们通常具有重叠的含义，但我们认为，与感兴趣的领域和其他POI集合相比，讨论诸如邻域，功能区域，模糊认知区域等术语的相似性和差异性将是有益的。感觉是一个全新的话题，针对POI这类VGI数据的一个语义思考，来自威斯康星大学麦迪逊分校高松老师的研究，在刚刚举办的国际地理信息科学大会的会议论文。]]></content>
      <categories>
        <category>Personal</category>
      </categories>
      <tags>
        <tag>Consideration of Ecology and Geography</tag>
        <tag>Summary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Coding and Paper Letter（十九）]]></title>
    <url>%2F2018%2F09%2F11%2FCoding-and-Paper-Letter%EF%BC%88%E5%8D%81%E4%B9%9D%EF%BC%89%2F</url>
    <content type="text"><![CDATA[资源整理。接上篇，这篇博客主要关注论文。 Paper:1.Spatial-Spectral Fusion by Combining Deep Learning and Variation Model/结合深度学习和变异模型的空间光谱融合 在空间光谱融合领域，基于模型的方法和基于深度学习（DL）的方法是最先进的。本文提出了一种融合方法，将深度神经网络结合到基于模型的方法中，用于空间光谱融合中最常见的情况：PAN /多光谱（MS）融合。具体来说，我们首先通过深度残差将高空间分辨率全色图像（HR-PAN）和低空间分辨率多光谱图像（LR-MS）的梯度映射到高空间分辨率多光谱图像（HR-MS）的梯度卷积神经网络（CNN）。然后我们通过LR-MS图像，从梯度网络学习的梯度和理想的融合图像构建融合框架。最后，使用迭代优化算法来求解融合模型。对来自各种来源的高质量图像的定量和视觉评估表明，所提出的融合方法在整体融合精度方面优于比较中包括的所有主流算法。武汉大学张良培老师团队的成果，利用深度学习进行空间和光谱融合，光谱级的融合目前还只是初探，是个很不错的尝试。之前见过NASA官方在利用MODIS的一些历史数据进行类似的工作，这方面的尝试值得探究。 2.A proportional odds model of human mobility and migration patterns/人类流动和迁移模式的proportional odds模型 由于其重要性，人类流动和迁移模式的建模受到了很多关注。尽管进行了长期努力，我们仍然缺乏一个能够捕捉流动模式的建模框架，并进一步获得有关各种影响因素的运动趋势的前瞻性观点。在这里，我们提出了人类迁移和迁移的比例概率模型（POM-HM），它采用概率方法来模拟人类运动。我们的模型基于迁移概率，在比率概率假设下具有对数 - 逻辑分布。通过重新参数化概率分布函数将解释变量引入到模型中。两个由此产生的函数，即迁移强度和累积危险，用于估计旅行流量及其趋势之间的区域差异。研究了POM-HM在有效性和准确性方面的性能，并与重力模型和辐射模型进行了比较。基于概率的建模框架使我们能够研究移民流量的区域变化，从而进一步预测潜在的未来模式。简而言之，我们的建模方法捕捉了人类流动和迁移的概率性质，并进一步加深了我们对人口迁移的时空模式和各种驱动力的影响的理解。地理所马廷老师的成果，发表于GIS界Top期刊IJGIS，基于概率统计建模来反映人类的mobility和migration，马廷老师自在给我们上课的时候就是专攻统计方面的知识，很好的数理基础建立的模型。值得细细研究。 3.8 million phenological and sky images from 29 ecosystems from the Arctic to the tropics: the Phenological Eyes Network/从北极到热带的29个生态系统中的800万个物候和天空图像：物候眼网络 我们报告了从北极到热带的各种生态系统中通过物候眼网络（http://www.pheno-eye.org，2018年5月29日访问）的延时摄像机拍摄的长期连续物候和天空图像。物候图像可用于记录开花时间，叶片冲洗，叶子着色和落叶的年度变化，并检测物种和生态系统中物候模式和时间敏感性的特征。它们还可以帮助解释陆地生态系统中碳，水和热循环的变化，并用于获取卫星观测产品验证的地面实况数据。天空图像可用于连续记录大气条件并获得地面实况数据，以验证卫星遥感数据中存在的云污染和大气噪声。我们采用天空，森林树冠，森林地面，拍摄一系列树种和景观的图像，使用安装在森林地面，塔楼和屋顶上的延时摄像机。自1999年以来，共有29个站点的84个延时摄像机拍摄了800万张图像。我们的图像提供了（1）植物物候的长期，连续详细记录，这些记录比指数树的原位视觉物候观测更加定量; （2）解释生态系统檐篷及其功能和服务对气候变化的响应能力，脆弱性和回复力的基本信息; （3）用于验证卫星遥感观测的地面实况。利用延时摄影数据，研究不同生态系统，尤其是植物物候，除了文章本身之外，文章介绍的数据是关键。非常不错的长期观测数据，正如文章提到的，可以为当前很多生态研究提供数据包括验证卫星遥感观测。关于利用照片来进行研究的一些案例在植被物候方面尤其多，当今图像识别和人工智能如此火爆的时代，相信这个数据会迸发出更大的潜力。另外比较有意思的应该是在去年R语言会议分会场上，狗熊会朱雪宁博士分享的一个他们利用手机拍摄天空，获取可见度和PM2.5校准匹配的研究。 4.Hyperspectral Image Denoising Employing a Spatial-Spectral Deep Residual Convolutional Neural Network/利用空间光谱深度残差卷积神经网络进行高光谱图像去噪 高光谱图像（HSI）去噪是一种关键的预处理程序，用于改善后续HSI解释和应用的性能。在本文中，通过组合空间谱深度卷积神经网络（HSID-CNN）学习噪声和干净HSI之间的非线性端到端映射，提出了一种基于深度学习的新方法。空间和频谱信息都同时分配给建议的网络。此外，多尺度特征提取和多级特征表示分别用于捕获多尺度空间光谱特征和融合最终恢复的不同特征表示。仿真和实际数据实验表明，所提出的HSID-CNN在定量评价指标，视觉效果和HSI分类准确性方面均优于许多主流方法。依旧是武大张良培老师团队的成果，张良培老师团队最近在利用深度学习处理遥感数据有不少成果，这里是对高光谱去噪的应用，使用的是深度残差卷积神经网络。发表于遥感界Top期刊IEEE TGRS上。 5.Unveiling Cabdrivers’ Dining Behavior Patterns for Site Selection of “Taxi Canteen” Using Taxi Trajectory Data/利用出租车轨迹数据揭示Cabdrivers的“出租车食堂”选址行为模式 近年来，中国的一些大城市建立了一些“出租车食堂”，这是一个特殊的自助餐厅，仅供驾驶员用餐和休息。在适当的时间用餐和休息是长时间连续驾驶的驾驶员最关心的问题之一，因为长时间的用餐延误可能会影响他们的健康和驾驶安全，长途搜索餐馆会增加出租车交通和空气污染和任意停车用餐将被罚款，甚至可能导致危险的交通事故。 “出租车食堂”的建立有望缓解这些问题。然而，使用基于GPS的出租车轨迹数据检查和优化出租车食堂的选址几乎没有做什么。本文介绍了一种在整个城市中分配“出租车食堂”的数据驱动方法，其主要目标是最小化从出租车轨迹和相应的最近“出租车食堂”位置识别的所有就餐需求位置之间的总距离。我们提出了一种用餐事件检测方法，该方法使用支持向量机（SVM）考虑四个特征，并进一步识别出驾驶员用餐行为的时空模式，即时间规律性和周期性以及用餐区域的空间分布。提出了一种约束优化模型来选择“出租车食堂”的位置。在中国武汉进行了一个案例研究，以评估驾驶员用餐行为模式的识别如何支持“出租车食堂”的选址。结果表明该方法具有优越的性能。该方法将为交通管理和规划部门提供有用的决策支持，以帮助解决驾驶员的用餐问题。大数据用在传统GIS问题的一个典型案例。传统GIS问题：资源分配或者调配。但是用了出租车轨迹的大数据以及机器学习算法。同时又是基于时间地理学的研究。我觉得大数据时代的研究，就应该把这些数据用到合适的地方。这篇文章提供了一个非常不错的案例。 6.Population dynamics based on mobile phone data to improve air pollution exposure assessments/基于手机数据的人口动态改善空气污染暴露评估 空气污染是当今城市面临的最大挑战之一，改善空气质量是减少负面健康影响的迫切需要。为了有效地评估哪些是减少城市污染源（如道路交通）影响的最合适的政策，必须进行严格的人口暴露评估。与这些研究相关的主要限制之一是缺乏有关当天城市人口分布的信息（人口动态）。移动设备在我们日常生活中的普遍使用为收集大量匿名和被动收集的地理定位数据提供了新的机会，可以分析人口活动和移动模式。本研究提出了一种基于以用户为中心的移动模型方法估算手机数据的人口动态的新方法。该方法在马德里市（西班牙）进行了测试，以评估人口暴露于NO2。与传统的基于人口普查的方法进行比较，显示出按分类水平存在的相关差异，并强调了将流动模式纳入人口暴露评估的必要性。这个研究与之前众山小翻译的一篇很像，我差点以为是同一篇，不过后面发现似乎略有差异。首先来说关于手机数据和人口暴露评估，是近年来大数据兴起健康地理一个很热的研究方向。也值得我们关注。总的来说，考虑细时间粒度，高精细空间分辨率的人口分布模式，是未来也是智慧城市的关键点。 Coding and Paper Letter（十）的第11篇论文可以对比。 7.Mapping and modelling the habitat of giant pandas in Foping Nature Reserve, China/中国佛坪自然保护区大熊猫栖息地的制图与建模 中国西部只剩下大约1000只大熊猫和29500平方公里的大熊猫栖息地，这是拯救这种濒临灭绝的动物物种并保护其栖息地的迫切问题。为了有效保护大熊猫及其栖息地，必须对每只大熊猫自然保护区的大熊猫栖息地和熊猫栖息地关系进行全面评估。制图一直是野生动物栖息地评估和监测的有效方法。因此，制图也是评估大熊猫栖息地的一个重要步骤，并进一步用于分析熊猫栖息地关系。只有佛坪自然保护区专注于这项研究。本研究的目标是：（1）开发一种高精度的制图方法，可以利用GIS中的多类型数据（遥感数据，数字地形数据，无线电跟踪数据和实地调查的地块数据）绘制大熊猫栖息地; （2）研究熊猫运动模式; （3）分析大熊猫栖息地的使用和选择。清华大学刘雪华老师的成果，看着似乎像是学位论文或报告。刘雪华老师一直专注于分析大熊猫栖息地，目前在这方面取得了很多成果，目前利用GIS在这方面，结合景观生态有很多研究。InVEST之类的提供了生境风险的一些模型。 8.Linear urban models/线性城市模型 开发了一类线性模型，其中活动源自彼此的变换和外源活动。 使用人口和就业的空间分布来说明模型。 推导出简化形式，并通过外生和内生变量的平衡以及通过对特征结构的分析来探索不同变换对空间模型解的影响。 包括传统Lowry模型和Coleman社会交换模型在内的十种模型类型应用于墨尔本的八区表示，分析用于显示模型解决方案如何在空间上独立于其输入。Michael Batty院士83年的成果，Batty院士是GIS空间分析和城市规划科学方面的大牛，一手创立了UCL的CASA。而这个模型让我想起了前一段看到的一个模型变式，我想科学进步应该是化繁为简，而不是逐步复杂。 9.An Improved Spatial and Temporal Reflectance Unmixing Model to Synthesize Time Series of Landsat-Like Images/一种改进的时空反射解混模型合成Landsat-Like图像的时间序列 空间和时间分辨率之间的权衡限制了Landsat图像密集时间序列的采集，并限制了及时正确监测地表动态的能力。时空图像融合方法为需要高空间和时间分辨率图像的应用生成密集时间序列的类似Landsat的图像提供了成本有效的替代方案。时空反射解混模型（STRUM）是一种基于空间解混的时空图像融合方法。由STRUM导出的时间变化图像缺乏光谱可变性和空间细节。本研究提出了一种改进的STRUM（ISTRUM）结构，通过考虑地表空间异质性并综合Landsat图像的光谱混合分析来解决该问题。在ISTRUM中也考虑了具有多个Landsat和粗分辨率图像对（L-C对）的传感器差异和适用性。实验结果表明，与STRUM得到的图像相比，ISTRUM得到的图像包含更多的光谱变异性和空间细节，提高了融合Landsat样图像的准确性。端元可变性和滑动窗口尺寸是影响ISTRUM精度的因素。通过将它们设置为不同的值来评估因子。结果表明，ISTRUM对于端部变异是稳健的，并且可以应用Landsat图像的公开发布的终端成员（全球SVD）。只有滑动窗口大小对ISTRUM的准确性有很大影响。此外，将ISTRUM与空间时间数据融合方法（STDFA），增强型空间和时间自适应反射融合模型（ESTARFM），混合色彩映射（HCM）和灵活时空数据融合（FSDAF）方法进行了比较。 ISTRUM优于STDFA，在时间变化显着，与ESTARFM相当且略逊于FSDAF的情况下略优于HCM。然而，ISTRUM的计算效率远高于ESTARFM和FSDAF。 ISTRUM可以在全球范围内合成类似Landsat的图像。一种新的时空影像融合模型。 10.Toward space-time buffering for spatiotemporal proximity analysis of movement data/通过时空缓冲区进行移动数据的时空邻近分析 用于确定时空邻近路径的时空邻近分析是许多移动分析方法的关键步骤。然而，在文献中已经开发了几种用于移动数据的时空邻近度分析的有效方法。因此，本研究提出了一种时空综合方法，用于同时考虑空间和时间维度的时空邻近度分析。所提出的方法基于时空缓冲区，这是传统空间缓冲操作对空间和时间维度的自然延伸。给定时空路径和空间容差，空时缓冲通过为沿时空路径的任何位置连续生成空间缓冲区来构建时空区域。构造的时空区域可以界定到目标轨迹的空间距离小于给定公差的所有时空位置。根据时空路径的不同时空邻近度量，例如Fréchet距离和最长公共子序列，提出了基于此时空缓冲的五个时空重叠操作来检索所有时空近端轨迹到目标时空路径。该方法扩展到分析道路网络中受限的时空路径。采用压缩线性参考技术实现所提出的大运动数据集中的时空邻近分析方法。使用真实世界运动数据的案例研究验证了所提出的方法可以有效地从大型运动数据库中检索在道路网络中受约束的时空邻近路径，并且与传统的时空分离方法相比具有显着的计算优势。将二维空间分析拓展到时空间分析的一个尝试和方法，缓冲区的思想结合上时间维创造出的时空缓冲区，是一个很有意思的点。 11.Urban sustainability and human health in China, East Asia and Southeast Asia/中国，东亚和东南亚的城市可持续发展与人类健康 导致人口变化的城市化将对人类健康产生深远影响，并为城市可持续发展带来挑战。我们回顾了目前在中国，东南亚和东亚地区对此问题的研究。东亚国家的城市化为改善人口健康提供了许多机会。然而，它也与健康风险有关，包括空气污染，职业危害和交通伤害，以及饮食和社会变化引起的风险。东南亚是新发传染病的热点，中国也因其人口规模而成为全球传染病负担的主要来源。农村 - 城市移民与城际或国际旅行相结合，可能导致农村和城市地区之间，甚至全世界城市之间更广泛的传染病蔓延。从城市环境规划的角度来看，塑造城市走向健康的未来可以帮助实现可持续发展目标。日本提供了许多关于公民如何保持健康的例子，例如全民医疗保险覆盖面，不同社会经济群体之间的差距减少以及强大的社区关系。由于地理和历史的不同，健康状况和卫生系统往往在东南亚国家内部和内部发生分歧。比较早的城市可持续发展与人类健康的综述性文章。 12.Validating canopy clumping retrieval methods using hemispherical photography in a simulated Eucalypt forest/在模拟的桉树林中使用半球摄影验证冠层丛生反演方法 所谓的聚集因子（Ω）量化了植被冠层中材料的随机3D分布的偏差，因此表征了冠层内空隙的空间分布。 Ω对于将有效的植物或叶面积指数转换为实际的LAI或PAI是必不可少的，之前已经证明这对于在森林，林地和稀树草原中使用光学遥感技术的生物物理参数反演具有显着影响。在这里，应用仿真框架来评估现有的原位聚集反演方法在具有高度建筑现实性的3D虚拟森林冠层中的性能。使用来自澳大利亚东部Box Ironbark桉树林的经验数据重建虚拟冠层。半球形摄影（HP）由于其无处不在的间接LAI和结构反演而被评估。使用基于不同茎分布和LAI的一系列结构配置来评估角结束反演方法性能。具有15°的区段尺寸的CLX聚集反演方法（Leblanc等，2005）是表现最佳的聚集方法，将参考值与平均近顶点的0.05Ω相匹配。对于所有结构配置，在75°时，结块误差与天顶角线性增加至&gt;0.3Ω（相当于30％PAI误差）。在较大的天顶角处，当从55-60°天顶角导出时，PAI误差平均为约25-30％。因此，建议仔细考虑HP使用的天顶角范围。我们建议制图或场地聚集因子应该伴随用于从空隙尺寸和空隙尺寸分布方法推导出它们的天顶角。此外，在1米的非代表性大树茎中捕获的HP中发现了更大的误差和偏差，因此在实践中应尽可能避免这些情况。这个事实上是在定量遥感和遥感物理中目前仍然很难从光学遥感攻克的难点，事实上涉及到光学几何模型，属于定量遥感的光学几何模型学派，而非辐射传输模型学派。但是光学几何模型通常在进行假设时对实际地物的几何模型做了大量简化，导致很多时候与地表的实际情况差异巨大，这里就是一个很典型的例子了，这篇文章做了非常不错的工作，因此也发在了农林领域Top期刊Agricultural and Forest Meteorology上。 13.Improved Salient Feature-Based Approach for Automatically Separating Photosynthetic and Nonphotosynthetic Components Within Terrestrial Lidar Point Cloud Data of Forest Canopies/改进的基于突变特征的森林冠层陆地激光雷达点云数据自动分离光合和非光合成分的方法 从三维地面激光扫描（TLS）数据中准确分离森林冠层中的光合作用和非光合作用成分是一项挑战，但对于了解森林的辐射状况，光合作用过程以及碳和水交换的空间分布至关重要。篷。本文的目的是通过仅根据其几何信息添加两个额外的过滤器来改进目前在森林冠层TLS数据中分离光合和非光合成分的方法。通过比较所提出的方法与特征值加上基于颜色信息的方法，我们发现所提出的方法可以有效地将整体生产者的准确度从62.12％提高到95.45％，并且整体分类生产者的准确性将从84.28％增加到97.80％。森林叶面积指数（LAI）从4.15降至3.13。此外，树种的变异对最终分类准确性的影响可以忽略不计，如针叶树（93.09％）和阔叶树（94.96％）的整体生产者准确性所示。为了定量地去除森林冠层中木质材料对改进基于TLS的LAI估计的影响，我们还基于来自单个树的分类线性类点计算“木质与总面积比”。森林点云数据集的自动分类将有助于TLS在反演三维森林冠层结构参数（包括LAI和叶片和木质面积比）方面的应用。比较少见的在激光雷达当中结合了森林生态特征做了分析的一篇文章。目前比较公认的是激光雷达更多是获取森林的几何结构特征，个人觉得SAR也偏向于几何结构特征，而高光谱则是获取森林的生物物理参数（光谱敏感性）。所以目前基于激光雷达数据的文章，大部分都是从如何提高提取几何结构特征的精度进行的，尤其在各类算法上，当然也已经有不少论文结合了多类数据进行融合，从而提升精度。而这篇文章很有意思的点就是利用LiDAR数据以及对森林生理结构的了解，人工设置了一种方法来提升提取精度。我觉得这是一个非常关键的学科交叉的成果。发表于遥感界Top期刊IEEE TGRS。]]></content>
      <categories>
        <category>Personal</category>
      </categories>
      <tags>
        <tag>Consideration of Ecology and Geography</tag>
        <tag>Summary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Coding and Paper Letter（十八）]]></title>
    <url>%2F2018%2F09%2F11%2FCoding-and-Paper-Letter%EF%BC%88%E5%8D%81%E5%85%AB%EF%BC%89%2F</url>
    <content type="text"><![CDATA[资源整理。这一期Coding内容有点多，所以将论文单独拆成另一篇。 Coding:1.利用ggplot2做轨迹方向可视化，从仓库名称看，应该是某次组会的报告。 Spatio temporal R BGU group meeting Sep 2018 2.R语言包gstat，比较出名的地统计学的R包，可以提供IDW，多种Kriging的空间插值。 gstat 3.百度研究院的开源项目NCRF，利用神经网络和条件随机场预测了癌症转移。 NCRF 4.Keras实现深度卷积生成对抗网络的开源项目。 keras dcgan 5.PyTorch交互式深色着色的重新实现。 colorization pytorch 6.Obejective-C上的简单库，用于检测运动类型（步行，跑步，汽车）和计算用户步数。 SOMotionDetector 7.RotationNet将对象的多视图图像作为输入，并联合估计其姿势和对象类别。 rotationnet 8.R语言包rethinking,这个R包与关于贝叶斯数据分析的课程和书籍配套（McElreath 2016.Dational Rethinking.CRC Press。）。另外还有一个关于这本书的材料。 rethinking Statistical Rethinking 9.基于R bookdown的elsevier（爱思唯尔）学术期刊模板。 bookdown elesevier 10.R语言包furrr，R语言并行计算包，用了future。 furrr 11.CityEngine Augmented Reality（AR,增强现实）的Unity模板。 CityEngine ArCore Unity 12.开源项目imagenet18，重复18分钟训练好imagenet实验的代码。 imagenet18 13.微软开源项目LightGBM，一个快速的、高性能的梯度提升算法框架。 LightGBM 14.OGR2GUI，转换和操作地理空间数据的应用程序。 OGR2GUI 15.R语言包available，检查包的名字是否可以使用。在R包开发的时候可以使用的包。 available 16.澳大利亚launceston的3D网格模型。 au tas launceston 3d mesh 17.几十年来，Gough岛上的研究人员在一系列令人困惑的无效Excel表中记录并存储了海鸟和其他监测数据。 在2018年，我们希望整理所有这些信息并建立一个数据库，以便有效地存储和提取这些信息以供分析 GoughDataRescue 18.使用数据为A-Frame场景创建地形，A-Frame是个虚拟现实的前端框架。 aframe terrain model component 19.Postgresql的插件，专门处理GeoJSON数据。 pgGeoJSON 20.MOLASSES（用于地球科学的MOdular LAva仿真软件） - MOLASSES模型依靠元胞自动机算法来估算熔岩流淹没的区域。 MOLASSES 21.使用scikit-learn的box plots竞赛获胜者使用的工具。 box plots sklearn 22.R语言包rtraveltime，绑定到traveltimeplatform.com的等时圈API。 rtraveltime 23.Mapbox开源项目集锦。 mapbox isochrone：在Mapbox Matrix API基础上上构建的Isochrone生成器，计算等时线最长1小时的旅行时间。 mapbox sdk py:Mapbox的Python SDK。 mapbox gl language:添加了对在Mapbox GL JS地图中切换地图样式语言的支持。 24.R语言包agridat，一些农业实验数据的集合。 agridat 25.Python库datadogpy，Datadogpy是一组适合包含在现有Python项目中或用于开发独立脚本的工具。 datadogpy 26.Gihutb上热门项目，高质量多领域公开数据集。 awesome public datasets 27.开源项目Tibet Landsat，基于R和GEE，用于青藏高原时间序列Landsat数据处理。 Tibet Landsat 28.Java库Mesh，用于创建和操作多边形网格。 主要针对Processing。 HE Mesh 29.主题为”Reproducible science, cloud-based Earth observation data processing, openEO”的汇报ppt，2018年9月6到7号GEO专家小组会议汇报。GEO（Group on Earth Observation）是100多个国家政府和超过100个参与伙伴的组织，它们设想未来可以通过协调，全面和持续的地球观测来为人类的利益做出决策和行动。 GEO 30.Julia包Triangle.jl。晶格三角化的julia接口。 Triangle.jl 31.Julia包Mesurements.jl。用于计算误差传递的物理学数值包。 Mesurements.jl 32.Python库ivy，Python的静态网页生成器。 ivy 33.开源项目，针对空间计算语言的规范和资源。 Concepts of Spatial Informantion 34.Python库wagl，用于将卫星图像标准化为分析就绪数据（ARD）形式。 wagl 35.R语言包mapview，R语言里空间数据交互视图操作。 mapview 36.R语言包rgdal2，R语言GDAL/OGR接口。 rgdal2 37.R语言包vegan3d，与vegan无关的三维可视化包。 vegan3d 38.Long Term Ecological Research(LTER,长期生态研究）的研讨会，主题为利用Rmarkdown和ggplot2可重复性地可视化数据。 reproducible dataviz 39.一个用于大规模空间数据的计算框架GeoSpark。 GeoSpark 40.Python库shapely的wheels包，wheels包是比较简单的Python库安装方式。 shapely wheels 41.Python库fiona的wheels包。 fiona wheels 42.R语言中，用于制作幻灯片的xaringan/remark.js的ninja主题。 ninja theme 43.R语言包fasterRaster，快速的栅格处理包利用GRASS GIS。 fasterRaster 44.Jupyter notebook一个插件，作为Markdown文档，Python，Julia和R脚本。 jupytext 45.开源项目，SQL Server，Oracle，MySQL，PostgreSQL，SQLite，DB2的示例数据库。 chinook database 46.scipy2018 geospatial data的研讨会内容。 scipy2018 geospatial data 47.Jupyter的widget样例。 tutorial 48.Python库pygslib，GSLIB fortran代码封装成python。 pygslib 49.Jupyter notebbok的拓展插件，推送到Github上的工具。 nbgitpuller]]></content>
      <categories>
        <category>Personal</category>
      </categories>
      <tags>
        <tag>Consideration of Ecology and Geography</tag>
        <tag>Summary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Coding and Paper Letter（十七）]]></title>
    <url>%2F2018%2F09%2F07%2FCoding-and-Paper-Letter%EF%BC%88%E5%8D%81%E4%B8%83%EF%BC%89%2F</url>
    <content type="text"><![CDATA[资源整理。 1 Coding:1.数据科学课程。课程、实验、教程以及code。 datascience box 2.自动根据github生成你的程序员简历。只需要输入github账户名即可生成。 resume.github.com 3.R语言包av，可以结合animation或者gganimate生成mp4视频。 av 4.Python开源项目PointProcesses，Python里点过程的简单模拟，点过程、时间点过程、时空过程，包括核密度估计。 PointProcesses 5.用GDAL/QGIS/WebGL制作3维地图，以DEM为主。 making 3d map 6.R语言开源项目，使用.stl文件中的R生成以3D打印。 impresion3D 7.机器学习研讨会。 ml workshop 1 ml workshop 2 ml workshop 3 ml workshop 4 8.基于R和QGIS的英国房价3维可视化。 datavis3d 9.R语言包ggcorrplot,ggplot2的拓展包， ggcorrplot 10.R语言周报，R语言社区的重要部分之一。更新R语言相关的各项资讯。 rweekly.org 11.美国环保署EPAR语言用户研讨会议程。 2018 12.Python机器学习书第二版代码和在线资源。 python machine learning book 2nd edition 13.R语言包facetscales，ggplot2拓展包，针对分面展示。 facetscales 14.将图片转成花。 flower power 15.R语言的一些脚本用来生成贝叶斯层次模型里的不同分布。 distribution diagrams 16.USGS-R开源项目，计算给定数据集的水文指标统计数据和每日流量的基本属性。 EflowStats 17.LANDIS II模型的生物量拓展模块。 Extension Biomass Succession 2 Paper:1.Bank gully extraction from DEMs utilizing the geomorphologic features of a loess hilly area in China/利用中国黄土丘陵区的地貌特征从DEM中提取堤坝 作为中国黄土高原最活跃的沟壑类型之一，河岸沟壑通常表明土壤流失和土地退化。这项研究解决了缺乏对堤坝的详细，大规模监测的问题，并提出了一种基于5米分辨率DEM的典型地形特征，提取堤坝的半自动方法。中国黄土高原林家尖流域黄土丘陵区的试验结果表明，生产精度达到87.5％ 。精度受DEM分辨率和RGD参数以及沟渠肩线精度的影响。在具有高DEM分辨率的Madigou流域中的应用证实了该方法在其他领域的可重复性。整体性能表明，银行沟渠可以在大面积上以可接受的精度提取，为土壤侵蚀，地貌和环境生态学研究提供了必要的信息。南师大汤国安老师团队的成果，从DEM提取堤坝的方法。 2.Method for the Analysis and Visualization of Similar Flow Hotspot Patterns between Different Regional Groups/不同区域群体间相似流热点模式的分析与可视化方法 可以以流的形式说明不同区域之间的相互作用。例如，人流和不同地区之间的信息之间的相互作用可以反映城市网络结构，以及城市功能和互连。大数据的普及促进了各类人员的流量数据的获取。区域交互模型的应用是基于个体流数据挖掘的总结水平，目前是一个热门的研究课题。然而，到目前为止，先前关于空间交互方法的研究主要集中在点对点和区域到区域的交互模式，以及对具有预定义邻域关系的两个区域组之间的交互热点模式的研究，即两个地区，仍然稀缺。在本研究中，提出了一种识别两个区域组之间相似交互热点模式的方法，并应用地理信息图谱方法来可视化交互模式。以中国的空中交通流量数据为例，说明所提方法的性能，以识别和分析中国各地区相互关系的区域群之间的交互热点模式。研究结果表明，该方法有效地识别了区域组之间交互流热点的模式。此外，它可以应用于分析区域群互动热点模式的挖掘中的任何流动空间。南师大汤国安老师团队的成果，关于流交互作用的数据挖掘和可视化研究。 3.Estimating household air pollution exposures and health impacts from space heating in rural China/估算中国农村地区空气供暖对家庭空气污染的影响和健康影响 由固体燃料烹饪造成的污染（称为家庭空气污染（HAP））引起的疾病暴露和相关负担已被纳入全球疾病负担（GBD）项目的评估中。相比之下，使用固体燃料进行空间加热的HAP（在中高海拔国家普遍存在）在GBD评估中的研究较少且缺失。考虑到从北方到南方的供暖需求发生显着变化以及依赖固体燃料的大量农村人口，中国是一个理想的例子，可以在空间供暖被忽略时估算暴露偏差和疾病评估负担。在这项研究中，基于对中国农村27个田间测量研究的荟萃分析，我们得出了加热和非加热季节的室内PM2.5（空气动力学直径小于2.5μm的细颗粒物）浓度。将这一数据集与时间活动模式和使用固体燃料的家庭百分比相结合，我们评估了2010年各县人口加权年均PM2.5（PWE）暴露量和中国大陆农村HAP对健康的影响。我们发现忽略加热影响导致全国农村人口PWE估计值低估38微克/立方米（四分之四范围为16至40），北方省份存在显着的负偏差。相应地，2010年过早死亡和残疾调整生命年将分别被低估约30×103和60×104。我们的研究表明，需要将加热效应纳入中国和全球的HAP风险评估。发表在EI（Environment International)上的一篇论文，目前热门的环境健康影响研究的题目，并且是基于家庭的视角，非常不错的研究。 4.Modified data-driven framework for housing market segmentation/住房市场细分的改进数据驱动框架 房地产市场细分在概念和经验层面都很重要，因为它反映了房价的空间异质性，提高了房价的预测准确性，并表明住房市场的动态变化。现有文献提供了一种流行的框架，称为数据驱动方法，用于基于主成分分析（PCA）和聚类分析来描绘子市场;然而，传统的框架不考虑空间异质性，并且难以平衡空间关系（即距离和拓扑关系）和属性相似性。为了解决这些局限性，本文提出了一种改进的数据驱动框架，用于通过整合地理加权主成分分析（GWPCA），空间异质性测试，基于密度的空间聚类（DBSC）算法和特征验证来描绘住房子市场。修改后的框架适用于中国深圳的住房市场细分。结果表明，改进后的框架在深圳的子市场细分中表现最佳。该框架具有重要的意义和在统计上确定住房子市场的巨大潜力，并且可以推广并应用于其他城市的住房市场。此外，可视化结果可供评估人员用于房产评估，也可由城市规划人员用于设施管理和社会平等改善与平衡。叶信岳老师团队成果，基于数据驱动方法在城市规划方面做探索，使用了大量的地理加权、空间分析针对住房市场细分。GWPCA和DBSC的结合值得关注。 5.Multi-level temporal autoregressive modelling of daily activity satisfaction using GPS-integrated activity diary data/使用GPS集成活动日记数据的日常活动满意度的多层次时间自回归建模 在本研究中，我们将基于网络的活动日记数据与GPS跟踪器记录的每日移动信息进行匹配，以便在2012年北京为期7天的调查中对709名居民进行抽样调查，以调查活动满意度。鉴于GPS集成日记数据的不规则时间间隔和相关的复杂依赖结构引起的复杂性，标准（空间）面板数据计量经济学方法的直接应用是不合适的。本研究开发了一种多层次的时间自回归建模方法来分析这些数据，将时间概念化为连续的，并通过时间或时空权重矩阵检查顺序相关性。此外，我们设法通过包含个体随机效应来同时模拟个体异质性，这些随机效应可以灵活地处理为独立的或依赖的。贝叶斯马尔可夫链蒙特卡罗（MCMC）算法是为模型实现而开发的。发现正序相关和个体异质性效应具有统计学意义。发生活动的场所的地理环境特征与日常活动满意度，控制一系列情境特征和个人社会人口统计特征显着相关。除了我们研究中可以想象的城市规划和发展影响之外，我们还展示了一种用于分析语义GPS轨迹数据的新颖统计方法。关美宝老师团队的关于时间地理学的成果，针对居民日常生活轨迹分析的新方法，基于时间自回归和MCMC算法，当大数据到来之后，关于人的移动轨迹的研究将会越来越重要，本文发表于IJGIS上，后续值得继续关注。 6.The Neighborhood Effect Averaging Problem (NEAP): An Elusive Confounder of the Neighborhood Effect/邻里效应平均问题（NEAP）：邻里效应的难以置信的混淆因素 忽视人们的日常流动性和暴露于非居住环境可能导致人们暴露于环境因素的健康影响的流行病学研究中的错误结果。 本文确定并描述了一种称为邻里效应平均的现象，当检查依赖于行动的暴露（例如，空气污染）对健康的影响时，这种现象可能会显着的混淆邻近效应。 最近的几项研究为邻里效应平均问题（NEAP）提供了有力的证据。 该论文的结论是，由于观察到与人们日常活动相关的邻里效应减弱，增加生活在贫困社区的人的流动性可能有助于改善他们的健康结果。关美宝老师的通讯文章，关注的是邻里效应造成的分析不确定性，关美宝老师近年来一直在关注地理学、GIS空间分析，尤其是大数据兴起后造成的分析不确定性。对此发表过多项研究成果。 7.Consumption-based greenhouse gas emissions accounting with capital stock change highlights dynamics of fast-developing countries/以资本存量变化为基础的以消费为基础的温室气体排放突显了快速发展中国家的动态 传统的基于消费的温室气体排放核算将消费和基于生产的排放之间的差距归因于国际贸易。然而，很少有人尝试分析当前排放与未来消费之间的时间偏差，这可以通过资本存量的变化来解释。在这里，我们开发了一个动态模型，将资本存量变化纳入基于消费的统计。使用1995 - 2009年的全球数据应用新模型。我们的研究结果表明，新模型确定的消费体现的全球排放量小于传统模型。在此期间，全球资本存量所体现的排放量稳步增长。然而，资本在为具有不同发展特征的经济体制定基于消费的排放量方面起着非常不同的作用因此，与传统模型相比，动态模型为许多发达国家产生类似的基于消耗的排放估算，但它突出了快速发展中国家的动态。能源消耗和温室气体排放的研究，发表于NC，多个团队合作成果。]]></content>
      <categories>
        <category>Personal</category>
      </categories>
      <tags>
        <tag>Consideration of Ecology and Geography</tag>
        <tag>Summary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Coding and Paper Letter（十六）]]></title>
    <url>%2F2018%2F09%2F05%2FCoding-and-Paper-Letter%EF%BC%88%E5%8D%81%E5%85%AD%EF%BC%89%2F</url>
    <content type="text"><![CDATA[资源整理。 1 Coding:1.Python库whitebox，用于地理空间数据高级分析。另外还有一个是whitebox tool，可运行的平台exe。 whitebox whitebox tools 2.R语言包sgd，大规模随机梯度下降法实现。 sgd 3.亚马逊云（AWS）上的无服务器地图瓦片。 serveless tiles 4.Juila语言包GeoStats，看完感觉Juila的语法相当舒服。 GeoStats.jl 5.R语言开源项目GeolocatorAnalyses，分析地理定位器数据。 GeolocatorAnalyses 6.R语言包EmissV，自上而下核算车辆及其他排放的方法。 EmissV 7.Python库pyncloud，用于分析3D点云数据。 pyncloud 8.转换geojson文件，将普通地图转换成三角式的。 geo triangulate 9.R语言包gdalmin，最小的桥接GDAL的R包，从rgdal中重构了一些代码。 gdalmin 10.R语言包ggTimeSeries，专门做时间可视化的ggplot2拓展包。 ggTimeSeries 11.巴塞罗那大学某门课程中优化算法的实现。混合编程。主要包括遗传算法、最短路径和模拟退火。 optimization algorithms 12.Python库sql2gee，将类似SQL的查询语句解析为Google Earth Engine语法的库。 sql2gee 13.由OSRM，Valhalla和Google Maps计算的不同自行车骑行轨迹的比较探索。 router comparison 14.用于地球科学研究计算的自定义Jupyterhub模板 rces custom jupyterhub templates 15.Python库eo learn，用机器学习处理对地观测数据的框架。 eo learn 16.Python库databot，用于数据管道工作的Python快速数据驱动编程框架（网络爬虫，机器学习，量化交易等） databot 17.R语言包CARBayes，面元数据的广义线性混合模型。 CARBayes 2 Paper:1.Evolutionary-driven search for solar building models using LiDAR data/数据演化驱动的研究：使用LiDAR数据驱动太阳能建筑模型 寻找太阳能建筑是城市规划的主要挑战之一，特别是在发展可持续发展的城市时。 这项工作使用一种演化方法，基于机载光探测和测距（LiDAR）激光扫描数据，找到关于太阳能潜力的最佳建筑模型。 该方法考虑自适应差分进化来解决约束优化问题。 在实验中，分析了不同建筑物的布局和设计参数对太阳辐照度的影响。 矩形，T形和L形建筑被认为具有各种设计参数：位置，建筑物旋转，立面高度，屋顶高度和坡度。 实验证明，该方法能够在约束优化空间内有效地找到具有最大太阳能潜力的太阳能建筑设计。新进遥感数据和太阳能建筑数据的耦合研究。之前有篇类似的风场数值模拟，微观尺度数值模拟与遥感数据的结合也是越来越紧密。 2.A Dark Target Method for Himawari-8/AHI Aerosol Retrieval: Application and Validation/Himawari-8 / AHI气溶胶反演的暗目标方法：应用和验证 Himawari-8（H8）作为地球静止卫星，每10分钟观测一次地球的全盘图像，是研究大气气溶胶时间变化的一种非常有力的工具。 H8上的高级himawari成像仪（AHI）具有与中分辨率成像光谱仪（MODIS）类似的几个光谱带。因此，可以使用MODIS的暗目标（DT）方法从AHI数据中检索气溶胶光学深度（AOD）。基于对这两种卫星仪器红外波段的统计研究，我们发现DT区域中AHI（2.3μm）和MODIS（2.12μm）之间的短波红外波段差异可以忽略不计。同时，对于AHI传感器，从0.86μm（而不是传统的1.24μm）和2.3μm计算的归一化差异植被指数（NDVI）也可以是表面光谱反射率的良好指标。因此，本文首先提出了一种基于AHI传感器的新NDVI，以提高基于DT反演方法的表面反射率估计。然后，使用查找表策略反演DT区域上的AOD，并基于2015年8月至2016年7月在中国区域的AHI观测进行测试。所有检索结果均根据气溶胶机器人网络和太阳天空辐射计的地面测量进行验证观察网络。葵花8号的气溶胶反演，基于暗目标法。不同卫星在气溶胶反演上做了很多工作，葵花8号的貌似比较少见，值得关注。尤其是这类高时间分辨率卫星。发表于IEEE TGRS top期刊上。 3.Evapotranspiration partitioning using an optimality-based ecohydrological model in a semiarid shrubland/在半干旱灌木丛中使用基于最优化的生态水文模型进行蒸发蒸腾分配 将蒸散（ET）划分为生物成分蒸散（T）和非生物成分蒸散（E）对于了解环境变化对生态系统和水资源的影响至关重要。然而，直接测量蒸腾仍然具有挑战性。在本文中，一个基于最优性的生态水文模型植被优化模型（VOM）被应用于ET分区。结果表明，VOM模型可以合理地模拟半干旱灌丛中的ET和ET组分。总体而言，整个时期蒸腾与蒸散的比例为49％。蒸发和植物蒸腾主要发生在降水事件后的季风中。蒸发对降水事件立即作出反应，而蒸腾作用显示对这些事件的几天滞后响应。不同年份表现出季风中不同的T / ET比动态模式。有些年份在季风开始时表现出较低的T / ET比率，并且T / ET比率缓慢增加。其他年份显示整个季风的T / ET比率高。我们发现春季降水，特别是降水的大小，对季风的T / ET比值有显着影响。蒸散的研究在生态水文界和生态模型界都很重要，很多研究证明蒸散是影响生态过程模型，尤其是相关生物量净初级生产力的关键因子。这篇文章的思路值得关注，将ET划分来进行估计。 4.Enhanced multi criteria decision analysis for planning power transmission lines/增强的多准则决策分析用于规划电力运输线路 能源向替代能源的过渡需要新的输电线路将这些额外的能源生产厂与配电中心连接起来。因此，多准则决策分析（MCDA）提供了一种有用的方法来确定未来输电线路的最佳路径，同时对环境，景观和受影响公民的影响最小。由于异议可能使这样的项目恶化并反过来增加成本，因此需要有关规划程序的透明沟通，以促进公民的接受。在这种情况下，基于地理信息系统的有关标准的信息以及对可能的输电线路进行建模至关重要。但是，规划人员经常忘记潜在的多准则决策分析和使用的数据可能会导致偏差的结果。因此，本研究通过对多准则决策分析应用灵敏度分析，实证研究各种MCDA参数的影响。该分析的输出结合聚类分析，主成分分析和多变量方差分析进行评估。我们的结果表明，通过使用不同的MCDA参数组合，可以增加不同走廊替代方案的可变性。特别是，我们发现在区域上应用连续边界模型会产生比使用锋利边缘模型更明显的走廊替代方案，并且更好地反映了保护区域免受输电线路影响的实际规划实践。比较两个研究领域的结果，我们得出结论，我们的决策模型在两个地点的表现相似，因此，建议的增强决策模型的程序适用于具有可比地形的其他研究区域。这些结果可以帮助决策者和输电线路规划者简化和改进他们的决策模型，从而提高可信度，合法性，从而提高实际适用性。MCDA用于输电线路规划的研究，考虑了模型灵敏性，对于决策分析而言更具备工程意义。是个很不错的研究，是ETH实验室团队在刚刚举行的今年澳大利亚墨尔本国际地理信息科学大会的成果。 5.Hydrological Performance of Green Roofs at Building and City Scales under Mediterranean Conditions/地中海条件下建筑尺度和城市尺度绿色屋顶的水文特性 绿色屋顶是一种特殊类型的可持续城市排水系统（SUDS）;他们的目标是通过在不同的层中储存水，延迟水文响应和恢复蒸发蒸腾来管理源头的径流。他们在地中海地区表现的证据仍然很少。本文的主要目的是分析地中海条件下建筑和城市规模的绿色屋顶的水文性能。在Benaguasil（西班牙巴伦西亚）监测了一年的绿色屋顶和传统屋顶。记录和分析降雨量和流量数据。水文模型在建筑尺度上进行了校准和验证，以分析绿色屋顶的水文长期效率，并将其与传统屋顶的水文长期效率进行比较。结果表明，即使在地中海等干燥气候下，绿色屋顶也能提供良好的水文性能。此外，考虑到获得的平均径流系数减少，它们在城市尺度上的影响也很显着。绿色屋顶是海绵城市建设中重要的人工绿色基础设施之一。关于它的水文特性研究，在中国却很少，之前笔者在参加LID2016会议时，就有很多人提出来目前中国在海绵城市走得太快，很多基础理论研究并没有进行。我想这一方面就是个关键。]]></content>
      <categories>
        <category>Personal</category>
      </categories>
      <tags>
        <tag>Consideration of Ecology and Geography</tag>
        <tag>Summary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Coding and Paper Letter（十五）]]></title>
    <url>%2F2018%2F09%2F02%2FCoding-and-Paper-Letter%EF%BC%88%E5%8D%81%E4%BA%94%EF%BC%89%2F</url>
    <content type="text"><![CDATA[资源整理。 1 Coding:1.Nature Climate Change论文”Higher temperatures increase suicide rates in the United States and Mexico”的code，更高的温度会增加美国和墨西哥的自杀率。 NCC2018 论文链接 2.Nature论文”Robust relationship between air quality and infant mortality in Africa”的code，非洲空气质量和婴儿死亡率的密切关系。 HBBB2018 论文链接 3.多模式的非监督图像转换，对抗生成网络相关项目。 MUNIT 4.Predictive Soil Mapping with R书的源码，我曾经有幸在5月份上过作者的关于这方面的课程，Tomislav Hengl老师非常风趣，这本书是基于谢益辉大大的bookdown包写的，他当时还在课程上推荐谢益辉大大的包。 PredictiveSoilMapping 5.R语言包RGDALSQL,GDAL的数据库接口（DBI)。 RGDALSQL 6.R语言包spatstat，spatstat的开发者版本，关于时空数据处理的R包。 spatstat 7.来自日本Himawari卫星的数据读程序。 该实用程序读取原始的HSD格式数据，并可将其转换为更友好的格式，如NetCDF4。 Himawari HSD Reader 8.从内容来看应当是城市形态相关的研究的code。 UrbanMorphology 9.使用pycollada操纵网格数据的工具。 meshtool 10.将DTM（数字高程模型）图像转换为Collada 3D网格。 使用OpenCV和PyCollada。 DTM2MESH 11.Python开源项目ee jupyter examples，关于Google Earth Engine的Python API的样例代码。 ee jupyter examples 12.Python开源库pixel decoder，一个深度学习处理卫星影像的机器学习库。 pixel decoder 13.Python开源库altair，声明性统计可视化库。 altair 14.AGU 2017 Presentation的目录。 AGU2017 15.一个致力于地球实验室团队开发的教程，课程和其他学习材料和资源的网站。 earthlab.github.io 2 Paper:1.Ancient herders enriched and restructured African grasslands/古代牧民对非洲草原的影响和重构 发表于Nature的论文。详情见如下的公众号链接。只能说人类活动与生态环境的关系是当今热点，另外非洲这个研究区也是如此。 微信公众号推文 2.Extending RAPID model to simulate forest microwave backscattering/扩展三维光学模型RAPID模拟森林微波后向散射 发表于RSE上的论文，作者为黄华国老师，北京林业大学林业遥感（激光雷达和辐射传输模型）的专家。三维光学模型，非常不错的研究。笔者有幸加了黄老师的科学网博客，链接请见下文。 微信公众号推文 黄老师科学网博客 3.Articulating natural resources and sustainable development goals through green economy indicators: A systematic analysis/通过绿色经济指标阐明自然资源和可持续发展目标：系统分析 SDGs的一篇文章，关于指标方面的研究。 微信公众号推文 4.Location based services: ongoing evolution and research agenda/基于位置的服务：持续的发展和研究议程 我们现在生活在一个移动信息时代，它正在从根本上改变科学和社会。 基于位置的服务（LBS）根据（移动）设备和用户的位置提供信息，在这个移动信息时代起着关键作用。 本文首先回顾了过去几年LBS科学领域的不断发展和研究趋势。 为了激发LBS的进一步研究并激发集体努力，本文提出了一系列关键的研究挑战，这些挑战对推动LBS的发展至关重要，为LBS制定研究议程以“积极”塑造我们的移动信息社会的未来。 这些研究挑战涵盖了与LBS开发的核心（例如定位，建模和沟通），LBS生成数据的评估和分析相关的问题，以及随着LBS进入人们日常生活而出现的社会，道德和行为问题住。LBS是当今大数据时代的典型空间数据，也是GISer能够在大数据时代大放异彩的关键。这篇文章讲述了LBS相关的研究内容，非常值得关注。 5.Representation of Multidecadal Sahel Rainfall Variability in 20th Century Reanalyses/20世纪再分析数据中多年代萨赫勒降水变率的表征 萨赫勒地区的夏季降雨在20世纪表现出强烈的多年代际变化，造成了巨大的人类和社会经济影响。研究表明，变异性与大西洋多年代际变率有关;北大西洋的一个空间持续的暖/冷海面温度模式。在过去几年中，已经提供了几个有希望的长达一年的再分析数据集，为进一步研究导致萨赫勒观测到的低频降雨变化的动力学开辟了道路。我们发现尽管20世纪的ECMWF重新分析中有三个显示出明显的多年代际降雨变化，并且干湿周期延长，但其中两次重新分析的多年代际变化的时间发现在20日的大部分时间内表现出几乎反向的特征。世纪与观察相比。多年代雨量变化的最佳表现在ECMWF再分析资料中发现，与其他再分析资料不同，它不同化任何观测数据，并且很可能是这种不匹配的关键原因，如本文所讨论的。因此，这种再分析资料，即ERA-20CM，被推荐用于未来研究萨赫勒地区多年代降雨变率的动态及其与低频北大西洋海温的联系。多个再分析资料在某一地区的比较，再分析资料在各种研究当中的应用越来越多，结合数据同化会有很多有意思的分析结论。 6.Evaluating Different Machine Learning Methods for Upscaling Evapotranspiration from Flux Towers to the Regional Scale/评估不同机器学习方法在蒸散从通量塔到区域尺度的升尺度应用的性能 蒸发蒸腾（ET）是陆地 - 大气相互作用的重要变量，它将地表能量平衡，水和碳循环联系起来。原位技术可以准确地测量ET，但观察结果限制了空间和时间覆盖范围。建模方法已用于在广泛的空间和时间尺度上估计ET，而在区域尺度上精确模拟ET仍然是一项重大挑战。在这项研究中，我们利用机器学习算法将涡旋协方差通量塔站点的ET升尺度至区域尺度。 ET升尺度采用五种机器学习算法，包括人工神经网络，Cubist，深度信念网络，随机森林和支持向量机。机器学习方法在黑河流域36个通量塔站点（65个站点年）进行训练和测试，然后用于估算流域内每个网格单元（1 km×1 km）的ET以及期间2012-2016。人工神经网络，Cubist，随机森林和支持向量机算法在估计ET时具有几乎相同的性能，并且在样地尺度上具有比深度信念网络略低的均方根误差。随机森林算法在区域尺度上的相对不确定性略低于基于三角帽方法的其他方法。此外，机器学习方法在密集植被条件下比贫瘠土地或植被稀疏的条件下表现更好。通过机器学习方法生成的区域ET捕获了区域尺度ET的空间和时间模式。机器学习在生态学中升尺度/尺度扩展中的应用。比较有意思的研究，发表于JGR大气上。]]></content>
      <categories>
        <category>Personal</category>
      </categories>
      <tags>
        <tag>Consideration of Ecology and Geography</tag>
        <tag>Summary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用virtualenv和pip构建项目所需的独立Python环境]]></title>
    <url>%2F2018%2F08%2F31%2F%E4%BD%BF%E7%94%A8virtualenv%E5%92%8Cpip%E8%BF%9B%E8%A1%8C%E5%8D%95%E7%8B%ACPython%E7%8E%AF%E5%A2%83%E5%BC%80%E5%8F%91%2F</url>
    <content type="text"><![CDATA[由于最近刚好有个测试需求，来讲一讲如何使用virtualenv和pip构建项目所需的独立Python环境。关于pip的介绍之前已有一篇博客，链接在下面。今天对pip的介绍主要是关于其他参数。 Python开篇——简介、pip和conda 1 为什么需要独立的Python环境？在讲技术前，想先讲讲目的。为什么我们需要独立的Python环境？这里就借用virtualenv的文档来解释吧。 virtualenv is a tool to create isolated Python environments. The basic problem being addressed is one of dependencies and versions, and indirectly permissions. Imagine you have an application that needs version 1 of LibFoo, but another application requires version 2. How can you use both these applications? If you install everything into /usr/lib/python2.7/site-packages (or whatever your platform’s standard location is), it’s easy to end up in a situation where you unintentionally upgrade an application that shouldn’t be upgraded. Or more generally, what if you want to install an application and leave it be? If an application works, any change in its libraries or the versions of those libraries can break the application. Also, what if you can’t install packages into the global site-packages directory? For instance, on a shared host. In all these cases, virtualenv can help you. It creates an environment that has its own installation directories, that doesn’t share libraries with other virtualenv environments (and optionally doesn’t access the globally installed libraries either). 当你在开发or数据分析时，可能会遇上不同的需求，对所需要的包的版本不统一，譬如前一段我在开发D3L Tool的时候遇上的一个问题。当时开发的程序并不能在Win 7系统上运行，后面搜索了很久，发现是pyinstaller版本的问题。但是我又不太想把pyinstaller版本往下降。所以这个时候virtualenv就很有用了。 2 使用virtualenv和pip来构建纯净和独立的Python环境接下来主要来讲讲怎么操作。另外提一句这里介绍的主要是Windows下的，Linux和Mac的会有些小差别。基于的Python环境是Anaconda2 Python 2.7.12。 2.1 安装安装部分还是pip大法好。具体就不展开了，pip的安装在前面的博客已经介绍过了。 1pip install virtualenv 2.2 使用virtualenv创建Python环境先选择你要创建的工程路径。用cmd进入到该文件夹里。 1cd your project path 接下来有两种情况，virtualenv的使用方式其实与pip类似，它也在Python安装路径的Scripts里。因此根据你是否设置了环境变量就有两种方式运行。 情况1：将Scripts路径设置为电脑的环境变量 1virtualenv venv #venv为你的文件名，也就是放置新的、纯净的、独立的Python环境的文件夹 情况2： 没有设置Scripts路径为电脑的环境变量 1.../Python/Scripts/virtualenv venv #...表示Python安装路径包，根据个人不同替换，venv同上 接着就开始运行了，定位到我们建立的文件夹下可以看到。 一共有这么几个文件。 接下来在cmd定位到项目路径，并运行如下命令。 12cd Scriptsactivate 这就进入了virtualenv的Python环境。 关闭这个环境，只需要运行如下命令。 1deactivate 2.3 使用pip安装包其实pip安装的部分我之前已经介绍过了，不过上一篇讲得比较简单，仅仅就讲了讲最简单的pip install。而pip 安装包的时候，由于使用的是国外的地址下载包，可能会有些慢或者经常掉线，因此使用国内镜像是比较快的，另外如前文的需求，有些时候需要安装指定版本的包。这也是这次的重点。 1pip install -i &quot;mirror&quot; numpy==version # mirror就是指国内的镜像地址，version就是指包的版本。 主要介绍的两个参数就是如上所示了，一个是填入国内镜像地址，一个是给定指定包的版本。具体镜像地址见问候链接的第二篇文章。这里给出清华的镜像。 清华大学镜像：https://pypi.tuna.tsinghua.edu.cn/simple 本文参考的一些文章链接如下。 1.用virtualenv建立多个Python独立开发环境 2.让PIP源使用国内镜像，提升下载速度和安装成功率]]></content>
      <categories>
        <category>Coding</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Coding and Paper Letter（十四）]]></title>
    <url>%2F2018%2F08%2F28%2FCoding-and-Paper-Letter%EF%BC%88%E5%8D%81%E5%9B%9B%EF%BC%89%2F</url>
    <content type="text"><![CDATA[资源整理。 1 Coding:1.R语言包ungeviz，ggplot2的拓展包，专门用来作不确定性的可视化。 ungeviz 2.计算机图形学相关开源项目。 计算机图形学光线追踪开源项目C++源码。 computer graphics ray tracing 计算机图形学格网开源项目C++源码。 computer graphics meshes 计算机图形学介绍开源项目。 computer graphics 3.R语言包GLMMadaptive，基于自适应高斯积分的广义线性混合模型。 GLMMadaptive 4.R语言包walkr，在n-simplex和hyperplanes的交集中实现了MCMC随机遍历。 walkr 5.最全的中华古典文集数据库, 包含5.5万首唐诗、26万首宋诗和2.1万首宋词. 唐宋两朝近1.4万古诗人, 和两宋时期1.5K词人. 数据来源于互联网。 chinese poetry 6.R语言包rworldmap，绘制全球数据的R包。 rworldmap 7.基于Go的快速生成delaunay三角的算法实现。 delaunay 8.R语言包sigmaNet，在R中用sigma.js渲染igraph的对象。 sigmaNet 9.Pysal里的广义线性回归模型模块。 spglm 10.Giddy是一个开源python库，用于分析纬向空间数据的动态。 源于PySAL（Python空间分析库）中的空间动力学模块，正在积极开发包含新提出的分析，这些分析考虑了空间在分布演变中的作用。 griddy 11.用于可视化数据的代码和教程。 RainCloudPlots 12.R语言包collections，R的高性能容器数据类型。 collections 13.Python项目pangeo example notebooks，用于pangeo-data / helm-chart的jupyternotebook。 pangeo example notebooks 14.Pythone库pyGeostatistics，python里的地统计学包。 pyGeostatistics 15.Python项目landsat ingestor，用于将Landat数据提取到Amazon公共托管中的脚本和其他工具。 landsat ingestor 16.R语言包vctrs，vctrs的短期目标指定了组合不同类型向量的函数。 vctrs 17.R语言包worldtilegrid,ggplot2的拓展包，专门针对世界瓦片格网。 worldtilegrid 18.Geostat18完整的资料链接。详情可以见官网。 geostat18 links 19.Python库keras工具箱，深度学习框架。 keras toolbox 20.R语言包GSIF，全球土壤信息数据库。 GSIF 21.ECPR暑期学校：社会科学的大数据分析。 ECPR SC105 22.Python库radarpy，处理radar的Python工具。 radarpy 23.R语言包uavRst，无人机相关遥感工具箱。 uavRst 2 Paper:1.Spatial association detector (SPADE)/空间关联探测器 发表于IJGIS上的一篇论文，介绍了由地理探测器改进而来的空间关联探测器，是针对地理探测器的一些问题做的改进。主要是罗卫老师和他的团队提出的，我后面会详细解读此文。 2.Using Google Earth Engine for Landsat NDVI time series analysis to indicate the present status of forest stands/利用Google Earth Engine做Landsat NDVI的时间序列分析来分析林分的现状 这篇文章是国外本科生的毕业设计。该研究使用了GEE与Landsat 5和8图像一起用于研究德国三个研究区域的归一化差异植被指数（NDVI）随时间的变化。 3.Land-cover mapping using Random Forest classification and incorporating NDVI time-series and texture: a case study of central Shandong/利用随机森林分类结合NDVI时间序列和纹理进行土地覆盖制图 - 以山东中部为例 复杂农业区的土地覆盖制图是一项艰巨的任务，因为植被复杂，山体湍急，河流快速流动，需要一种精确分类复杂土地覆盖的方法。随机森林分类（RFC）具有分类准确率高和在土地覆盖制图中测量变量重要性的能力。本研究使用RFC对复杂农业区域的土地覆盖制图进行了归一化差异植被指数（NDVI）时间序列和灰度共生矩阵（GLCM）纹理变量的加法评估。在此基础上，选择最佳分类模型，提取山东中部的土地覆盖分类信息。为了探索哪些输入变量为复杂农业区的土地覆盖分类提供最佳准确度，我们评估随机森林变量的重要性。结果表明，不仅加入多时相图像和地形变量，而且加入GLCM纹理变量和NDVI时间序列变量。对随机森林分类器重要性的评估表明，关键输入变量为夏季NDVI，随后是夏季近红外波段和海拔，以及GLCM均值，GLCM对比度。中山大学刘小平老师团队的成果，针对土地覆被的分类研究，主要是在特征工程上增加了NDVI时间序列和灰度共生矩阵的一些纹理变量。 4.A Forest Attribute Mapping Framework: A Pilot Study in a Northern Boreal Forest, Northwest Territories, Canada/森林属性制图框架：加拿大西北地区北方北方森林的样地研究 提出了一种方法框架，利用样地，机载光探测和测距（LiDAR）以及星载地球科学激光高度计系统（GLAS）数据来估算加拿大北部20 Mha地区的森林属性。实施该框架是为了将森林属性模型从现场数据扩展到交叉的机载LiDAR数据，然后扩展到GLAS足迹。 GLAS数据被顺序过滤并提交给k-最近邻（k-NN）插补算法，以产生30米分辨率的林分高度和树冠闭合的区域估计。根据独立的机载LiDAR数据评估得到的输出，以评估林分高度的平均估计值和冠闭合。作为主要植被类型和生态区域的函数进行了额外的评估，以进一步评估区域产品。这些属性构成了森林清查绘图程序典型的主要描述性结构属性，并提供了在北方寒带地区如何得出这些属性的信息。机载和星载激光雷达数据的耦合研究。关于不确定性制图的思路值得借鉴。]]></content>
      <categories>
        <category>Personal</category>
      </categories>
      <tags>
        <tag>Consideration of Ecology and Geography</tag>
        <tag>Summary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Coding and Paper Letter（十三）]]></title>
    <url>%2F2018%2F08%2F23%2FCoding-and-Paper-Letter%EF%BC%88%E5%8D%81%E4%B8%89%EF%BC%89%2F</url>
    <content type="text"><![CDATA[资源整理。 1 Coding:1.R语言包mapdeck，使用mapbox GL和deck.gl的交互式地图可视化包。 mapdeck 2.R语言包spatsoc，检测GPS轨迹重定位里的时空分组的包，从而构建基于邻近度的网络。 spatsoc 3.R语言包rstanarm，贝叶斯应用回归建模包。 [rstanarm]（https://github.com/stan-dev/rstanarm） 4.R语言包rstan，stan的R接口。stan是一个统计建模和高性能计算平台。 rstan 5.R语言包nlrx，提供了一些在R语言中用netlogo建模的工具。 nlrx 6.开源项目斯坦福机器学习课程的备忘录。吴恩达大大的课，后面有空一定要来介绍学习成果（挖坑）。 stanford cs 229 machine learning 7.R语言包mapsapi，与谷歌地图API兼容的接口。 mapsapi 8.王江浩老师在GeoSTAT2018上报告的ppt，上一篇也有一位汇报者的ppt，就不一一列出了，GeoSTATA是一个暑期学校，主题是关于联合地理与统计建模。具体介绍见官网。从内容来看，非常不错。希望明年有机会可以前往学习。王江浩老师的汇报题目是Urban Sensing and Computing - Big Data Analytic with Open Source Software,也就是城市感知与计算——基于开源软件的大数据分析。 GeoSTAT2018 9.同样是来自GeoSTAT2018的报告ppt，包括课程和汇报的材料，主题是基于环境监测数据的机器学习案例。 Geostat2018 10.R语言包fasterize，高性能的栅格转换格式包。 fasterize 11.R语言包sendmailR，R语言用于发邮件的包。 sendmailR 12.AGU2018会议上的presentation，题目是Coupled Interpolation of Three-component GPS Velocities，三分量GPS速度耦合插值。 agu2018 13.R语言包corrr，相关系数可视化的包。 corrr 14.基于Julia编写的气候科学工具包。 ClimateTools.jl 15.R语言包lazyraster，这个包的作用是通过GDAL按照需求获取指定分辨率栅格。 lazyraster 2 Paper:1.Mapping daily evapotranspiration based on spatiotemporal fusion of ASTER and MODIS images over irrigated agricultural areas in the Heihe River Basin, Northwest China/基于ASTER和MODIS影像时空融合的黑河流域灌区农牧区日蒸散量制图 持续监测日蒸散量（ET）对于干旱地区灌溉农业区的水资源分配和管理至关重要。在这项研究中，使用表面能量平衡系统（SEBS）通过融合具有高时间分辨率的中分辨率成像光谱仪（MODIS）图像和先进的星载热发射反射辐射计（ASTER）来估算90米空间分辨率的连续每日具有高空间分辨率的ET。使用空间和时间自适应反射融合模型（STARFM）获得这些传感器的时空特征。通过自动气象系统（AMS）和涡度协方差的现场观测，在农田，住宅，林地，水，戈壁沙漠，沙漠，沙漠草原和湿地区域覆盖的异质绿洲 - 荒漠地区验证了该方法的性能。 （EC）系统位于中国西北黑河流域中游。在基于STARFM的数据融合过程中引入的误差在90米空间分辨率下的预测LST的可接受范围内。使用SEBS基于预测的遥感数据估算的表面能量通量结合MODIS和ASTER的时空特征，与使用EC系统观测到的所有土地覆盖类型的表面能量通量很好地吻合。李新老师团队的成果，发表于农林科学top的Agricultural and Forest Meteorology，基于时空融合模型STARFM，高时间分辨率的MODIS，高空间分辨率的ASTER融合了高时空分辨率的ET。并利用实测数据做验证。非常坚实的定量遥感与生态水文研究，另外不得不感慨黑河流域数据的恢弘啊。 2.Wind dynamics over a highly heterogeneous oasis area: An experimental and numerical study/高度异质性的绿洲地区的风力动态模拟：实验和数值研究 发表于JGR的一篇文章，采用了综合方法，将计算流体动力学（CFD）方法与k - ɛ湍流模型和高分辨率地面测量数据相结合，以分析高度地表异质性的绿洲上的风力动态。具体来说，1）天气研究和预测模型（WRF）数据被用作边界条件来启动模拟; 2）根据机载激光扫描（ALS）数据估算的冠层叶面积密度（LAD）作为动量和湍流输运方程的源项，它代表了绿洲地区高度异质的植被结构。 CFD模拟的风场结果与通量观测矩阵数据（在5.5 km×5.5 km实验区域中的17个塔测量）一致。成功捕获了受异质地表影响的风场的时空变化。 CFD模拟的风场也清楚地显示了在高度异质的陆地表面上的“挡风效果”，其中在防护林带的迎风侧和背风侧存在更短和更长的风速减少区域有助于保护农田和果园免受风侵蚀。此外，目前基于高分辨率CFD模拟风廓线估算空气动力学粗糙度长度（z0m）的方法被证明是捕获异质表面上的风力动力学的有前景的方法。数值模拟(WRF，CFD)+地面观测数据的一个研究，非常有意思，也可以看到目前在小尺度很多数值模拟的研究越来越成熟，而且通常需要融合多个数值模拟模型与地面观测数据。 3.Exploring evapotranspiration dynamics over Sub-Sahara Africa (2000-2014)/探索撒哈拉以南非洲的蒸散量变化（2000-2014） 监测蒸散量（ET）的变化有助于管理灌溉农业景观中的水资源，以及评估干旱脆弱地区的作物压力和植被状况。这项研究探讨了MODIS（中分辨率成像光谱仪）衍生的ET（2000-2014）在大部分撒哈拉沙漠以南非洲（SSA）的变化。对SSA的ET的多变量分析显示，ET中观察到的动态的四种主要模式，占总变异性的约90％，主要来自Sudano-Sahel和刚果盆地的一些部分。根据Man-Kendall的统计数据，观察到中非共和国和萨赫勒地区大部分地区ET的显着正趋势（α= 0.05）。尽管如此，在刚果盆地的大部分地区，ET显示出广泛的负面趋势的显着（α= 0.05）分布。 ET的这些趋势被发现与模型土壤水分的观测变化一致，但并非在所有位置都是如此，可能是由于最大降雨量和地表温度的趋势不一致。然而，时空干旱分析的结果证实，刚果盆地广泛的ET损失在某种程度上是由土壤水分亏缺引起的。在ET的其他主要驱动因素中，ET对SSA陆地生态系统的动态似乎是一种可能超越自然气候变化的更复杂现象。我想这个文章最大特色可能是长时间大洲尺度研究，并且是非洲的案例。很好地响应SDGs的实证研究。 4.Urban Land Extraction Using VIIRS Nighttime Light Data: An Evaluation of Three Popular Methods/利基于三种流行方法与VIIRS夜光数据提取城市土地的评价 使用夜光数据及时准确地提取城市土地面积对于城市研究非常重要。然而，对提取城市土地的现有方法的综合评估仍然不足。该研究选择了三种利用夜间光照数据提取城市土地面积的流行方法。这些方法包括局部优化阈值（LOT），植被调整夜光城市指数（VANUI），综合夜光数据，归一化差异植被指数和地表温度支持向量机分类（INNL-SVM）。然后，我们根据中国不同自然和社会经济条件的七个评价区域的VIIRS夜光数据，评估了这些提取城市土地面积的方法的表现。我们发现INNL-SVM具有最佳性能，平均kappa为0.80，比LOT高6.67％，比VANUI高2.56％。 INNL-SVM的卓越性能主要归功于夜间光线，植被覆盖和地表温度信息的整合。这种集成有效地减少了由VIIRS夜间光数据的溢出效应和低光亮度引起的错误。此外，INNL-SVM可以更轻松地提取城市土地面积。因此，我们建议INNL-SVM具有很大的潜力，可以用大规模的VIIRS夜光数据有效地提取城市土地。夜光数据的研究越来越重要，另外珞珈一号的应用也值得关注。 5.Comparison of Two Satellite-Based Evapotranspiration Models of the Nagqu River Basin of the Tibetan Plateau/青藏高原那曲河流域两种卫星蒸散模型的比较 蒸发蒸腾（ET）是能量和水循环的主要不确定组成部分之一，是在无云条件下基于遥感数据和大气表层（ASL）观测得出的那曲河流域。两个基于过程的模型用于确定ET：基于Priestley-Taylor（PT）的模型和地形增强的表面能平衡系统（TESEBS）模型。将改进的宽带反照率，向下短波辐射通量和重建归一化差异植被指数（NDVI）耦合到TESEBS模型和基于PT的模型中以估计实际ET。 ASL气象数据，SPOT植被（VGT）数据和中分辨率成像光谱仪（MODIS）数据被用作10天ET计算的输入。将模型估计结果与通过组合方法计算的基础事实进行比较。结果表明，两种模型确定的ET均符合实际ET。然而，TESEBS模型显示出比PT模型更好的性能，具有更低的平均偏差误差和更低的均方根误差。尽管PT模型计算简单并且需要的参数很少，但NDVI的强烈加权可能会导致一些过高估计，特别是在生长季节。两种模型确定的蒸散量很好地符合实际值。 TESEBS表现出比PT模型更好的性能。虽然PT模型计算简单且参数很少，但NDVI的强加权可能会导致一些过高的估计。蒸散一直是生态水文和生态建模的关键，尤其是耦合遥感数据和遥感模型的一个关键要素。可以对这两个模型做些研究。本文的两个蒸散模型还是很经典的。其次，青藏高原的研究也更有意思些。 6.Modeling the Distributions of Brightness Temperatures of a Cropland Study Area Using a Model that Combines Fast Radiosity and Energy Budget Methods/利用结合快速光能传递和能量预算方法的模型对农田区域的亮度温度分布进行建模 从遥感数据中获得的地表温度（LSTs）对于监测作物和城市热岛的状况至关重要。然而，由于反演到的LST仅代表像素的平均温度状态，因此各个像素内的温度分布仍然未知。这些数据不能满足精准农业等应用的要求。因此，在本文中，我们提出了一种模型，该模型结合了快速光能传递模型，适用于多孔单个对象（RAPID）模型的光能传递和能量预算方法，以动态模拟复杂曲面上的亮度温度（BT）。该模型代表了一种基于模型的工具，可用于使用精细尺度的可见光以及近红外（VNIR）数据和气象条件的时间变化来估计温度分布。所提出的模型在中国西北地区的人工绿洲的研究区域进行了测试。模拟的BT与先进的星载热辐射和反射辐射计（ASTER）测量的BT很好地吻合。此外，与叶面积指数（LAI）相比，该模型在验证期间显示出对风速的高灵敏度。尽管可以采用简化以用于特定模拟，但是该提出的模型可用于支持原位测量并提供异质植被表面上的参考数据。柳钦火老师团队的成果，亚像元级定量热红外遥感研究。值得关注。 7.Impacts of spatial heterogeneity on crop area mapping in Canada using MODIS data/空间异质性对加拿大作物区域MODIS数据制图的影响 由于存在各种空间异质性，使用粗空间分辨率遥感图像精确地绘制作物区域是具有挑战性的。该研究分析了受空间异质性影响的作物分类和面积估计的准确性，尤其是样本杂质和景观异质性。从中分辨率成像光谱仪（MODIS）MOD09Q1 8天计算的归一化差异植被指数（NDVI）时间序列用于对加拿大曼尼托巴省的作物区域进行分类。分类和回归树（CART）方法应用于分类。将具有30米空间分辨率的加拿大农业和农业食品（AAFC）土地覆盖数据集用作确定研究区域和训练和验证样本的基础图。结果可以得出结论：（1）MODIS影像的分类精度对样本杂质和景观异质性都很敏感。样品中的纯度限制会对分类准确性产生很大影响。具有更均匀像素的区域更可能被准确地分类，反之亦然; （2）作物面积估计误差对样品杂质不敏感。它不仅取决于培养样品的纯度，还取决于作物类型的实际纯度条件。最纯粹的训练样本组与最低误差不相符; （3）构型异质性对面积估计的影响比构成异质性的影响更大。总体而言，样本杂质和景观异质性都可以在很大程度上影响分类准确性，而只有构型异质性对作物面积估计有显着影响。地表异质性是老生常谈的话题，任何地学研究都难以避免，这篇文章利用两套数据做了一些异质性造成的不确定性和误差的分析。 8.Spatiotemporal Fusion of Multisource Remote Sensing Data: Literature Survey, Taxonomy, Principles, Applications, and Future Directions/多源遥感数据的时空融合：文献调研，分类，原理，应用和未来方向 具有高空间分辨率的卫星时间序列对于监测异质景观中的陆地表面动态是至关重要的。尽管遥感技术近年来经历了快速发展，但从单个卫星传感器获得的数据往往无法满足我们的需求。因此，在过去十年中，来自不同传感器的数据的综合使用变得越来越流行。已经开发了许多时空数据融合方法以从两种类型的卫星图像，频繁的粗分辨率图像和稀疏的精细分辨率图像产生具有高空间和时间分辨率的合成图像。这些方法是根据不同的原则和策略设计的，因此表现出不同的优势和局限。这种多样性为用户选择适合其特定应用和数据集的方法带来了困难。为此，本综述文章研究了当前时空数据融合方法的文献，对现有方法进行了分类，讨论了这些方法的基本规律，总结了它们的潜在应用，并提出了该领域未来研究的可能方向。遥感影像时空融合的综述，写得还是很详细的，对这个领域的做了些较为系统的回顾，做了文献计量分析。这里推荐一篇笔者翻译的黄波老师的论文(原作为黄波老师团队赵涌泉博士，译文首发于一览众山小·可持续城市与交通）。 有GIS有意思︱针对复杂地表变化的鲁棒自适应时空影像融合模型 9.Mapping China’s Ghost Cities through the Combination of Nighttime Satellite Data and Daytime Satellite Data/通过夜间卫星数据与日间卫星数据相结合绘制中国鬼城 中国大陆城市化进程产生的副作用之一是“鬼城” - 一般被定义为废弃建筑群或住房结构 - 但是对于与这种现象有关的基本特征，如尺寸，显然缺乏研究。增长，水平，分布，规模，强度，模式和决定因素。通过结合夜间卫星数据和日间卫星数据作为有用的代理，在本文中，我们展示了过去二十年中国鬼城的空间格局和时间演变。夜间灯光在新建区域的变化率是基于DMSP / OLS和归一化差异建立指数来评估城市的黑暗。结果显示鬼城问题是真实的，但至少到目前为止，仅限于22个较小的城市。然而，进一步分析显示，新建区域的夜间灯光发生变化，大城市倒U型曲线表示近年来趋势从正值回归到负值。通过在我们的研究中使用DMSP / OLS和Landsat数据之间的时间互补特征的方法证明可以作为确定和量化这种社会经济现象的直接证据。一个基于夜间灯光和普通Landsat数据结合的应用研究。鬼城识别，是一个非常有意思的问题研究。这篇文章利用不同时间成像卫星的互补做了识别。相比于几年前北大刘瑜老师与百度大数据实验室合作的，基于VGI数据的鬼城识别，可能可以做一个比较。 10.Linking Heat Source–Sink Landscape Patterns with Analysis of Urban Heat Islands: Study on the Fast-Growing Zhengzhou City in Central China/联结热源-汇景观格局与城市热岛分析-快速发展的中部地区郑州市案例研究 在全球范围内，城市热岛（UHI）效应是一个主要问题，导致城市居民遭受不利的城市生态环境和严重的健康风险。了解城市景观特征对热环境的影响一直是各个研究领域的重点。本研究的目的是利用中国中部快速发展的郑州市作为案例研究，分析城市热源-汇景观格局对城市热岛的影响。应用Landsat数据（在1996年，2006年和2014年捕获），各种地理空间方法和相关性分析以促进分析。基于城市景观对地表温度（LST）的贡献，我们根据经验确定了热源和热汇。然后，通过景观和等级的一系列空间度量来估计热源和汇景观的构成和配置。结果表明，研究区域的总平均地表温度（LST）从1996年到2014年增加了2.72°C。观察到的总体平均LST的增加趋势与研究区域的快速城市化过程一致，由不透水表面的显着增加和植被覆盖的大量损失证明。通常，如所观察到的，景观组成对LST的影响比景观配置更强。对于热源，斑块的比例，大小，聚集和密度对LST有积极影响，而调整城市景观的空间分布和丰度是控制UHI效应的有效方法。相比之下，散热片的百分比，大小，密度和聚集对LST有负面影响。此外，在减轻UHI效应时，应考虑增加总贴片边缘和形状复杂性的影响。这些发现有助于进一步了解城市景观格局如何影响UHI，并有助于优化城市景观格局，减轻UHI效应，促进研究区的可持续发展。总的来说，这篇文章主要做的就是景观指数与LST的分析，可能比较关键的是热源汇景观的概念提出。前一段广州大学吴志峰老师团队发表了一篇中文名为人为热排放源的分析，印象中是基于WRF和排放源的一个研究，可能可以做些类比和探究。 11.predictSLUMS: A new model for identifying and predicting informal settlements and slums in cities from street intersections using machine learning/预测SLUMS：一种利用机器学习从街道交叉口识别和预测城市非正规住区和贫民窟的新模型 确定城市内当前和未来的非正规区域仍然是发展中国家政策制定者和政府的关键问题。在城市中识别这些区域的划分过程需要大量资源。虽然有各种研究基于卫星图像分类识别非正式定居点，依赖于有监督或无监督的机器学习方法，但这些模型要么需要多个输入数据才能运行或需要在精度方面进一步发展。在本文中，我们介绍了一种仅使用街道交叉口数据来识别和预测非正规住区的新方法，无论城市形态，楼层数量，建筑材料或街道宽度的变化如何。通过这种最小的输入数据，我们试图为规划者和政策制定者提供一个有助于识别城市非正规区域的实用工具。该模型的算法基于空间统计和机器学习方法，使用多项Logistic回归（MNL）和人工神经网络（ANN）。拟议的模型依赖于根据两个普遍存在的特征定义非正规住区，这些区域倾向于填充相对于当地环境中的正式区域的较小的细分住房，以及这些住区边界内的服务和基础设施的缺乏。需要相对较大的批次。我们在埃及和印度的五个主要城市应用了该模型，这些城市具有非正式性的空间结构。这些城市分别是埃及的大开罗，亚历山大，赫尔格达和明亚以及印度的孟买。预测SLUMS模型显示出高度有效性和准确性，用于识别和预测模型在相同城市内或在不同类似环境中训练的非正规性。机器学习地理学应用，可以说还是蛮有意思的，无论是使用的特征，或者是识别的目标。 12.Understanding road congestion as an emergent property of traffic networks/将道路拥堵理解为交通网络的新兴属性 尽管对通过公路网络的交通流量建模进行了大量研究，但对导致和加剧城市道路拥堵的条件的清晰理解仍然是难以捉摸的。本文提出将拥塞识别为驾驶员与驾驶员之间相互作用的无意识紧急属性。它描述了人类行为是城市驾驶的一个恒定和重要的内在属性，以及这些相互作用如何导致明确的现象。提出了一个框架，用于进一步分析三个空间级别的拥塞，以及在每个空间级别可能最重要的驾驶员行为。在此模型的基础上，本文介绍了在伦敦高度拥挤的黑墙隧道进行的案例研究。在为本文所述的一些概念提供证据时，案例研究展示了人类行为如何导致道路拥堵的出现。本文提出的概念和框架为进一步理解和最终模拟道路拥堵的发生和传播提供了一个强有力的起点。交通拥堵也是笔者一直比较关心的一个研究问题，这个研究的概念和框架是一个很有意思的点，可以说类似于逆向思维的一个研究。 13.Evaluation of machine learning techniques with multiple remote sensing datasets in estimating monthly concentrations of ground-level PM 2.5/利用多个遥感数据集评估不同机器学习技术估算地面PM 2.5的月浓度的效果 细颗粒物（PM2.5）已被公认为可影响人口健康风险的关键空气污染物，特别是在野火等极端情况下。以前的研究已经应用地理空间技术，如土地利用回归来绘制地平面PM2.5，而最近的一些研究发现，从卫星影响和机器学习技术得到的气溶胶光学深度（AOD）可能是两个可以改善时空的元素预测。然而，缺乏研究评估使用不同的机器学习技术与AOD数据集来映射PM2.5，特别是在PM2.5的高时空变异性的区域。在本研究中，我们将八种预测算法的性能与使用多种遥感数据集（包括卫星衍生的AOD数据）进行比较，以预测地面PM2.5浓度。根据结果，Cubist，随机森林和极限梯度提升算法具有更好的性能，而Cubist是最好的。变量重要性分析表明，建模贡献最高的预测因子是月度AOD和海拔。总之，适当选择机器学习算法可以改善地面PM2.5估计，特别是对于PM2.5与复杂地形引起的预测因子之间存在非线性关系的区域。卫星导出的数据，如AOD和地表温度（LST），也可以替代从气象站检索到的传统数据集，特别是对于站点分布稀疏和不均匀的地区。这篇文章结合多源遥感和机器学习做PM2.5制图，数据很全面，包括站点数据、MODIS产品（AOD，Albedo，NDVI，LST，Vapor）、NCEP再分析资料（气象数据）。还用了多种机器学习算法，包括时下流行的随机森林和梯度提升类的算法。结论上有一点跟笔者参与的一个研究比较类似，海拔是有比较显著的影响。]]></content>
      <categories>
        <category>Personal</category>
      </categories>
      <tags>
        <tag>Consideration of Ecology and Geography</tag>
        <tag>Summary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Coding and Paper Letter（十二）]]></title>
    <url>%2F2018%2F08%2F16%2FCoding-and-Paper-Letter%EF%BC%88%E5%8D%81%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[资源整理。 1 Coding：1.R语言生成的ppt，GeoStat2018会议报告，时空模式分析的报告。 geostat18 2.欧空局哨兵和SMOS的工具集，关于对地观测数据的处理与分析的docker容器。 docker esa snap 3.R语言包ggmapstyles，一个R包可以切换各种不同风格的地图。 ggmapstyles 4.地理空间的docker镜像并且打包成AWS（亚马逊云服务器）的linux系统。 geolamda 5.R语言包ggrastr，ggplot2的拓展包，专门针对栅格几何图形。 ggrastr 6.一系列关于使用Google Earth Engine(GEE)的工具（javascript）。 geetools code editor 7.R语言教程展示如何构建一个简单的ABM模型。 cultural evolution ABM tutorial 8.基于Python API的Google Earth Engine(GEE)的最佳可获取像素组合。 geebap 9.R语言包caiman，冠层照片分析。 caiman 10.R语言包imager，专门用做图像处理的R包。 imager 11.基于neo4j的推荐引擎模块。 neo4j reco 12.高性能，易用且可扩展的机器学习包（C ++，Python，R）。 xlearn 13.将光线应用到rgl的绝对坐标上。 montereybayshader 14.将shapefile转换为json文件。 shapefile js 15.基于R的贝叶斯分析模板。 bayesian template 16.R语言包autoxgboost，自动调整和安装xgboost的R包。 autoxgboost 2 Paper:1.Air Quality Monitoring Network Design Optimisation for Robust Land Use Regression Models/鲁棒土地利用回归模型的空气质量监测网络优化设计 为了解空气污染对健康的影响，一个非常普遍的流行病学研究是可用的暴露数据质量。许多流行病学研究依赖于经验建模技术，例如土地利用回归（LUR）来评估环境空气暴露。以前的研究已经以临时的方式定位监测站，有利于它们在交通“热点”中的位置，或者在主观上被认为对土地使用和人口感兴趣的区域。然而，监测站的临时安置可能导致长期暴露分析的不明智决定。本文介绍了一种识别空气质量监测站位置的系统方法。它结合了LUR的灵活性和将权重放在优先区域（如人口密集区域）的能力，以最小化空间平均预测误差。在研究区域测试方法已经表明它导致平均预测误差的显着下降（没有空间权重的情况下为99.87％;在研究区域中具有空间权重的99.94％）。这项工作的结果可以指导网站的选择，同时扩展或创建空气质量监测网络，以实现稳健的LUR估算，同时将预测误差降至最低。土地利用回归模型是一个比较常用的环境大气污染监测建模模型。这篇文章不仅仅是从模型角度对模型改进，还针对空气质量监测网络做了优化。 2.Partitioning evapotranspiration using an optimized satellite-based ET model across biomes/使用优化的基于卫星的ET模型在生物群系中划分蒸散 蒸散（ET）的划分是陆地水平衡和全球水循环的关键因素，了解陆地生物群落的划分以及ET划分与潜在影响因素之间的关系对于预测未来的生态系统反馈至关重要。基于优化的Priestly-Taylor喷射推进实验室模型，我们将ET分为三个组成部分蒸腾（T），冠层拦截蒸发（EI）和土壤蒸发（ES）。我们发现EI的成分是显着的，不同生物群落中EI与降水的比率在0.02到0.29之间。 T / ET比率范围为0.29至0.72，生物群落之间存在明显差异，且比率通常低于先前使用同位素方法的研究。 （T + EI）/ ET比率被限制在从0.57到0.86的相对窄的范围内。随着年降水量的增加，T / ET值呈明显下降趋势，但T / ET与年叶面积指数之间无显着相关性。蒸散是生态系统中很关键的一个组成，近些年来很多研究都是针对ET的。这个文章将ET更好地与生物群落结合在一起，值得一度，发表在农林科学top期刊Agricultural and Forest Meteorology上。]]></content>
      <tags>
        <tag>Consideration of Ecology and Geography</tag>
        <tag>Summary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Coding and Paper Letter（十一）]]></title>
    <url>%2F2018%2F08%2F12%2FCoding-and-Paper-Letter%EF%BC%88%E5%8D%81%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[接上文的这一段时间的资源整理，这一篇专门针对Coding部分。 Coding：1.GeoTrellis框架的Spark Python库。分布式地理处理环境。 geopyspark 2.GEE(Google Earth Engine），GEE平台支持的简单命令行（基于Python）。 geeup 3.R语言包scales，用于转换ggplot2绘图所需的数据。 scales 4.R语言包rosm，R中开源的Open Street Map瓦片数据包。可以绘制OSM数据。 rosm 5.R语言包GeoMLBStadiums，ggplot2拓展包，定义了一些ggplot2里的geom对象来绘制MLB体育场、 GeoMLBStadiums 6.R语言包landscapemetrics，R包，R中的Fragsstats。 landscapemetrics 7.2015年论文提出的Stochastic antecedent modelling框架的开源代码（R和pymc3）。 Ogle et al. (2015) Quantifying ecological memory in plant and ecosystem processes. Ecology Letters, 18: 221–235 stochastic antecedent modelling 8.R语言Shiny工程geoloc，geoloc的目标是从现代Web浏览器提供对地理位置API的访问，以便在Shiny应用程序中获取用户的位置。 geoloc 9.动物迁徙分析与模拟的开源代码库（R语言）。 moveecology 10.用于整个机器学习生命周期的开源平台mlflow。 mlflow 11.R docoker的教程。 r docker tutorial 12.R包ResistanceGA，用遗传算法优化阻抗面（2014年发表论文）。 Peterman, W.E., G.M. Connette, R.D. Semlitsch, and L.S. Eggert. 2014. Ecological resistance surfaces predict fine-scale genetic differentiation in a terrestrial woodland salamander. Molecular Ecology 23:2402–2413. ResistanceGA 13.R语言包cavityuse，从地理定位数据中监测cavity use的包。 cavityuse 14.R语言包gestalt，数据预处理包。 gestalt 15.NASA的HiMAT团队利用卫星遥感观测来描述亚洲高山地区这些变化（冰川，雪，永久冻土和降水模式），深入了解控制它们的地球系统过程，并为决策，管理行动和政策制定提供信息。 HiMAT 16.用Postgresql/PostGIS导入New York的出租车和Uber轨迹数据，用R分析。 nyc taxi data 17.R语言（数学加统计）的练习教程（分析）。 R 18.R语言包timevis，交互式的时间可视化包。 timevis 19.全球公开地图数据集。 natural earth vector 20.R语言包ggvoronoi，ggplot2的拓展包，简单绘制泰森多边形等值图。 ggvoronoi 21.开源R项目admin GIS,从代码内容来看，是将WRF-CHEM输出数据转化为栅格的代码。 admin GIS 22.R语言包stylest，文本挖掘方面的包，可以估计小说中人物讲话风格。 stylest 23.R语言包unpivotr，用于处理非表格数据。 unpivotr 24.R语言包reticulate，R语言的Python接口。 reticulate 25.Python库pygeotools，地理空间数据处理与分析的库和命令行工具。 pygeotools 26.R语言开源项目bookdown.org,用于生成bookdown.org上书籍的源文件。 bookdown.org 27.统计之都和R语言中文社区活跃作者黄湘云的书，关于用R做统计计算与图形的介绍。 ISCGwr 28.R语言包DataPackageR，作用似乎和R markdown/notebook类似。 DataPackageR 29.使用R markdown的秘籍。 rmarkdown cookbook 30.R语言包ggRandomForests，ggplot2的画图拓展包，主要负责随机森林的可视化分析。 ggRandomForests 31.R语言包manipulateWidget，可以添加更多的widget，也就是网页上的元素。 manipulateWidget 32.Python开源项目wechat spider，微信公众号文章爬虫。 wechat spider 33.Python库pyresample，负责栅格数据的重采样。 pyresample 34.无监督学习的稀疏自动编码器。 SparseAutoEncoder 35.R语言包cartography，各种不同类型的地图可视化包。 cartography 36.用于创建rasterio的geotiff的云优化插件。 rio cogeo 37.连接rasterio和mapbox GL js的样例UI。 rio glui 38.使用R语言编程处理不同类型的数据（地球系统数据）的教程（课程）。 earth analytics r course 39.《Spatial Microsimulation with R》书的代码和内容。 spatial microsim book 40.R语言包rasterTools,用来获取和处理对地观测数据的包。 rasterTools 41.R语言包fieldRS,用于遥感数据地面检验数据收集与处理。 fieldRS 42.R语言包ggstatsplot，ggplot2的拓展包，提供丰富的统计检验的图表信息。 ggstatsplot 43.Asana API的元数据，用于生成客户端库和文档。 asna api meta 44.用于维护自动化GIS过程课程页面的源文档，2017年。 CSC18 45.用Python工具处理栅格数据的教程。 raster 46.Echarts的3D图形扩展。 echarts-gl 47.openlayers3和Echarts的结合。 ol3Echarts 48.蜂巢六边形地图。 hexgridmap 49.开源R语言项目，从代码内容来看，是基于土壤水分等数据绘制土壤盐度数据。 MAPPING maps meters 50.开源R语言项目，从代码内容看，是融合或者集成多源包括MODIS，欧洲数据同化中心（ECMWF)数据的AOD数据。 ECMWF CAMS]]></content>
      <categories>
        <category>Personal</category>
      </categories>
      <tags>
        <tag>Consideration of Ecology and Geography</tag>
        <tag>Summary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Coding and Paper Letter（十）]]></title>
    <url>%2F2018%2F08%2F09%2FCoding-and-Paper-Letter%EF%BC%88%E5%8D%81%EF%BC%89%2F</url>
    <content type="text"><![CDATA[继续之前的资源整理，前段时间有事没有整理，最近有些空闲，先来整理，这一篇决定只更论文部分。 Paper:1.Quantification of the traffic-generated particulate matter capture by plant species in a living wall and evaluation of the important leaf characteristics/定量生活墙/立体绿化中植物物种捕获的交通产生的颗粒物质并评估重要的叶片特征 交通产生的颗粒物（PM）是城市PM污染的重要部分，对于使用生活墙作为减少这种污染的短期策略知之甚少。本研究利用位于英国特伦特河畔斯托克（Stoke-on-Trent）繁忙道路上的生活墙/立体绿化系统，评估了20座生活墙/立体绿化植物减少基于交通的PM的潜力。使用环境扫描电子显微镜（ESEM）和ImageJ软件来量化叶片（PM1，PM2.5和PM10）上的PM积累，并使用能量分散X射线（EDX）测定它们的元素组成。使用广义线性混合效应模型（GLMM）以时间为因子评估叶-PM积累的种间变异;鉴定了由于特定叶特征（气孔密度，毛发/毛状体，脊和沟）引起的任何差异PM积累。该研究表明，活壁植物有望去除大气PM。不同物种捕获的所有粒径都有明显不同的数量;在Juniperus chinensis L.的叶针上发现了最大量的所有粒径，其次是小叶种。在PM积累和叶表面特征之间没有明显的相关模式的情况下，该研究强调了个体叶片大小在PM捕获中的重要性，而不管它们的可变微观形态如何。捕获的颗粒的元素组成与基于交通的PM和各种重要的重金属显示出强烈的相关性。我们的结论是，使用主要由小叶种和针叶树组成的生活墙/立体绿化可能会通过消除交通产生的PM污染来改善空气质量，从而改善城市居民的福祉。微观尺度上的植被滞尘研究，结合扫描电镜的研究非常有亮点，这一方面中科院生态中心周伟奇老师组也做了很多工作。而且有一个蛮有意思的就是，反而小叶种和针叶树吸收PM污染效果好，这反而是我所没有预料到的结果。 2.Spatial-Temporal Variability and Dust-Capture Capability of 8 Plants in Urban China/中国城市8种植物的滞尘能力与时空变异 城市植物已被证明可以减少环境颗粒物（PM），这有助于城市规划者控制城市空气污染。在这项研究中，在一年的时间内，在中国南京市的7个功能区域对8种树木叶片的PM沉积进行了定量分析。结果表明叶片PM含有不同的粒径组分（PM10和PM2.5），并且季节和物种之间存在差异。工业区PM，PM10和PM2.5总量最高，总PM累积量最高在冬季发生。在测试的树种之间发现显着差异。 Cedrus deodara表现出大量的PM，PM10和PM2.5总量。本研究检测了树种间PM的质量和数量分布，并用扫描电子显微镜（SEM）确定了颗粒。结果显示气孔大小，密度和绒毛与PM2.5捕获量显着相关。据我们所知，这是第一篇介绍南京不同树种PM的质量和数量分布的论文。结果不仅提供了对树种保持灰尘能力的全面见解，而且还为城市绿地提供了一系列物种，其目标是减轻城市空气中的PM。又是一篇微观的植被滞尘研究且结合扫描电镜，不仅针对树种，针对叶片的性状也给出了实证研究，并且是中国的case study。值得关注。 3.Multiple Intra-urban Land Use Simulations and Driving Factors Analysis: A case study in Huicheng, China/多个城市内部土地利用模拟及驱动因素分析 - 以中国惠城为例 城市内部土地利用变化的模拟逐渐引起了更多关注，因为这些方法在决策和政策制定方面极为有用。虽然之前的研究主要集中在开发城市内水平模拟的方法，但很少有研究解释推动城市内土地利用变化的因素。城市规划者高度关注城市内部结构的形成及其运作方式。在这里，为了模拟多个城市内的土地利用变化并确定不同驱动因子的贡献，我们开发了一种基于随机森林（RF）算法的元胞自动机（CA）模拟模型。在这项研究中，该模型应用了不同类别的空间变量，包括交通位置因素，环境因素，公共服务和人口密度，作为增强我们对城市内部土地利用动态的理解的驱动因素。 CA模型使用来自中国广东省惠州市惠城区的数据进行测试。该模型使用2000年至2010年的实际历史土地利用数据进行了验证。通过应用经验证的模型，模拟了2015年的多个城市内土地利用图。同时，使用计算了空间变量重要性度量（VIM）的RF算法的误差估计方法。根据计算结果，我们评估和分析了该地区每个城市内土地利用驱动因素的重要性。该研究为城市规划者和相关学者提供了详细和有针对性的信息，可以帮助制定针对不同城市内土地利用的具体规划策略，并支持该地区的未来发展。来自中山大学刘小平老师团队CA-Land use simulation的研究成果，国内土地利用模拟的翘楚团队，这篇文章结合了比较新颖的RF算法（虽然我觉得现在也是烂大街了），并且提供了RF算法的误差估计方法，在方法上就很有新意，其次关注的是城市内部土地利用变化——也就是城市功能区的变化，最后得到的结果就是居住用地、工业用地、商业用地和公共服务设施用地，我觉得对城市规划的政策启示要比单纯的土地利用好得多。 4.Capturing exposure in environmental health research: Challenges and opportunities of different activity space models/环境健康研究中的暴露评估：不同空间行为模型的挑战和机遇 背景：在过去十年中，建筑环境健康促进在广泛的健康相关研究中引起了显着的关注。然而，关于健康和PA的背景影响的结果是高度异质的。结果之间的差异可能部分地通过不同空间分析单元在评估个体对各种环境特征的暴露方面的不同使用来解释。该研究调查了不同的住宅和活动空间分析单元是否产生了关于建筑环境与健康之间关联的不同结果。此外，本研究还探讨了不同空间分析单元对环境健康相关研究的挑战和机遇。 方法：使用两个常见的住宅分析单元和两个新的活动空间模型来检查芬兰赫尔辛基都市区的老年人的健康状况。行政单位，500米住宅缓冲区，家庭范围模型和个性化住宅暴露模型被用来评估建筑环境与受访者福利之间的关联（n = 844）。 结果：所有四种不同的空间分析单元都产生了关于建筑环境特征与健康之间关联的不同结果。只有在通过个性化住宅暴露模型评估暴露时，才发现绿地与健康之间存在正相关关系。发现可步行性指数以及行人和自行车道路的长度与感知的健康措施正相关，仅与家庭范围模型相关。此外，所有分析单元在大小，形状以及如何捕获不同的上下文度量方面彼此不同。 结论：结果表明，不同的空间分析单元导致建筑环境的测量结果差异很大。反过来，使用不同空间单位产生的差异似乎会显着影响环境特征与健康措施之间的关联。虽然不容易争论这些测量的正确性，但显而易见的是它们可以揭示不同的健康结果。虽然某些方法特别可用于确定促进积极旅行和相关健康结果的环境机会的可用性，但其他方法可以让我们深入了解实际暴露与绿色空间如何能够增强健康的机制。 环境健康的暴露评估研究，事实上来说，不同的分析单元造成的结果差异正是地学、生态学中目前的热点问题，由于尺度效应造成的原因，多尺度研究将会是未来的趋势，另外绿地、以及可步行性对健康的效应值得关注。一个是降低污染和心理压力，一个是吸引步行从而锻炼身体（从个人直观来看目前阅读的一些文献内容是这么解释的）。 5.Portraying Urban Functional Zones by Coupling Remote Sensing Imagery and Human Sensing Data/通过耦合遥感图像和人类感知数据绘制城市功能区 描绘城市功能区为理解复杂的城市系统和建立合理的城市规划提供了有用的见解。尽管一些研究证实了遥感影像在城市研究中的有效性，但仍然没有研究将遥感影像与新的人类感知数据（如手机定位数据）相结合来识别城市功能区。在这项研究中，开发了一个集成遥感影像和手机定位数据的新框架，用景观和人类活动指标分析城市功能区。根据遥感图像的土地覆盖计算景观指标。从大量的手机定位数据中提取人类活动。通过整合它们，城市功能区（城市中心，分中心，郊区，城市缓冲区，过境区和生态区）通过层次聚类来识别。最后，对三个典型的横断面进行了梯度分析，以研究景观和人类活动的模式。以中国深圳为例，进行的实验表明，深圳城市功能区的景观和人类活动模式并不完全符合古典城市理论。结果表明，遥感影像与人类感知数据的融合可以很好地刻画深圳复杂的城市空间结构。城市功能区有可能成为城市结构，人类活动和城市规划政策之间的桥梁，为合理的城市规划和可持续城市发展政策制定提供科学支持。城市功能区的分类越来越受到研究学者的重视，而所谓的human sensing data与北京大学刘瑜老师2015年提的social sensing是不谋而合，深圳大学的团队也在这方面做了很多深入的研究，总的来说，利用ICT技术产生的LBS、社交媒体和手机信令等现在流行的大数据进行城市地理方面研究，确实会给城市地理学注入新的活力。当然也要同时规避这些数据所产生的不确定性（这一方面我推荐关美宝老师的文章）。 6.Using GIS and Perceived Distance to Understand the Unequal Geographies of Healthcare in Lower-Income Urban Neighborhoods/利用GIS和感知距离来理解低收入城市社区医疗保健的地理位置不平等性 地理学家在公共卫生研究中发挥着重要作用，特别是在了解医疗保健的可及性，利用率和个人医疗保健经验方面。大多数可访问性研究都受益于地理信息系统（GIS）日益复杂化。一些研究通过半结构化的深度访谈得到了加强，以了解人们获得医疗保健时的个人经历。然而，很少有可访问性研究明确利用个人深度访谈数据来构建新的GIS可访问性措施。使用包括GIS分析在内的混合方法和来自半结构化深度访谈的个人数据，我们提供满意度调整距离作为GIS中可访问性概念化的新方法。基于俄亥俄州哥伦布市（美国）主要是低收入社区的实地调查，我们发现许多居民认为社区医疗机构提供的是低质量的医疗服务，这表明他们试图获得高质量的医疗设施时会增加感知距离。满意度调整的距离度量是一些居民在低收入城市社区寻找高质量医疗保健时的感知距离。通过这种方式超越传统地理信息系统并重新构建可访问性，我们可以更加真实地描述低收入城市居民在尝试获得高质量医疗设施时所面临的问题。这项工作对于概念化医疗保健可及性具有理论意义，推进了混合方法学文献，并争论在城市社区中更公平地分配高质量的医疗保健。关美宝老师的成果，本科期间参与过师妹医院GIS可达性分析的项目，也听过师兄硕士毕业论文答辩，事实上对于低收入群体的医疗公平性问题研究，我觉得是社会学更为关注的，但是却也是更为人道，更为追求社会公平的一项研究。此外，根据最近SDGs的火热程度，我预估这方面的研究将成为未来的热点。 7.Does bus accessibility affect property prices?/公交可达性是否会影响房价？ 现有的研究已经就公交车的可达性效益得出了一致的结论。大多数现有的研究都是在西方的背景下进行的，那里的公共汽车乘客量普遍很低。在这项研究中，我们使用了中国厦门358个住宅区的22,586个二手住宅物业数据库，开发了四个非空间特征定价模型（一个标准和三个Box-Cox变换）和两个空间计量经济模型来量化其影响。公共汽车在房地产价格上的可获得性，并分析空间计量经济模型的引入将如何影响这些效益的估计。我们的研究结果如下。 （1）巴士站的通道与物业价格正相关。这一结果与主流研究的结果形成对比。对于500米范围内的每个巴士站，物业的价格高出0.5％，其他条件相同。 （2）到主要目的地的公共汽车旅行时间对房价的影响很大。 （3）考虑空间自相关的空间计量经济模型优于传统的特征定价模型。一些稳健性检查分析进一步保证了本研究的合理性。然而，由于公共汽车旅行的吸引力下降和未来几年的持续运输服务增加，公共汽车可达性提供的价格溢价可能会逐渐降低，甚至最终被丢弃。公交可达性对于房价的影响在厦门的实证研究。可以探究一下另外的因素对房价的影响（也是西方的结论的实证研究），研究思路蛮有意思。 8.Evaluation of the MODIS C6 Aerosol Optical Depth Products over Chongqing, China/中国重庆MODIS C6气溶胶光学厚度产品评估 首次使用太阳光度计的地面观测AOD评估暗目标（DT）和深蓝（DB）算法生成的中分辨率成像光谱仪（MODIS）集合6（C6）气溶胶光学深度（AOD）产品。重庆，中国西南部的一个多山的大城市。验证结果表明，DT算法的MODIS AOD与太阳光度计的相似，尽管有轻微的高估。然而，与太阳光度计相比，DB算法大大低估了MODIS AOD。误差分析意味着表面反射率估计的偏差是两种算法的主要误差源。 DT算法的云筛选方案比DB算法更有效。在两种算法的质量控制过程中应考虑云附近效应。敏感性试验表明，在重庆等复杂地形区域，应根据当地情况仔细选择卫星产品验证中的配置方法。当比较MODIS产品的月平均AOD与太阳光度计观测时，表明Terra MODIS AOD产品有效代表夏季和秋季的平均状态，但Aqua MODIS AOD的月平均值在重庆是有限的。对遥感产品的地面验证，这是定量遥感的关键一步，尽管现在很多研究没有做这一步，但是当地面验证的数据慢慢增多之后，才能真正的定量。 9.Eigenvector Spatial Filtering Regression Modeling of Ground PM2.5 Concentrations Using Remotely Sensed Data/基于遥感数据的地面PM2.5浓度特征向量空间滤波回归建模 本文提出了一种回归模型，使用特征向量空间滤波（ESF）方法来估计地面PM2.5浓度。协变量来自遥感数据，包括气溶胶光学深度，NDVI，LST，气压，相对湿度，行星边界层高度和数字高程模型。此外，模型中还使用了工厂密度和道路密度等社会变量。以长江三角洲地区为研究区域，利用2015年12月至2016年11月期间的数据，建立了不同时间尺度的基于ESF的回归模型（ESFR）。我们发现ESFR模型有效地过滤了空间自相关。与传统的OLS模型相比，OLS残差导致拟合优度度量的增加以及残差标准误差和交叉验证误差的减少。年度ESFR模型解释了PM2.5浓度变异性的70％，比非空间OLS模型高16.7％。通过ESFR模型，我们对研究区PM2.5浓度的空间和时间分布进行了详细分析。模型预测低于地面观测但与总趋势相符。实验表明，ESFR为PM2.5分析和预测提供了一种有前景的方法。类似于LUR的全遥感建模方法，非常有借鉴意义。 10.Evaluating the uncertainty of Landsat-derived vegetation indices in quantifying forest fuel treatments using bi-temporal LiDAR data/使用双时间LiDAR数据评估Landsat衍生植被指数在量化森林燃料处理中的不确定性 美国西部的森林生态系统长期以来受到木材采伐和灭火的影响，最近还通过减少火灾管理燃料的处理方式。准确量化燃料处理引起的森林结构变化是评估其影响的重要步骤。卫星图像衍生植被指数，如归一化植被指数（NDVI），已被广泛用于绘制森林动态图。然而，使用这些植被指数量化森林结构变化的不确定性尚未得到彻底研究，主要是由于缺乏全样本验证数据。在这项研究中，我们通过在加利福尼亚州内华达山脉北部的混合针叶林中使用双时间空气光探测和测距（LiDAR）数据和野外测量，在地上生物量（AGB）和冠层覆盖中产生了森林结构变化。这些LiDAR衍生的森林结构测量用于评估使用Landsat衍生植被指数量化处理的不确定性。我们的研究结果证实，植被指数可以准确地绘制燃料处理引起的森林干扰和冠层覆盖变化的程度，但AGB变化量化的准确性因治疗前森林密度和处理强度而异。与中等密度森林相比，植被指数变化与稀疏或密集生物量的森林生物量变化相关性较弱。我们的研究结果表明，在将植被指数与AGB变化联系起来时，研究人员和管理人员应对其在极密或稀疏森林中的不确定性持谨慎态度，特别是当处理主要去除小树或林下燃料时。LIDAR和Landsat结合的研究，尤其是衡量林火造成的生物量不确定性估计问题。 11.Dynamic assessment of exposure to air pollution using mobile phone data/使用手机数据动态评估空气污染暴露度 这篇文章一览众山小·可持续城市与交通已经翻译过。就不具体阐述了，讲述的也是新兴大数据在环境污染暴露评估的应用。 一览众山小翻译 12.The Transferability of Random Forest in Canopy Height Estimation from Multi-Source Remote Sensing Data/基于多源遥感数据的冠层高度随机森林模型可迁移性研究 林冠高度是了解森林生态系统和提高全球碳储量量化准确度的重要森林结构参数。光探测和测距（LiDAR）可以提供精确的冠层高度测量，但其在大规模的应用是有限的。使用LiDAR衍生的冠层高度作为地面实况来训练随机森林（RF）算法并因此在没有LiDAR覆盖的区域中预测来自其他遥感数据集的冠层高度已经是大规模冠层高度映射中最常用的方法之一。然而，研究地点的位置，植被类型和空间尺度的差异如何影响RF建模结果仍然是一个需要解决的问题。在这项研究中，我们选择了16个研究地点（每个100平方公里），在美国各地进行全机载LiDAR覆盖，并使用LiDAR衍生的冠层高度以及光学图像，地形数据和气候表面来评估其可迁移性。基于射频的冠层高度预测方法。结果显示了从一般到复杂的一系列发现。在特定位置或植被类型训练的RF模型不能转移到其他位置或植被类型。然而，通过使用来自具有各种植被类型的所有地点的样本训练RF算法，可以实现通用模型来预测不同位置和不同植被类型的冠层高度。此外，当研究地点的空间范围小于50平方公里或者训练像素的空间分辨率小于500米时，空间尺度对RF预测精度的影响是显着的。冠层高度预测精度随空间范围和目标空间分辨率而增加。用多元遥感的数据探究机器学习算法模型的可移植性，其实要求算法有非常强的泛化能力。 13.Retrieving 2-D Leaf Angle Distributions for Deciduous Trees From Terrestrial Laser Scanner Data/从地面激光扫描仪数据中反演落叶树的二维叶角分布 地面激光扫描是估算叶片角度（包括叶片倾角和方位角）分布（LAD）的有前途的工具。然而，之前的研究主要集中在叶片倾角分布的反演上，很少有研究考虑到由于测量技术的限制而导致叶片方位角的分布。在本文中，我们开发了一种基于叶点云分割和过滤获得更准确的叶片倾角和方位角估计的新方法，然后使用双参数Beta分布模型拟合LAD函数。此外，我们基于LAD的精确反演，利用Nilson算法构造了一个具有两个参数G（θ，φ）的投影系数模型。为了评估叶片数量对叶片倾向和方位角估计的影响，我们模拟了160个单独的叶子和10个具有不同叶片数量的树木。此外，为了验证最终结果，我们还使用角度测量装置对具有不同叶数的三棵木兰树进行采样，并手动测量所有叶子的叶片倾斜度和方位角。结果表明，本文提出的方法可以提供准确的叶片倾角和方位角。基于这些叶片倾角和方位角的模拟LAD和G（θ，φ）估计与从地面实况测量获得的那些强烈相关。叶片角度事实上在植被定量遥感里非常重要，记得在牛老师介绍李小文光学几何模型的时候有听到过。LiDAR的主动遥感技术为过去仅依靠光学被动遥感反演提供了新的可能性（毕竟IEEE TGRS大作）。 14.Assessment of Pollution-Health-Economics Nexus in China/中国污染 - 健康 - 经济联结评估 严重的雾霾会导致污染疾病，通过提高心血管和呼吸系统疾病的死亡率和发病率来触发生产劳动时间。卫生研究很少考虑工业相互联系的宏观经济影响，而灾害研究很少涉及空气污染及其对健康的影响。本研究采用供应驱动的投入产出模型，利用最新的中国多区域投入产出表，估算2012年中国30个省份因疾病导致的工作时间缩短所造成的经济损失。结果显示，经济损失总额为3982.3亿元人民币（占2012年中国GDP的1％左右），其中大部分来自华东和中南部。受影响劳动者总数为8219万。跨区域经济影响分析表明，中南，华北和华东地区间接损失占绝大部分。实际上，华北，西北和西南地区的大部分间接损失可归因于其他地区的制造业和能源，而华东，中南和东北地区的亏损主要来自其他地区的煤炭和采矿业。在次工业层面，华北和西北地区的大部分内陆区域性损失来自煤炭和矿业，中国东部和西南部来自设备和能源，中南部来自金属和非金属。这些研究结果强调了由于独特的区域经济结构和南北之间的依赖性，地理距离在区域相互联系中的潜在作用以及区域内外区域损失的区域异质性。目前非常火的Nexus系列研究，关大博老师团队的成果。将空气污染、健康和经济联结做的评估，非常有意思的研究，当然更多倾向于经济学。目前还在学习。 15.Air Pollution Removal by Urban Forests in Canada and its Effect on Air Quality and Human Health/加拿大城市森林空气污染及其对空气质量和人体健康的影响 城市树木提供了许多生态系统服务，包括空气污染清除，碳封存，冷却气温和为城市景观提供美学。 树木通过拦截植物表面的颗粒物质和通过叶子气孔吸收气态污染物来消除空气污染。 根据当地环境数据进行的计算机模拟显示，2010年加拿大86个城市的树木清除了16,500吨（吨）空气污染（范围：7500-21,100吨），人类健康影响价值为2.272亿加元（范围：5250-402.6百万美元））。 不同城市的年污染去除率不同，不列颠哥伦比亚省温哥华的污染范围高达1740吨。 总体健康影响包括避免这些城市中30例人类死亡率（范围：7-54）和22,000例急性呼吸道症状（范围：7900-31,100）。将健康量化成生态系统服务价值，这也是之前在上景观生态学课程时候所预期的看法，现在看到正式的论文也是非常激动。 16.Mapping annual urban dynamics (1985–2015) using time series of Landsat data/使用Landsat数据的时间序列绘制逐年城市动态变化（1985-2015） 精细时空分辨率下的城市动态信息对城市增长模型和城市可持续发展至关重要。然而，在长时间内获得城市化在时间和地点的变化信息方面仍然存在挑战。在这项研究中，我们开发了一个框架，通过使用Landsat数据的时间序列，以1985年至2015年的年度间隔绘制城市扩展图。首先，根据现有的国家土地覆盖数据库（NLCD），Landsat数据的时间序列（1985-2015）分为三个时期，即1985-2001,2001-2011和2011-2015。然后，使用表示植被，水和裸地到城市的变化的三个指标，为每个时期实施时间分割方法。确定了变化开始和结束的多年。相应地生成表示先前改变，改变和改变后的阶段的三个时间段。此后，使用基于变化向量分析（CVA）的NLCD辅助方法和确定的时间段对2001年之前和2011年之后的城市范围进行分类。最后，根据确定的转弯年份确定每个时期的城市化像素。我们的时间分割方法对于检测城市增长引起的变化是可靠的，在识别转弯年（±1年）时总体准确度为90％。使用独立的验证样本集，基于CVA的方法达到87％的总体准确度。城市动态变化的产品显示，在美国爱荷华州得梅因和埃姆斯，城市增长相对稳定，大多数城市化地区在2 - 3年内从植被土地转变而来。拟议的框架能够以年度间隔绘制城市范围的长期动态，其结果有助于有效更新城市范围的当前产品和改善城市增长模型。发表在遥感界Top上的文章，做了长时间序列高精细分辨率的城市扩张研究。最近对这方面很有兴趣，可能会做深一步的学习。 17.Spatiotemporal Distribution of Satellite-Retrieved Ground-Level PM2.5 and Near Real-Time Daily Retrieval Algorithm Development in Sichuan Basin, China/四川盆地卫星地面PM2.5的时空分布及近实时日反演算法的发展 基于卫星的监测可以反演具有更高分辨率和连续空间覆盖的地面PM2.5浓度，以帮助制定管理战略和估算健康暴露。四川盆地地形复杂，几个城市群与中国其他地区不同：它有一个封闭的空气盆地，具有独特的行星边界层动态，积累了空气污染。利用改进的暗像素方法和中分辨率成像光谱仪（MODIS）数据，反演了四川盆地1 km分辨率气溶胶光学厚度（AOD）的时空分布。反演的季节性AOD在春季达到最高值，在秋季达到最低值。基于地面的激光雷达AOD和1-km分辨率MODIS AOD之间的较高相关性（r = 0.84，N = 171）表明高分辨率MODIS AOD可用于反演地面PM2.5浓度。激光雷达测量的年平均消光系数随着行星边界层高度（PBLH）在100~670 m范围内线性增加，但在670~1800 m之间呈指数减小。来自气象研究和预报（WRF）模型和SHIN模型，加州气象（CALMET）模型进行了检验。PM2.5反演的最新热点集中在日尺度以下的反演，大家更关注的是短时空气污染与污染事件所产生的拐点时刻。所以接下来对时间分辨率的需求不断上升，这个研究还是用了多个数值模拟模型进行检验，工作很全面。 18.Automating land parcel classification for neighborhood-scale urban analysis/用于邻里尺度的城市分析的自动化地块分类 房主协会（HOA）通过在美国社区规模的法律强制执行的土地契约来规定景观结构和管理。确定HOA的位置和空间范围对于检查其影响至关重要。然而，这种分析因适用于这种分析的单位缺乏空间数据而混淆。本文的目的是开发和实现一个自动化地块分类（开源实现），这是确定HOA对城市土地管理影响的目标的第一步。使用亚利桑那州的马里科帕县作为试验台，我们发现包裹合并过程将细分的数量从26,042减少到17,269，这样边界更好地与适用于土地契约的规则集的邻域单元对齐。此外，在最初的训练期后，这个过程在短短7个多小时内就完成了。该研究是实现大量分析的重要的第一步，包括在区域内确定HOA的位置和空间范围，并最终在全国范围内确定HOA与土地管理结果之间的拟议联系。叶信岳老师的大作，邻里尺度在社会与城市地理学是一个很重要的研究尺度，从生产数据角度而言，需要这样子的成果。 19.Urban growth simulation by incorporating planning policies into a CA-based future land-use simulation model/通过将规划政策纳入基于CA的未来土地利用模拟模型进行城市增长模拟 城市规划和政府决策影响城市土地利用变化。以前的城市模拟方法只关注规划限制，以防止城市增长在特定地区发展。然而，区域规划制定了推动城市发展的规划政策，例如交通规划和开发区，这在以前的研究中很少被考虑。本研究旨在设计两种基于细胞自动机的未来土地利用模拟模型的机制，将不同的规划驱动因素整合到模拟中。第一种更新机制考虑了交通规划的影响，而第二种机制可以模拟规划开发区的指导效果。拟议的机制适用于珠江三角洲地区，这是中国发展最快的地区之一。第一种机制通过2000 - 2013年的模拟验证，并证明通过考虑交通规划提高了模拟精度。在2013 - 2052年的模拟中，实施了这两种机制，产生了更加真实的城市空间格局。模拟结果可用于识别总体规划内的潜在城市扩张。拟议的方法可以作为一种有用的工具，帮助规划者在不同规划政策的影响下评估城市演变。依旧是国内土地利用模拟的翘楚团队中大刘小平老师的成果，关于规划政策对于城市增长的模拟还是很有意思的。如何做空间化就是一个比较有意思的研究。此外此文又发在了IJGIS上，该团队不愧为IJGIS第一论文大户（印象中黎夏老师发的最多）。 20.A scalable cyberinfrastructure and cloud computing platform for forest aboveground biomass estimation based on the Google Earth Engine/基于Google Earth Engine的森林地上生物量估算的可扩展的网络基础设施和云计算平台 地球观测（EO）数据，如高分辨率卫星图像或LiDAR，已成为森林地上生物量（AGB）测绘和估算的主要来源。但是，管理和分析大量全球或本地可用的EO数据仍然是一项巨大的挑战。谷歌地球引擎（GEE）利用云计算服务提供强大的管理和快速分析各种类型的EO数据的能力，已成为应对这一挑战的不可估量的工具。在本文中，我们提出了一个可扩展的网络基础设施，用于在很大的空间范围内进行动态AGB估计，统计和可视化。该网络基础设施集成了最先进的云计算应用程序，包括GEE，Fusion Tables和Google Cloud Platform（GCP），以建立可扩展，高度可扩展和高性能的分析环境。设计了两个实验来证明其在传统桌面环境中的性能优势以及在处理复杂工作流程方面的可扩展性。此外，还开发了一个门户网站，将网络基础设施与一些可视化工具（例如Google Maps，Highcharts）集成，为一般公众和地理空间研究人员提供图形用户界面（GUI）和在线可视化。GEE，可以说是当今遥感与云计算的集大成者，值得深入学习。]]></content>
      <categories>
        <category>Personal</category>
      </categories>
      <tags>
        <tag>Consideration of Ecology and Geography</tag>
        <tag>Summary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Coding and Paper Letter（九）]]></title>
    <url>%2F2018%2F07%2F20%2FCoding-and-Paper-Letter%EF%BC%88%E4%B9%9D%EF%BC%89%2F</url>
    <content type="text"><![CDATA[资源整理 1 Coding：1.高光谱遥感相关代码资源。 Sensor Specific Hyperspectral Image Feature Learning利用卷积神经网络学习高光谱图像传感器特有的空间谱特征。 Hyperspectral Image Spatial Super Resolution via 3D Full Convolutional Neural Network基于三维全卷积神经网络的高光谱图像空间超分辨率重建，3D-FRCNN是具有单个网络的高光谱图像超分辨率（SR）的统一框架。 您可以使用该代码来训练/评估网络以获得hsi超分辨率（SR）。 3dfcnn3dfcn用于超光谱超分辨率的Python代码。 2.开源项目Johns Hopkins University Data Science Specialization on Coursera，约翰霍普金斯大学数据科学专业领域的学生或社区导师期间开发的内容，该内容是通过Coursera提供的。 许多人已经开发了内容来帮助学生完成专业化的十门课程。 datasciencectacontent 3.CVPR 17 论文”Image Super-Resolution via Deep Recursive Residual Network”的代码。 DRRN CVPR17 4.Python库，轻量级库，用于在Theano中构建和训练神经网络。 Lasagne 5.Python项目2d unet with keras，使用2d unet来做分割节点。 2d unet with keras 6.NASA的开源项目。 Python项目： POPP棕榈油种植预测（POPP）。 该Python软件可自动执行下载，大气校正和处理栅格数据的过程，以识别潜在的棕榈油种植园。 DRIP SLIPDRIP SLIP,检测实时增加降水（DRIP）/突然滑坡识别产品（SLIP）的代码。 SETSkyglow Estimation Toolbox，Skyglow估算工具箱（SET）。工具箱采用Python 2.7编写，并从NASA和NOAA的Suomi国家极地轨道合作伙伴（NPP）可见红外成像辐射计套件（VIIRS）卫星传感器进行卫星测量，以使用当地参数绘制天光图像。使用工具箱的研究人员可以通过考虑不同视角的光散射，并将SET的传播模型应用于不同的位置，从而以更高的精度识别光污染源。 R项目： PiCoPiCo,基于像素相关的景观分类（PiCo）。 PiCo是一个R脚本，自动化并区域化了Wallace等人2016年开发的气候景观响应（CLaRe）指标。该脚本执行像素逐步回归分析，以生成相关值可以评估为目标波束草的栅格。 GEE项目： LUCTLUCT，用Google地球引擎代码界面进行了美属维尔京群岛（USVI）的土地使用分类。一共六个类：水，低密度住宅，高密度住宅，森林/灌木，农业和裸地。 MARSHe利用GEE制作从2000年到2017年切萨皮克湾沼泽健康状况变化的地图。 7.Python项目Hierarchical Attention Network，用于文档分类的分层强化网络。 Hierarchical Attention Network 8.开源项目深度强化学习Nanodegree计划。 deep reinforcement learning 9.开源项目关于生成对抗（神经）网络的论文清单。 really awesome gan 10.R语言开源项目r4ds，R在数据科学中的应用。 r4ds 11.Python库verde，用于处理空间数据（水深测量，地球物理调查等）并在常规网格上进行插值（即网格化）。 verde 12.Python项目ee jupyter contrib，使用Jupyter作为GEE的IDE。 ee jupyter contrib 13.R语言项目model gov,h2o-3中的模型改进。 model gov 14.Python库inequality，空间（非空间）不平衡的测度。 inequality 15.R语言包darksky，darksky API的R接口。 darksky 16.R语言包SpaceTimeModels，使用INLA拟合空间和时空模型参数的R包。 SpaceTimeModels 17.R语言项目Spatio temporal Kriging R,用于3D克里金插值的R脚本。 Spatio temporal Kriging R 18.R语言包rsatscan，与SaTScan独立软件连接的工具，类和方法。 rsatscan 19.R语言包MSScvm，Landsat MSS图像的自动云掩膜实现。 MSScvm 20.R语言项目Downscaling，用于SNAP气候降尺度的R代码。 Downscaling 2 Paper:1.Multidecadal, county-level analysis of the effects of land use, Bt cotton, and weather on cotton pests in China/多年度土地利用，Bt抗虫棉花和天气对中国棉花害虫的影响的县级分析 土地利用，气候和农业技术的长期变化可能会影响有害生物的严重程度和管理。只有通过分析长期数据才能确定这些主要驱动因素的影响。本研究调查了1991 - 2015年间中国51个县的三种主要棉花害虫的土地利用，转基因苏云金芽孢杆菌（Bt）抗虫棉的采用，天气，害虫严重程度和杀虫剂使用面板数据。 Bt棉对棉花及其管理中的整个害虫复合体具有普遍影响。研究结果支持基于Bt的植物抗性作为综合虫害管理（IPM）的一个组成部分的有用性，但强调了农业生态系统反馈循环以及气候重要性导致的意外结果的可能性。发表于PNAS的一篇论文，结合了自然生态、农业、遥感数据，计量经济学的面板数据分析方法。 2.Learning Transferable Deep Models for Land-Use Classification with High-Resolution Remote Sensing Images/利用高分辨率遥感影像学习可转移的土地利用分类深度模型 近年来，大量的高空间分辨率遥感（HRRS）图像可用于土地利用制图。然而，由于增加的空间分辨率和由不同的图像采集条件引起的数据干扰带来的复杂信息，通常很难找到一种有效的方法来实现具有异构和高分辨率遥感图像的准确的土地利用分类。本文提出了一种方案，用HRRS图像学习土地利用分类的可转移深度模型。主要思想是依靠深度神经网络来呈现不同类型土地利用中包含的语义信息，并提出伪标记和样本选择方案，以提高深层模型的可转移性。深度学习在土地利用分类的应用，前一段时间RSE也刊登了黄波老师这方面的研究。 3.Adaptive Deep Sparse Semantic Modeling Framework for High Spatial Resolution Image Scene Classification/高空间分辨率图像场景分类的自适应深度稀疏语义建模框架 发表于IEEE TGRS，遥感界Top期刊。是关于语义建模的文章。高空间分辨率（HSR）图像场景分类涉及根据地理属性用特定语义类别标记HSR图像，已经受到越来越多的关注，并且已经为此任务提出了许多算法。使用概率主题模型来获取潜在主题和使用卷积神经网络（CNN）来捕获用于表示HSR图像的深度特征已经是桥接语义差距的有效方式。但是，中级主题功能通常是本地的和重要的，而高级深度功能则传达更多的全局和详细信息。为了发现HSR图像的更多判别语义，提出了一种结合稀疏主题和深度特征的自适应深度稀疏语义建模（ADSSM）框架，用于HSR图像场景分类。在ADSSM中，集成了完全稀疏的主题模型和CNN。为了利用HSR场景的多级语义，稀疏主题特征和深层特征在语义层面上被有效地融合。基于稀疏主题特征和深度特征之间的差异，提出了一种自适应特征归一化策略来改善不同特征的融合。用四个HSR图像分类数据集获得的实验结果证实，与其他现有技术方法相比，所提出的方法显着改善了性能。 4.Measuring night sky brightness: Methods and challenges/测量夜空亮度：方法和挑战 近年来，测量夜空的亮度已成为一个越来越重要的话题，因为人造光及其在地球大气层中的散射继续在全球蔓延。已经为此任务开发了若干仪器和技术。本文概述了这些，并讨论了它们的优点和局限性。讨论了在测量夜空亮度时可以和应该得出的不同数量，以及在这种情况下已经并且仍然需要定义的程序。尽管如此，仅有天顶的单波段单通道设备，如“Sky Quality Meter”，仍然是长期研究夜空亮度和从移动平台进行研究的可行选择。准确解释这些数据需要对天光的颜色组成有一些了解。我们建议通过校准的摄像系统和校准的照度计或亮度计，对这些设备的长期时间序列进行补充，并定期进行全天空采样。与光污染相关的文章。 5.The Limits of the Neighborhood Effect: Contextual Uncertainties in Geographic, Environmental Health, and Social Science Research/邻域效应的限制：地理，环境健康和社会科学研究中的背景不确定性 本文借鉴了最近的研究，认为研究人员需要关注常规理解的邻域效应的极限。它强调了背景影响的复杂性以及准确表示和测量个体暴露于这些影响的挑战。具体而言，它讨论了语境效应的特质和多维性质，语境影响的时间复杂性，曝光度量的框架依赖性，选择性流动性偏差以及邻域效应研究中的发表偏倚。它还讨论了在未来的研究中如何减轻背景不确定性（例如，通过收集和使用高分辨率的时空数据，并转向不依赖于帧的暴露测量，其结果不受数据在空间方面的组织方式的影响，时间）。邻域是空间统计绕不开的关键点，也是造成各类空间统计结果不确定性的一个重要原因之一。 6.Estimation of land surface heat fluxes based on visible infrared imaging radiometer suite data: Case study in northern China/基于可见红外成像辐射计套件数据的地表热通量估算：中国北方的案例研究 蒸发蒸腾（ET）在地表 - 大气相互作用中起着重要作用，可以使用遥感数据进行监测。可见红外成像辐射计套件（VIIRS）传感器是一代光学卫星传感器，提供375至750米空间分辨率的日全球覆盖，22个光谱通道，能够监测从区域到全球的ET。然而，很少有研究关注从VIIRS图像获取ET的方法。本研究的目的是引入一种算法，该算法利用VIIRS数据和气象变量来估算陆地表面的能量预算，包括净辐射，土壤热通量，显热通量和潜热通量。基于表面能量平衡方程的单源模型用于获取中国张掖绿洲内的地表热通量。使用在HiWATER（黑河流域联合遥测实验研究）项目期间收集的观测结果验证了结果。为了便于比较，还使用中等分辨率成像光谱仪（MODIS）数据来检索区域表面热通量。误差分析表明，在本文的模型中，估计的显热通量的准确度依赖于检索到的表面温度和冠层高度的误差。生态水文过程与遥感的耦合一直是最近的一个研究热点。 7.人口城市化对空气污染人群暴露贡献的定量方法研究 生态中心周伟奇老师组韩立建老师的成果，短期快速城市化引发一系列生态环境问题，尤其是近年来以细颗粒物（PM2.5）为代表的城市与区域空气污染问题。人群的污染暴露一方面是因为污染区范围的扩张，另外一方面则归因于城市化引发的人口迁移，目前的研究重点关注于前者的贡献，而忽略了后者的贡献。因此，本研究建立了城市化对空气污染人群暴露贡献的定量方法，并选取我国PM2.5污染最为严重的京津冀城市群开展了实证研究，通过利用2000、2005、2010、2015年PM2.5浓度和人口栅格数据以及人口自然增长率数据，定量评估了城市化引发的人口迁移对空气污染人群暴露的贡献。本研究建立了定量化的方法揭示了城市化在空气污染人群暴露中的定量贡献，为科学引导城市化发展提供了定量的手段，为合理规划京津冀城市群地区的人口流动与空气污染奠定了数据基础。]]></content>
      <categories>
        <category>Personal</category>
      </categories>
      <tags>
        <tag>Consideration of Ecology and Geography</tag>
        <tag>Summary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Coding and Paper Letter（八）]]></title>
    <url>%2F2018%2F07%2F18%2FCoding-and-Paper-Letter%EF%BC%88%E5%85%AB%EF%BC%89%2F</url>
    <content type="text"><![CDATA[资源整理 1 Coding：1.Python项目，由Allen Downey撰写的Think Python第二版的LaTeX源代码和支持代码。 ThinkPython2 2.R语言包h3jsr，h3jsr使用V8的神奇力量通过其javascript绑定提供对Uber H3库的访问。 h3jsr 3.Python项目roi pooling,深度学习项目，这个项目包含自定义TensorFlow操作的感兴趣区域池化的实现。 负责计算的CUDA代码主要取自Ross Girshick最初的Caffe实现。 roi pooling 4.开源项目Weak Supervised Segmentation List，该项目包含一些弱监督语义分割工作的列表。根据监督学习类型，下面列出了论文和资源。 Weak Supervised Segmentation List 5.Python项目General Framework fo SR Tasks。图像超分辨率率重建任务的通用开源框架 General Framework for SR Tasks 6.Python开源项目3D Deepbox，论文3D Bounding Box Estimation Using Deep Learning and Geometry by Fu-Hsiang Chan的Tensorflow实现。目的是从单个二维图像预测边界框的大小和3D空间中对象的方向。 3D Deepbox 7.Python项目开源框架pyroSAR，用于大规模SAR卫星数据处理的Python框架。 pyroSAR 8.开源项目DeepGlobe Road Extraction Challenge，DeepGlobe道路提取挑战赛第一名解决方案代码。 DeepGlobe Road Extraction Challenge 9.Python库pygdal，Virtualenv和setuptools友好版本的标准GDAL python桥接项目。如果您在virtualenv中安装GDAL时遇到问题，那么此软件包适合您。 您可以使用此软件包将GDAL安装到virtualenv中，但仍需要在系统上安装GDAL库及其头文件。 在Ubuntu上可以这样做： pygdal 10.开源项目Slides SciPyConf 2018,第17届Python科学会议（2018年）上公开ppt。 Slides SciPyConf 2018 11.R语言包redux，R语言的Redis客户端。 redux 12.开源项目road orientation map，当前地图视图的道路方向的可视化。 浏览地图以查看您所在城市的图表。将360°划分为64个区间并累积具有相应方向的路段长度，然后将分布绘制为极坐标图。 两个方向都计算双向道路。 road orientation map 13.开源项目SparseNet，稀疏聚合卷积网络的开源代码。另外一个是关于使用稀疏聚合卷积网络做图像分类的开源代码。 SparseNet SparseNet A Sparse DenseNet for Image Classification 14.开源项目Object Detection Metrics，用于评估对象检测算法的最常用指标。 Object Detectin Metrics 15.R语言项目SoilGrids250m，全球土壤属性和类别的空间预测，分辨率为250米。 SoilGrids250m 16.R语言项目Spatial data visualization with R，一本R语言可视化秘籍，用R做空间可视化的代码。 Spatial data visualization with R 17.Python项目urban data science，基于Python的城市数据科学课程的课程材料，Jupyter笔记本，教程，指南和演示。 urban data science 18.R语言包rpostgis，支持R和PostGIS的PostgreSQL数据库的接口。 rpostgis 19.R语言包getlandsat，从AWS公共数据集中获取Landsat 8数据的包。 getlandsat 20.R语言包MVST，用于多变量时空建模的R包。 MVST 2 Paper：1.Potential of Particle Matter Dry Deposition on Green Roofs and Living Walls Vegetation for Mitigating Urban Atmospheric Pollution in Semiarid Climates/半干旱气候下绿色屋顶和生活墙植被减缓城市大气污染的颗粒物干沉降的潜力 在过去二十年中，绿色屋顶和生活墙植被在建筑物中的应用增加，因为它们建筑节能，促进生物多样性，控制水径流，减轻城市热岛效应，改善室内和城市空气质量，并将人与自然联系起来。然而，很少有研究量化绿色屋顶（GR）和生活墙植被（LW）对减轻空气污染的影响，特别是在空气颗粒物（PM）水平较高的半干旱气候中。因此，本文的目的是通过半干旱气候下GR和LW中常用的几种植被物种来量化PM 10和PM 2.5的干沉降。使用方法是传统的滞尘采样研究，并得出了几种类型较为有效。这种绿色基础设施有助于减轻空气污染。可以说GI也是近年来很火的一个研究方向，因为GI上承热岛效应，下接海绵城市。 2.A multiscale dataset for understanding complex eco-hydrological processes in a heterogeneous oasis system/用于理解绿洲异质系统中复杂生态水文过程的多尺度数据集 该文章发表于Nature子刊Scientific Data，是当下流行的数据文章和数据期刊。主要介绍了中国科学院寒旱所/西北生态环境资源研究院李新老师团队牵头的黑河流域项目的数据。推荐指数五颗星。该文章的数据为2012年在绿洲 - 沙漠地区从黑河流域联合遥测实验研究（HiWATER）获得的多尺度数据集。在异质地表面上提升生态水文过程是一项巨大的挑战。多尺度观测的可用性很差，阻碍了这一领域的进展。 HiWATER是一项旨在通过分层嵌套比例仪器来解决这一挑战的实验，以获得多尺度和多学科数据。 HiWATER观测系统由涡动协方差磁通，大孔径闪烁计和自动气象站的通量观测矩阵组成;土壤水分和叶面积指数的生态水文传感网络;利用激光雷达，成像光谱仪，多角度热像仪和L波段微波辐射计进行超分辨率机载遥感;和植被动态和光合作用过程的同步地面测量。在传感器校准，数据收集，数据处理和数据集生成过程中，所有观测数据都经过精心控制。这些数据可在figshare和寒冷干旱地区科学数据中心免费获取。这些数据对于阐明多尺度生态水文过程和开发升级方法非常有用。 3.Gender, the Home‐Work Link, and Space‐Time Patterns of Nonemployment Activities/性别，家庭工作联系和非就业活动的时空模式 美国伊利诺大学厄巴纳-香槟分校著名时间地理学家关美宝老师的大作，在重新定义家庭作业链接的理论工作的基础上，该论文将户外非就业活动确定为家庭与工作之间动态依赖关系的另一个重要组成部分。利用俄亥俄州哥伦布市的旅行日记数据和基于GIS的三维可视化技术，比较了三个人口群体的这些活动的时空模式。使用了非递归结构方程模型研究。结果显示，无论其就业状况如何，女性的日间固定性限制都高于男性。当家庭中有其他成年人分担一些家庭责任时，这种限制就会减少。面临更高固定性约束的女性更有可能兼职工作。一个重要的含义是，纠正家庭内部的分工和性别关系不仅会减少妇女的固定性限制，还会改善她们的劳动力市场地位（特别是对于目前从事兼职工作的妇女）。一个意想不到的结果是，即使遇到更高水平的固定性限制，全职女性也会比男性更长距离上班。这表明，与过去的研究通常所假设的相反，工作之旅可能无法反映女性在日常生活中面临的固定性约束的程度。 4.Light pollution is greatest within migration passage areas for nocturnally-migrating birds around the world/世界各地夜间迁徙鸟类的迁徙通道区域内的光污染最严重 夜间过多或误导的人造光（ALAN）产生的光污染会影响鸟类生物学和生态学的几个方面，包括昼夜节律的破坏和飞行过程中的迷失方向。当ALAN照亮天空时，许多迁徙鸟类每年两次穿越大片土地。考虑到全世界光污染的广泛和日益增加的侵蚀，我们评估了298只夜间迁徙鸟类的地理范围内的年平均ALAN强度与5个因素的关联：年周期阶段，育种与非之间的平均距离 - 养殖范围，范围大小，全球半球范围和IUCN保护类别。在迁移季节，对于短距离移民，对于范围较小的物种和在西半球的物种，地理范围内的光污染相对较大。我们的研究结果表明，候鸟可能受到光污染的影响，特别是在迁徙过程中，这是其年度周期中最关键的阶段。我们希望这些结果能够进一步研究光污染如何影响迁徙鸟类，以及其他高度流动的动物在整个年度周期中的影响。一个非常有意思的光污染的研究。拓展了夜间灯光数据的应用研究。]]></content>
      <categories>
        <category>Personal</category>
      </categories>
      <tags>
        <tag>Consideration of Ecology and Geography</tag>
        <tag>Summary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Coding and Paper Letter（七）]]></title>
    <url>%2F2018%2F07%2F16%2FCoding-and-Paper-Letter%EF%BC%88%E4%B8%83%EF%BC%89%2F</url>
    <content type="text"><![CDATA[资源整理 1 Coding：1.R语言包smapr，用于获取和处理NASA SMAP数据的R包。NSIDC提供多个SMAP数据产品，这些产品的处理量各不相同。 目前，smapr主要支持3级和4级数据产品，分别代表全球每日复合和全球三小时模型数据产品。 包括了多个分辨率的土壤湿度和NEE产品。 smapr 2.开源项目Big Data，该项目涉及如何使用Apache Spark执行时空热点分析。 Big Data 3.开源项目Geospat，基于时空数据的时间多样性在推断社会关系中的作用。 Geospat 4.开源项目stark，基于Spark的时空数据分析开源框架。 stark 5.开源项目DeepST，时空数据的深度学习开源工具箱。 DeepST 6.Python库cartopy，一个支持matplotlib的地图制图python库。 cartopy 7.R语言包rLandsat，可以获取Landsat8数据的R包。 rLandsat 8.R语言包spm，空间预测模型。 spm 9.开源项目BIMsurfer，第一个基于WebGL的开源IFC浏览器。 10.R语言包paleteer，R语言的调色板集合。 paleteer 11.R语言包RCSF，基于布料仿真进行机载LiDAR滤波的CSF算法集成包。 RCSF 12.igraph和图遍历的R Workshop资料。 traversing graphs in R 13.开源项目PyTorch从入门到精通。深度学习框架PyTorch的教程。 PyTorch From Zero to One 14.R语言包shinymaterial，shiny网页组件优化，仪表盘等。 shinymaterial 15.R语言项目Soil Carbon Debt，WHRC-TNC项目的R代码和农业土壤碳损失的空间预测模拟 Soil Carbon Debt 16.开源数据US SoilGrids 100m。100米空间分辨率下美国土壤性质和类型图,美国土壤性质（有机碳百分比，总氮，堆积密度，pH值，沙子和粘土百分比）和类别（分类大组和粒度）的完全覆盖网格预测。 US SoilGrids 100m 17.R语言包dtwSat，用于卫星图像时间序列分析的时间加权动态时间校准方法的R包。 dtwSat 18.开源数据geojson map China，中国的geojson数据。 geojson map China 19.R语言包rticles，用R Markdown写论文的神器，各个出版社论文的Latex模板。 rticles 20.R语言包arm，使用回归和多层/分层线性模型的数据分析包。 arm 2 Paper：1.A simplified model of all-sky artificial sky glow derived from VIIRS Day/Night band data/一种从VIIRS日/夜波段数据得到的全天空人造天空发光的简化模型 文章提出了一种简化的模型使用地理分析工具来预测夜空半球的平均人工亮度，将其表示为与自然条件的比率。使用Suomi NPP卫星的VIIRS日/夜波段向上辐射数据用于输入模型。该方法基于天空发光亮度与从观察者到向上辐射源的距离之间的关系。这种关系是使用Garstang辐射传输模型开发的，其中日/夜波段数据作为输入，然后使用在无云和低气压气溶胶条件下拍摄的地基全天空V波段光度数据进行精细和校准。非常有意思的研究，就笔者目前的感受，夜间灯光数据很少结合定量遥感的辐射方程定量求解，通常都是利用统计模型得到类似碳排放、电力消耗，住房空置率等，这样子的研究可以说是夜间灯光里较为新颖的方向。 2.A Multilevel Analysis of Perceived Noise Pollution, Geographic Contexts and Mental Health in Beijing/北京市噪声污染感知，地理环境与心理健康的多层次分析 关美宝老师关于噪声污染的新作。随着城市化的快速发展和汽车保有量的增加，多样化资源（如道路交通，铁路，商业服务）造成的环境噪声污染已成为中国人口稠密地区的严重环境问题。然而，在中国这样的发展中国家，对噪声污染的空间变化及其对城市居民心理健康的潜在影响的研究迄今为止还很少。通过2017年在北京进行的健康调查，我们首次调查了北京居民感知的多重噪声污染的空间分布，包括道路交通噪声，铁路（或地铁）噪声，商业噪声和房屋翻新（或建筑） ）噪音。我们的研究结果表明，邻近地区的噪声污染存在地理差异，道路交通和房屋改造/建设是北京噪声污染的主要来源。然后，我们采用贝叶斯多层次逻辑模型来检验多元化噪声污染与城市居民心理健康症状之间的关联，包括焦虑，压力，疲劳，头痛和睡眠障碍，同时控制各种混杂因素，如社会人口统计学，客观建构的环境特征，社会环境和地理环境。结果表明，感知到的较高噪声污染暴露与较差的心理健康显着相关，而物理环境变量似乎对自我报告的精神障碍的变化几乎没有贡献，除了靠近主要道路。社会因素或社会人口属性，如年龄和收入，是城市居民心理健康的重要协变量，而社会环境（即社区依恋）和住房满意度与焦虑和压力显着相关。本研究为中国背景下的噪声与健康关系提供了实证证据，并揭示了中国环境污染减缓和健康城市发展的政策含义。噪声与健康城市是一个非常新的方向，声景观，以及噪声污染也是未来值得关注的一个研究。 3.Reconstruction of MODIS Land Surface Temperature Products Based on Multi-Temporal Information/基于多时相信息的MODIS地表温度产品重建 本文基于地表变量的时空自相关，开发了一种重建算法，该算法取决于来自可用MODIS LST数据的多个时间相位中的空间像素之间的相关性，以重建缺失像素的晴空LST值。考虑到预测器和重建数据之间的相关性和偏差对建模误差的影响，将重建时间相位中的已知数据与时间上最接近它们的数据组合作为预测变量，以建立它们与重建数据的时间关系。通过一系列评估指标验证重建结果。重建结果与地基观测值之间的平均相关系数为0.87，显示出高时间变化精度。代表已知数据和重建数据之间空间结构特征的Moran’s I的差异平均为0.03，表明空间精度略有下降。平均重建率约为87.0％。作为重建误差的一部分，建模误差平均仅为1.40 K，占总误差的5.0％。遥感数据的重建，质量控制与优化是空间精度的一个重要研究内容。该文章的思路值得研究。 4.Delineating the perceived functional regions of London from commuting flows/通过交通流量描绘伦敦的感知功能区域 由不同类型城市流量定义连接良好的城市功能区域定义了反映地点在其功能方面的相关性的边界。然而，基于汇总数据来定义城市及其社区的尝试通常忽略了不同人群之间的固有差异。基于分解的流量数据，该研究使用多级模块化优化算法检测不同职业感知的伦敦都市区的社区结构。基于交通流探测城市功能区的研究，值得学习。此外得到的结论对于规划的启示同样重要。 5.Intensive land-use drives regional-scale homogenization of plant communities/密集的土地利用推动了植物群落的区域规模同质化 密集的人为土地利用导致栖息地丧失和景观同质化，导致生物多样性和生态系统退化的减少。因此，研究景观异质性对生物多样性的影响非常重要。在这项研究中，在位于中国内蒙古农牧交错带的塔布河流域53个地点进行的植被调查揭示了146种。物种多样性在三个尺度上进行评估：斑块内的物种丰富度（α多样性），斑块之间（β多样性）和景观尺度（γ多样性）。我们分析了景观异质性（LHtotal）及其驱动因素，包括环境变量（LHDFenv-var，如降水和海拔高度），环境异质性（LHDFenv-het）和人类活动（LHDFhum）。我们使用结构方程模型（SEM）来评估物种丰富度对三个尺度的景观异质性的响应，并确定驱动因子在解释这些尺度的物种多样性方面的相对贡献。研究结果总结如下，人类活动超过了阳性效应的阈值。根据我们的研究结果，我们建议沿着河流限制农业用途，以防止物种多样性的减少。人类活动、人类干扰对于生态系统中生物多样性的影响研究范例，结合多种方法，思路值得借鉴。 6.Integrating Extended Fourier Amplitude Sensitivity Test and Set Pair Analysis for Sustainable Development Evaluation from the View of Uncertainty Analysis/从不确定性分析的角度整合扩展傅立叶振幅灵敏度测试和集对分析的可持续发展评价 客观和定量地评估可持续发展水平具有重要意义但是很困难，特别是在权重确定过程和不确定性评估中。传统的权重确定方法几乎不能反映指数之间的耦合效应（相互作用）。更重要的是，传统的评估方法很少考虑指标体系中指数的不确定性。因此，应用更全面的方法来解决这些缺陷是必不可少的。本文提出了一种评估可持续发展水平的新方法。该方法集成了扩展傅里叶幅度灵敏度测试（EFAST）和集对分析（SPA）（称为EFAST-SPA）的优点。 EFAST算法用于确定指标的权重，SPA用于处理评估系统中的不确定关系并计算可持续发展水平。利用EFAST-SPA方法对黑河中游农业可持续发展进行了定量评价。将结果与传统的熵方法进行了比较，得出EFAST-SPA和熵与实际发展状况高度吻合。在大多数情况下，EFAST-SPA方法可以更准确地描述开发级别，这反映了该方法的更高可靠性和应用价值。此外，所提出的方法从评估系统内部的不确定性分析的角度加深了对可持续发展评估的理解。从不确定性分析的角度提出了对可持续评估的新方法。 7.Do Different Datasets Tell The Same Story About Urban Mobility - A Comparative Study of Public Transit and Taxi Usage/不同的数据集讲述城市流动的故事是否相同？ - 公共交通与出租车使用的比较研究 了解人类活动及其与建成环境的相互作用长期以来一直是交通地理学的研究兴趣。近年来，两种重要类型的城市交通数据集 - 智能卡交易和出租车GPS轨迹 - 已被广泛使用，但通常分别用于量化旅行模式以及城市空间结构。尽管研究成果丰硕，但同一地理区域内不同类型的交通流之间的关系仍然知之甚少。在这项研究中，我们提出了一个分析框架来比较从这两个数据源中提取的城市流动模式。本研究以新加坡为案例研究，引入三重比较分析，以了解：（1）公共交通和出租车使用的空间分布及其相对平衡; （2）行进距离的距离衰减，以及（3）从两种运输模式中提取的空间交互作用社区。研究结果表明，从两种运输方式中提取的旅行需求的空间分布呈现出高度的相关性。然而，更深入的分析（基于等级大小分布和对数比值比）揭示了公共交通使用中更高程度的空间异质性。公共交通出行的旅行距离比出租车出行的旅行距离更快，突出了出租车在促进长途旅行方面的重要性。当行程距离超过20km时，两种类型的行程都会更快地衰减，这对应于从城市周边到中心的平均距离。来自公共交通的空间互动社区在工作日和周末是不同的，而出租车的空间互动社区显示出类似的模式。这两种交通方式都产生了揭示城市多中心结构的社区，但它们的差异表明每种交通方式在连接城市中的某些地方时起着特定的作用。该研究表明了比较数据分析对城市和交通研究的重要性。两种新兴城市大数据的分析比较，再次证明了城市计算和城市大数据不能仅仅依靠单一数据，而是需要多源数据的融合才能得到准确的结论。]]></content>
      <categories>
        <category>Personal</category>
      </categories>
      <tags>
        <tag>Consideration of Ecology and Geography</tag>
        <tag>Summary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Coding and Paper Letter（六）]]></title>
    <url>%2F2018%2F07%2F13%2FCoding-and-Paper-Letter%EF%BC%88%E5%85%AD%EF%BC%89%2F</url>
    <content type="text"><![CDATA[资源整理 1 Coding：1.Python工程，使用networkx，geopandas，mplleaflet在地图上可视化网络流。 map-network 2.R语言包rsample, 用于创建和汇总不同类型的重采样对象的类和函数。 rsample 3.R语言包lomm，lomm软件包为透明且可重现的工作流程，获取和处理空间（地球观测）数据提供了完整的工具链。 它为景观生态问题提供了一种基于证据的方法。 lomm 4.R语言包deckard，它为Uber刚刚开源的deck.gl数据可视化框架提供了一个接口。它允许用户： 从R交互式渲染数百万个点。 在浏览器中可视化数据，无需专门的软件即可提供富有表现力的可视化。 使用矢量tilesets而不是raster tilesets。 创建非地理空间数据的自定义可视化。 deckard 5.R语言包googleway,提供访问各种Google Maps API的机制，包括从R绘制Google Map并使用形状和标记覆盖它，以及从地点，方向，道路，距离，地理编码，高程和时区API检索数据。 googleway 6.将深度神经网络中的一些模型 进行统一的图示，便于大家对模型的理解。 AlphaTree graphic deep neural network 7.精选的ETL（提取，转换，加载）框架，库和软件的精选列表。ETL是大数据的关键一步。 awesome-etl 8.Chawanda等人，2018年EMS中提出的用于建立SWAT模型的自动化工作流程。 2018 Chawanda etal EMS 9.Python项目Urbansprawl。urbansprawl项目提供了一个开源框架，用于使用开放数据计算空间城市蔓延指数，评估城市蔓延。 它使用OpenStreetMap（OSM）数据来计算其蔓延指数。并使用开放数据进行分解人口估计（降尺度） urbansprawl 10.微软开源项目DMTK。分布式机器学习工具包。 DMTK框架（Multiverso）：用于分布式机器学习的参数服务器框架。 LightLDA：用于大规模主题建模的可扩展，快速和轻量级系统。 LightGBM：LightGBM是一种基于决策树算法的快速，分布式，高性能梯度增强（GBDT，GBRT，GBM或MART）框架，用于排名，分类和许多其他机器学习任务。 分布式字嵌入：在multiverso上实现的字嵌入分布式算法。 DMTK 11.Python书籍。又名“黑客贝叶斯方法”：介绍贝叶斯方法+概率编程与计算/理解 - 第一，数学 - 第二观点。 全部都是纯Python）。 Probabilistic-Programming-and-Bayesian-Methods-for-Hackers 12.R语言包stplanr, stplanr 13.Python库pygwr，Python中的地理加权回归（GWR）。 pygwr 14.R-Shiny工程GWR。 GWR 15.R语言包lidR，用于林业应用的机载激光雷达数据处理和可视化的R包。 lidR 16.R语言包gwrr，适合使用诊断工具的地理加权回归模型。 gwrr 17.R语言包spnetwork,地理空间网络分析包，使用SpatialLines作为网络的edge。 spnetwork 18.UrbanSim的新版本，一个为大都市房地产市场建模的平台 urbansim 19.Python库folium，Python的Leaflet可视化库。 folium 20.Python库spandex，Spandex是一个对pandas的数据框和空间数据进行操作的函数库。UrbanSim的数据处理和归集步骤。 spandex 2 Paper:1.Patterns of local segregation: Do they matter for neighborhood crime?/地方隔离的模式：它们对邻里犯罪有影响吗？ 本文通过概念化，测量和描述种族 - 种族和经济状况的地方隔离，并检查这些条件与邻里暴力水平的联系，扩展了最近关于城市犯罪的隔离空间测量,财产犯罪和空间动态的研究。 该分析基于86个美国大城市样本中的所有8895个人口普查区域。 使用了包含地方隔离措施的多层次犯罪模型。 结果显示，除了城市层面和邻里特征外，白黑区域隔离与较低的暴力和财产犯罪有关。 相比之下，高收入家庭的低收入地方隔离与较高的犯罪，特别是邻里暴力有关。犯罪地理学近年来更为关注的都是邻里模式的小尺度犯罪研究。值得学习。 2.China’s response to a national land-system sustainability emergency/中国对国家土地系统可持续发展突发事件的响应 由景观生态领域大牛邬建国老师参与的一个研究。具体的中文介绍见此。可以说可持续科学当下是一个研究热点，同时这个学科又需要跨学科合作。 3.Urbanization-induced population migration has reduced ambient PM2.5 concentrations in China/中国城市化引起的人口迁移降低了人们对PM2.5暴露的浓度 去年11月在广州参加景观生态研讨会的时候，生态中心的韩立建老师也有类似的研究。非常有意思的主题。 4.Estimation of ultrahigh resolution PM 2.5 concentrations in urban areas using 160 m Gaofen-1 AOD retrievals/使用160 m Gaofen-1 AOD反演估算城市地区的超高分辨率PM 2.5浓度 发表于遥感领域Top期刊Remote Sensing of Environment的一篇关于PM2.5反演的文章。这项研究中，主要使用新的AOD数据估算每日PM 2.5浓度，其中通过Gaofen-1（GF）宽视场（WFV）反演的160 m空间分辨率以及嵌套线性混合效应模型和来自的辅助变量来自天气研究和预报（WRF）气象模拟数据。该实验在武汉，北京和上海进行，近年来遭受严重的大气细颗粒污染。所提出的模型对于GF和中分辨率成像光谱仪（MODIS）都表现良好，具有轻微的过拟合和很小的空间自相关。]]></content>
      <categories>
        <category>Personal</category>
      </categories>
      <tags>
        <tag>Consideration of Ecology and Geography</tag>
        <tag>Summary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Coding and Paper Letter（五）]]></title>
    <url>%2F2018%2F07%2F11%2FCoding-and-Paper-Letter%EF%BC%88%E4%BA%94%EF%BC%89%2F</url>
    <content type="text"><![CDATA[资源整理 1 Coding：1.Python模块libpysal，pysal的核心组件。与pysal的区别目前没有明确。有空研究一下。功能都是Python空间分析的模块。 libpysal 2.R语言包mongrel，多项逻辑斯蒂-正态线性回归模型。 mongrel 3.R语言工程SLATRRA——Satellite Latency Assessment Tools for Real-time River Applications，用于实时河流应用的卫星延迟评估工具。包含Allen等人的数据分析和数字和表格的制作，“河流波浪传播时间的全球估计和低延迟卫星数据的影响”。代码的最基本部分包括： 计算河流坡度； 将兴趣点（POI：城市，水坝和仪表）连接到河网； 模拟流量波动和计算行程时间； 使用基于仪表的快速估算来验证模型； 生成图表，并计算论文中提供的各种统计数据。 SLATRRA 4.R语言工程RSSA——统计分析用于估算GRWL数据库中的全球河流和河流表面积。 RSSA 5.R语言包nassR。通过R下快速统计载各种USDA数据的方法。 nassR 6.书籍《社会空间数据科学书》。 SSDSBook 7.R语言包getSpatialData。通过R可以轻松查询，预览，下载和预处理多种空间数据（包括MODIS, Landsat等卫星）。 getSpatialData 8.R语言包blockCV,包创建空间或环境分离的训练和测试K折数据用以进行交叉验证，以在空间结构化环境中提供稳健的误差估计。 blockCV 9.R-Shiny工程hikeR,用于轻松规划下一次徒步旅行或骑自行车旅行。 hikeR 10.R-Shiny示例工程。使用Electron封装Shiny WebApp作为独立应用程序的演示和教学材料。 useR_electron_meet_shiny 11.Python工程senti_analysis，利用Python实现酒店评论的中文情感分析。 senti_analysis 12.Python软件包PyMC3，Python中的概率编程：使用Theano进行贝叶斯建模和概率机器学习。PyMC3是一个用于贝叶斯统计建模和概率机器学习的Python软件包，侧重于高级马尔可夫链蒙特卡罗（MCMC）和变分推理（VI）算法。 其灵活性和可扩展性使其适用于大量问题。 pymc3 13.深度学习库tensorflow的可视化工具tensorboard。 tensorboard 14.R语言包geodist，超轻量级，超快速计算地理距离。 geodist 15.深度学习和机器学习研究人员使用的参照表 cheatsheets-ai 16.数据科学家的空间可视化养成手册。 spatial dataviz for data scientists 2 Paper：1.Role of Groundwater in the Dryland Ecohydrological System: A Case Study of the Heihe River Basin/地下水在旱地生态水文系统中的作用 - 以黑河流域为例 地下水维持旱地的粮食生产和生态系统健康。地下水影响相互关联的水文过程和生态状态，然而，生态水文系统中地下水的功能尚未明确量化。在这项研究中，我们使用具有多个独立数据库的区域尺度综合模型评估地下水在黑河流域生态水文系统中的作用。事实上很多生态系统服务测算的时候在地下水这块考虑明显不足（以InVEST模型来说基本忽略地下水部分）。 2.Changes in outdoor lighting in Germany from 2012-2016/2012 - 2016年德国户外照明的变化 使用可见红外成像辐射计套件的白天和夜晚波段调查了2012 - 2016年德国联邦州总光照区域和稳定照明区域的光度变化。 大多数州的照明区域和光泽都增加了。本文还讨论了遥感夜间数据在可持续照明环境中的作用。事实上目前光污染的问题也是一个城市研究较少的问题，去年esri杯开发竞赛地理分析组一等奖也是以灯光污染为题，我想这是一个很有前景的方向。 3.基于随机森林和时空核密度方法的不同周期犯罪热点预测对比 推荐柳林老师团队的一篇犯罪地理的论文，用目前新兴的机器学习算法随机森林与时空统计算法时空核密度对犯罪热点进行预测比较。结果发现：在各时间周期上,随机森林分类热点预测方法的面积和案件量命中率均比时空核密度方法准确性高;并且2种方法均能有效地识别犯罪热点中的高发区域,其中在较小范围较短时间内随机森林识别热点中的高发区效率更高,而在较大范围较长时间周期上时空核密度方法识别高发区更优。]]></content>
      <categories>
        <category>Personal</category>
      </categories>
      <tags>
        <tag>Consideration of Ecology and Geography</tag>
        <tag>Summary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Coding and Paper Letter（四）]]></title>
    <url>%2F2018%2F07%2F10%2FCoding-and-Paper-Letter%EF%BC%88%E5%9B%9B%EF%BC%89%2F</url>
    <content type="text"><![CDATA[资源整理 1 Coding：1.与Ecological Forecast这本书以及研究生相关的实践活动。 EF_Activities 2.h2o的R示例，h2o是一个机器学习的平台。 h2o-r-examples 3.R语言包rnassqs，是NOAA快速API的R接口。 rnassqs 4.Python模块spatiallist，用于空间数据处理的模块，从pyroSAR项目中提取。Ubuntu系统上，基于GDAL以及sqlite和spatialite。 spatialist 5.R语言包rayshader,用来将DEM生成各式各样的山体阴影数据。 rayshader 6.Scipy2018年关于地理空间数据的Workshop资料。 scipy2018-geospatial-data 7.R语言包HydroData，可以获取大量开放的地球系统观测数据、矢量数据、栅格数据。 HydroData 8.R语言包fredr，美国联邦银行经济数据的Restful API接口简单封装的包。 fredr 9.R语言包ncdump,简化我们在R中处理NetCDF的方式的一个包。 ncdump 10.《用R做地理计算》书籍。基于gitbook的书籍。讲述了如何用R做地理计算。包括源码以及书籍的在线阅读。 geocompr 11.R语言包leaflet，开源地图库leaflet的R语言接口。用于R语言中地图数据的交互可视化。 leaflet 12.R语言包FRK,针对大数据的固定秩克里金插值算法。FRK算法的论文发表于统计学顶刊Journal of Statisticial Software。以后有空来学习和介绍。 FRK 13.pandoc，通用的文档转换开源方案。 pandoc 14.R语言包ggthemr,可以设定固定的几种ggplot2的绘图风格。 ggthemr 15.R语言包alluvial，用于绘制如下的类似于平行坐标图的图。 alluvial 16.R语言包ggResponse，用于绘制不同模型的响应曲线。 ggResponse 2 Paper:1.HIV Clustering in Mississippi: Spatial Epidemiological Study to Inform Implementation Science in the Deep South/密西西比州的艾滋病毒聚类：空间流行病学研究，以便在南方深入了解实施科学 近年来，美国一半以上的新艾滋病病毒感染发生在美国东南部的非洲裔美国人中。空间流行病学分析可以通过识别与聚类相关的HIV热点和社区层面因素，为深南地区的公共卫生应对提供信息。这项研究的目的是通过分析州级HIV监测数据来识别和描述密西西比州的HIV群集。我们结合使用空间流行病学和统计模型来识别和描述2008年至2014年密西西比州人口普查区（n = 658）的艾滋病病毒热点。 2.What Is It Like Down There? Generating Dense Ground-Level Views and Image Features From Overhead Imagery Using Conditional Generative Adversarial Networks/它在那里是什么样的？利用条件生成对抗网络从正射图像生成密集的地平面视图和图像特征 本文研究条件生成对抗网络（cGAN），以克服使用地理标记媒体进行地理发现的基本限制，即其稀疏和不均匀的空间分布。我们训练cGAN以生成给定顶部图像的位置的地平面视图。我们展示的“假”地平面图像看起来很自然，并且在结构上与真实图像相似。更重要的是，我们显示生成的图像代表了位置，并且cGAN学习的表示是提供信息的。我想条件生成对抗网络是深度学习和机器学习一个很重要的研究方向，这篇文章很好的结合了地理信息做了研究。值得学习。]]></content>
      <categories>
        <category>Personal</category>
      </categories>
      <tags>
        <tag>Consideration of Ecology and Geography</tag>
        <tag>Summary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Coding and Paper Letter（三）]]></title>
    <url>%2F2018%2F07%2F09%2FCoding%20and%20Paper%20Letter%EF%BC%883%EF%BC%89%2F</url>
    <content type="text"><![CDATA[资源整理 1 Coding：1.变化检测专题。 Change-Detection-in-Remote-Sensing-Images遥感影像变化检测的Python代码。 change-detection-tutorial时间序列数据的变化检测。 SAR-change-detectionSAR影像的变化监测。 demeter土地利用土地覆盖分解和变化检测模型，demeter是一个开源Python包，旨在分解由综合评估模型（IAM）生成的未来土地分配预测。 lcmap-ccdcLCMAP-ccdc - Python连续变化检测和分类库。 cglops-change-detection通过土地覆盖变化检测增强CGLOPS。 Land-use-change-detection利用多传感器卫星数据进行土地利用变化检测。 REU-AcceleratedChangeDetectioninSARImages用于合成孔径雷达（SAR）图像变化检测的深度神经网络算法。 bayesian-change-detection基于贝叶斯模型的变化检测Python模块。 Change-Detection-in-Satellite-Imagery采用主成分分析（PCA）和差分图像上的K-Means来检测多时相图像卫星图像的变化。 Temporal-Changes-Detection-in-3D-scenes使用VisualSfM重建的3D场景中的时间变化检测。 Opticks_Gsoc2013用于Opticks的基于对象的图像融合和变化检测工具。 ChangeAnomalyDetectionCRAN上的R语言包，变化检测。 VGG-net-for-photo-change-detection用VGG Net训练检测照片。 matlab-ccdc用于CCDC相关处理的原始Matlab代码。 CCDC使用所有可用的Landsat数据为土地覆盖的连续变化检测和分类（CCDC）开发的算法。 lcmap-ccdc基于Apache Spark的LCMAP变化检测和分类。 CRCPython遥感影像分析，分类和变化检测。 NRT_Validation在遥感影像中验证近实时变化检测产品。 CRC4Docker用于书“遥感影像分析，分类和变化检测，第四修订版”的Python脚本。 2.数据科学可视化项目，有非常多有趣的项目。 Data-And-Visualization-Projects 3.Python的一个库，用线要素和三维组合来表达地理要素。 GeospatialLineGraphs 4.R语言包raster的教程说明。 visualraster 5.R语言包sparsebn，用于通过稀疏正则化从高维数据中学习稀疏贝叶斯网络和其他图形模型。 sparsebn 6.Docker的实践资源，关于Docker是啥的可以去翻我前面的博客，有简单介绍以及如何安装。 docker_practice Win7下蓝鲸鱼安装以及Xshell连接操作) 花式安装蓝鲸鱼札记 7.Processing的R拓展。Processing是一个基于Java的动态可视化库，提供了R的接口（接口不一定对，但是就是可以利用R来写Processing）。 Processing.R 8.R Shiny的资源，Shiny是R语言的神器，通过R的代码可以设计html的网页。 awesome-rshiny 9.MapD Core是一个内存中的列存储SQL关系数据库。 mapd-core 10.想要熟练使用Python for GIS的GIS分析师的进步路径：从学徒到大师 python-for-gis-progression-path 11.基于贝叶斯方法的pm2.5预测（R语言），从抓取、数据分析到预测。 PredictPM25 12.Python库Geopandas，Pandas包的地理扩展。 geopandas 13.用于空间/地理Python探索的笔记和库，UCL CASA的课程资源。 Geopython 14.自动化GIS流程课程的课程信息 Course-information 15.R语言包baidumap，百度地图的R语言接口。 baidumap 2 Paper:1.Deep Learning: Individual Maize Segmentation From Terrestrial Lidar Data Using Faster R-CNN and Regional Growth Algorithms/深度学习：使用更快的R-CNN和区域增长算法从地面激光雷达数据中分割玉米 深度学习在LiDAR中的应用。在对象检测，分类和分割方面表现出很高的性能。在这项研究中，我们提出了一种结合深度倾斜和区域生长算法从地面激光雷达数据中分割单个玉米的方法。训练场地的扫描3D点被切成行和行，具有固定的3D窗口。窗口内的点被压缩成深度图像，用于训练更快的R-CNN（基于区域的卷积神经网络）模型以学习检测玉米茎的能力。使用不同种植密度的三个地点来测试该方法。 2.Challenging the Establishment of Cartography and GIS/地图学与地理信息系统建立的挑战 2018年7月6-8日中国兰州第六届全国青年学者地理空间信息论坛，江斌老师的汇报。针对大数据与传统地理学理论的一个新思考。]]></content>
      <categories>
        <category>Personal</category>
      </categories>
      <tags>
        <tag>Consideration of Ecology and Geography</tag>
        <tag>Summary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Coding and Paper Letter（二）]]></title>
    <url>%2F2018%2F07%2F08%2FCoding%20and%20Paper%20Letter%EF%BC%882%EF%BC%89%2F</url>
    <content type="text"><![CDATA[资源整理 1 Coding：1.近期高光谱遥感的论文和开源代码。 LandcoverClassification_BaselineEvaluation GitHub基于高光谱数据对土地覆被进行分类的代码。 Matlab code for hyperspectral image classification based on JSaCR GitHub发表于IEEE TGRS Letter上论文的源码。 Multiview Marginal Discriminant Projection for Hyperspectral Images ClassificationIntroduction GitHubNCIG 2018的论文，高光谱影像分类。 Supervised classification of hyperspectral image(HSI) GitHub高光谱影像的监督分类器。 Deep learning library for hyperspectral image classification GitHubPython的开源库hyspeclib，基于高光谱影像分类的深度学习库。 ResNet-for-hyperspectral-image-classification GitHub基于残差神经网络的高光谱分类代码。 Undergraduate thesis work on hyperspectral image classification GitHub研究高光谱影像的毕业论文。 hyperspectral-classification-with-svm GitHub基于SVM的高光谱影像分类。该仓库还提供了与最小二乘法的对比。 Hyperspectral-classification-CNN GitHub基于CNN的高光谱分类。 Hyperspectral-Imagery-Classification GitHub发表于IEEE Remote Sensing Letter的关于高光谱影像分类的文章的代码。 2018 IEEE GRSS Data Fusion Contest GitHubIEEE的数据融合竞赛。主要提供高光谱、LiDAR和高分辨率RGB影像。 Hyperspectral-Image-Classification GitHub高光谱影像分类的代码（Tensorflow）。 hyperspectral_data_classification GitHub高光谱影像分类开源代码。 HSI_Classification GitHub高光谱影像的分类代码。方法包括knn, svm, 1D-CNN, 2D-CNN, 3D-CNN, DPPN, DCPN。 Hyperspectral classification using DNN improved by attention and inception structure GitHub使用DNN改进的高光谱分类开源代码。 spectral GitHubPython用于高光谱影像处理的模块spectral。 Indian_pines_classification GitHub一个使用CNN与keras的简单分类器用于印度松树高光谱图像分类。 Dimensionality reduction and classification on Hyperspectral Image Using Python GitHub基于Python的高光谱图像降维与分类。 Matlab Hyperspectral Image Classification ToolboxMatlab的高光谱影像分类工具箱。 2.激光雷达与高光谱在森林遥感中应用。 DeepForest GitHub利用激光雷达和高光谱数据与卷积神经网络进行树分割和分类。 3.R语言包compareDF。用于比较两个数据框。 compareDF 4.基于PyQGIS的加权Voronoi算法实现。这个也是比较有意思的一个算法。后面可以来考虑介绍下这个内容。 Weighted-Voronoi-PyQGIS 5.R语言包cartogram，R语言中变形地图的包。后面会针对不同软件实现变形地图做些介绍。 cartogram 6.R语言包spdplyr。R语言数据清洗与重构神器dplyr的空间拓展。 spdplyr 7.R语言与ArcGIS的桥接库。也先挖坑吧，这个也是想介绍的内容之一。 R-ArcGIS bridge 8.R语言包ggspatial。ggplot2对空间要素的扩展。 ggspatial 9.基于SportUV数据对NBA球员的分析代码。 NBA-Player-Movements 10.一个NASA开放数据的简单Python接口pyNASA。 pyNASA 11.R语言包rnoaa，可以连接许多NOAA数据的API接口。 rnoaa 12.Markdown中绘制流程图的两种方式。 1 mermaid 2 flowchart.js 13.R语言包velox。R语言中快速操作栅格的包，运行速度快于raster等。 velox 2 Paper:1.Inference in multiscale geographically weighted regression/多尺度GWR的推论 最近的一篇论文（Fotheringham et al.2017）通过允许GWR中的带宽或平滑因子为模型中的每个协变量分别导出，显着扩展了众所周知的地理加权回归（GWR）框架—— 一个称为多尺度GWR的框架（MGWR）。然而，MGWR框架的一个限制是，到目前为止，没有关于局部参数估计的推断是可能的。本文通过将GWR重新设计为广义加法模型（GAM）来解决此限制，将此框架扩展到MGWR，然后导出MGWR中本地参数的标准误差。 2.Spatially-correlated Multilevel Models: A Generic Specification with Spatially-Local Regularization/空间相关的多层次模型：具有空间局部正则化的通用规范 多层次（或方差分量）模型已应用于区域科学，流行病学和polimetrics的许多领域。它们最常用于模拟政策制度中的非平稳性处理，这是一种空间过程异质性。具有空间相关分量的多级模型越来越多地用于模拟空间异质性和空间依赖性的存在。在本文中，开发了用于空间相关多层次模型的通用Gibbs采样器，并在癌症筛查模型中检查其性质。 3.Assessing the Potential of Land Use Modification to Mitigate Ambient NO2 and Its Consequences for Respiratory Health/评估土地利用变化减少环境NO2及其对呼吸系统健康的影响的潜力 这篇文章使用了波特兰 - 希尔斯伯勒 - 温哥华（美国）的夏季和冬季NO2空间密集观测来建模，并且使用随机森林（一种集合数据学习技术）研究NO2与LULC的空间变化。随机森林模型与BenMAP一起进一步用于更好地理解LULC，环境NO2和呼吸系统健康之间的关系。还使用灵敏度分析研究了土地利用改变对环境NO2的影响，并且如何影响呼吸健康。结果显示与道路和树冠区相关的NO2可能影响4-12岁儿童哮喘急性发作的年发病率。 4.Quantifying particulate matter accumulated on leaves by 17 species of urban trees in Beijing, China/量化中国北京17种城市树木积累的颗粒物质 这项研究使用洗涤和称重方法来量化17种城市植物物种（包括4种灌木和13种树木）叶片表面和叶子蜡质内水溶性离子和不溶性PM的积累。沉积的PM以三种尺寸分数确定：细（0.2-2.5μm），粗（2.5-10μm）和大（&gt;10μm）。在各种物种中检测到PM积累的显着差异。侧柏（Platycladus orientalis）和华山松（Pinus armandi）的叶子是捕获PM的最有效的。在整个物种中，65％和35％的PM平均分别沉积在叶片表面和蜡质中。]]></content>
      <categories>
        <category>Personal</category>
      </categories>
      <tags>
        <tag>Consideration of Ecology and Geography</tag>
        <tag>Summary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Coding and Paper Letter（一）]]></title>
    <url>%2F2018%2F07%2F07%2FCoding%20and%20Paper%20Letter%EF%BC%881%EF%BC%89%2F</url>
    <content type="text"><![CDATA[最近发现需要在快速阅读背景下，对快餐式资源做整理与收集。以Coding（以Github）和Paper（自己看到的一些论文，论文一般主要看题目和摘要做些简单小结）的资源为主。 1 Coding：1.QGIS上的变形地图插件，我后面会专门来介绍变形地图这个主题的内容。 qgis-cartogram源码 2.火星坐标与地球坐标转换开源代码。 命令行版 Python版 项目与说明 3.空间统计开源软件GeoDa资源。 GeoDa 源码 4.空间统计分析开源Python库——PySAL。 PySAL GitHub 5.GIS资源链接整理。 Awesome GIS 6.R语言包（rasterVIS）。一个专门针对栅格做可视化的包。十分强大。 rasterVIS GitHub 7.基于CityEngine开发的地理设计工具箱。这个项目讨论了一系列工具，这些工具旨在使数据驱动设计能够支持大规模方案规划项目。这些工具旨在集成GIS和CityEngine，以支持创建大量3D内容，以支持城市规划/地理设计项目。创建的内容可用于创建图像作为剪切图纸的一部分（与数据驱动页面一起使用），或链接到Web地图中的Web内容（通过提供弹出窗口或Web场景链接到的内容）。这里提出的工作流程的重点是街道，但脚本也支持与建筑物/批次/分区可视化相关的项目。意图：这些工具的目的是通过结合使用GIS和CityEngine，实现大规模的数据驱动设计。 CityEngineToolKit-GeodesignToolkit GitHub 8.深度照片风格转换。基于深度学习的照片风格转换。 deep-photo-styletransfer 源码 9.R语言包（scanstatistics）。时空扫描统计算法的R包实现，这个算法最早由哈佛大学学者提出，用于疾病的空间统计分析。 scanstatistics GitHub 2 Paper:1.Outdoor air pollution, green space, and cancer incidence in Saxony: A semi-individual cohort study/萨克森州的室外空气污染，绿色空间和癌症发病率：半个体的队列研究。 这是目前比较有意思的一个方向，空气污染的人群暴露、绿色空间与疾病三者的关系。使用的是萨克森州的保健数据（主要研究了口腔和咽喉，皮肤——非黑色素瘤皮肤癌 - NMSC的癌症事件（2010-2014），前列腺癌，乳腺癌和结肠直肠癌等疾病），室外空气污染主要考虑PM10和NO2，绿色空间使用NDVI做表征，模型选用的是多层次泊松回归模型。结论主要是高空气污染会增加癌症患病风险，而增加住宅绿色空间则可以降低。 2.Spatial Morphing Kernel Regression For Feature Interpolation/基于空间变形核回归的高维特征空间插值 针对近年来兴起的带有地理标记的社交媒体数据——也就是志愿者地理信息数据（Volunteer Geographical Information，VGI）。这次用的是Flickr数据。首先是基于卷积神经网络（CNN）提取了Flickr图片的高维特征，然后针对提取的特征进行空间插值。比较了IDW，核回归（高斯核和空间变形核）不同插值方法的结果（以parcel classification结果为例）。 3.Social media data as a proxy for hourly fine-scale electric power consumption estimation/社交媒体数据作为小时级精细电力消耗估计的辅助数据 准确预测电力需求对现代电力系统的运行至关重要。不准确的负荷预测将显着影响电网效率。预测一个小区域（如建筑物）的电力需求长期以来一直是众所周知的挑战。这项研究分析了带有地理标记的推文与每小时电力消耗之间的关联。检索所有可用的带有地理标记的推文和电表读数，并在空间上汇总到研究区域中的每个建筑物。人类活动指标（推文所反映的）与电力消耗之间存在高度相关性，相关系数超过0.8。非常有意思的研究。]]></content>
      <categories>
        <category>Personal</category>
      </categories>
      <tags>
        <tag>Consideration of Ecology and Geography</tag>
        <tag>Summary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[R语言字符串处理的一次经历]]></title>
    <url>%2F2018%2F06%2F05%2FR%E8%AF%AD%E8%A8%80%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%A4%84%E7%90%86%E7%9A%84%E4%B8%80%E6%AC%A1%E7%BB%8F%E5%8E%86%2F</url>
    <content type="text"><![CDATA[最近笔者在研读一些文献，发现了Remote Sensing of Environment上的一期Special Issues。这一期可以说是地学上Data Assimilation较为经典的研究吧。所以也是目前研读的重点。当然也是有些其他需求，现在想对这一期专刊的作者与客座编辑做些分析探讨。涉及到一些R语言的字符串处理方式。这里记录下。 1 数据描述数据就比较简单了。一共两个数据。第一个数据如下。 主要包括Title和Author两列，这个数据我命名为RSEDAPaper.xlsx文件。 第二个数据如下。 主要包括EditorBoard，这个数据我命名为EditorBoard.xlsx文件。 2 问题描述与思路我其实想了解Remote Sensing of Environment这一期专刊里，Editor Board参与的文章数量有几篇？所以这就涉及到两个处理，第一步是首先要对Author的字段进行分割成单独的作者，第二步是与EditorBoard的数据做匹配。 3 R语言实现第一步首先要把用R语言将数据读入到内存里。由于我存的都是Excel文件，就需要用到openxlsx包。之前我已经介绍过如何在R里读取Excel文件。详情请见下文链接。 R语言读取Excel的神器——openxlsx 1234library(openxlsx)basepath &lt;- "E:/RSEDA/"RSEDA &lt;- read.xlsx(paste(basepath, "RSEDAPaper.xlsx", sep = ""))Editor &lt;- read.xlsx(paste(basepath, "EditorBoard.xlsx", sep = "")) basepath是你存放数据的路径，根据具体情况来处理。 接下来就是涉及到第一步处理，我们首先将Author这种一长串的数据进行分割。 其实这种论文的作者名是比较好分割的，直接使用”,”分割即可。使用的R语言函数是strsplit。输入函数最主要包括两个，一个是字符串，一个是分割符号。样例如下： 1234a &lt;- RSEDA$Author[2]aa &lt;- unlist(strsplit(a, split = ","))a 两次输出分别为： 可以发现已经成功做了分割，使得变成了7个作者单独的一个向量，当然如果你的字符串连接方式不是”,”，你只需要在split的等号后面进行修改。而作者个数不相同的情况下，这样子如何存储呢？这时候就用到了R里的一个特殊存储结构：列表。列表很适合存储这种长度不一的一些数据。 1234567authorlist &lt;- list()for (i in 1:nrow(RSEDA)) &#123; authors &lt;- RSEDA$Author[i] authors &lt;- unlist(strsplit(authors, split = ",")) authorlist[[i]] &lt;- authors&#125;authorlist 可以发现很好的存储起来了，当然还有个小问题。由于英文的一些空格的原因，导致有些作者前后多了空格。所以做下一步匹配之前需要对这个进行处理，这里用的是stringr包。 123library(stringr)b &lt;- " John M. Morrison "str_trim(b, "both") 效果如图，side = “both”，指去除掉两边的空格，”left”和”right”则是去除左边或右边的空格。接下来只需要筛选数据做匹配。这里先生成一个跟前面authorlist一样结构的editorlist列表。然后针对每一篇文章作者分析，用一个for循环和luse获取作者个数，然后，再嵌套一个for循环，获取这一篇文章里每个作者名字，接着去除空格，然后是匹配，ifelse语句的含义是表示，如果这个作者名字有出现在Editor Board里，就输出1，如果没有输出0。 12345678910editorlist &lt;- list()editorlist &lt;- authorlistfor (i in 1:nrow(RSEDA)) &#123; luse &lt;- length(authorlist[[i]]) for (m in 1:luse) &#123; deauthor &lt;- authorlist[[i]][m] deauthor &lt;- str_trim(deauthor, 'both') editorlist[[i]][m] &lt;- ifelse(deauthor%in%Editor$EditorBoard, 1, 0) &#125;&#125; 输出结果如图。接着对每一篇文章统计，是否有Editor Board，有的话是1，没有的话是0。 1234RSEDA$editor &lt;- 1for (i in 1:nrow(RSEDA)) &#123; RSEDA$editor[i] &lt;- ifelse("1"%in%editorlist[[i]], 1, 0) &#125; 先生成了一个字段editor表示是否有Editor Board，默认值为1。而接着就是对每一行分析，这里每一行，是否有含”1”，有的话，即为有Editor Board。 事实上分析结果显示，这一期专刊里居然一个Editor Board也没有参与文章发表。也是蛮奇怪的。后期可能会针对这些文献做些介绍。这一期的R语言处理的步骤也可以用到其他部分，其实主要是字符串分割，去除空格以及简单的包含处理。]]></content>
      <categories>
        <category>Coding</category>
      </categories>
      <tags>
        <tag>R</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MODIS数据的简介和下载（六）——基于浏览器模拟登陆下载的方式以及D3L Tool开发]]></title>
    <url>%2F2018%2F05%2F18%2FMODIS%E6%95%B0%E6%8D%AE%E7%9A%84%E7%AE%80%E4%BB%8B%E5%92%8C%E4%B8%8B%E8%BD%BD%EF%BC%88%E5%85%AD%EF%BC%89%E2%80%94%E2%80%94%E5%9F%BA%E4%BA%8E%E6%B5%8F%E8%A7%88%E5%99%A8%E6%A8%A1%E6%8B%9F%E7%99%BB%E9%99%86%E4%B8%8B%E8%BD%BD%E7%9A%84%E6%96%B9%E5%BC%8F%E4%BB%A5%E5%8F%8AD3L%20Tool%E5%BC%80%E5%8F%91%2F</url>
    <content type="text"><![CDATA[接上文，由于NASA官方弃用了FTP改用HTTPS服务，所以关于MODIS数据的下载方式有所改变。完整系列博客可以参照以下链接。本篇主要介绍的是我自己写的一个下载方式，以及我为了方便大家下载开发的一个带图形界面的下载工具。 MODIS数据的简介和下载（一）——MODIS数据简介 MODIS数据的简介和下载（二）——MODIS数据下载方式（FTP） MODIS数据的简介和下载（三）——MODIS数据下载方式（基于MODIS Web Service） MODIS数据的简介和下载（番外篇）——MODIS Web Service的Python客户端应用 MODIS数据的简介和下载（四）——HTTPS服务下载说明 MODIS数据的简介和下载（五）——应用密钥的Python脚本下载 1 基于NASA官方脚本封装的exe这应该是近段时间MODIS数据的最后一篇系列，如果有新的内容我会继续更新。废话不多说，事实上基于Python的脚本下载，可能还是有很多小伙伴们不是很能get。毕竟也是门编程语言，就像下图。 为此，为了方便大家使用这个脚本下载，我用pyinstaller对NASA官方提供的官方下载脚本做了封装，变成了可以在Windows上运行的exe。盗用了下nasa的图标（后面有空我会顺带来介绍下pyinstaller）。 这样子，无需python环境也可以运行程序。如果是win10，会有传统的CMD和Powershell两个窗口，按住shift右击可以打开的是Powershell，如果是win7的话，就是CMD窗口，这里都讲述下怎么使用。 打开Powershell窗口之后，在窗口上输入如下命令。即如图所示。其余的命令行跟上一篇教程提到的一样。这里就不赘述了。 1.\nasa.exe -h win10（包括win7）如果打开CMD窗口。通常需要先定位到这个exe所在路径（F：/MODISDownload）。 12cd DIR(eg. F:/MODISDownload)F: 这样就定位到了exe所在路径。 12nasa.exe -hnasa -h 在CMD中上述两个语句都可以，都是查询帮助语句。下载的语句可以见上文。 如果需要这个exe，可以在下面的百度网盘链接下载。 nasa.exe 2 基于浏览器模拟登陆下载与D3LTool开发当然对于我封装的这个exe，依旧是个基于命令行的程序，可能大家还是不甚喜爱。基于这个原因，我最近花了一小点时间，开发了一个小的GUI软件，我把它称为D3L Tool of NASA Satellite。主要功能就是针对LAADS系列的卫星影像的下载。 软件整体界面如下： 主要功能就是两个下载，一个是使用NASA脚本下载，一个是使用谷歌浏览器下载。NASA脚本下载功能的原理其实就是调用了上面的nasa.exe下载。你只需要填入所需要的数据url地址，下载路径以及你的token再点击下载即可。相比于命令行可能更友好些吧。而使用谷歌浏览器下载的方式，是我自己想到的批量下载方式（前面的博客也有提到），其实就是通过selenium这个自动化测试的神器（后面有空也会聊一聊这个东西），打开浏览器，模拟登陆NASA Earthdata账户，然后自动下载所有数据。所需要填入的就是用户名，密码，订单号和下载路径。但是由于谷歌浏览器和selenium的一些问题，下载路径在软件里面修改是无效的，必须得从你电脑上的谷歌浏览器的设置里进行修改。才能让所有下载的卫星影像数据存储到制定路径里。否则就是默认的谷歌浏览器下载路径。 具体的功能我就不详细介绍了，我已经在建立了这个软件的一个官方网站，具体的使用教程和软件下载链接都在下面的官网里。 D3L Tool of NASA Satellite 也提供了多个版本的下载（当前仅支持Windows上的版本）。 如果有什么问题欢迎在github上提交issues或者邮件联系我，如果你觉得不错的话，也欢迎star。 最后附上两张软件下载中的截图。]]></content>
      <categories>
        <category>RS</category>
      </categories>
      <tags>
        <tag>MODIS</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MODIS数据的简介和下载（五）——应用密钥的Python脚本下载]]></title>
    <url>%2F2018%2F04%2F23%2FMODIS%E6%95%B0%E6%8D%AE%E7%9A%84%E7%AE%80%E4%BB%8B%E5%92%8C%E4%B8%8B%E8%BD%BD%EF%BC%88%E4%BA%94%EF%BC%89%E2%80%94%E2%80%94%E5%BA%94%E7%94%A8%E5%AF%86%E9%92%A5%E7%9A%84Python%E8%84%9A%E6%9C%AC%E4%B8%8B%E8%BD%BD%2F</url>
    <content type="text"><![CDATA[接上文，由于NASA官方弃用了FTP改用HTTPS服务，所以关于MODIS数据的下载方式有所改变。完整系列博客可以参照以下链接。本篇主要接着上一篇没有讲完的应用密钥的脚本下载介绍。 MODIS数据的简介和下载（一）——MODIS数据简介 MODIS数据的简介和下载（二）——MODIS数据下载方式（FTP） MODIS数据的简介和下载（三）——MODIS数据下载方式（基于MODIS Web Service） MODIS数据的简介和下载（番外篇）——MODIS Web Service的Python客户端应用 MODIS数据的简介和下载（四）——HTTPS服务下载说明 1 官方教程与说明LAADS Data Download Scripts 接着上文的部分往下，上一篇博客已经讲了一小部分应用密钥。本篇主要针对以下部分介绍（红框部分）。 1 应用密钥1 申请一个应用密钥任何注册了Earthdata账户(注册链接)的人都可以申请应用密钥。通过以下步骤就可以申请一个应用密钥。 1.首先转到对应的页面：LAADS DAAC，登陆Earthdata。2.接着点击Profile→App Keys（见截图）。3.通过输入你对keys的描述并且点击 “Create New App Key”按钮创建一个新的应用密钥。 当然如果以前你就有应用密钥，但是你忘记了，那就按照如下的步骤操作：1.登陆Earthdata（同上）。2.接着点击Profile→App Keys（同上）。3.复制你的密钥。 总的来说这个操作跟国内百度地图、高德地图API也没太大差别。 2 我有一个应用密钥后，应该怎么样呢?应用密钥可以通过HTTPS GET服务请求数据。关于HTTPS的GET和POST服务，可以看一下我找的几个帖子吧，对于做过爬虫，调用过API的人应该不陌生。 HTTP 方法：GET 对比 POST知乎：get和post区别？ 官方给了个样例，是用“curl”命令行工具来创建带请求的URL。 https://ladsweb.modaps.eosdis.nasa.gov/PATH_TO_MY_FILE 1curl -v -H &apos;Authorization: Bearer MY_APP_KEY&apos; &apos;https://ladsweb.modaps.eosdis.nasa.gov/PATH_TO_MY_FILE&apos; &gt; result -v和-H属于附加的设置命令。 curl是个适用于所有操作系统的命令行工具。curl简介，也就是说通过curl可以下载对应订单的数据。 它给出了使用这个方式下载的一些要点： 1.所有的字符串都很重要，包括破折号、冒号和引号；2.将’MY_APP_KEY’替换成你的应用密钥；3.把“PATH_TO_MY_FILE”替换成你所需要的文件的路径。4.通常LAADS DAAC的文件路径像下面的形式： archive/allData/COLLECTION/PRODUCT/YEAR/DAY_OF_YEAR/FILENAME 这里给出一个URL的示例： https://ladsweb.modaps.eosdis.nasa.gov/archive/allData/6/MOD02QKM/2007/018/MOD02QKM.A2007018.0105.006.2014227230926.hdf 在发送请求之后会返回给你一个2007年第18天MODIS Terra250m的大气顶层反射率产品。 笔者常用系统是Ubuntu和Windows10，这里就演示下如何用curl下载数据吧(以Ubuntu为例）。以给出的URL为样例。 curl官网 Ubuntu上可以直接用apt-get install命令安装curl。网上有帖子，这里不细述了。接着按照上面所说的改写命令行，如果不要“&gt; result”，是按照原来的文件名下载。 下载中。 结果数据。 Windows下的尝试不是很愉快。当然curl也不是主要下载方式，所以我就不继续探索了，如果后面有机会再来说这个吧。 2 自动化如果你需要的数据是单个文件，并且你知道它位于LAADS数据存档的路径，那么点击并下载它是很简单的。如果你需要下载的文件非常多（比如上个月整个月的VIIRS数据），你可能更愿意利用脚本来下载。因此这里给出了一些代码的示例：Shell脚本、Perl和Python版的。两条警告：1.不要把全部数据下到你的硬盘。2.尽可能在你的脚本里避免错误，以防下载过多导致IP被封。 3 代码示例大多数语言都可以进行HTTPS通信，下面有些样例。使用方式是点击“下载源代码”以下载或复制代码并将其粘贴到反映语言的文件中（Shell脚本为.sh，Perl为.p1.，Python为.py）。 确保为文件设置了执行权限。 最后，打开终端或使用您的首选运行时执行文件。 示例： 1perl laads-data-download.pl Perl我不是特别懂，本篇主要介绍Python脚本，Shell脚本也会提一下。 2 使用Python脚本下载首先下载下来laads-data-download.py，然后放到一个文件夹里，接着打开cmd，输入如下的命令。 1python laads-data-download.py -h 这句代码的意思就是，-h是指help，也就是说关于这个Python函数的使用说明。 1laads-data-download.py [-h] -s URL -d DIR -t TOK 简单地说这个函数有几个参数需要传进去，-s就是下载源，URL就是你要下载的数据的URL路径，-d就是下载路径，也就是数据应该下载到哪个路径里，-t就是token，令牌，其实就是你的app keys。也就是说完整的运行代码应该是如下： 1python laads-data-download.py -s https://ladsweb.modaps.eosdis.nasa.gov/archive/orders/YOUR ORDERS ID -d Paht TO MY FILE -t MY_APP_KEYS 第一个红框就是你订购数据的ID（如下图）。 第二个红框是你数据存放在电脑里的路径。 第三个红框是你的app keys。 接下来就只需要等待数据下载完即可。 顺带提下Shell脚本，也是下载laads-data-download.sh文件。事实上语法都相同。但是Shell脚本呢还需要依赖‘jq’来下载。 1./laads-data-download.sh [-h] -s URL -d PATH -t TOKEN ‘jq’的安装用命令即可。 1apt-get install jq 等待下载结束。 所以事实上，Python脚本下载其实并不难。只需要替换对应的URL、路径、App Keys即可。其他的也如此，如果你懂了就可以开始尝试了。当然笔者之前还用过另一种方式来进行批量下载。接下来可能会就这个部分也来介绍一下。另外一点就目前笔者测试结果，感觉Shell脚本和Ubuntu下载速度要明显快于Python脚本和Windows。]]></content>
      <categories>
        <category>RS</category>
      </categories>
      <tags>
        <tag>MODIS</tag>
        <tag>Python</tag>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MODIS数据的简介和下载（四）——HTTPS服务下载说明]]></title>
    <url>%2F2018%2F04%2F22%2FMODIS%E6%95%B0%E6%8D%AE%E7%9A%84%E7%AE%80%E4%BB%8B%E5%92%8C%E4%B8%8B%E8%BD%BD%EF%BC%88%E5%9B%9B%EF%BC%89%E2%80%94%E2%80%94HTTPS%E6%9C%8D%E5%8A%A1%E4%B8%8B%E8%BD%BD%E8%AF%B4%E6%98%8E%2F</url>
    <content type="text"><![CDATA[由于NASA官方MODIS服务的变化和网站的改版。所以重新来介绍下MODIS数据新的下载方式。至于数据的简介和Web Service的，不清楚的小伙伴可以去点击前面的文章回顾下（其中“MODIS数据的简介和下载（二）”一文教程由于NASA官网关闭FTP服务器的原因在最后提交数据的部分有所变化，详情见本文）。 MODIS数据的简介和下载（一）——MODIS数据简介 MODIS数据的简介和下载（二）——MODIS数据下载方式（FTP） MODIS数据的简介和下载（三）——MODIS数据下载方式（基于MODIS Web Service） MODIS数据的简介和下载（番外篇）——MODIS Web Service的Python客户端应用 注册了NASA官网earthdata账户的小伙伴们应该在最近都收到了NASA官网关于关闭FTP服务器的邮件，之前也有评论区的小伙伴来询问相关。今天就来介绍新的下载方式。 1 NASA官方邮件通知 提供的原文链接如下 。 LAADS Data Download Scripts 这个链接的目录如下： 也就是说官方提供了下载的脚本，包括Linux Shell脚本、Perl脚本和Python脚本。此时的内心OS大概是这样吧。 当然其实我也蛮喜欢Linux Shell脚本的。 言归正传，来介绍下这个说明的内容。 2 HTTPS服务获取数据说明1 使用LAADS DAAC应用密钥下载文件这个部分的内容主要是提了下背景原因，现在搞这个密钥的原因主要是，MODIS和VIIRS团队以及母公司都想追踪谁使用了相关数据。使用在Earthdata的账户里采用了Earthdata.Profile以及一些其他服务，这也就是说，在访问一些受限资源（Sentinel-3），必须先授权，并且登陆之后才能识别你的身份才能下载。 其实这个部分我感觉有Earthdata账户的很简单。 登陆账户后，点击Edit Profile。然后页面往下。这两个数据的简介我就不提了。勾选即可完成。 然后点击Save Profile。 第一步就算完成了，当然还有提到刚刚那俩数据的授权，后面还会进一步介绍。 2 弃用FTP这部分没啥干货，回顾了FTP的辉煌一生，然后果断弃用（我想起那天夕阳下的奔跑，那是我逝去的青春）。 3 通过HTTP下载这部分干货也没啥，介绍了HTTP和HTTPS，然后说明所有数据都支持HTTPS服务下载。 4 Earthdata配置文件需要有Earthdata Profile才能下载，看了下在注册Earthdata的时候其实就应该配置过了。 5 授权创建Earthdata的配置文件后，你就可以请求需要下载的数据了，不同数据授权方式不同。这边给了一份表格。其实就分两类（1.MERIS和Sentinel-3；2.除了这俩之外的）。 资源 说明 MERIS或者Sentinel-3 在这两个链接（MERIS和Sentinel-3）在点击勾选同意之后，跟着系统提示即可 其他数据 根据项目理由和注册的邮件来申请资源 这里点开MERIS和Sentinel-3的链接出现如下页面，随机点击一个数据，又跳出后面的页面。 接着点Aggree to。 接着显示。即有新的链接可以下载。 6 应用密钥这里说明了如果你只希望通过浏览器下载的用户只需登录即可，也就是说登陆完账户就可以下载了。如果你要用 脚本下载需要使用LAADS应用程序密钥才能正确授权。LAADS应用程序密钥是识别您身份呢的字符串标记。 应用程序获取HTTP GET请求。 查看下面的代码示例。 这部分的话，我打算放到下一篇来讲，因为内容可能会有点多。所以关于不懂脚本的同学也不必灰心，并非是前面所说的不懂Python就不会下数据了。通过浏览器的话，只需要登录账户即可下载数据。 3 新版网站下载方式选择关于HTTPS服务下载，前面的步骤是一样的。具体的下载教程，请看”MODIS数据的简介和下载（二）——MODIS数据下载方式（FTP）“一文。链接在前面。唯一的差别是最后数据订单提交的时候。 选择Pull。 然后Submit Order。 稍等一会，可以在Post Orders找到你的订单。 点击你的订单就是这样子的。 接下来只需点击我画红框的部分（打码部分是订单号）。链接会跳转到一个页面（如果你点击无法访问的话，请稍等一会再重新点击）。 这就是你所提交的订单数据。接下来只需要鼠标点击数据即可下载。事实上，你不懂任何脚本也可以继续下载数据，只需要通过点击链接（像IDM这类下载工具可能也可以使用，我这里没有使用过）。当然如果你的数据非常多的话，一个一个点确实很头疼。而批量下载的话，就需要写点小代码了。关于官方脚本的下载以及如何批量下载，我会在后面继续发布。]]></content>
      <categories>
        <category>RS</category>
      </categories>
      <tags>
        <tag>MODIS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[快速生成Github README.md的目录]]></title>
    <url>%2F2018%2F03%2F19%2F%E5%BF%AB%E9%80%9F%E7%94%9F%E6%88%90Github%20README.md%E7%9A%84%E7%9B%AE%E5%BD%95%2F</url>
    <content type="text"><![CDATA[熟悉Github的同学可能知道创建一个Repo，通常都会生成一个README.md。好的README能增加代码的可阅读性。另外通常也可以将README作为开发文档。而这个README本身是遵循Markdown语法的，但是Markdown本身并没有绝对标准，Github的渲染方式与一些常用博客渲染方式不相同，导致在使用时有些麻烦。这里推荐一个Github上的教程。 GFM教程 GFM教程博客地址 事实上大部分和普通Markdown还是类似的，但是目录的语法差别蛮大，刚好对于笔者而言，最近需要在Github上文档上建立目录来使用，但是又不想写GFM的语法。这个时候刚好搜索到了一些可以用的开源代码。这里简单介绍一个目前使用的方法。 1 Github+百度搜索结果 事实上解决方案还蛮多的（Github大法好）。 当时还在百度上搜索了下，找到了这个方案。 ghtoc Github地址（pyhon） ghtoc博客 2 解决方案：gh-md-toc后面发现了gh-md-toc这个神器。 gh-md-toc Github地址 但是这个东西在Mac和Linux很友好，windows似乎不那么友好。不过这里也给了windows的解决方案。 就是github-markdown-toc.go。 github-markdown-toc.go Github地址 如果你有GO语言（又是你）的编译环境，可以尝试自己编译，如果没有，可以直接下载编译好的二进制文件。 二进制文件 下载下来之后，发现没有后缀名无法识别，实际上这是个exe文件，所以只需要暴力地在后面加上.exe就可以开始愉快使用了。 首先将README.md文档复制到gh-md-toc.exe的根目录下。 接着按住shift键同时右击。 打开Powershell窗口后，直接键入。 1./gh-md-toc.exe README.md 接下来只需将这段话复制粘贴到README.md里面即可。]]></content>
      <categories>
        <category>Coding</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[R语言高清图片输出设置]]></title>
    <url>%2F2018%2F03%2F14%2FR%E8%AF%AD%E8%A8%80%E9%AB%98%E6%B8%85%E5%9B%BE%E7%89%87%E8%BE%93%E5%87%BA%E8%AE%BE%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[以ggplot2等包为基础的R语言可视化是科研人员非常喜爱的一个方式，不过我也在这个上遇到了些问题。就是导出高分辨率的图片之后，插入到word里，就显得模糊不清（压缩得非常厉害）。如果不压缩的话，word动辄100M以上。最近刚好有了一个解决方式，就来介绍下。 解决方案思路：R+Corel Draw这也是某期刊图的修改要求，必须提供.cdr文件。当然测试后发现，.cdr输出的tif即使被压缩，也能很清晰。 这里谈谈怎么做。首先R目前是没法直接输出.cdr格式的文件的，根据网上的经验就是用emf这个格式，能够输出Corel Draw能读取的矢量文件，导入后再做些微调。 但是R输出emf没有像tiff和jpeg那样的语句，主要使用的是savePlot函数。 这里摘下R的帮助文档再来解释这个函数 Usage savePlot(filename = “Rplot”, type = c(“wmf”, “emf”, “png”, “jpg”, “jpeg”, “bmp”, “tif”, “tiff”, “ps”, “eps”, “pdf”), device = dev.cur(), restoreConsole = TRUE) Arguments filenameThe filename under which to save the plot. Tilde-expansion (see path.expand is supported. typeThe type of plot, Windows metafile, PNG, JPEG, BMP (Windows bitmap format), TIFF, PostScript or PDF. deviceA device number of a windows device, by default the current device. restoreConsoleSee the ‘Details’ section of windows. 一个参数一个参数来解释吧。filename：很好理解，就是你要输出的图片路径和名称，用字符串类型。如“C:/Rplot”。不必加后缀。type：输出格式。device：Windows设备的设备编号，默认为当前设备，这个参数。restoreConsole：这个参数也是跟windows图形设备相关的。 实际使用时，后两个参数默认就可以。主要是针对前两个参数。 接下来用一个案例来展示下操作。使用的是R语言默认的mtcars数据。用plot绘图和ggplot2绘图各测试一遍。但是笔者就如网上所说在Rstudio中运行savePlot报错。 事实上这个语句只能在原生的Rgui中运行。因此将R代码存成脚本，在Rgui中直接用source调用写好的脚本即可。 plot只需直接绘图语句。而ggplot则需要多一句print语句，才能输出图片。 运行完后，打开corel draw，按下图进行操作。 这样就能把emf转变成全部可编辑的矢量了。 当然Rstudio也有个方法。就是使用复制到剪贴板的功能，然后粘贴到Corel Draw里面。 这就是将R导入到Corel Draw前期工作。相比与之前压缩得非常厉害的图片，我感觉Corel Draw输出的图片质量非常高。此外，后面搜索时，我也发现了R的一个包：devEMF: EMF Graphics Output Device。可以输出emf，这样在Rstudio里也可以操作了。 参考博客：R语言可以这么玩 |高质量图片这样导出！]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>R</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[天不生Tobler，万古GIS如长夜]]></title>
    <url>%2F2018%2F02%2F22%2F%E5%A4%A9%E4%B8%8D%E7%94%9FTobler%EF%BC%8C%E4%B8%87%E5%8F%A4GIS%E5%A6%82%E9%95%BF%E5%A4%9C%2F</url>
    <content type="text"><![CDATA[今日在QQ上惊闻Waldo Tobler老先生已于昨日过世，实乃地理学界的一大憾事，特地以此文表示深切的悼念。 （一）Waldo Tobler，生于1930年，圣塔芭芭拉加州大学（UniversityofCalifornia,SantaBarbara，简称UCSB，又常译为加州大学圣塔芭芭拉分校）退休教授，美籍瑞士地理学家，制图学家。下图的帅哥就是老爷子（文字介绍来自百度百科，图片来自维基百科）。 百度百科 维基百科 Tobler先生最广为人知的就是他提出的观点，也就是后来被地理学界称为地理学第一定律的“Everything is related to everything else, but near things are more related to each other”。个人的翻译为：世界上的一切事物都是相关的，但是相邻的事物相关性更大，当然有各自的翻译，整体意思是一致的，空间邻近的事物具有相关性，也就是所谓的空间自相关性。小文院士在2007年在《自然杂志》上撰文《地理学第一定律与时空邻近度的提出》，对地理学第一定律做了官方的阐释。 正如题目所言，Tobler先生对于地理学界而言是个活着的传奇，他是当今GIS与空间统计研究基础的奠基人，而这一切都因为他的地理学第一定律。无论是莫兰指数、地理加权回归、克里金插值都是建立在空间自相关的基础上衍生开来的理论。正如他在第一篇提到这个的文章所说，”As a premise, I make the assumption that everything is related to everything else.“ 地理学从古代发展至今，这个古老的学科曾今因为缺乏足够的合法性，而一度濒临灭亡，很多学科都有地理学深深的印记，却又在不断发展中独立出来。而当地理学的分支学科纷纷独立时，地理学本身独立存在的合法性又何在？不同地理学派对此的争论，在1950时代引发了地理学的计量革命，以及GIS的出现，给了地理学又一次新的生命。而在计量革命与GIS出现之后，随着Tobler先生的地理学第一定律提出，GIS和地理学界重新激发了蓬勃的生命力。 所以，深切地感谢Tobler先生与他所提出的地理学第一定律。 时空尺度与地表过程 1948-2006：哈佛大学地理系的灭亡与地理学的重生 （二）地理学第一定律用简介的语言描述了地理学现象的规律，中国人喜欢咬文嚼字，我曾经在早前大学给一次学弟学妹的汇报里以自己的理解解读过地理学与物理学。理者，可以翻译为规律，如此翻译而来，地理就是研究地球/地球表层事物的规律，物理就是研究事物之间的规律。 当然无非提的就是地理学的定律与物理学的定律。物理学有着牛顿三大定律，而地理学目前有两大定律（第一和第二定律，分别是讲述空间自相关性与空间异质性）。两个学科都有着一些定律，却有些不同。物理学的定律是普适性的定律，放之四海而皆准，除了二次元，你怕是在任何地方都无法脱离地心引力。而地理学的定律却不一定有那么强的普适性，之前有人将地理学第一定律的中文翻译为，世界上的一切事物都是相关的，但是相邻的事物往往相关性更大。相比于我的直白翻译，他加上了一个往往。往往也就是说是可能，而非完全确定的，也就是说有些地理现象确实不存在空间自相关性，随机分布或者均匀分布。 时至今日这依旧是被诟病的点，空间自相关性确实是地理学特征，也是空间统计仰赖基础，但是空间统计却出现了一千个作者，一千种结果的情况，随着空间权重矩阵和空间关系的变化，同一个区域的空间统计结果各不相同，甚至于今日我在Research Gate上看到的一个问题：同一个空间权重矩阵（至少他认为一样），但是STATA，R和Geoda得到的莫兰指数结果各不相同。 而我的看法是，正是因为地学现象受到诸多环境因素、人类因素、生物因素的耦合影响，导致它具有非常强的复杂性。因此如何用模型去表达一个地球表层，本身是一件很困难的事。我认为空间统计已经将地学的实质之一表达出来了，但是地球表层的复杂性使得研究人员必须在了解地球表层地理现象的大体过程的同时，选择最为适宜的空间统计方法进行分析。当然我认为空间统计依旧有很多值得完善的问题，如始终横亘在地理学面前的可变面元问题，抑或者是尺度问题，抑或者是如何实现地球表层要素的渐变与突变的表达，抑或者是老生常谈的不确定性问题。而这些则需要我们去进一步地研究与挖掘。 而到目前为止，我认为这两条定律已经很好地为我们描绘了地球表层地理现象的两大基本特性，而一些潜在的其他特性，则需要我们进一步发现和刻画，从而使得对地理现象更好的了解。 （三）从微博上道听途说Tobler老先生依旧在88岁高龄的情况下亲临博士毕业答辩现场。在去年，我在Research Gate上关注了Tobler先生，而就在去年，他更新了自己的Research Gate，依旧在提出新的东西——这回是他另一个主要的研究方向，地图制图与地理投影，Tobler先生又提出了一种新的墨卡托投影。88岁高龄的先生依旧充满着活跃的思想，我也是由衷地钦佩。 用中国人的话来说，可以说先生仙风道骨，仿佛不食人间烟火，一心只有科研。同时这又让我想起了小文院士。 曾经听中国地理学会副理事长张国友老师评价道：”地理学是一门经世致用的学科“，当时为之一振。这样的学科，也正因为有这些苦心研究的学者，而更加熠熠生辉吧。 天不生Tobler，万古GIS如长夜。 向先生以及诸多地学先驱致以最高的敬意。 var options = {"narrow":false,"autoplay":true,"showlrc":0,"mode":"random","music":[{"title":"落叶归根","author":"王力宏","url":"http://oyo5uzjmz.bkt.clouddn.com/%E7%8E%8B%E5%8A%9B%E5%AE%8F%20-%20%E8%90%BD%E5%8F%B6%E5%BD%92%E6%A0%B9.mp3","pic":"http://oyo5uzjmz.bkt.clouddn.com/250px-Waldo_Tobler_2007.jpg"}]}; options.element = document.getElementById("aplayer0"); new APlayer(options);]]></content>
      <categories>
        <category>Personal</category>
      </categories>
      <tags>
        <tag>Consideration of Ecology and Geography</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MODIS数据的简介和下载（番外篇）——MODIS Web Service的Python客户端应用]]></title>
    <url>%2F2018%2F01%2F18%2FMODIS%E6%95%B0%E6%8D%AE%E7%9A%84%E7%AE%80%E4%BB%8B%E5%92%8C%E4%B8%8B%E8%BD%BD%EF%BC%88%E7%95%AA%E5%A4%96%E7%AF%87%EF%BC%89%E2%80%94%E2%80%94MODIS%20Web%20Service%E7%9A%84Python%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[新年开坑第一篇，关于之前MODIS系列博客的补充和番外篇。有兴趣的同学可以去翻阅前面的文章复习。 MODIS数据的简介和下载（一）——MODIS数据简介 MODIS数据的简介和下载（二）——MODIS数据下载方式（FTP） MODIS数据的简介和下载（三）——MODIS数据下载方式（基于MODIS Web Service） 之前有小伙伴在评论区问过我，说Matlab客户端不能用了，前一段笔者自己使用的时候发现R的客户端也挂了，去官网一看，发现MODIS官网更新了产品版本，原来的这些客户端都不支持了。当时仅剩一个Python版本的客户端（不过好消息是最近又把各个语言的客户端都更新了，习惯用Matlab或者R的同学可以继续使用）。 Web Service客户端下载地址 Matlab只需要解压即可，R的MODISTools包则需要下载下来离线安装（我会把新的客户端的文件：R、Matlab、Python放到网盘共享，大家也可以在文末找链接）。 今天重点还是讲Python的客户端，点击开Python客户端下载之后是一个网页显示的文本文件。本文的Python环境是基于Anaconda的2.7.12。 将页面复制下来，存成Python文件。另外还需要安装SUDS的模块，通过pip就可以安装（前面的博客已经介绍过pip）。 Python开篇——简介、pip和conda 只需要在cmd里运行pip install suds（确保你的pip在系统变量路径里） 1pip install suds 接下来就是将下载的Python文件作为包引入即可。如何引用一个别人写好的未打包成包的Python函数？其实这里有两种方式。 一种是把别人写好的Python函数放到如下的路径’Python安装路径/Lib/site-packages’，这种方式一劳永逸，这样就等同于你安装了这个Python函数。可以随意的import。 另一种方式就是现在系统路径里加入Python函数所处的路径。具体的实现如下面的代码。 123import os,syssys.path.append("MODIS Web Service的Python客户端所在路径")import MODISWeb 最后import 下载的MODIS Web Service的python文件名（我这里用的MODISWeb）即可。 使用的方式与前文的MODIS和R的客户端大体相同。 因为LAI是8天合成数据，我们想通过已有的数据进行拟合，对时间序列做个简单的预测。这里用线性回归模型进行拟合。 这里使用了sklearn里面的线性模型来训练拟合线性回归模型。 绘制回归图。 上文只是简单地对MODIS数据做些简单分析，如果拥有实测数据，则可以通过遥感数据和实测数据的拟合，实现遥感数据反演。而具体的应用就待各位进一步挖掘了。 此外，MODIS系列下载区有小伙伴问过关于MODIS16蒸散发产品的下载。这一点，有位热心小伙伴找到了最新的下载方式，这里放出博客的链接，有需要的请自取。 MOD16 蒸散发数据下载 R、Matlab、Python客户端下载链接。 https://pan.baidu.com/s/1c3DsMUO]]></content>
      <categories>
        <category>RS</category>
      </categories>
      <tags>
        <tag>MODIS</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[迟到的2017总结文]]></title>
    <url>%2F2018%2F01%2F10%2F%E8%BF%9F%E6%9D%A5%E7%9A%842017%E6%80%BB%E7%BB%93%E6%96%87%2F</url>
    <content type="text"><![CDATA[悄然过去的2017年，仿佛还来不及说再见。突然想起那天科比球衣退役时热泪盈眶地在宿舍看直播的自己。 默默做个总结来迎接新的一年。 2017年走过的城市还蛮多的。一年下来，半年北方，半年小厦门。参加的学术活动也算不少，也算有些小成果。不过我想这一年来在github和博客上确实花了不少功夫，对于开源、编程，自己也有了更深入的了解。 2017年博客一共发了44篇博客，第一次利用github搭建了自己的主页和博客。而自己的各种博客也是基本同步。 对整体的博客内容做些梳理。 第一部分：技术实践笔记杂谈，像学了半天Fortran开始配环境的、装WRF的、Hexo和NexT优化的、装系统的。 第二部分：R语言相关的编程笔记，R算是我现在比较熟练的语言，当然去年特地为了记录公选课学习内容，连载了一系列的应用统计学与R语言实践笔记（也是github上开源了的项目，前几天被人forked了下，还有点小激动）。 第三部分：地理、生态、GIS相关的，阅读量最高的MODIS系列——其实也是源自我上课的实习内容。其实今天在回顾过去的一些基础知识，发现课堂上掌握得确实还不够，仍然需要好好温习。 第四部分：学习方面的感受，esri用户大会，定量遥感讲座。 新的一年先立些flag。 （一）机器学习笔记——最近在学习吴恩达大大的公开课，希望有所斩获。有空会更新这部分的笔记。 （二）空间统计内容——这里还是要推荐虾神的白话空间统计系列，但是我也想对之前自己学习空间统计内容做些梳理（最近正在看莫兰指数推导——嗯，死去活来），数学恐惧症就跳过吧。 （三）论文推荐和阅读——我可能会把阅读文献内容也放到博客内。 （四）研究成果推荐——虽然成果不多，但也会考虑，哈哈。 如果你们还对我的博客有啥建设性意见。欢迎留言。 var options = {"narrow":false,"autoplay":true,"showlrc":0,"mode":"random","music":[{"title":"灌篮高手","author":"青春","url":"http://oyo5uzjmz.bkt.clouddn.com/BAAD%20-%20%E5%90%9B%E3%81%8C%E5%A5%BD%E3%81%8D%E3%81%A0%E3%81%A8%E5%8F%AB%E3%81%B3%E3%81%9F%E3%81%84.mp3","pic":"http://oyo5uzjmz.bkt.clouddn.com/SD.jpg"}]}; options.element = document.getElementById("aplayer1"); new APlayer(options);]]></content>
      <categories>
        <category>Personal</category>
      </categories>
      <tags>
        <tag>Summary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu下口袋妖怪终端主题安装]]></title>
    <url>%2F2017%2F12%2F13%2FUbuntu%E4%B8%8B%E5%8F%A3%E8%A2%8B%E5%A6%96%E6%80%AA%E7%BB%88%E7%AB%AF%E4%B8%BB%E9%A2%98%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[之前看到开源中国的文章，介绍了国内最火的开源项目——Python篇。看到一个比较有意思的项目——终端的口袋妖怪主题。之前介绍安装WRF的博客，细心的同学已经发现，我已然安装上了那个主题，今天就来介绍下Ubuntu下口袋妖怪终端主题安装吧。 先上图。 这回先贴出这个链接。 可能是国内最火的开源项目——Python篇 还有做这个主题的github链接。 Pokemon-Terminal github链接 我用的Linux是Ubuntu，接下来就按照这个进行安装。首先这个主题支持的终端模拟器主要是以下三个：iTerm2， Terminology，Tilix。这里选择安装Tilix，首先添加这个终端模拟器仓库的公钥。这里我都是以root超级用户权限操作的，如果没有的话，请在命令前面加sudo。 1add-apt-repository ppa:webupd8team/terminix 1apt update 安装Tilix。 1apt install tilix 然后打开Tilix，并锁定到启动器。 有可能出现配置问题，建议是在bashrc中添加语句。 123if [ $TILIX_ID ] || [ $VTE_VERSION ]; then source /etc/profile.d/vte.shfi 具体问题可参照如下网址：终端配置 接下来设置配置方案。 不过下面的教程是针对该主题的1.0.7版本，目前主题已经更新到1.1.1版本。如果现在安装的话，更方便的方式是，先安装Python3.6，同时安装setuptools（推荐新立得安装），然后下载github仓库。接着只需要如下的命令即可。 1sudo python3.6 setup.py install 下面的npm安装方式只针对之前的版本（只是顺带记录，不过现在也提供了这个方式，但还是建议上面的安装方法）然后安装npm，最主要Ubuntu16.04默认有个python3.5.2，npm直接安装是跟Python版本对应，而新主题要求在3.6的Python以上，也可以考虑升级原有的Python。 1apt install npm 接着安装pokemon-terminal。 1npm install --global pokemon-terminal 大功告成。 主要参考：国外大神安装教程]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Windows和Linux双系统安装教程]]></title>
    <url>%2F2017%2F12%2F12%2FWindows%E5%92%8CLinux%E5%8F%8C%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[最近刚刚完成了Windows和Linux双系统（这里以Ubuntu安装为例）的安装，应某奔同学要求，这里简单记录下安装过程。 1 系统启动盘准备因为不想装第二个系统的时候重做系统盘，所以这里做的系统启动盘本身就是Windows和Linux双系统引导的。这里用的工具前面在docker安装笔记的时候已经介绍过：YUMI。可以翻翻前面的博客进行了解。 花式安装蓝鲸鱼札记 百度搜索的时候，要准确定位，请搜YUMI USB，如果想了解点其他的（咳咳咳），去掉USB。不过另外一点是有人推荐用EFI的版本（虽然觉得差别不大），制作系统启动盘前面的博客也介绍过了。唯一要注意的就是为了做成多引导启动，在选择windows系统制作的时候，记得选择multiboot。 2 Windows系统安装Windows和Linux双系统安装，通常是选择先装Windows，然后再安装Linux，最后通过Windows引导Linux系统启动。 Windows安装是比较方便的，网上教程颇多，对于还没有系统的电脑来说，其实就是把做好的启动盘插入，然后狂按某FX键（反正视电脑型号和品牌而定）。主要是设置boot，选择从U盘启动。如果是在Windows系统下重装系统，就只需要把我们的系统盘放进去。然后双击setup.exe就好了。 3 分出给Linux系统的磁盘空间安装完成之后，首先先从Windows的磁盘里面分出給Linux系统的空间。 右击”我的电脑”→”管理”→”存储”→”磁盘管理” 接下来只要选择你要分出空间的盘，右击压缩卷。这个画红圈的就是设置Linux系统的大小，1024M是1G，根据情况分区。 4 安装Linux系统接下来就插入系统启动盘，重启电脑，通常系统启动盘会引导进入图形安装界面，选择Linux安装。Ubuntu这里会让你选择Win10和Ubuntu共存，还是清除Windows系统，还有一个其它选项，这里选择其它选项。接下来就是Linux系统分区了。这个分区的内容以及具体安装教程参照前面的博客，之前在虚拟机上安装Ubuntu的时候我已经提过了，这里就不详细介绍。 VMware Workstation下安装Ubuntu 64位系统 注意：分区分完了，不能直接安装，最后选用引导的选项必须改选为前面Linux分区里面的”/boot”分区。不能选U盘，也不能选其他盘。然后就可以一路安装了。最后重启电脑。 于是——你发现开起来还是Windows。嗯，主要原因需要用一个多重系统启动引导的文件，这个时候最后一个主人公就要登场了。 5 EasyBCD安装使用最后一个主人公就是EasyBCD啦，这个软件是用于系统配置创建多重启动系统的引导文件，也就是新创建一个启动文件，可以让你的电脑在启动的时候，有进入何种系统的选择。 EasyBCD官网地址 “添加新条目” -“Linux/BSD”-类型“Grub 2”驱动器“自动定位和加载”-“添加条目” 一波操作猛如虎。然后重启电脑就可以了。 最后效果。 顺带感谢一波网上大神，附上链接。 知乎：怎样安装 Windows 7 与 Linux 的双系统？ 电脑安装双系统（win+Linux）的一些重要步骤总结]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>Windows 10</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python开篇——简介、pip和conda]]></title>
    <url>%2F2017%2F11%2F29%2FPython%E5%BC%80%E7%AF%87%E2%80%94%E2%80%94%E7%AE%80%E4%BB%8B%E3%80%81pip%E5%92%8Cconda%2F</url>
    <content type="text"><![CDATA[人生苦短，我用Python。 那我还是来介绍一下它（凑一波字数）吧。 Python（英国发音：/ˈpaɪθən/ 美国发音：/ˈpaɪθɑːn/）, 是一种面向对象的解释型计算机程序设计语言，由荷兰人Guido van Rossum于1989年发明，第一个公开发行版发行于1991年。Python是纯粹的自由软件， 源代码和解释器CPython遵循 GPL(GNU General Public License)协议。Python语法简洁清晰，特色之一是强制用空白符(white space)作为语句缩进。Python具有丰富和强大的库。它常被昵称为胶水语言，能够把用其他语言制作的各种模块（尤其是C/C++）很轻松地联结在一起。常见的一种应用情形是，使用Python快速生成程序的原型（有时甚至是程序的最终界面），然后对其中有特别要求的部分，用更合适的语言改写，比如3D游戏中的图形渲染模块，性能要求特别高，就可以用C/C++重写，而后封装为Python可以调用的扩展类库。需要注意的是在您使用扩展类库时可能需要考虑平台问题，某些可能不提供跨平台的实现。7月20日，IEEE发布2017年编程语言排行榜：Python高居首位 。 百度百科 也有不少新闻提了，Python在数据科学领域位居首位。可以说接着深度学习和机器学习的火热，Python再次大热了一波，当然说Python是深度学习的语言也不准确，事实上深度学习里的Python主要是胶水语言的作用，比如大家喜闻乐见的Tensorflow，其实底层是C++，只不过提供了Python接口。 总体来说Python就是一句话，写得快，跑得慢。同样的功能实现，C和C++可能要100行，Python可能只需要10行（数字不一定准，但是能节省写的时间是真的）。同时最强大的大概是Python丰富和强大的库了（这点跟R还是蛮像的，所以都很流行）。 这里简介一些重点库。 1 Python常用库爬虫：Scrapy（举世闻名，分布式爬虫框架，不仅仅是简单的库）、beautifulsoup4、urllib、urllib2、selenium等。 机器学习：scikit-learn（灰常牛逼的一个库，几乎所有机器学习算法都囊括了应该），NLTK（自然语言处理工具包 ）等（用一个等的原因是，说起来除了scikit-learn，我还真不知道还有啥，hhh）。 网站：Django（重量级网页框架）、Flask（轻量级网页框架）等。 数据处理科学计算：Numpy（数组矩阵神器）、Scipy（科学计算神器）、Pandas（熊猫包，R语言玩家转Python的最爱）等。 可视化：matplotlib（matlab风格式的包）、seaborn（散点图矩阵神器）、ggplot（R语言可视化神器的Python版本）、plotly（这个神器是个js库，不过也有各种流行的语言接口）等。 深度学习：看知乎吧（强行蹭一波热点，深度学习是机器学习的一部分） 地学相关：basemap（画地图的库）、cartopy（画地图的库）、Folium（leaflet的Python版本 ）、GDAL（开源GIS库）、geocoder（地理编码神器）、geopandas（地理数据的熊猫包）、geopy（还没玩过）、PySAL（空间计量经济学的一个神包）等（跟地学相关的包实在太多，后面有空的话，考虑会重点介绍几个包）。 另外这里多提两个关于ArcGIS的包，一个是arcpy，熟悉ArcGIS的同学知道，这个是ArcGIS内嵌Python的神器，可以非常方便调用ArcGIS各项功能，但是有一点就是不开源（毕竟人家是商业软件嘛，所以那些老想着在自己安装的Python上import arcpy的同学可以省省功夫了），另外多提一个Esri公司新推出的ArcGIS API for Python，这个在前面的用户大会观感上提到过，是基于portal和online的一套API，还是有些可以玩的价值，后面也会考虑介绍这个内容。 2 Python安装安装这个事情实在太小了。毕竟开源语言，一路next安装完毕。唯一问题可能是要配个环境变量。 Python官网 顺带一提就是现在的2.0和3.0之争。Python 2.0到3.0过渡确实还做得一般，但是3.0有它的好处，2.0目前就是比较稳定。很多包都暂时没迁移到Python3.0上。但是最近numpy的一个通知，正在显示3.0时代的到来。 numpy团队宣布2020年停止支持2.0 笔者自己也还是用的2.7，不过还是在考虑学习3的事情（其实也不是很麻烦），如果你刚刚起步就从3.0开始也没毛病。 当然如果为了科学计算，可以考虑直接安装Anaconda，而不是从Python开始一步一步安装。 anaconda （一个开源的Python发行版本）anaconda指的是一个开源的Python发行版本，其包含了conda、Python等180多个科学包及其依赖项。[1] 因为包含了大量的科学包，Anaconda 的下载文件比较大（约 500 MB），如果只需要某些包，或者需要节省带宽或存储空间，也可以使用Miniconda这个较小的发行版（仅包含conda和 Python）。 百度百科 3 pip和conda最后讲讲题目里的这俩货，其实conda在上面介绍Anaconda的时候已经讲到了，这两个都是Python包管理的工具。还是很不错的。这个部分也介绍下这两个工具怎么用。 pip安装就不提了，不清楚可以自己百度。 安装包的命令如下： 1pip install packages 然而一顿操作猛如虎之后。 事实上，我们去找一下pip的文件就明白为什么了。 位置是Python安装路径/Scripts下。pip是个exe呀。这回只要打开cmd，定位到pip的exe文件夹下，然后pip install就OK了。用查看已经安装的包的命令测试。 1pip list conda其实功能命令跟pip差别不大，这里就不多做介绍了。也是献上conda查看包的结果图。]]></content>
      <categories>
        <category>Coding</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo博客评论新神器——Valine]]></title>
    <url>%2F2017%2F11%2F24%2Fhexo%E5%8D%9A%E5%AE%A2%E8%AF%84%E8%AE%BA%E6%96%B0%E7%A5%9E%E5%99%A8%E2%80%94%E2%80%94Valine%2F</url>
    <content type="text"><![CDATA[接着前文的hexo博客继续优化。其实也没什么大动作，这回主要是对评论系统做些整理。本文如题目所示：介绍一个神器，Valine。 本来hexo博客用的是gitment，我也非常喜欢，看着逼格就超高呀。无奈我用着bug略多，而且毕竟有github账户的小伙伴似乎并不多。于是我就忍痛准备换评论系统。然后在最近刚刚加入的hexo博客群里，看见了一个神器。也就是本篇主人公——Valine.js。 具体配置就见如下的文章吧。它的定义—— 一款极简的无后端评论系统。 在多说和网易云跟帖相继倒闭的情况下，这个简直是救人一命胜造七级浮屠呀。 Valine – 一款极简的评论系统 Valine官网 这个评论系统是基于LeanCloud的，大家应该对这个很熟悉，对，Hexo的博客阅读量统计也是它。官网网址如下，需要注册一个账户。 LeanCloud官网 另外多提一句，最近为了更好更快升级，我重新在本地部署了下我的hexo博客，就是把NexT主题利用Git方式克隆到本地，以后升级就比较快了。这个内容可以参见官网。也因为克隆了最新版本，发现已经集成了gitment和valinejs（神速）。所以配置起来就很方便了。 这里重点讲一下关于邮件提醒的事。 这样设置一下就可以了。不清楚的查看下面的链接也可以。 valline详细配置官网 Valine 评论系统中的邮件提醒设置 最后多说一句。支持导出评论和数据分析。]]></content>
      <categories>
        <category>Coding</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo+NexT博客优化第二弹]]></title>
    <url>%2F2017%2F11%2F22%2Fhexo%2BNexT%E5%8D%9A%E5%AE%A2%E4%BC%98%E5%8C%96%E7%AC%AC%E4%BA%8C%E5%BC%B9%2F</url>
    <content type="text"><![CDATA[最近对hexo和NexT博客又做了一次优化。主要干了三件事。 博客地址 顶部加载条实现： 这个如果用的是比较新的NexT主题，只需要在配置文件里面进行修改就可以了。旧的话，就需要对/next/layout/_partials/head.swig文件做些修改，添加对应的代码。 123456789101112131415&lt;script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"&gt;&lt;/script&gt;&lt;link href="//cdn.bootcss.com/pace/1.0.2/themes/pink/pace-theme-flash.css" rel="stylesheet"&gt;&lt;style&gt;.pace .pace-progress &#123;background: #1E92FB; /*进度条颜色*/height: 3px;&#125;.pace .pace-progress-inner &#123;box-shadow: 0 0 10px #1E92FB, 0 0 5px #1E92FB; /*阴影颜色*/&#125;.pace .pace-activity &#123;border-top-color: #1E92FB; /*上边框颜色*/border-left-color: #1E92FB; /*左边框颜色*/&#125;&lt;/style&gt; 具体的可以点击上次那篇推荐的文章。 hexo的next主题个性化教程：打造炫酷网站 另外就是增加了词云和运行时间。 词云其实就是标签做的，放在侧边栏上。需要安装插件。 npm install hexo-tag-cloud@^2.0.* --save 接着在next/layout/_macro/sidebar.swig添加如下内容。 123456789101112&#123;% if site.tags.length &gt; 1 %&#125;&lt;script type="text/javascript" charset="utf-8" src="/js/tagcloud.js"&gt;&lt;/script&gt;&lt;script type="text/javascript" charset="utf-8" src="/js/tagcanvas.js"&gt;&lt;/script&gt;&lt;div class="widget-wrap"&gt;&lt;h3 class="widget-title"&gt;Tag Cloud&lt;/h3&gt;&lt;div id="myCanvasContainer" class="widget tagcloud"&gt;&lt;canvas width="250" height="250" id="resCanvas" style="width=100%"&gt;&#123;&#123; list_tags() &#125;&#125;&lt;/canvas&gt;&lt;/div&gt;&lt;/div&gt;&#123;% endif %&#125; 运行时间的话，在next/layout/_custom/sidebar.swig文件中先添加。 123456789101112131415161718192021222324252627&lt;div id="days"&gt;&lt;/div&gt;&lt;/script&gt;&lt;script language="javascript"&gt;function show_date_time()&#123;window.setTimeout("show_date_time()", 1000);BirthDay=new Date("05/27/2017 15:00:00");today=new Date();timeold=(today.getTime()-BirthDay.getTime());sectimeold=timeold/1000secondsold=Math.floor(sectimeold);msPerDay=24*60*60*1000e_daysold=timeold/msPerDaydaysold=Math.floor(e_daysold);e_hrsold=(e_daysold-daysold)*24;hrsold=setzero(Math.floor(e_hrsold));e_minsold=(e_hrsold-hrsold)*60;minsold=setzero(Math.floor((e_hrsold-hrsold)*60));seconds=setzero(Math.floor((e_minsold-minsold)*60));document.getElementById('days').innerHTML="已运行"+daysold+"天"+hrsold+"时"+minsold+"分"+seconds+"秒";&#125;function setzero(i)&#123;if (i&lt;10)&#123;i="0" + i&#125;;return i;&#125;show_date_time();&lt;/script&gt; 接着在next/layout/_macro/sidebar.swig文件中修改。 123456789101112131415161718&#123;# Blogroll #&#125;&#123;% if theme.links %&#125; &lt;div class="links-of-blogroll motion-element &#123;&#123; "links-of-blogroll-" + theme.links_layout | default('inline') &#125;&#125;"&gt; &lt;div class="links-of-blogroll-title"&gt; &lt;i class="fa fa-fw fa-&#123;&#123; theme.links_icon | default('globe') | lower &#125;&#125;"&gt;&lt;/i&gt; &#123;&#123; theme.links_title &#125;&#125;&amp;nbsp; &lt;i class="fa fa-fw fa-&#123;&#123; theme.links_icon | default('globe') | lower &#125;&#125;"&gt;&lt;/i&gt; &lt;/div&gt; &lt;ul class="links-of-blogroll-list"&gt; &#123;% for name, link in theme.links %&#125; &lt;li class="links-of-blogroll-item"&gt; &lt;a href="&#123;&#123; link &#125;&#125;" title="&#123;&#123; name &#125;&#125;" target="_blank"&gt;&#123;&#123; name &#125;&#125;&lt;/a&gt; &lt;/li&gt; &#123;% endfor %&#125; &lt;/ul&gt; &#123;% include '../_custom/sidebar.swig' %&#125; &lt;/div&gt; &#123;% endif %&#125; 觉得需要调整颜色的还可以在/next/source/css/_custom/custom.styl加入如下的语句。 1234567// 自定义的侧栏时间样式#days &#123; display: block; color: rgb(7, 179, 155); font-size: 13px; margin-top: 15px;&#125; 另外参照着增加了Readme，增加了一些图标等。 有找到了几篇还不错的文章。以及本次优化参考的主要文章链接。 打造个性超赞博客Hexo+NexT+GithubPages的超深度优化 在移动设备下启用NexT主题的目录页面和回到顶部按钮 Hexo博客中使用标签云hexo-tag-cloud Hexo 标签云插件github地址]]></content>
      <categories>
        <category>Coding</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Endnote使用小记]]></title>
    <url>%2F2017%2F11%2F20%2FEndnote%E4%BD%BF%E7%94%A8%E5%B0%8F%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[如何高效快速管理阅读的文献是研究生学习中的第一步。这里就推荐下目前正在使用的Endnote（当然还有其他平台，这里就对我用的Endnote重点介绍下）。这里提三个简单的功能小记。 1 导入Web of Science的参考文献首先是进入Web of Science首页，这里顺带提供一个外网访问的方法。使用机构登陆，选择中科院CAS。 原理是中科院集成在WOS的机构用户登录中，是机构用户登录中唯一一个国内授权账号体系，任何用户只要注册了中国科技网通行证（目前为免费注册）即可通过该机构用户转至登录，即可实现利用中科院机构账号访问WOS的若干数据库。 具体可以参照如下的链接：科研干货之——随时随地访问Web of Science 有用过地理空间数据云的同学应该会对这个通行证比较熟悉，是同一个通行证。具体注册就不讲了。 这次选择的样例文章是：Urban Energy Index for Buildings (UEIB): A new method to evaluate the effect of urban form on buildings’energy demand。 来自于景观生态学中除了Landscape Ecology之外的另一本旗舰刊物——Landscape and Urban Planning。 勾选，并点击保存至“Endnote desktop”。 记录内容选择包括摘要的那个（这个其实根据个人需求）。 存储ciw文件。 Endnote中操作。 选择Web of Science Core Collection(TR)和Unicode(UTF-8) 接着就成功导入了。可以点击画圈部分链接pdf。 2 在Endnote上做笔记在看的时候我们想做些简单的笔记。 确实这篇文章最大亮点之一就是这个图摘要。第一眼就看到了这个图之后，我就直接点击下载了。 3 在Endnote上做文献阅读后的Summary在看完英文文献之后，我觉得必要的工作是做summary。那么如何在Endnote上做这个工作呢？ 首先点击“edit” Note或者Research Notes都可以。 双击打开，可以在这两个下面写你的summary 保存之后还可以显示在首页。 具体的还可以看知乎上的解答。 EndNote X7 如何做笔记？]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>Endnote</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何实现一个以中国为中心的世界地图]]></title>
    <url>%2F2017%2F11%2F14%2F%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E4%BB%A5%E4%B8%AD%E5%9B%BD%E4%B8%BA%E4%B8%AD%E5%BF%83%E7%9A%84%E4%B8%96%E7%95%8C%E5%9C%B0%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[最近屡屡有小伙伴为各种目的在询问有没有中国位于中心的世界地图。在某位同学的强烈要求下，我决定稍微记录下这个以我大中华为中心的世界地图的做法。效果图： 原始数据。 1 ArcGIS第一种就简单介绍下ArcGIS平台上如何操作吧。 首先在ArcGIS软件中，右击Layers（图层）→Properties（属性）→Coordinate System（坐标系） 然后如图所示点击生成一个新的Projected Coordinate System（投影坐标系）。 按照如图所示设置。 并用Save As，导出一个.prj的投影文件。 接着用Arctoolbox的投影工具进行投影变换（我本身数据是WGS1984的地理坐标系）。 选择投影的时候可以直接import。 等待运行。 结果图。 如上，其实过程不复杂。最关键的这个使得中国能居于中间的原因是投影参数里面的第三个参数——Central Meridian，也就是中央经线。有兴趣还可以自行调整，我这里设150结果如上，也可以自行设定，只需要双击投影文件修改属性即可。 2 R第二种介绍下R语言的方法。R语言做空间数据的这些处理最主要的两个包就是sp和rgdal。所以在处理前请先安装这两个包。 接下来直接进入正题。 我们需要先读入空间数据，然后对空间数据进行投影变换。 如何读空间数据就请点击前面我写过的文章，戳 其实关键步骤就是用prj4字符串构造出我们需要的投影坐标系。关于这一点，推荐看下面的这篇博客学习。 坐标详解与PROJ.4使用说明 此外推荐几个网站用来查询相关坐标系信息。 epsg开源查询网站，托管在github上 空间参考官网网站 OGR驱动中的矢量格式、读写情况以及代码 这里直接给出对应的prj4字符串。”+proj=eqc +lat_ts=30 +lat_0=0 +lon_0=150 +ellps=WGS84 +datum=WGS84 +units=m +no_defs” 用sptransform转换投影坐标系，结果如图。 打完收工。 贴个R语言源码图。]]></content>
      <categories>
        <category>GIS</category>
      </categories>
      <tags>
        <tag>ArcGIS</tag>
        <tag>R</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[花式安装蓝鲸鱼札记]]></title>
    <url>%2F2017%2F11%2F08%2F%E8%8A%B1%E5%BC%8F%E5%AE%89%E8%A3%85%E8%93%9D%E9%B2%B8%E9%B1%BC%E6%9C%AD%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[大家好，蓝鲸鱼又来了。 自从上篇搞完蓝鲸鱼在Win 7下安装之后，笔者就看到了另一篇文章。 Win10 Docker 安装使用 感觉仿佛很棒的样子。于是我们就开始愉快地新系（zuo）统（si）旅程，笔者顺手就升级了Win 10系统。这里顺带介绍一个神器。 YUMI是一个多系统USB启动盘制作的软件。最早是在知乎回答上看到。 如何制作支持安装多系统（Win/Linux）的U盘启动盘？ YUMI官网 也可以点击这个百度网盘地址 操作手册。 一键安装即可。 好。回到正题。Win 10升完之后，我遇上了各种有的没的bug。。。包括蓝鲸鱼！ 当然还是先简介下怎么安装。 算了。。。自己看官网文档去。 官网 简单地说。我遇上的问题就是如下。 其实总结起来，就是网络网卡一些问题。百度、必应、谷歌都未果。但是在github上找到了对应的issues。 Hyper-V was unable to find a virtual switch with name “DockerNAT”. 然后历经磨难，突然发现，是我的毒霸把一堆服务给禁止了。然后没有按顺序一个个开启，一堆毛病。于是就愉快地开启docker之旅。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Win7下蓝鲸鱼安装以及Xshell连接操作]]></title>
    <url>%2F2017%2F11%2F06%2FWin7%E4%B8%8B%E8%93%9D%E9%B2%B8%E9%B1%BC%E5%AE%89%E8%A3%85%E4%BB%A5%E5%8F%8AXshell%E8%BF%9E%E6%8E%A5%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[我爱吃金拱门，开封菜也不错，但我觉得最好吃的是小红帽，那我们就来安装个蓝鲸鱼吧。 1 Docker简介隆重推出我们的主人公——蓝鲸鱼，Docker先生。 接下来让我抄一段百度百科的简介。 Docker （基于Go语言开发！基于Go语言开发！基于Go语言开发！）是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。容器是完全使用沙箱机制，相互之间不会有任何接口。看不够的点这里，看不懂的点这里。 嗯，所以这东西吧，你可以把它当成小型虚拟机，貌似目前的需求也差不多，配置消耗相对虚拟机小得多，相对来说能快速部署环境是个优点。 具体的也可以查看Docker官网 2 Win 7下安装过程目前来看，Docker跟Linux和MacOS系统应该还是更相容的，但是毕竟我们是研究GIS的人员，Windows才是王道（谁让ArcGIS只有windows版本呢？呃，不过其实QGIS和GRASS GIS就有各种平台版本，功能也相当强大)。那么如何在Win 7下安装Docker呢？其实这样子我们通过Docker去运行Linux环境（用Docker的话讲，这叫容器）的话，相对更方便些，消耗资源也比虚拟机小，这也是我开始安装的目的。本文就来介绍下。 目前Docker在Win 10最新系统安装已经十分方便，而且不需要依赖Virtual Box。 具体就看官网吧 直接下载Docker for Windows的app安装就可以。 而Win 7的话，上面那个不支持，所以还得依赖Virtual Box（其实说来还是得靠虚拟机）。接下来就来讲讲怎么安装吧。 Win 7上使用Docker Toolbox.exe进行安装。 github下载地址，但是这个地址国内下载很慢（而且似乎不是很新，也可以从Docker官网下载）。可以用下面的另一个地址。 下载地址 下载下来之后，就只需双击exe开始安装。 如果第二步已经安装过Git和Virtual也可以不勾选，中间还会让安装Oracle的一些东西，全部安装即可。但是后面就不能直接双击.sh文件运行docker了，得在git bash下面运行。 安装完毕之后，应该会出现这两个文件。 通常双击什么的快速启动终端就可以了，第一次需要配置花的时间久一点。或者也可以到Docker安装文件夹下，双击.sh文件。不过后面发现这会报错，找不到boot2docker.iso文件，而这个文件就在Docker安装文件夹下。 先将这个iso文件拷贝到，C:[用户]Administrator.docker\machine\cache下，再运行就.sh文件或者运行Docker Quickstart Terminal就成功了。 3 用Xshell连接自己的Docker用单纯的命令行有很多限制，一般可以用终端模拟器来连接，这里用的Xshell，也可以用其他终端模拟器。 这里用户名为docker，密码为tcuser（默认）。 连接成功。接下来运行个hello world。 docker run hello-world 4 docker hub注册这个就是可以将自己的镜像push到仓库里的账户，登陆的话，只需要敲入如下命令。 docker login 填入账户和密码即可。 账户名最好用小写字母和数字即可。 一些参考博客及文档。 创建Docker Hub账号&amp;库 你的Docker Hub账户 使用Docker Hub | Docker 中文指南 DOCKER windows 7 详细安装教程 Windows7 上运行docker实战 完整记录在 windows7 下使用 docker 的过程 Docker在windows下的使用【一】]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hugo使用备忘录]]></title>
    <url>%2F2017%2F11%2F05%2Fhugo%E4%BD%BF%E7%94%A8%E5%A4%87%E5%BF%98%E5%BD%95%2F</url>
    <content type="text"><![CDATA[最近在github上发现了除了hexo外的另一个静态网页神器：hugo，这里就简单记录下使用的一些记录。 这里抄一下hugo官方文档的介绍。 Hugo是由Go语言实现的静态网站生成器。简单、易用、高效、易扩展、快速部署。 官方文档地址 这里多说几句Go语言。该语言貌似最近挺火热，很多人看好的一门新语言。以后有空闲可以考虑看看这个语言，不得不说最近在考虑使用docker的问题（配置环境十分方便），突然发现这东西好像也是Go写的。 进入正题，使用hugo其实没那么麻烦，因为可以用编译好的exe文件（windows系统下）。具体的安装教程见如下： Install hugo 翻译一下：第一步，从Hugo Release页面下载hugo的压缩包。第二步，在你喜欢的地方创建一个Hugo和bin的文件夹：’C:\Hugo\bin\’。第三步，将下载的压缩包放到刚刚建立的文件夹里面。第四步，解压压缩包文件，提取hugo.exe到’C:\Hugo\bin\’里。第五步，在你的windows环境变量中加入Hugo exe路径。 顺带一提，最近用hugo的原因是，刚刚发现的一个开源hugo的学术主页框架项目。 项目地址 接着就开始建立站点了。 在你的Hugo exe所在文件夹下打开cmd（按住shift右击，可以在当前文件夹打开cmd）。 hugo new [创建站点文件夹路径名字] 这样就算创建好了。接下来就只需要拷贝主题即可，用git clone，这里需要开启Git bash。 拷贝主题之后，针对配置文件进行修改。主要修改的是content里的一些markdown的文档。其实是各个主页。而其他配置则通过根目录的config.toml，熟悉hexo的同学上手速度应该快一些，跟.yml文件类似。 接下来记录一些常用命令。 本地预览命令。 hugo server 访问端口，localhost:1313。 生成public文件夹，baseUrl填部署的仓库地址，这里用的github部署。 hugo --theme=academic --baseUrl=&quot;https://xxxx&quot; 切换到public文件夹，并push到远程仓库。 cd public git init git remote add origin https://github.com/xxxx/xxx.git(从仓库的clone那里复制) git add -A git commit -m &quot;first commit&quot; git push -u origin master 之后的更新就只需要后面三句命令就可以了。]]></content>
      <categories>
        <category>Coding</category>
      </categories>
      <tags>
        <tag>hugo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo博客优化相关内容]]></title>
    <url>%2F2017%2F10%2F31%2Fhexo%E5%8D%9A%E5%AE%A2%E4%BC%98%E5%8C%96%E7%9B%B8%E5%85%B3%E5%86%85%E5%AE%B9%2F</url>
    <content type="text"><![CDATA[记录最近hexo博客优化的一些网址。我的博客 增加了RSS订阅，支付宝打赏，建站时间，博客版权许可，动画效果。这里参照的主要是NexT官网文档。 NexT官网文档 另外支付宝打赏功能似乎有些bug，参照下面的帖子做了修改。 hexo的next主题打赏 接着后面增加了评论功能（就在多说倒闭后不久）。使用的是Gitment。 感谢大神。 Gitment：使用 GitHub Issues 搭建评论系统Hexo博客框架下Gitment取代多说评论 效果： 然而不满足的我顺带增加了留言板（hhh），并在留言板上加上了音乐播放器。 参考博客： 给Hexo添加留言板 知乎提问·给Hexo添加留言板？ Hexo博客中插入音乐 hexo添加音乐、high一下及一些坑 怎样用七牛空间获得音乐外链 效果： 顺带一提，挖到了篇好文章。 hexo的next主题个性化教程：打造炫酷网站 现在又增加了字数统计、访客统计、Fork me on github等（参照的是上文和官方文档）。 效果如下： 还有添加日历的功能。但是似乎没见到用在NexT上的。先存下地址，后面有空研究一下。 Hexo主题中添加日历云功能 Hexo日历插件 接下来多实现一个功能，在留言板中增加一个访客地理分布功能。 基于以下的网址： revolvermaps 只需复制代码，放在markdown文档中就OK。 效果： 不过后面发现有些问题在本地预览能够显示，但是在github上部署完后，网页无法显示。目前就先去掉了。等后期再研究。]]></content>
      <categories>
        <category>Coding</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017第十五届esri用户大会观感（二）——大会整体]]></title>
    <url>%2F2017%2F10%2F31%2F2017%E7%AC%AC%E5%8D%81%E4%BA%94%E5%B1%8Aesri%E7%94%A8%E6%88%B7%E5%A4%A7%E4%BC%9A%E8%A7%82%E6%84%9F%EF%BC%88%E4%BA%8C%EF%BC%89%E2%80%94%E2%80%94%E5%A4%A7%E4%BC%9A%E6%95%B4%E4%BD%93%2F</url>
    <content type="text"><![CDATA[上文初步介绍了大会的盛况以及笔者负责的Web App Builder for ArcGIS，本篇来讲讲大会整体观感。总体来说，我觉得本次大会的两大亮点可能不在产品技术本身。而是此次宣布的两大关于产品销售的消息。第一是ArcGIS个人版使用许可推出（960元/年，详情请点击），第二是扶持初创GIS企业的计划（该计划主要面向经营线下或线上的软件产品和服务，员工不超过50人，年营业额不超过一千万人民币的初创企业，提供ArcGIS软件三年的免费使用权）。当然技术上也有些亮点，我会就我的认识来谈一谈。 先谈谈两大亮点，而后聊些具体的技术和应用上看到的。 1 ArcGIS个人版使用许可先来看看960元/年提供了啥。 ArcGIS Pro，ArcMap，ArcCatalog的桌面高级版许可+桌面版中包括的所有高级分析功能拓展模块。直到工作流管理模块来说，已经涵盖了ArcGIS系列桌面的所有软件和功能，非开发人员需要用的ArcGIS桌面已经全部包括，另外传统的ArcGIS系列只留了ArcMap和ArcCatalog，某种程度来说，esri公司确实在推动ArcGIS Pro替代传统桌面。当然我个人觉得更关键的应该是”ArcGIS Online Level 2 Named User account and 100 Service Credits”。 不知大家有没有注意到前文提到的关于Web App Builder for ArcGIS许可方面的内容，明确要求Level 2成员。ArcGIS Online Level 2成员账户事实上具备了可以使用esri多个app的许可。同时应当拥有一个主页，也就是可以当做公有portal的url地址。 产品的简介如下。事实上ArcGIS Desktop大家还是比较熟悉的，Pro则是新一代桌面，而且是为Web GIS平台打造的桌面应用，它本身可以直连portal，同时又具备多种Web GIS相关关联的功能，二三维一体化可以去参考我前面的博客。其他新特性就暂且不提了。ArcGIS Online是公有云平台，事实上就是公有的和在线版本的portal。 附赠的还有一堆视频和文档。 总的来说，价格相当超值，而且符合esri公司在云计算时代的产品定位规划。 2 关于初创企业支持计划这个，毕竟笔者非企业人士就不瞎逼逼了，个人感觉还是蛮超值的，不过跟当年esri刚进中国在打通高校是一个道理。esri如今能在全世界包括中国占据这么大地理信息市场份额一大原因是因为他们在进入市场时送给各大高校那些软件造就的。现在相信对企业来说也是差不多的。 3 所见所闻由于企业主办的会议，比普通学术会议来说，我个人感觉是见到更多的落地项目，也见到了更多接地气的应用，当然逼格依旧在。印象比较深的包括今年获评esri用户最佳应用奖之一的“智慧宁波时空信息云平台”。当然原因主要还是笔者最近有些宁波这块研究的任务。基于portal for ArcGIS搭建的云平台，在辅助智慧城市建设方面，可以说走出了坚定的一步。ps，宁波市规划局没记错的话，似乎和百度慧眼也有合作，应该算是国内规划信息化走得很前端。 还有是江苏省的互联网+国土资源服务平台。 接下来聊一聊web平台中的另外两架马车（ArcGIS API for Javascript和ArcGIS API for Python）。JS API演示demo十分丰富，最主要是基于4.5版本的API，听到了两个比较大的亮点。 一个是点云数据支持渲染（在线地址）。 激光雷达和倾斜摄影的技术使得三维建模越来越快速。而JS 4.5 API是esri最主要做三维web的版本。 另外一个应该是号称可以渲染大数据的JS API，不过后面据闻需要ArcGIS Enterprise 10.6版本发布的服务支持（在线地址）。 ArcGIS API for Python的话，这次看到的是基于scikit-learning和esri存储的landsat数据实现遥感分类的相关样例。关于landsat存储的可以见虾神博客。此外值得推荐的是另外一个web appLandsat Explorer web app，来源于2017 esri 全球用户大会。 很多demo可以在体验中心查看。 另外ArcGIS runtime SDK现在可以实现.Net跨平台开发，以及三维支持。当然还有Geoevent，GeoAnalytics Server，矢量切片，无人机等多种技术。 很凑巧，今天esri官方放出了主题演示的一些视频。详情请点击 记录些观感。欢迎交流。]]></content>
      <categories>
        <category>GIS</category>
      </categories>
      <tags>
        <tag>ArcGIS</tag>
        <tag>ArcGIS Pro</tag>
        <tag>ArcGIS Online</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017第十五届esri用户大会观感（一）——WAB敏捷开发]]></title>
    <url>%2F2017%2F10%2F30%2F2017%E7%AC%AC%E5%8D%81%E4%BA%94%E5%B1%8Aesri%E7%94%A8%E6%88%B7%E5%A4%A7%E4%BC%9A%E8%A7%82%E6%84%9F%EF%BC%88%E4%B8%80%EF%BC%89%E2%80%94%E2%80%94WAB%E6%95%8F%E6%8D%B7%E5%BC%80%E5%8F%91%2F</url>
    <content type="text"><![CDATA[2017年10月24日和25日，在北京国际会议中心召开了第十五届esri用户大会。本次会议的主题围绕着slogan的理念提出的”Applying The Science of Where”，一共有6大主题报告，6大技术论坛，10大行业论坛，业界称为GIS届的饕餮盛宴。从Enabling a Smarter World到The Science of Where,大概是走过风风雨雨，看过世界万物最终又返璞归真回到原点去回答，我是谁？我从哪里来？我到哪里去？ 空间贯穿着我们的一生，从子宫到坟墓，人依托着空间而存在，而地理与GIS正是用来理解我们所生存的地球空间的语言。 笔者很荣幸地成为了本届esri用户大会体验区志愿者之一，所负责的产品是esri推出的0代码敏捷开发的Web App Builder for ArcGIS。所以从观感来讲，就先来介绍下Web App Builder for ArcGIS产品吧。 1 Web App Builder for ArcGIS简介ArcGIS WebApp Builder 是Esri在2014年4月份推出的一种直观的所见即所得式 (WYSIWYG) 应用程序，可用于构建 2D 和 3D web 应用程序，而无需编写一行代码。它所包括的强大工具可用来配置功能完备的 HTML 应用程序。添加地图和工具时，您可以在应用程序中看到这些地图和工具并立即使用。 主要功能可通过 Web AppBuilder for ArcGIS 进行以下操作： 创建能在所有设备上运行的 HTML/JavaScript 应用程序。 使用即用型微件构建所需应用程序。 使用可配置的主题自定义应用程序的外观。 在线托管应用程序或在自己的服务器上运行应用程序。 创建自定义应用程序模板。 详情请点击 当然这里有许可相关限制。 2 Web App Builder for ArcGIS在线版敏捷开发正如前面所说，对于许可的限制，事实上目前Web App Builder for ArcGIS必须有ArcGIS Online或者是Portal的支持。而简单地说Web App Builder for ArcGIS有两种版本，一种是在线版本，内置在ArcGIS Online或者Portal中，只需有账户就可以快速搭建，另一种则是独立的开发者版本，需要部署。那我们就先来介绍第一种方式。 第一种方式对于许可有限制，事实上作为试用和测试的话，我们只需要注册一个账户，试用ArcGIS即可享受21天的ArcGIS Online组织2级成员的许可，当然这个也支持ArcGIS Pro等。 至于如何申请请点击：ArcGIS及Online使用许可申请。 接下来进入正题。进行快速的敏捷开发。这是笔者试用账户下托管的数据。我利用ArcGIS Pro发布了一份2016年1月1日到1月7日全国各个县级市空气质量的数据。并做了一张简易热力图。 接着点击“创建”→“使用Web App Builder” 设置好标题、标签和摘要即可创建（也可以选择3D，这里就选择2D）。 这里可以选择任意一个主题。也可以设置颜色以及布局 接着点击”地图”，选择所需要的数据和底图。这里选择了做好的”Urban Air”。此外还可以选择地图初始化的范围等。 接下来就可以点击”微件”，配置webgis地图的基础功能了。这里最新版提供了超过33个微件，满足webgis地图应用基本需求。 该主题里画框的”微件”分别对应的位置如上。 微件列表。 微件内部配置 最终页面。 最后还可以修改下”属性”，即可。 接下来可以选择保存，或者预览，或者启动。保存即保存在自己的账户项目内，预览可以观察不同尺寸的效果（web app是自适应的html5），启动的话直接访问该应用。 保存完毕即可查看。 也可以下载下来进行部署。下图为访问的页面。 如上是在线版本的敏捷开发。 3 Web App Builder for ArcGIS开发者版本部署前文提到，Web App Builder for ArcGIS有独立的开发者版本，可以下载下来自己部署。不过依旧需要有ArcGIS Online或者portal账户来支撑。 Web App Builder for ArcGIS开发者版本 开发者版本下载下来的文件夹结构。 只需要点击startup.bat运行，即可启动。cmd运行后，在浏览器中输入http://localhost:3345或https://localhsot:3346访问。 与在线版不同的就是，接着就需要你填入ArcGIS Online或者portal的组织url了。同时还需要有个应用ID。 试用账户组织的url可以直接点击组织查询（这个为自己申请试用时设置的）。 所以这里需要先从ArcGIS Online先行创建app，传递ID。首先点击”添加项目”→”应用程序”。 选择”Web制图”→”添加”。笔者测试过，这里必须设置为https://localhost:3346/webappbuilder。 点击”设置”→”注册” 必须做个重定向，将回调地址设为本地（除了localhost还可以设置为计算机名），注册。 即可看到ID。 运行startup.bat，访问https://localhost:3346。 接下来步骤与前面在线版本差异不大。当然也有一个公用的可以使用的portal: http://www.arcgisonline.cn/portal。也可以通过这个进行配置。相关教程在第一篇参考博客中。 整体来说，在用户大会体验区开放的接近一天半的时间内，还是有大量的人对零代码构建web app的工具产生了浓厚兴趣，整体来说大家都在询问的无非是：如何部署在自己的服务器上以及如何进行二次开发，而不仅仅是基于现有的框架。 解答如下：部署在自己服务器上的话必须购买portal for ArcGIS。而由于该工具是以敏捷开发为目的，封装得较好，所以二次开发支持的无非是主题配置和微件使用（具体可见文末的几篇博客）。当然也有大神对源码进行了改动，使其可以不依赖于portal for ArcGIS，这里就不提了（因为某种程度上失去了敏捷开发的特性，当然改完之后的倒是很完美）。 WAB敏捷开发目前来看已经是portal for ArcGIS以及新一代ArcGIS平台web开发的三架马车（另两架分别是ArcGIS API for Python，ArcGIS API for Javascript）了，当然个人理解，仅从我们体验区布设来看。 WAB的敏捷开发实现了一个快速开发的途径，某种程度上也降低了无代码人员开发的难度，本身也具有不错的平台扩展性，演示的demo中有集成了百度Echarts的可视化，当然基于portal for ArcGIS或者ArcGIS Online的这个特性确实在彰显esri公司在云计算时代的应对之策。 最后的最后，我个人觉得该产品可以类比Tableau Public和power BI。当然相对而言，WAB确实更偏向于GIS，而后两者则纯粹考虑可视化。 相关教程学习资料与博客: Web Appbuilder For ArcGIS# 正式版使用教程 配置与使用 webAppbuilder微件使用教程1 快速入门 webAppbuilder微件使用教程2 常用微件介绍 webAppbuilder微件使用教程3 地理处理微件 Webappbuilder开发快速预览 Webappbuilder自定义widget模板 WebAppBuilder自定义主题 ArcGIS WebApp builder 教程（一）简介 ArcGIS WebApp builder 教程（二）入门 ArcGIS Web Appbuilder代码改动为不需要protal步骤初探 Web App Builder For ArcGIS 安装部署使用 ArcGIS WebApp Builder 使用指南]]></content>
      <categories>
        <category>GIS</category>
      </categories>
      <tags>
        <tag>ArcGIS</tag>
        <tag>Web App Builder</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[WRFDA与WRFDA-4DVAR的编译安装]]></title>
    <url>%2F2017%2F10%2F30%2FWRFDA%E4%B8%8EWRFDA-4DVAR%E7%9A%84%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[前面介绍过WRFDA的安装教程了。这次主要是跟着前面的WRF安装程序再次安装下来。参考文档 1 WRFDA（运行三维变分）编译安装事实上在安装完WRF后，再安装WRFDA应该是比较简单的。这里遇到了一个问题。就是hdf5库的安装。按教程似乎必须安装hdf5库。但是前文安装WRF的时候，netcdf安装并没有基于hdf5库编译安装。所以现在再安装的话，也无法编译成功WRFDA(我尝试了挺多次，前面在WRF编译完成后，再安装hdf5，再编译无法成功)，这一点可以在网上找一些教程，网上大多教程都是先安装hdf5和zlib然后再装的netcdf。这一方面我也发了邮件向官方求助，目前还没收到回复，但是先按照如上的安装程序走下来看看。 在编译安装完WRF后，其实WRFDA只需要再设置NETCDF（在不需要hdf5安装的前提下）的环境变量就可以安装，当然需要做辐射传输模型同化的，则可以考虑，WRFDA自带的是CRTM，如果需要用RTTOV的需要在编译前安装并且设置环境变量（我前面的安装教程已经交代过设置环境变量的内容，RTTOV)。这里就不安装了，直接下载WRFDA的源码编译安装。 事实上前文安装WRF的时候已经设置过NETCDF的环境变量，此外前文设置的环境变量也请一一设置。所以这里所需的操作如下。 gunzip WRFDA_V3.9.1.tar.gz tar -xf WRFDA_V3.9.1.tar.gz ./configure wrfda 确实显示了hdf5没有设置环境变量。所以编译出来应该是无法使用这个数据格式同化的。这里依旧选择34。接下来可以开始编译。 ./compile all_wrfvar &gt;&amp; compile.out 接着等待编译完成。用如下的命令查看生成的exe。 ls -l var/build/*exe var/obsproc/src/obsproc.exe 2 WRFDA-4DVAR编译安装WRFDA-4DVAR就是运行四维变分程序同化的模块。至于这个的要求也在之前写WRFDA安装的文章里有介绍。可以翻到前面的博客查看。要安装WRFDA-4DVAR，必须先安装WRFPLUS。 gunzip WRFPLUSV3.9.1.tar.gz tar -xf WRFPLUSV3.9.1.tar cd WRFPLUSV3 ./configure wrfplus 用下面的命令查询生成的exe。 ls -ls main/*.exe 接着设置环境变量。 export WRFPLUS_DIR=/home/Build_WRF/WRFPLUSV3 生成编译的文件。 ./configure 4dvar 开始编译 ./compile all_wrfvar &gt;&amp; compile.out ls -ls var/build/*.exe var/obsproc/*.exe 编译出现跟上面3DVAR相同的44个exe即成功。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>WRF</tag>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[WRF主程序与WPS的编译与安装]]></title>
    <url>%2F2017%2F10%2F13%2FWRF%E4%B8%BB%E7%A8%8B%E5%BA%8F%E4%B8%8EWPS%E7%9A%84%E7%BC%96%E8%AF%91%E4%B8%8E%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[最近重新把WRF学习提上事宜，所以开始重新鼓捣WRF。由于WRF-DA的运行需要依赖WPS程序，这里就填下之前两篇WRF-DA模块编译中挖的坑。即WRF主程序的编译与安装。如果不太清楚的WRF与WRF-DA相关的可以去翻下前两篇博客。 博客地址 最近本来准备换VitualBox来玩虚拟机，结果不小心玩脱了，把之前编译安装好WRF-DA模块的Ubuntu系统删除了，所以只好重头再来了。所以这回我是从WRF主程序等一一安装完，最后再来安装WRF-DA模块。不过这一次按照网上原来的教程装了好多次都失败了，不得已之下，我去请教了WRF官方邮箱。他们给我提供了一份官方安装教程，结果一次成功。这里介绍下这份教程的过程。 WRF官方在线安装教程 1 系统环境测试首先对编译需要的gfortran,cpp,gcc检查是否安装，版本是否匹配。 which gfortran which cpp which gcc gfortran --version gcc --version g++ --version 能显示路径说明已安装，版本检查也未出现。可以发现gfortran并未安装。 apt install gfortran 接下来在安装WRF的文件夹下创建两个文件夹。一个是Build_WRF，一个是TESTS。然后下载Fortran and C Tests Tar File文件，并放入TESTS文件夹下，对编译器做测试。解压完毕。 一共有7个测试。首先是对Fortran和C的编译器做测试。 gfortran TEST_1_fortran_only_fixed.f ./a.out gfortran TEST_2_fortran_only_free.f90 ./a.out gcc TEST_3_c_only.c ./a.out gcc -c -m64 TEST_4_fortran+c_c.c gfortran -c -m64 TEST_4_fortran+c_f.f90 gfortran -m64 TEST_4_fortran+c_f.o TEST_4_fortran+c_c.o ./a.out 接下来测试下csh，perl，sh是否可行。 ./TEST_csh.csh ./TEST_perl.pl ./TEST_sh.sh 可以发现csh测试不通过。解决方案为安装tcsh。 apt install tcsh 安装完，测试通过。 2 安装依赖库首先在Build_WRF文件夹下面创建一个LIBRARIES的文件夹。然后下载所需的依赖库。 mpich-3.0.4netcdf-4.1.3Jasper-1.900.1libpng-1.2.50zlib-1.2.7 把这些压缩包全部放到LIBRARIES下面。 接着设置环境变量开始安装。 1 netcdf安装这里用的是4.1.3版本的netcdf，这个版本还没有把netcdf-fortran和netcdf-c拆开。比较新的版本已经把二者拆开了，新版本则必须两个都安装。 exprot DIR=/home/Build_WRF/LIBRARIES export CC=gcc export CXX=g++ export FC=gfortran export FCFLAGS=-m64 export F77=gfortran export FFLAGS=-m64 tar zxvf netcdf-4.1.3.tar.gz cd netcdf-4.1.3 ./configure --prefix=$DIR/netcdf --disable-dap \ --disable-netcdf-4 --disable-shared make make install export PATH=$DIR/netcdf/bin:$PATH export NETCDF=$DIR/netcdf 虽然网上有很多教程要求先安装zllib和hdf5后安装netcdf，但是我决定按官方教程走走看。 2 mpich安装如果不需要并行运算，可以不安装这个库。这里还是安装一下。 tar xzvf mpich-3.0.4.tar.gz cd mpich-3.0.4 ./configure --prefix=$DIR/mpich make make install export PATH=$DIR/mpich/bin:$PATH 3 zlib安装export LDFLAGS=-L$DIR/grib2/lib export CPPFLAGS=-I$DIR/grib2/include tar xzvf zlib-1.2.7.tar.gz cd zlib-1.2.7 ./configure --prefix=$DIR/grib2 make make install 4 libpng安装tar xzvf libpng-1.2.50.tar.gz cd libpng-1.2.50 ./configure --prefix=$DIR/grib2 make make install 5 jasper安装tar xzvf jasper-1.900.1.tar.gz cd jasper-1.900.1 ./configure --prefix=$DIR/grib2 make make install 3 依赖库兼容性测试接下来对安装完的依赖库兼容性做测试。测试文件 1 Fortran+C+NetCDFtar -xf Fortran_C_NETCDF_MPI_tests.tar cp ${NETCDF}/include/netcdf.inc . gfortran -c 01_fortran+c+netcdf_f.f gcc -c 01_fortran+c+netcdf_c.c gfortran 01_fortran+c+netcdf_f.o 01_fortran+c+netcdf_c.o \ -L${NETCDF}/lib -lnetcdff -lnetcdf ./a.out 2 Fortran+C+NetCDF+MPIcp ${NETCDF}/include/netcdf.inc . mpif90 -c 02_fortran+c+netcdf+mpi_f.f mpicc -c 02_fortran+c+netcdf+mpi_c.c mpif90 02_fortran+c+netcdf+mpi_f.o \ 02_fortran+c+netcdf+mpi_c.o \ -L${NETCDF}/lib -lnetcdff -lnetcdf mpirun ./a.out 4 编译WRF下载WRF的源码，放在Build_WRF里面。WRF3.9.1 gunzip WRFV3.9.1.1.TAR.gz tar -xf WRFV3.9.1.1.TAR cd WRFV3 ./configure 需要安装m4。 apt-get install m4 接着configure一下，出现如下界面。 选择34和1。 ./compile em_real &gt;&amp; log.compile 接下来只要等待编译完成了。用下面的语句检查是否生成exe。 ls -ls main/*.exe 5 编译WPS接下来就是编译WPS。 gunzip WPSV3.9.1.TAR.gz tar -xf WPSV3.9.1.TAR cd WPS ./clean export JASPERLIB=$DIR/grib2/lib export JASPERINC=$DIR/grib2/include ./configure 出现如下界面 选择3，然后运行如下命令编译。 WRF_DIR = ../WRFV3 ./compile &gt;&amp; log.compile 上述的exe出现且不为红色可以初步认为编译安装成功。如何运行WRF后面再介绍。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>WRF</tag>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VMware Workstation下安装Ubuntu 64位系统]]></title>
    <url>%2F2017%2F10%2F11%2FVMware%20Workstation%E4%B8%8B%E5%AE%89%E8%A3%85Ubuntu%2064%E4%BD%8D%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[虽然笔者开始接触Linux有一段时间了，但是安装Ubuntu 64位系统并自己分区貌似也是才第一次。这里记录下安装过程。首先打开VMware Workstation。点击文件。 选择自定义。 这里直接点下一步。 选择稍后安装操作系统。 选择Linux，Ubuntu64位。并命名。因为这个虚拟机需要运行WRF之类的程序，选择了双核，当然目的也是实验看看。内存也调大了一些，4G。 网络设置默认，直接下一步。 如图，下一步。 虚拟磁盘类型也是默认，下一步。 创建新磁盘，下一步。 设置80G空间，并存储为单个文件。下一步。 OK，完毕。 存储位置自选。 接着右击设置。在CD/DVD里设置找到提前下载好的iso系统镜像。 接着启动虚拟机就开始安装程序了。 这个不勾选，继续。 点击”Something else”，自己分区，如果选择上面的选项则是推荐分区（看个人需求）。 我的分区如下。 各个分区的意思呢，可以查看这篇博客。安装Ubuntu Linux系统时硬盘分区最合理的方法 简单说至少需要四个分区（下面的第四个看需求）。 目录：/；大小：10G-20G；格式：ext4，描述：根目录。 目录：swap；大小：&lt;2048M；格式：swap；描述：交换空间。 目录：/boot；大小：200M左右；格式：ext4； 描述：Linux的内核及引导系统程序所需要的文件，比如 vmlinuz initrd.img文件都位于这个目录中。在一般情况下，GRUB或LILO系统引导管理器也位于这个目录；启动撞在文件存放位置，如kernels，initrd，grub。 目录：/tmp；大小：5G左右；格式：ext4；描述：系统的临时文件，一般系统重启不会被保存。（建立服务器需要？）。 目录：/home；大小：尽量大些；格式：ext4；描述：用户工作目录；个人配置文件，如个人环境变量等；所有账号分配一个工作目录。分完之后，接下来基本是一路默认了。 这里设置中文。 设置超级用户和登录密码。 正式开始安装。 安装完毕重启。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>Vmware Workstation</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[应用统计学与R语言实现学习笔记后记]]></title>
    <url>%2F2017%2F10%2F10%2F%E5%BA%94%E7%94%A8%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B8%8ER%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%90%8E%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[1 后记应用统计学与R语言实现学习笔记这一系列博客断断续续写了5个月左右。现在终于算是基本完成了。我个人比较强迫症，比较喜欢一个系列更完再更其他的。所以中间有一些不错的内容想写到博客里都没动笔。后面会继续填坑。另外之后遇到的跟应用统计学与R语言实现相关的内容会以番外篇形式发布。 当时想到写这个东西，主要是自己选了门应用统计学的公选课，个人觉得不能浪费了这门课，而且其实我们在做一些研究的时候，其实都用了很多新的、高大上的所谓的新方法，并且不断在追逐所谓的Big data，但是回过头来想想，最基础的统计学理论可能才是我们需要补课的地方（不得不说这门课挺对我胃口，去年暑假花了一部分时间在啃贾俊平的统计学，刚好是这门课的参考教材）。这个年代，用个tensorflow的包，import一下，训练个模型出来就能说自己做的是深度学习。个人意见，也对也不对。IT技术飞速发展，大大降低了程序猿的门槛，但是现在的情况更应当说是程序猿的行当易学难精了。扯得有点远，总之我认为返璞归真地去学一学高数、概率论、统计学、线性代数可能比一上来就开始各种机器学习什么的要强得多。 这份笔记的定位，就是一份笔记，某些程度上就是课程老师给我们的ppt，我对理论部分做了整理。所以要归功于我的任课老师王老师。我不求大家从头到尾看完这份笔记，因为理论很枯燥，但是当需要用些什么内容的时候，可以想起这份笔记，供大家查找和参考。我的笔记并不像《深入浅出统计学》那样直白而又易懂的语言，尽管中间有一定的尝试，所以不可能看完我的这个系列博客就能对统计学的基本内容完全融会贯通，如果你希望在统计学上有所建树，需要大家自己去补课。另外我这部分更多针对于应用，而且基于我自己本身地学背景，我讲的例子也都跟尽量跟地学、生态相关。所以其他专业的同学会觉得一些例子苦涩难懂是比较正常的（在此向其他专业同学说声不好意思，你们的批评我虚心接受，但是你们这方面的建议我坚决不改，傲娇脸）。 好，讲了这么多。这个系列我其实是作为我自己的一个开源项目做的，我希望大家有什么意见可以一起来帮忙修改完善这个项目。如果你觉得还不错，也不要吝啬你的star。我博客里提到的很多代码之类的也都在这个项目里面开源了。就请大家批评指正。 Note-of-Applied-Statistics-with-R 2 基于gitbook的电子书生成教程 Modern book format and toolchain using Git and Markdown 这是 gitbook 项目主页上对 gitbook 的定义。gitbook 首先是一个软件，正如上面定义的那样，它使用 Git 和 Markdown 来编排书本。 gitbook官网 也可以使用gitbook editor。gitbook可以与github关联，直接将仓库的markdown文档发布成电子书。为了方便管理，选择在github上搭建电子书整体内容，然后push到github上，同时同步到gitbook中。首先用github登录gitbook。接着在github上创建一个新的仓库。只保留markdown文档和文件夹。gitbook的关键是需要SUMMARY的markdown文档，这个文件是用来组织书的框架。如下图。 README的前言其实就是上面的后记，想说的话大体相同。只不过时间先后问题导致成了前言和后记。其他的是链接各章节。接着看一下github上仓库项目结构（初步构成）。 因为在线渲染电子书速度较慢，我们可以在本地进行渲染和修改。目前只需将仓库先克隆到本地。接着安装gitbook（基于node.js）。因为gitbook是基于node.js的，先查看是否安装了node.js。 node -v npm -v 接着输入命令，安装gitbook。 npm install gitbook-cli -g 接下来在github上先安装gitbook的拓展应用。并选择应用的仓库范围（可以选择所有仓库，也可以只选择对应的仓库） 这样在gitbook上创建新书的时候，可以选择github的模板，直接导入书籍的仓库，并且后面可以自动同步。 在gitbook的setting中设置，默认生成pdf，mobi，epub的电子书供下载，选择MIT许可证。 gitbook可以通过book.json这个文件来控制生成电子书的一些具体定制化的需求。我的设置如下，因为用到了流程图和大量数学公式，就多加了katex和mermaid的插件。 首先通过命令行，定位到克隆到本地书籍的路径。 gitbook install 先安装插件。接着渲染一下。 gitbook build 最后本地服务器运行。 gitbook serve 在浏览器网址输入localhost:4000。即可查看。 执行gitbook build的时候可能会有各种报错，根据报错信息一个一个修改。目前发现似乎gitbook不太支持mathjax。而且公式里面不能有中文及中文标点符号，而且原来在博客上，两个$是表示数学符号，但是不是自己占一行。四个 $是表示独立的公式，必须另起一行。但是katex只认四个$。所以进行了一番较多修改，流程图目前也一直无法显示。mermaid跟我博客的流程图插件也不相同。我用的是flowchart，但是安装了似乎也不显示。最后就先用截图来表示了。全部搞定后直接push到github上。 发现gitbook上没有完全同步。可以从setting里面设置。 OK，大工告成，接下来只需等它在线渲染成功就可以了。PDF版本。 每每看到封面的熊本分分钟出戏。。。 在线网址访问网址：应用统计学与R语言实现学习笔记 有兴趣的同学可以下载这本电子书，也可以在评论留邮箱，可以发送给大家。 参考博客： 使用GitBook平台发布电子书 【Gitbook】实用配置及插件介绍 GitBook使用教程 GitBook 制作 Kindle 电子书详细教程（可视化版）]]></content>
      <categories>
        <category>Statistics &amp; Model</category>
      </categories>
      <tags>
        <tag>R</tag>
        <tag>Theory</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[应用统计学与R语言实现学习笔记（十四）——案例与实践]]></title>
    <url>%2F2017%2F10%2F08%2F%E5%BA%94%E7%94%A8%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B8%8ER%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%8D%81%E5%9B%9B%EF%BC%89%E2%80%94%E2%80%94%E6%A1%88%E4%BE%8B%E4%B8%8E%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[Chapter 14 Case and Practice本篇是第十四章，内容是案例与实践。这里其实是对我公选课的作业做了个汇总。 1 描述性统计与抽样分布1.一种袋装食品用生产线自动装填，每袋重量大约为50g，但由于某些原因，每袋重量不会恰好是50g。下面是随机抽取的100袋食品，测得的重量数据见附录。（1）构建这些数据的频数分布表。（2）绘制频数分布的直方图。（3）说明数据分布的特征。 2.甲乙两个班各有40名学生，期末统计学考试成绩的分布见附录。（1）根据上面的数据，画出两个班考试成绩的复合柱形图、环形图和图饼图。（2）比较两个班考试成绩分布的特点。（3）画出雷达图，比较两个班考试成绩的分布是否相似。 3.随机抽取25个网络用户，得到他们的年龄数据（单位：周岁）见附录。（1）计算众数、中位数。（2）根据定义公式计算四分位数。（3）计算平均数和标准差。（4）计算偏态系数和峰态系数。（5）对网民年龄的分布特征进行综合分析。 4.某银行为缩短顾客到银行办理业务等待的时间，准备采用两种排队方式进行试验：一种是所有顾客都进入一个等待队列；另一种是顾客在三个业务窗口处列队三排等待。为比较哪种排队方式使顾客等待的时间更短，两种排队方式各随机抽取的9名顾客，得到第一中排队方式的平均等待时间为7.2分钟，标准差为，1.97分钟，第二种排队方式的等待时间（单位：min）见附录。（１）画出第二种排队方式等待时间的茎叶图。（２）计算第二种排队方式等待时间的平均数和标准差。（３）比较两种排队方式等待时间的离散程度。（４）如果让你选择一种排队方式，你会选择哪一种？试说明理由。 5.从均值为200、标准差为50的总体中，抽取n=100的简单随机样本，用样本均值`x估计总体均值。a)描述重复抽样的样本均值的抽样分布。b)不重复抽样，总体单位数分别为10000、1000时的样本均值的抽样分布。 2 参数估计与假设检验1.某大学为了解学生每天上网的时间，在全校7500名学生中采取不重复抽样方法随机抽取36人，调查他们每天上网的时间（单位：小时） ，得到的数据见附录。求该校大学生平均上网时间的置信区间，置信概率分别为90%、95%和99%。 2.假定两个总体的标准差分别为：$\sigma_1$=12，$\sigma_2$=15，若要求误差范围不超过5，相应的置信水平为95%，假定$n_1=n_2$，估计两个总体均值之差$m_1-m_2$时所需的样本容量为多大？ 3.经验表明，一个矩形的宽与长之比等于0.618的时候会给人们比较良好的感觉。某工艺品工厂生产的矩形工艺品框架的宽与长要求也按这一比例设计，假定其总体服从正态分布，现随机抽取了20个框架测得比值见附录。在显著性水平 ＝0.05时，能否认为该厂生产的工艺品框架宽与长的平均比例为0.618？。 4.一家大型超市连锁店上个月接到许多消费者投诉某种品牌炸土豆片中60克一袋的那种土豆片的重量不符。店方猜想引起这些投诉的原因是运输过程中沉积在食品袋底部的土豆片碎屑，但为了使顾客们对花钱买到的土豆片感到物有所值，店方仍然决定对来自于一家最大的供应商的下一批袋装炸土豆片的平均重量（克）进行检验，假设陈述如下： $H_0: \mu\le 60$ $H_1:\mu&lt;60$如果有证据可以拒绝原假设，店方就拒收这批炸土豆片并向供应商提出投诉。（1）与这一假设检验问题相关联的第一类错误是什么？（2）与这一假设检验问题相关联的第二类错误是什么？（3）你认为连锁店的顾客们会将哪类错误看得较为严重？而供应商会将哪类错误看得较为严重？ 3 方差分析与回归分析1.某家电制造公司准备购进一批5#电池，现有A、B、C三个电池生产企业愿意供货，为比较它们生产的电池质量，从每个企业各随机抽取5只电池，经试验得其寿命（单位：h）数据见附录。试分析三个企业生产的电池的平均寿命之间有无显著差异（$\alpha=0.05$）。如果有差异，用LSD方法检验哪些企业之间有差异？ 2.一家超市连锁店的老板进行一项研究，确定超市所在的位置和竞争者的数量对销售额是否有显著影响。获得的月销售额数据（单位：万元）见附录。取显著性水平$\alpha=0.01$，检验：（1）竞争者的数量对销售额是否有显著影响。（2）超市的位置对销售额是否有显著影响。（3）竞争者的数量和超市的位置对销售额是否有交互影响。 3.附录中有随机抽取的15家大型商场销售的同类产品的有关数据（单位：元）。（1）计算y与$x_1$ 、y与$x_2$之间的相关系数，是否有证据表明销售价格与购进价格、销售价格与销售费用之间存在线性关系？（2）根据上述结果，你认为用购进价格和销售费用来预测销售价格是否有用？（3）用Excel进行回归，并检验模型的线性关系是否显著（$\alpha=0.05$）。（4）解释判定系数$R^2$，所得结论与问题（2）中是否一致?（5）计算$x_1$与$x_2$之间的相关系数，所得结果意味着什么？（6）模型中是否存在多重共线性？你对模型有何建议？ 4.附录中有32名美士足球运动员的rating及其他相关信息。请建立一个回归模型以预测一位美士足球运动员的rating。提交报告包括：使用什么方法建立的模型，该方法的运行结果，最终模型的解释（拟合程度、预测误差）。 这一份作业汇总从最原始的描述统计、参数估计、假设检验到基础的方差分析与回归分析均有了。根据这里的习题即可对前面的内容再次熟悉。这里就不多说了，我有一份比较完整的文档针对这份内容。这里先给出节选部分的截图。具体地址再给出。]]></content>
      <categories>
        <category>Statistics &amp; Model</category>
      </categories>
      <tags>
        <tag>R</tag>
        <tag>Theory</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[应用统计学与R语言实现学习笔记（十三）——因子分析]]></title>
    <url>%2F2017%2F10%2F06%2F%E5%BA%94%E7%94%A8%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B8%8ER%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%8D%81%E4%B8%89%EF%BC%89%E2%80%94%E2%80%94%E5%9B%A0%E5%AD%90%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[Chapter 13 Factor Analysis本篇是第十三章，内容是因子分析。 1 因子分析概念因子分析是一种数据简化的技术。它通过研究众多变量之间的内部依赖关系，探求观测数据中的基本结构，并用少数几个假想变量来表示其基本的数据结构。这几个假想变量能够反映原来众多变量的主要信息。原始的变量是可观测的显在变量，而假想变量是不可观测的潜在变量，称为因子。即一种用来在众多变量中辨别、分析和归结出变量间的相互关系并用简单的变量（因子）来描述这种关系的数据分析方法。寻求基本结构 通过因子分析，找出几个较少的有实际意义的因子，反映出原来数据的基本结构。 通常找出的这组观察不到的因子概括了原始的变量的大多数信息。 数据简化 强相关问题会对分析带来困难。 通过因子分析，可以用所找出的少数几个因子代替原来的变量做回归分析、聚类分析、判别分析等。 因子分析的用途 产生新的、更少的变量以便为后续的回归和其他分析做基础。 识别概念或产品的基本感知和特性。 改善市场研究领域多元测量的结构与方法。 2 因子分析模型数学模型设$X_i(i=1,2,\cdots,p)$p个变量，如果表示为：$$ X_i=\mu_i+a_{i1}F_1+\cdots+a_{im}F_m+\varepsilon_i(m\le p) $$或$$ \begin {bmatrix} X_1\\X_2\\\vdots\\X_p \end {bmatrix}=\begin {bmatrix} \mu_1\\\mu_2\\\vdots\\\mu_p \end {bmatrix}+\begin {bmatrix} \alpha_{11}&amp;\alpha_{12}&amp;\cdots&amp;\alpha_{1m}\\\alpha_{21}&amp;\alpha_{22}&amp;\cdots&amp;\alpha_{2m}\\\vdots&amp;\vdots&amp;&amp;\vdots\\\alpha_{p1}&amp;\alpha_{p2}&amp;\cdots&amp;\alpha_{pm} \end {bmatrix}\begin {bmatrix} F_1\\F_2\\\vdots\\F_m \end {bmatrix}+\begin{bmatrix} \varepsilon_1\ \varepsilon_2\\\vdots\ \varepsilon_p \end {bmatrix} $$或$$ X-\mu=AF+\varepsilon $$$F_1,F_2,\cdots,F_m$称为公共因子,是不可观测的变量，它们的系数称为因子载荷。$\varepsilon_i$是特殊因子，是不可能被前m个公共因子包含的部分。并且满足：$cov(F,\varepsilon)=0$，即$F,\varepsilon$不相关；$$ D(F)=\begin {bmatrix} 1 &amp; &amp; &amp; \\&amp;1&amp;&amp;&amp;\\&amp;&amp;\ddots&amp;\\&amp;&amp;&amp;1 \end {bmatrix}=I $$即$F_1,F_2,\cdots,F_m$互不相关，方差为1。$$ D(\varepsilon)=\begin {bmatrix}\sigma_1^2&amp;&amp;&amp;\\&amp;\sigma_w^2&amp;&amp;&amp;\\&amp;&amp;\ddots&amp;\\&amp;&amp;&amp;\sigma_p^2\end {bmatrix} $$即$\varepsilon_i\sim N(0,\sigma_i^2)$互不相关，方差不一定相等。用矩阵的方式表达$$ X-\mu=AF+\varepsilon $$ $$ E(F)=0 $$ $$ E(\varepsilon)=0 $$ $$ Var(F)=1 $$$$ cov(F,\varepsilon)=E(F\varepsilon’)=\begin {pmatrix}E(F_1\varepsilon_1)&amp;E(F_1\varepsilon_2)&amp;\cdots&amp;E(F_1\varepsilon_p)\\E(F_2\varepsilon_1)&amp;E(F_2\varepsilon_2)&amp;\cdots&amp;E(F_2\varepsilon_p)\\\vdots&amp;\vdots&amp;&amp;\vdots\\E(F_p\varepsilon_1)&amp;E(F_p\varepsilon_2)&amp;\cdots&amp;E(F_p\varepsilon_p) \end {pmatrix}=0 $$$$ Var(\varepsilon)=diag(\sigma_1^2,\sigma_2^2,\cdots,\sigma_p^2) $$因子分析模型的性质 1、原始变量X的协方差矩阵的分解$$ \Sigma_x=AA’+D $$A是因子模型的系数$$ Var(\varepsilon)=D=diag(\sigma_1^2,\sigma_2^2,\cdots,\sigma_p^2) $$D的主对角线上的元素值越小，则公共因子共享的成分越多。2、模型不受计量单位的影响。3、因子载荷不是惟一的：设T为一个p×p的正交矩阵，令A=AT， F=T’F也是一个满足因子模型条件的因子载荷。 因子载荷矩阵中的统计特征 因子载荷$a_{ij}$是第i个变量与第j个公共因子的相关系数。 变量$X_i$的共同度是因子载荷矩阵的第i行的元素的平方和。记为$h_i^2=\sum_{i=1}^ma_{ij}^2$所有的公共因子和特殊因子对变量$X_i$的贡献为1。如果$\sum_{i=1}^ma_{ij}^2$非常靠近1， $\sigma_i^2$非常小，则因子分析的效果好，从原变量空间到公共因子空间的转化性质好。 因子载荷矩阵中各列元素的平方和$S_j=\sum_{i=1}^pa_{ij}^2$称为$F_j(j=1,2,\cdots,m)$对所有的$X_i$的方差贡献和。衡量$F_j$的相对重要性。 3 因子载荷矩阵的估计方法 主成分分析法设随机向量$x=(x_1,x_2,\cdots,x_p)’$的均值为$\mu$，协方差为$\Sigma$，$\lambda_1\ge\lambda_2\ge\cdots\ge\lambda_p\ge0$为$\Sigma$的特征根，$u_1,u_2,\cdots,u_p$为对应的标准化特征向量，则：$$ \Sigma=U\begin {bmatrix}\lambda_1&amp;&amp;&amp;\\&amp;\lambda_2&amp;&amp;\\&amp;&amp;\cdots&amp;\\&amp;&amp;&amp;\lambda_p \end {bmatrix}U’=AA’+D=\begin {bmatrix}\sqrt\lambda_1u_1&amp;\sqrt\lambda_2u_2&amp;\cdots&amp;\sqrt\lambda_pu_p \end {bmatrix}\begin {bmatrix}\sqrt\lambda_1u_1’\\\sqrt\lambda_2u_2’\\\vdots\\\sqrt\lambda_pu_p’ \end {bmatrix}+D $$上式给出的Σ表达式是精确的，然而，它实际上是毫无价值的，因为我们的目的是寻求用少数几个公共因子解释，故略去后面的p-m项的贡献。上式有一个假定：模型中的特殊因子是不重要的，因而从Σ的分解中忽略了特殊因子的方差。确定因子个数（特征根大于1所对应的特征向量；碎石原则：把特征根从大到小排列，把特征根减小速度变缓的特征根都删掉）。 主因子法主因子方法是对主成分方法的修正，假定我们首先对变量进行标准化变换。则$$ R=AA’+D\\R^{\ast}=AA’=R-D $$称$R^{\ast}$为约相关矩阵，$R^{\ast}$对角线上的元素是$h_i^2$，而不是1。$$ R^{\ast}=R-\hat D=\begin {bmatrix}\hat h_1^2&amp;r_{12}&amp;\cdots&amp;r_{1p}\\r_{21}&amp;\hat h_2^2&amp;\cdots&amp;r_{2p}\\\vdots&amp;\vdots&amp;&amp;\vdots\\r_{p1}&amp;r_{p2}&amp;\cdots&amp;\hat h_p^2 \end {bmatrix} $$直接求$R^{\ast}$的前p个特征根和对应的正交特征向量。得如下的矩阵：$$A=\begin {bmatrix}\sqrt{\lambda_1^{\ast}}u_1^{\ast}&amp;\sqrt{\lambda_2^{\ast}}u_2^{\ast}&amp;\cdots&amp;\sqrt{\lambda_p^{\ast}}u_p^{\ast} \end {bmatrix}$$$R^{\ast}$特征根：$\lambda_1^{\ast}\ge\lambda_2^{\ast}\ge\cdots\ge\lambda_p^{\ast}\ge0$，正交特征向量：$u_1^{\ast},u_2^{\ast},\cdots,u_p^{\ast}$当特殊因子$\varepsilon_i$的方差已知：$$ R^{\ast}=R-\begin {bmatrix}\sigma_1^2&amp;&amp;&amp;\\&amp;\sigma_2^2&amp;&amp;\\&amp;&amp;\ddots&amp;\\&amp;&amp;&amp;\sigma_p^2 \end {bmatrix}=\begin {bmatrix}\sqrt{\lambda_1^{\ast}}u_1^{\ast}&amp;\sqrt{\lambda_2^{\ast}}u_2^{\ast}&amp;\cdots&amp;\sqrt{\lambda_p^{\ast}}u_p^{\ast} \end {bmatrix}\begin {bmatrix}\sqrt{\lambda_1^{\ast}}u_1^{‘\ast}\\\sqrt{\lambda_2^{\ast}}u_2^{‘\ast}\\\vdots\\\sqrt{\lambda_p^{\ast}}u_p^{‘\ast} \end {bmatrix} $$$$ A=\begin {bmatrix}\sqrt{\lambda_1^{\ast}}u_1^{\ast}&amp;\sqrt{\lambda_2^{\ast}}u_2^{\ast}&amp;\cdots&amp;\sqrt{\lambda_m^{\ast}}u_m^{\ast}\end {bmatrix} $$$$ D=\begin {pmatrix}1-\hat h_1^2&amp;&amp;0\\&amp;\ddots&amp;\\0&amp;&amp;1-\hat h_p^2 \end {pmatrix} $$在实际的应用中，个性方差矩阵一般都是未知的，可以通过一组样本来估计。估计的方法有如下几种：首先，求$h_i^2$的初始估计值，构造出R*1、取$h_i^2=1$，在这个情况下主因子解与主成分解等价；2、取$h_i^2=R_i^2$，$R_i^2$为$x_i$与其他所有的原始变量$x_j$的复相关系数的平方，即$x_i$对其余的p-1个$x_j$的回归方程的判定系数，这是因为xi与公共因子的关系是通过其余的p-1个$x_j$的线性组合联系起来的；3、取$\hat h_i^2=max\left|r_{ij}\right|(j\neq i)$，这意味着取$x_i$与其余的$x_j$的简单相关系数的绝对值最大者；4、取$h_i^2=\frac{1}{p-1}\sum_{j=1,j\neq i}^pr_{ij}$，其中要求该值为正数。5、取$h_i^2=1/r^{ii}$，其中$r^{ii}$是$R^{-1}$的对角元。 极大似然估计法如果假定公共因子F和特殊因子$\varepsilon$服从正态分布，那么可以得到因子载荷和特殊因子方差的极大似然估计。设$x_1,x_2,\cdots,x_n$为来自正态总体$N_p(\mu,\Sigma)$的随机样本。$\Sigma=AA’+\Sigma_{\varepsilon}$$$\begin {aligned} L(\hat \mu,\hat A,\hat D)&amp;=f(X)=f(X_1)\cdot f(X_2)\cdots f(X_n)\\&amp;=\prod_{i=1}^n(2\pi)^{-p/2}\left |\Sigma\right|^{1/2}exp\begin {bmatrix}-\frac{1}{2}(x_i-\mu)’\Sigma^{-1}(x_i-\mu) \end {bmatrix}\\&amp;=\begin {bmatrix}(2\pi)^p\left |\Sigma \right |^{-n/2} \end {bmatrix}exp\begin {bmatrix}-\frac{1}{2}\sum_{i=1}^n(X_i-\mu)’\Sigma^{-1}(X_i-\mu) \end {bmatrix} \end {aligned} $$用数值极大化的方法可以得到极大似然估计。 4 因子旋转（正交变换）旋转因子的目的因子分析的目的不仅仅是要找出公共因子以及对变量进行分组，更重要的是要知道每个公共因子的意义，以便进行进一步的分析。如果每个公共因子的含义不清，则不便于进行实际背景的解释。初始因子的综合性太强，难以找出因子的实际意义。由于因子载荷阵是不唯一的，所以可以对因子载荷阵进行旋转，使因子载荷阵的结构简化，使其每列或行的元素平方值向0和1两极分化。旋转方法设$\Gamma$正交矩阵，做正交变换$B=A\Gamma$。 变换后各变量的共同度不会发生变化。 变换后各因子的贡献会发生变化。 三种主要的正交旋转法 方差最大法方差最大法从简化因子载荷矩阵的每一列出发，使和每个因子有关的载荷的平方的方差最大。当只有少数几个变量在某个因子上有较高的载荷时，对因子的解释最简单。 方差最大的直观意义是希望通过因子旋转后，使每个因子上的载荷尽量拉开距离，一部分的载荷趋于±1，另一部分趋于0。$$ A=\begin {bmatrix} a_{11}&amp;a_{12}\\a_{21}&amp;a_{22}\\\vdots&amp;\vdots\\a_{p1}&amp;a_{p2} \end {bmatrix} $$$$ X_1=a_{11}F_1+a_{12}F_2\\X_2=a_{21}F_1+a_{22}F_2\\\cdots\\X_p=a_{p1}F_1+a_{p2}F_2 $$设旋转矩阵：$ T=\begin {pmatrix}\cos\varphi&amp;-\sin\varphi\\\sin\varphi&amp;\cos\varphi \end {pmatrix} $则$$ \begin {aligned}B&amp;=AT=A\begin {pmatrix}\cos\varphi&amp;-\sin\varphi\\\sin\varphi&amp;\cos\varphi \end {pmatrix}\\&amp;=\begin {pmatrix}a_{11}\cos\varphi+a_{12}\sin\varphi&amp;-a_{11}\sin\varphi+a_{12}\cos\varphi\\\vdots&amp;\vdots\\a_{p1}\cos\varphi+a_{p2}\sin\varphi&amp;-a_{p1}\sin\varphi+a_{p2}\cos\varphi \end {pmatrix}\\&amp;=\begin {pmatrix}a_{11}^{\ast}&amp;a_{12}^{\ast}\\\vdots&amp;\vdots\\a_{p1}^{\ast}&amp;a_{p2}^{\ast} \end {pmatrix} \end {aligned} $$令$ d_{ij}=\frac{a_{ij}^{\ast}}{h_i},i=1,2,\cdots,p;j=1,2 $$ \bar d_j=\frac{1}{p}\sum_{i=1}^pd_{ij}^2 $（这是列和）简化准则为：$ V(\theta)=\sum_{j=1}^m\sum_{i=1}^p(d_{ij}^2-\bar d_j)^2=max $即：$ V_1+V_2+V_3+\cdots+V_m=max $令$ \frac{\partial V}{\partial \theta}=0 $，则可以解出$ \theta_0 $旋转矩阵为：$ T=\begin {pmatrix}\cos\theta_0&amp;-\sin\theta_0\\\sin\theta_0&amp;\cos\theta_0 \end {pmatrix} $ 四次方最大法四次方最大旋转是从简化载荷矩阵的行出发，通过旋转初始因子，使每个变量只在一个因子上有较高的载荷，而在其它的因子上尽可能低的载荷。 如果每个变量只在一个因子上有非零的载荷，这时的因子解释是最简单的。四次方最大法通过使因子载荷矩阵中每一行的因子载荷平方的方差达到最大。简化准则为：$ Q=\sum_{i=1}^p\sum_{j=1}^m(b_{ij}^2-\frac{1}{m})^2=max $$$ \begin {aligned} Q&amp;=\sum_{i=1}^p\sum_{j=1}^m(b_{ij}^2-\frac{1}{m})^2=\sum_{i=1}^p\sum_{j=1}^m(b_{ij}^4-2\frac{1}{m}b_{ij}^2+\frac{1}{m^2})\\&amp;=\sum_{i=1}^p\sum_{j=1}^m(b_{ij}^4-2\sum_{i=1}^p\sum_{j=1}^m\frac{1}{m}b_{ij}^2+\sum_{i=1}^p\sum_{j=1}^m\frac{1}{m^2})\\&amp;=\sum_{i=1}^p\sum_{j=1}^m(b_{ij}^4-2\sum_{i=1}^p\sum_{j=1}^m\frac{1}{m}b_{ij}^2+\sum_{i=1}^p\sum_{j=1}^m\frac{1}{m^2})\\&amp;=\sum_{i=1}^p\sum_{j=1}^m(b_{ij}^4-2+\frac{p}{m}) \end {aligned} $$最终的简化准则为：$ Q=\sum_{i=1}^p\sum_{j=1}^mb_{ij}^4=MAX $ 等量最大法等量最大法把四次方最大法和方差最大法结合起来求Q和V的加权平均最大。最终的简化准则为：$ E=\sum_{i=1}^p\sum_{j=1}^mb_{ij}^4-\gamma\sum_{j=1}^m(\sum_{i=1}^pb_{ij}^2)^2/p=MAX $权数$\gamma$等于$m/2$，因子数有关。 5 因子得分当解决了用一组公共因子的线性组合来表示一组观测变量后，有时我们需要使用这些因子做其他的研究。比如把得到的因子作为自变量来做回归分析，对样本进行分类或评价，这就需要我们对公共因子进行测度，即给出公共因子的值。因子得分因子分析的数学模型：$$ \begin {bmatrix}X_1\\X_2\\\vdots\\X_p \end {bmatrix}=\begin {bmatrix}\alpha_{11}&amp;\alpha_{12}&amp;\cdots&amp;\alpha_{1m}\\\alpha_{21}&amp;\alpha_{22}&amp;\cdots&amp;\alpha_{2m}\\\vdots&amp;\vdots&amp;&amp;\vdots\\\alpha_{p1}&amp;\alpha_{p2}&amp;\cdots&amp;\alpha_{pm} \end {bmatrix}\begin {bmatrix}F_1\\F_2\\\vdots\\F_p \end {bmatrix} $$原变量被表示为公共因子的线性组合，当载荷矩阵旋转之后，公共因子可以做出解释，通常的情况下，我们还想反过来把公共因子表示为原变量的线性组合。因子得分函数：$F_j=\beta_{j1}X_1+\cdots+\beta_{jp}X_p, j=1,\cdots,m$。可见，要求得每个因子的得分，必须求得分函数的系数，而由于p&gt;m，所以不能得到精确的得分，只能通过估计。巴特莱特因子得分(加权最小二乘法）把$x_i-\mu_i$看作因变量；把因子载荷矩阵$$ \begin {bmatrix}\alpha_{11}&amp;\alpha_{12}&amp;\cdots&amp;\alpha_{1m}\\\alpha_{21}&amp;\alpha_{22}&amp;\cdots&amp;\alpha_{2m}\\\vdots&amp;\vdots&amp;&amp;\vdots\\\alpha_{p1}&amp;\alpha_{p2}&amp;\cdots&amp;\alpha_{pm} \end {bmatrix} $$看成自变量的观测；把某个个案的得分$F_j$看作最小二乘法需要求的系数。$$ \begin {cases}x_{i1}-\mu_1=a_{11}f_1+a_{12}f_2+\cdots+a_{1m}f_m+\varepsilon_1\\x_{i2}-\mu_2=a_{21}f_1+a_{22}f_2+\cdots+a_{2m}f_m+\varepsilon_2\\\cdots\\x_{ip}-\mu_p=a_{p1}f_1+a_{p2}f_2+\cdots+a_{pm}f_m+\varepsilon_p \end {cases} $$由于特殊因子的方差相异，所以用加权最小二乘法求得分，每个个案作一次，要求出所有样品的得分，需要作n次。$$ \sum_{j=1}^p[(x_i-\mu_i)-(a_{i1}\hat f_1+a_{i2}\hat f_2+\cdots+a_{im}\hat f_m)]^2/\sigma_i^2 $$使上式最小的$\hat f_1,\cdots,\hat f_m$是相应个案的因子得分。回归方法$$ \begin {bmatrix}X_1\\X_2\\\vdots\\X_n \end {bmatrix}=\begin {bmatrix}\alpha_{11}&amp;\alpha_{12}&amp;\cdots&amp;\alpha_{1m}\\\alpha_{21}&amp;\alpha_{22}&amp;\cdots&amp;\alpha_{2m}\\\vdots&amp;\vdots&amp;&amp;\vdots\\\alpha_{p1}&amp;\alpha_{p2}&amp;\cdots&amp;\alpha_{pm} \end {bmatrix}\begin {bmatrix}F_1\\F_2\\\vdots\\F_p \end {bmatrix}+\begin {bmatrix}\varepsilon_1\\\varepsilon_2\\\vdots\\\varepsilon_n \end {bmatrix} $$$$ \hat F_j=b_{j1}X_1+\cdots+b_{jp}X_p, j=1,\cdots,m $$$$ \begin {bmatrix}b_{11}&amp;b_{12}&amp;\cdots&amp;b_{1p}\\b_{21}&amp;b_{22}&amp;\cdots&amp;b_{2p}\\\vdots&amp;\vdots&amp;&amp;\vdots\\b_{m1}&amp;b_{m2}&amp;\cdots&amp;b_{mp} \end {bmatrix}=\begin {bmatrix}b_1\\b_2\\\vdots\\b_m \end {bmatrix} $$$$ \begin {aligned} \alpha_{ij}=\gamma_{x_iF_j}=E(X_i,F_j)&amp;=E[X_i(b_{j1}X_1+\cdots+b_{jp}X_p)]\\&amp;=b_{j1}\gamma_{i1}+\cdots+b_{jp}\gamma_{ip}=\begin {bmatrix}\gamma_{i1}&amp;\gamma_{i2}&amp;\cdots&amp;\gamma_{ip} \end {bmatrix}\begin {bmatrix}b_{j1}\\b_{j2}\\\vdots\\b_{jp} \end {bmatrix} \end {aligned}$$则，我们有如下的方程组：$$ \begin {bmatrix}\gamma_{11}&amp;\gamma_{12}&amp;\cdots&amp;\gamma_{1p}\\\gamma_{21}&amp;\gamma_{22}&amp;\cdots&amp;\gamma_{2p}\\\vdots&amp;\vdots&amp;&amp;\vdots\\\gamma_{p1}&amp;\gamma_{p2}&amp;\cdots&amp;\gamma_{pp} \end {bmatrix}\begin {bmatrix}b_{j1}\\b_{j2}\\\vdots\\b_{jp} \end {bmatrix}=\begin {bmatrix}a_{1j}\\a_{2j}\\\vdots\\a_{pj} \end {bmatrix},j=1,2,\cdots,m $$$\begin {bmatrix}\gamma_{11}&amp;\gamma_{12}&amp;\cdots&amp;\gamma_{1p}\\\gamma_{21}&amp;\gamma_{22}&amp;\cdots&amp;\gamma_{2p}\\\vdots&amp;\vdots&amp;&amp;\vdots\\\gamma_{p1}&amp;\gamma_{p2}&amp;\cdots&amp;\gamma_{pp} \end {bmatrix}$为原始变量的相关系数；$\begin {bmatrix}b_{j1}\\b_{j2}\\\vdots\\b_{jp} \end {bmatrix}$为第j个因子得分函数的系数；$\begin {bmatrix}a_{1j}\\a_{2j}\\\vdots\\a_{pj} \end {bmatrix}$为载荷矩阵的第 j列注：共需要解m次才能解出所有的得分函数的系数。 6 因子分析步骤 选择分析的变量用定性分析和定量分析的方法选择变量，因子分析的前提条件是观测变量间有较强的相关性，因为如果变量之间无相关性或相关性较小的话，他们不会有共享因子，所以原始变量间应该有较强的相关性。 计算所选原始变量的相关系数矩阵相关系数矩阵描述了原始变量之间的相关关系。可以帮助判断原始变量之间是否存在相关关系，这对因子分析是非常重要的，因为如果所选变量之间无关系，做因子分析是不恰当的。并且相关系数矩阵是估计因子结构的基础。 提取公共因子这一步要确定因子求解的方法和因子的个数。需要根据研究者的设计方案或有关的经验或知识事先确定。因子个数的确定可以根据因子方差的大小，只取方差大于1(或特征值大于1)的那些因子，因为方差小于1的因子其贡献可能很小。或者按照因子的累计方差贡献率来确定，一般认为要达到60％才能符合要求。 因子旋转通过坐标变换使每个原始变量在尽可能少的因子之间有密切的关系，这样因子的实际意义更容易解释,也更容易为每个潜在因子赋予有实际意义的名字。 计算因子得分求出各样本的因子得分，有了因子得分值，则可以在许多分析中使用这些因子，例如以因子的得分做聚类分析的变量，做回归分析中的回归因子。 注 因子分析是十分主观的，在许多出版的资料中，因子分析模型都用少数可命名因子提供了合理解释。实际上，绝大多数因子分析并没有产生如此明确的结果。不幸的是，评价因子分析质量的法则尚未很好量化，质量问题只好依赖一个“哇！”准则如果在仔细检查因子分析的时候，研究人员能够喊出“哇，我明白这些因子”的时候，就可认为是成功地运用了因子分析方法。 主成分分析与因子分析主成分分析与因子分析有所不同，主成分分析仅仅是变量变换。 主成分分析：原始变量的线性组合表示新的综合变量，即主成分。 因子分析：潜在的假想变量和随机影响变量的线性组合表示原始变量。因子模型除了公共因子外还有特殊因子。公共因子只解释了原来变量的部分方差，而全部主成分解释了原来变量的全部方差。 主成分和公共因子的位置不同。因子分析也有因子载荷（ factor loading）的概念，代表了因子和原先变量的相关系数。但是在因子分析公式中的因子载荷位置和主成分分析不同。在数学模型上，因子分析和主成分分析也有不少区别。而且因子分析的计算也复杂得多。根据因子分析模型的特点，它还多一道程序：因子旋转（ factor rotation）；这个步骤可以使结果更好。旋转后的公共因子一般没有主成分那么综合，公共因子往往可以找到实际意义，而主成分常找不到实际的含义。可以看出，因子分析和主成分分析都依赖于原始变量，也只能反映原始变量的信息。所以原始变量的选择很重要。在得到分析的结果时，并不一定会都得到如我们例子那样清楚的结果。这与问题的性质，选取的原始变量以及数据的质量等都有关系。如果原始变量本质上独立，就很难把很多独立变量用少数综合的变量概括，降维就可能失败。数据越相关，降维效果就越好。可用如下方法进行变量间的相关性检验： KMO样本测度： KMO在0.9以上，非常适合； 0.8-0.9，很适合； 0.7-0.8，适合； 0.6-0.7，不太适合；0.5-0.6；很勉强； 0.5以下，不适合； 巴特莱特球体检验： H0：相关系数矩阵R为单位阵I。拒绝时H0可作因子分析 7 因子分析的R语言实现R语言做因子分析这里主要介绍三个函数，一个是自带的factanal函数。 factanal(x,factors,data=NULL,covmat=NUL,n.obs=NA,subset,na.action,start=NULL,score=c(&quot;none&quot;,&quot;regression&quot;,&quot;Bartlett&quot;),rotation=&quot;varimax&quot;,control=NULL,…) x是公式或者用于因子分析的数据，可以是矩阵（每一行为一个样本）或数据框；factors表示要生成的因子个数；data指定数据集，当x为公式的时候使用；covmat是样本的协方差矩阵或者相关系数矩阵，使用这个参数的时候x可以忽略；scores表示计算因子得分的方法；rotation表示因子旋转的方法，默认为”varimax”，最大方差旋转。这里近介绍几个常用的几个参数，其他参数说明可查询R语言官方帮助。另外，这个函数事实上仅支持用极大似然估计方法做因子分析。第二个函数就是自编函数实现的主成分分析方法做因子分析（具体函数代码后面给出）。 factor.analysis(x,m) x为相关系数矩阵，m为因子个数。第三个函数是psych包里的fa函数。 fa（r，nfactors=，n.obs=，rotate=，scores=，fm） r是相关系数矩阵或原始数据矩阵；nfactors设定提取的因子数（默认为1）；n.obs是观测数（输入相关系数矩阵时需要填写）；rotate设定放置的方法（默认互变异数最小法）；scores设定是否计算因子得分（默认不计算）；fm设定因子化方法（默认极小残差法）。用上一章提供的数据再进行因子分析。比较不同函数结果的差异。基于factnal函数，3个因子。 基于自编函数，3个因子。 基于fa函数，3个因子。]]></content>
      <categories>
        <category>Statistics &amp; Model</category>
      </categories>
      <tags>
        <tag>R</tag>
        <tag>Theory</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[应用统计学与R语言实现学习笔记（十二）——主成分分析]]></title>
    <url>%2F2017%2F09%2F22%2F%E5%BA%94%E7%94%A8%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B8%8ER%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%8D%81%E4%BA%8C%EF%BC%89%E2%80%94%E2%80%94%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[Chapter 12 Priciple Component Analysis本篇是第十二章，内容是主成分分析。 1 主成分分析基本思想依旧从问题开始本篇的介绍。地理学和生态学研究里经常遇到的问题就是，影响变量非常之多，而且地球表层地理生态环境现象无法使用控制变量的方式进行实验。同时影响变量非常多，经常出现变量冗余、冗杂的现象，同时多元分布数据本身对人类的认知就是一种挑战。这里举个栗子：比如在研究城市经济发展的时候，我们会考虑到的因素会包括第一产业、第二产业、第三产业占比，城市人口，城市地理位置，城市气候适宜度，政策扶持等等很多因子，但是这里有很多因子存在共线性的情况，也就是变量冗余冗杂。用矛盾论的话说，要抓住主要矛盾，那么如何在多元分布数据中分离出主要的因子，这就是本篇的主角主成分分析（Priciple Component Analysis，PCA）。 所以它的基本思想是。 在社会经济的研究中，为了全面系统的分析和研究问题，必须考虑许多经济指标，这些指标能从不同的侧面反映我们所研究的对象的特征，但在某种程度上存在信息的重叠，具有一定的相关性。这种信息的重叠有时甚至会抹杀事物的真正特征与内在规律。主成分分析是利用降维的思想， 在力求数据信息丢失最少的原则下，对高维的变量空间降维，即在众多变量中找出少数几个综合指标（原始变量的线性组合），并且这几个综合指标将尽可能多地保留原来指标变异方面的信息，且这些综合指标互不相关。这些综合指标就称为主成分。主成分的数目少于原始变量的数目。在一个低维空间识辨系统要比在一个高维空间容易得多。因此，更容易抓住主要矛盾，揭示事物内部变量之间的规律性，使问题得到简化，提高分析效率。指标间具有相关性是做主成分分析的前提。主成分分析是一种数学变换方法，它把给定的一组变量通过线性变换转换为一组不相关的变量。在这种变换中，保持变量的总方差不变，同时，使第一主成分具有最大方差，第二主成分具有次大方差，依此类推。主成分与原始变量间的关系（1）每一个主成分是原始变量的线性组合。（2）主成分的数目少于原始变量的数目。（3）主成分保留了原始变量的大多数变异信息。（4）各主成分间互不相关。 2 几何解释与数学模型2.1 几何解释假定只有二维，即只有两个变量，由横坐标和纵坐标所代表；每个观测值都有相应于这两个坐标轴的坐标值。如果这些数据形成一个椭圆形状的点阵（这在二维正态的假定下是可能的）该椭圆有一个长轴和一个短轴。在短轴方向上数据变化较少。在极端的情况，短轴如退化成一点，长轴的方向可以完全解释这些点的变化，由二维到一维的降维就自然完成了。 由图可以看出这些样本点无论是沿着$x_l$轴方向或$x_2$轴方向都具有较大的离散性，其离散的程度可以分别用观测变量$x_l$的方差和$x_2$的方差定量地表示。显然，如果只考虑$x_1$和$x_2$中的任何一个，那么包含在原始数据中的经济信息将会有较大的损失。当坐标轴和椭圆的长短轴平行，那么代表长轴的变量就描述了数据的主要变化，而代表短轴的变量就描述了数据的次要变化。但是，坐标轴通常并不和椭圆的长短轴平行。因此，需要寻找椭圆的长短轴，并进行变换，使得新变量和椭圆的长短轴平行。如果长轴变量代表了数据包含的大部分信息，就用该变量代替原先的两个变量（舍去次要的一维），降维就完成了。椭圆的长短轴相差得越大，降维也越有道理。 2.2 数学模型如果我们将xl轴和x2轴先平移，再同时按逆时针方向旋转$\theta$角度，得到新坐标轴Fl和F2。Fl和F2是两个新变量。根据旋转变换的公式：$$ \begin{cases} y_1=x_1\cos\theta+x_2\sin\theta\\y_2=-x_1\sin\theta+x_2\cos\theta \end{cases} $$$$ \begin{pmatrix} y_1\\y_2 \end{pmatrix}=\begin{pmatrix} \cos\theta &amp; \sin\theta\\-sin\theta &amp; \cos\theta \end{pmatrix} \begin{pmatrix} x_1\\x_2 \end{pmatrix}=U’x $$$U’$为旋转变换矩阵，它是正交矩阵，即有$U’=U^{-1},U’U^{-1}=I$。旋转变换的目的是为了使得n个样品点在$F_l$轴方向上的离散程度最大，即$F_l$的方差最大。变量$F_l$代表了原始数据的绝大部分信息，在研究某经济问题时，即使不考虑变量$F_2$也无损大局。经过上述旋转变换原始数据的大部分信息集中到$F_l$轴上，对数据中包含的信息起到了浓缩作用。$F_l$， $F_2$除了可以对包含在$X_l$，$ X_2$中的信息起着浓缩作用之外，还具有不相关的性质，这就使得在研究复杂的问题时避免了信息重叠所带来的虚假性。二维平面上的个点的方差大部分都归结在$F_l$轴上，而$F_2$轴上的方差很小。 $F_l$和$F_2$称为原始变量，$x_1$和$x_2$的综合变量。 简化了系统结构，抓住了主要矛盾。多维情形多维变量的情况和二维类似。正如二维椭圆有两个主轴，三维椭球有三个主轴一样，有几个变量，就有几个主轴。和二维情况类似，高维椭球的主轴也是互相垂直的。首先把高维椭球的主轴找出来，再用代表大多数数据信息的最长的几个轴作为新变量。这些互相正交的新变量是原先变量的线性组合，叫做主成分(principal component)。假设我们所讨论的实际问题中，有p个指标，我们把这p个指标看作p个随机变量，记为$X_1， X_2， \cdots，X_p$，主成分分析就是要把这个p指标的问题，转变为讨论p个指标的线性组合的问题，而这些新的指标$F_1， F_2， \cdots， F_k(k\le p)$，按照保留主要信息量的原则充分反映原指标的信息，并且相互独立。这种由讨论多个指标降为少数几个综合指标的过程在数学上就叫做降维。主成分分析通常的做法是，寻求原指标的线性组合Fi。$$ F_1=u_{11}X_1+u_{21}X_2+\cdots+u_{p1}X_p\\F_2=u_{12}X_1+u_{22}X_2+\cdots+u_{p2}X_p\\\cdots\\F_p=u_{1p}X_1+u_{2p}X_2+\cdots+u_{pp}X_p $$满足条件每个主成分的系数平方和为1。即$$ u_{1i}^2+u_{2i}^2+\cdots+u_{pi}^2=1 $$主成分之间相互独立，即无重叠的信息。即$$ Cov(F_i，F_j）=0，i\neq j,i,j=1,2，\cdots，p $$主成分的方差依次递减，重要性依次递减，即$$ Var(F_1)\ge Var(F_2)\ge \cdots \ge Var(F_p) $$ 3 主成分的推导两个线性代数的结论1、若A是p阶实对称矩阵，则一定可以找到正交阵U，使$$ U^{-1}AU=\begin{bmatrix} \lambda_1 &amp; 0 &amp; \cdots &amp; 0\\0 &amp; \lambda_2 &amp; \cdots &amp; 0\\\vdots &amp; \vdots &amp; \ddots &amp; \vdots\\0 &amp; 0 &amp; \cdots &amp; \lambda_p \end{bmatrix}_{p\times p} $$其中$\lambda_i，i=1,2,\cdots,p $是A的特征根。2、若上述矩阵的特征根所对应的单位特征向量为$u_1,\cdots,u_p$。令$$ U=(u_1,\cdots,u_p)=\begin {bmatrix} u_{11} &amp; u_{12} &amp; \cdots &amp; u_{1p}\\u_{21} &amp; u_{22} &amp; \cdots &amp; u_{2p}\\\vdots &amp; \vdots &amp; &amp; \vdots\\u_{p1} &amp; u_{p2} &amp; \cdots &amp; u_{pp} \end {bmatrix} $$则实对称阵A属于不同特征根所对应的特征向量是正交的，即有$U’U=UU’=I$第一主成分设X的协方差阵为$$ \Sigma_x=\begin {bmatrix} \sigma_{11} &amp; \sigma_{12} &amp; \cdots &amp; \sigma_{1p}\\\sigma_{21} &amp; \sigma_{22} &amp; \cdots &amp; \sigma_{2p}\\\vdots &amp; \vdots &amp; &amp; \vdots\\\sigma_{p1} &amp; \sigma_{p2} &amp; \cdots &amp; \sigma_{pp} \end {bmatrix} $$由于$\Sigma_x$为非负定的对称阵，必存在正交阵U，使得：$$ U’\Sigma_x U=\begin {bmatrix} \lambda_1 &amp; &amp; 0\\&amp; \ddots &amp;\\0 &amp; &amp; \lambda_p \end {bmatrix} $$其中$\lambda_1，\lambda_2，\cdots，\lambda_p$为$\Sigma_x$的特征根。不妨假设$\lambda_1\ge \lambda_2\ge \cdots \ge \lambda_p$。而U恰好是由特征根相对应的特征向量所组成的正交阵。$$ U=(u_1,\cdots,u_p)=\begin {bmatrix} u_{11} &amp; u_{12} &amp; \cdots &amp; u_{1p}\\u_{21} &amp; u_{22} &amp; \cdots &amp; u_{2p}\\\vdots &amp; \vdots &amp; &amp; \vdots\\u_{p1} &amp; u_{p2} &amp; \cdots &amp; u_{pp} \end {bmatrix} $$$$ U_i=(u_{1i},u_{2i},\cdots,u_{pi})’ i=1,2,\cdots,p $$设有p维正交向量$a_1=(a_{11},a_{21},\cdots,a_{p1})’$，$F_1=a_{11}X_1+\cdots+a_{p1}X_p=a’X$$$ V(F_1)=a_1’\Sigma a_1==a_1’U\begin {bmatrix} \lambda_1 &amp; &amp; &amp;\\&amp; \lambda_2 &amp; &amp;\\&amp; &amp; \cdots &amp; &amp;\\&amp; &amp; &amp; \lambda_p &amp;\end {bmatrix}U’a_1 $$当且仅当$a_1=u_1$时，即$F_1=u_{11}X_1+\cdots+u_{p1}X_p$时，有最大的方差$\lambda_1$。$Var(F_1)=U_1’\Sigma_x U_1=\lambda_1$。如果第一主成分的信息不够，则需要寻找第二主成分。第二主成分在约束条件$cov(F_1,F_2)=0$下，寻找第二主成分，取线性变换$$ F_2=u_{12}X_1+\cdots+u_{p2}X_p $$的方差次大$$ cov(F_1,F_2)=cov(u_1’x,u_2’x)=u_2’\Sigma u_1=\lambda_1 u_2’u_1=0 $$$$ Var(F_2)=U_2’\Sigma_x U_2=\lambda_2 $$类推$$ F_1=u_{11}X_1+u_{21}X_2+\cdots+u_{p1}X_p\\F_2=u_{12}X_1+u_{22}X_2+\cdots+u_{p2}X_p\\\cdots\\F_p=u_{1p}X_1+u_{2p}X_2+\cdots+u_{pp}X_p$$写成矩阵形式：$$ F=U’X $$$$ U=(u_1,\cdots,u_p)=\begin {bmatrix} u_{11} &amp; u_{12} &amp; \cdots &amp; u_{1p}\\u_{21} &amp; u_{22} &amp; \cdots &amp; u_{2p}\\\vdots &amp; \vdots &amp; &amp; \vdots\\u_{p1} &amp; u_{p2} &amp; \cdots &amp; u_{pp} \end {bmatrix} $$$$ X=(X_1,X_2,\cdots,X_p)’ $$ 4 主成分的性质1、均值 $E(U’x)=U’\mu$2、方差为所有特征根之和$$ \sum_{i=1}^pVar(F_i)=\lambda_1+\lambda_2+\cdots+\lambda_p=\sigma_1^2+\sigma_2^2+\cdots+\sigma_p^2 $$说明主成分分析把p个随机变量的总方差分解成为p个不相关的随机变量的方差之和。协方差矩阵$\Sigma$的对角线上的元素之和等于特征根之和。3、精度分析1）贡献率：第i个主成分的方差在全部方差中所占比重$\lambda_i/\sum_{i=1}^p\lambda_i$，称为贡献率，体现这个主成分的综合能力的大小，即反映原来p个指标的信息的多少。2）累积贡献率：前k个主成分共有多大的综合能力，用这个k个主成分的方差和在全部方差中所占比重$$ \sum_{i=1}^k\lambda_i/\sum_{i=1}^p\lambda_i $$来描述，称为累积贡献率。我们进行主成分分析的目的之一是希望用尽可能少的主成分$F_1，F_2，\cdots，F_k(k\le p)$代替原来的p个指标。到底应该选择多少个主成分，在实际工作中，所采用主成分个数的多少取决于能够反映原来变量85%以上的信息量为依据，即当累积贡献率≥85%时的主成分的个数就足够了。最常见的情况是主成分为2到3个。4、载荷矩阵$$ \begin {bmatrix} u_{11} &amp; u_{12} &amp; \cdots &amp; u_{1m}\\u_{21} &amp; u_{22} &amp; \cdots &amp; u_{2m}\\\vdots &amp; \vdots &amp; &amp; \vdots\\u_{p1} &amp; u_{p2} &amp; \cdots &amp; u_{pm} \end {bmatrix} $$原始变量与主成分之间的相关系数$$ F_j=u_{1j}x_1+u_{2j}x_2+\cdots+u_{pj}x_p j=1,2,\cdots,m,m\le p $$$$ F=U’X UF=X $$$$ \begin {bmatrix} x_1\\x_2\\\vdots\\x_p \end {bmatrix}=\begin {bmatrix} u_{11} &amp; u_{12} &amp; \cdots &amp; u_{1p}\\u_{21} &amp; u_{22} &amp; \cdots &amp; u_{2p}\\\vdots &amp; \vdots &amp; &amp; \vdots\\u_{p1} &amp; u_{p2} &amp; \cdots &amp; u_{pp} \end {bmatrix}\begin {bmatrix} F_1\\F_2\\\vdots\\F_p \end {bmatrix} $$$$ Cov(x_i,F_j)=Cov(u_{i1}F_1+u_{i2}F_2+\cdots+u_{ip}F_p,F_j)=u_{ij}\lambda_j $$$$ \rho(x_i,F_j)=\frac{u_{ij}\lambda_j}{\sigma_i\sqrt{\lambda_j}}=\frac{u_{ij}\sqrt{\lambda_j}}{\sigma_i} $$可见，$x_i$和$F_j$的相关的密切程度取决于对应线性组合系数的大小。该相关系数又叫因子负荷量。在解释主成分的成因或是第i个变量对第k个主成分的重要性时，应当根据因子负荷量而不是变换系数u.原始变量被主成分的提取率主成分的贡献率和累计贡献率度量了$F_1，F_2，\cdots，F_m$分别从原始变量$X_1, X_2, \cdots, X_P$中提取了多少信息。那么$X_1, X_2, \cdots, X_P$各有多少信息分别被$F_1，F_2，\cdots，F_m$提取？这可以用$F_1，F_2，\cdots，F_m$分别与$X_1, X_2, \cdots, X_P$的相关系数的平方来衡量。$$ Var(x_i)=Var(u_{i1}F_1+u_{i2}F_2+\cdots+u_{ip}F_p) $$则$$ u_{i1}^2\lambda_1+u_{i2}^2\lambda_2+\cdots+u_{im}^2\lambda_m+\cdots+u_{ip}^2\lambda_p=\sigma_i^2 $$$u_{ij}^2\lambda_j$是$F_j$能说明的第i 原始变量的方差。$u_{ij}^2\lambda_j/\sigma_i^2$是$F_j$提取的第i原始变量信息的比重。如果我们仅仅提出了m个主成分，则第i原始变量信息的被提取率为：$$ \Omega_i=\sum_{j=1}^m\lambda_ju_{ij}^2/\sigma_i^2=\sum_{j=1}^m\rho_{ij}^2 $$公共成分定义：如果一个主成分仅仅对某一个原始变量有作用，则称为特殊成分。如果一个主成分对所有的原始变量都起作用，则称为公共成分。 5 主成分分析的步骤第一步：由X的协方差阵或相关系数阵Σ，求出其特征根，即解方程，可得特征根。第二步：求出特征根所对应的特征向量$U_1,U_2,\cdots,U_p$，$$ U_i=(u_{1i},u_{2i},\cdots,u_{pi})’ $$第三步：计算累积贡献率，给出恰当的主成分个数。$$ F_i=U_i’X，i=1,2,\cdots,k(k\le p) $$第四步：计算所选出的k个主成分的得分。将原始数据的中心化值:$$ X_i^{\ast}=X_i-\bar X=(x_{1i}-\bar x_1,x_{2i}-\bar x_2,\cdots,x_{pi}-\bar x_p)’ $$代入前k个主成分的表达式，分别计算出各单位k个主成分的得分，并按得分值的大小排队。 基于协方差矩阵 在实际问题中， X的协方差通常是未知的，样品有$$ X_1=(x_{1l},x_{2l},\cdots,x_{pl})’(l=1,2,\cdots,n) $$$$ \hat\Sigma_x=(\frac{1}{n-1}\sum_{l=1}^n(x_{ij}-\bar x_i)(x_{jl}-\bar x_j))_{p\times p} $$ 基于相关系数矩阵 如果变量有不同的量纲， 变量水平差异很大，应该基于相关系数矩阵进行主成分分析。不同的是计算得分时应采用标准化后的数据。 6 主成分的应用与回归1、主成分分析能降低所研究的数据空间的维数。即用研究m维的Y空间代替p维的X空间(m＜p)，而低维的Y空间代替高维的x空间所损失的信息很少。即使只有一个主成分$Y_1$(即m＝1)时，这个$Y_1$仍是使用全部X变量(p个)得到的。在所选的前m个主成分中，如果某个Xi的系数全部近似于零的话，就可以把这个Xi删除，这也是一种删除多余变量的方法。2、多维数据的一种图形表示方法。多元统计研究的问题大都多于3个变量，要把研究的问题用图形表示出来是不可能的。然而，经过主成分分析后，我们可以选取前两个主成分或其中某两个主成分，根据主成分的得分，画出n个样品在二维平面上的分布情况，由图形可直观地看出各样品在主分量中的地位。3、用主成分分析法构造回归模型。即把各主成分作为新自变量代替原来的自变量做回归分析。主成分回归方法$$ F_1=u_{11}X_1+u_{21}X_2+\cdots+u_{p1}X_p\\F_2=u_{12}X_1+u_{22}X_2+\cdots+u_{p2}X_p\\\cdots\\F_p=u_{1p}X_1+u_{2p}X_2+\cdots+u_{pp}X_p$$ $$ Y_i^{\ast}=\gamma_1F_{11}+\gamma_2F_{12}+\cdots+\gamma_mF_{1m}+\varepsilon_i\\\sum_{i=1}^n[Y_i^{\ast}-\gamma_1F_{11}-\gamma_2F_{12}-\cdots-\gamma_mF_{1m}]^2=min $$ 原始数据观测矩阵 $$ X_0=\begin {bmatrix} x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1p}\\x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2p}\\\vdots &amp; \vdots &amp; &amp; \vdots\\x_{n1} &amp; x_{n2} &amp; \cdots &amp; x_{np} \end {bmatrix} $$ 主成分系数矩阵 $$ U=(u_1,\cdots,u_p)=\begin {bmatrix} u_{11} &amp; u_{12} &amp; \cdots &amp; u_{1p}\\u_{21} &amp; u_{22} &amp; \cdots &amp; u_{2p}\\\vdots &amp; \vdots &amp; &amp; \vdots\\u_{p1} &amp; u_{p2} &amp; \cdots &amp; u_{pp} \end {bmatrix} $$ 主成分得分矩阵 $$ \begin {bmatrix} F_{11} &amp; F_{12} &amp; \cdots &amp; F_{1p}\\F_{21} &amp; F_{22} &amp; \cdots &amp; F_{2p}\\\vdots &amp; \vdots &amp; &amp; \vdots\\F_{n1} &amp; F_{n2} &amp; \cdots &amp; F_{np} \end {bmatrix}\\F=X_0U $$ 主成分分析的一些注意事项主成分分析依赖于原始变量，也只能反映原始变量的信息。所以原始变量的选择很重要。如果原始变量本质上独立，那么降维就可能失败，这是因为很难把很多独立变量用少数综合的变量概括。数据越相关，降维效果就越好。分析结果并不一定会有清楚的解释。这与问题的性质，选取的原始变量以及数据的质量等都有关系。基于相关系数矩阵还是基于协方差矩阵做主成分分析？有时基于相关系数矩阵和基于协方差矩阵求出的主成分会有很大不同，且两者之间不存在简单的线性关系。一般而言，当分析中所选择的经济变量具有不同的量纲，变量水平差异很大，应考虑将数据标准化，选择基于相关系数矩阵的主成分分析。对同度量或是取值范围在同量级的数据，选择基于协方差矩阵的主成分分析。选择几个主成分？主成分分析的目的是简化变量，一般情况下主成分的个数应该小于原始变量的个数。关于保留几个主成分，应该权衡主成分个数和保留的信息。如何解释主成分所包含的经济意义？主成分分析不要求数据来自于正态总体。一般认为当原始数据大部分变量的相关系数都小于0.3时，运用主成分分析的效果不显著。 7 主成分分析的R语言实现主成分分析的函数本篇介绍的主要有两个。一个是princomp，一个是psych里的principal。 princomp(x,cor=FALSE,scores=TRUE) x为主成分分析数据集，cor=TRUE和FALSE分别代表是基于相关系数矩阵计算还是协方差矩阵计算。scores则代表是否存储主成分得分。 principal(x,nfactors=2,rotate=&quot;varimax&quot;,scores=T,covar=F) x为主成分分析数据集，nfactors为主成分个数，rotate表示旋转方式（一般选方差最大，保证互不相关），scores则代表是否存储主成分得分，covar=TRUE和FALSE分别代表是基于协方差矩阵计算还是相关系数矩阵计算。这回用的数据是2006年城市统计年鉴285个地级市的经济人口数据，探究gdp与人口之间的关系。先做一个相关系数可视化。发现人口因子之间相互影响因子很高。 于是先对人口的几个因子进行降维和主成分分析，中途发现第三产业从业人数（third)加入会使得系数矩阵不正定，后面就删除了第三产业从业人数(third)。分别用不同方式进行主成分分析结果。princomp结果（基于协方差矩阵）碎石图 结果 主成分得分图 princomp结果（基于相关系数矩阵）碎石图 结果 主成分得分图 principal结果碎石图 因子关系图 主成分得分图 碎石图表示的是曲线与纵坐标1交点的横坐标即为主成分个数，而主成分得分荷图是将原始数据的坐标映射在主成分分析的坐标上，事实上可以根据主成分得分在不同象限对原始数据进行分类，在本篇的样例数据里其实就是可以通过人口生成的几个主成分对中国地级市进行分类，可以区分出是在第一主成分得分高，第二主成分得分低的城市，亦或是其他排列组合的分类结果。关于这种可视化图具体如何解释。可以参照如下的文章。 http://www.cnblogs.com/SCUJIN/p/5965946.html]]></content>
      <categories>
        <category>Statistics &amp; Model</category>
      </categories>
      <tags>
        <tag>R</tag>
        <tag>Theory</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[应用统计学与R语言实现学习笔记（十一）——判别分析]]></title>
    <url>%2F2017%2F09%2F11%2F%E5%BA%94%E7%94%A8%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B8%8ER%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%8D%81%E4%B8%80%EF%BC%89%E2%80%94%E2%80%94%E5%88%A4%E5%88%AB%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[Chapter 11 Discriminant Analysis笔者最近任务繁重，断更了一顿时间，最近会开始慢慢把这个系列写完。本篇是第十一章，内容是判别分析。 1 判别分析应用判别分析（Discriminant Analysis）——判别分析的目的是对已知分类的数据建立由数值指标构成的分类规则，然后把这样的规则应用到未知分类的样本中去分类，以识别未知样本所属的类别。判别分析是多元数据分析的重要方法之一。通常解决被解释变量是非数值变量，解释变量是数值变量的情形。事实上地学领域应用判别分析最多的是在哪里呢？其实是遥感影像的地物分类，通常遥感导论中无论Erdas或者ENVI在做完监督分类之后，其实就是用标注的样本去训练判别函数，然后用判别函数完成整幅影像的判别分析，就可以分出不同的地物类型，这种方法就是我们最普遍使用的极大似然法。而这里的被解释变量就是地物类型，解释变量（多元）就是遥感影像不同波段的DN值，或者是辐射率。 聚类分析和判别分析差异在聚类分析中，人们一般事先并不知道应该分成几类及哪几类，全根据数据确定。在判别分析中，至少有一个已经明确知道类别的“训练样本”，并利用该样本来建立判别准则，并通过预测变量来为未知类别的观测值进行判别。通常实际问题中，可以先聚类以得知类型,再进行判别。用机器学习的话来说，聚类分析是非监督学习，判别分析属于监督学习。 判别分析的数据结构 individuals $X_1$ $X_2$ $\cdots$ $X_l$ $\dots$ $X_p$ Y 1 28 1.0 $\cdots$ 114 $\cdots$ 0.15 1 2 29 2.0 $\cdots$ 117 $\cdots$ 0.20 1 $\cdots$ $\cdots$ $\cdots$ $\cdots$ $\cdots$ $\cdots$ $\cdots$ $\cdots$ i $x_{i1}$ $x_{i2}$ $\cdots$ $x_{il}$ $\cdots$ $x_{ip}$ 2 $\cdots$ $\cdots$ $\cdots$ $\cdots$ $\cdots$ $\cdots$ $\cdots$ $\cdots$ 47 15 8 $\cdots$ 64 $\cdots$ 0.51 2 48 16 7.5 $\cdots$ 65 $\cdots$ 0.50 3 $\cdots$ $\cdots$ $\cdots$ $\cdots$ $\cdots$ $\cdots$ $\cdots$ $\cdots$ n $x_{n1}$ $x_{n2}$ $\cdots$ $x_{nl}$ $\cdots$ $x_{np}$ 3 对比聚类分析的数据结构，事实上就是多了最后一列的Y。 个体由$X_1,X_2,\cdots,X_p$变量描述。 有分类变量$Y$明确对个体分类。 问题：建立$Y与X_1,X_2,\cdots,X_p$变量间关系的函数。根据函数将新个体进行分类。 误判率误判率的高低有下面两个因素决定： 主观因素：分界线的位置要正确。 客观因素：均值，方差——通过选择指标来控制：一般来说，维度高一点，可以使分辨率高一些，但在许多情况下，指标太多，不仅不能提高分辨率，还增加计算量（需要丰富的实际经验和试算）；在做判别分析前，要做假设检验。在两个总体的均值有显著差异的情况下，再做判别分析。 判别分析的假设 每一个判别变量（解释变量）不能是其他判别变量的线性组合——不符合该假设的话，无法估计判别函数，变量间高度相关或一变量与其他变量的线性组合高度相关时，参数估计的标准误差将很大。 判别变量之间具有多元正态分布——可精确的计算显著性检验值和归属概率。 如要采用线性判别函数，还要求各组协方差距阵相等——线性判别函数使用起来最方便、在实际中使用最广。 2 判别分析方法2.1 距离判别法两总体情况假设有两个总体$G_1$和$G_2$，如果能够定义点x到它们的距离d(x,$G_1$)和d(x,$G_2$)，则可用如下规则进行判别： 如果d(x,$G_1$) &lt; d(x,$G_2$)则$x\in G_1$ 如果d(x,$G_2$) &lt; d(x,$G_1$)则$x\in G_2$ 如果d(x,$G_1$) = d(x,$G_2$)则待判。 距离常选用马氏距离——假设$\mu_1,\mu_2,\Sigma_1,\Sigma_2$分别为$G_1和G_2$的均值向量和协方差阵，则点$x$到$G_i$的马氏距离为$$ d^2(x,G_i)=(x-μ_i)’(\Sigma_i)^{-1}(x-μ_i) $$马氏距离的好处是可以克服变量之间的相关性干扰，并且消除各变量量纲的影响。 $\Sigma_1=\Sigma_2=\Sigma$定义：$$ \begin{aligned}d^2(x,G_1)-d^2(x,G_2) &amp; =(x-\mu_1)’\Sigma^{-1}(x-\mu_1)-(x-\mu_2)’\Sigma^{-1}(x-\mu_2) \ &amp;=-2[x-(\mu_1+\mu_2)/2]’\Sigma^{-1}(\mu_1-\mu_2) \end{aligned} $$令：$ \bar\mu=(\mu_1+\mu_2)/2, \alpha=\Sigma^{-1}(\mu_1-\mu_2),W(x)=(x-\bar\mu)’\alpha=\alpha’(x-\bar\mu) $判别规则：如果W(x)&gt;0，d(x,$G_1$) &lt; d(x,$G_2$)则$x\in G_1$如果W(x) d(x,$G_2$)则$x\in G_2$如果W(x)=0，d(x,$G_1$) = d(x,$G_2$)则待判。称W(x)为判别函数(discriminant function)，α为判别系数。当$\mu_1,\mu_2,\Sigma$未知时，可通过样本来估计。$ x_1^{(i)},\cdots,x_{n_i}^{(i)} $为来自$G_i$的样本(i=1,2)。$$ \hat\mu^{(i)}=\frac{1}{n_i}\sum_{k=1}^{n_2}x_k^{(i)}=\bar x^{(i)},\hat \Sigma=\frac{1}{n_1+n_2-2}(S_1+S_2), $$$$ S_i=\sum_{t=1}^{n_i}(x_t^{(i)}-\bar x^{(i)})(x_t^{(i)}-\bar x^{(i)})’,\bar x=\frac{1}{2}(\bar x^{(1)}+\bar x^{(2)}) $$判别函数为$W(x)=(x-\bar x)’\Sigma^{-1}(\bar x^{(1)}-\bar x^{(2)})$ $\Sigma_1 \neq \Sigma_2$判别函数为二次函数$W(x)=d^2(x,G_2)-d^2(x,G_1)=(x-\mu_2)’\Sigma_2^{-1}(x-\mu_2)-(x-\mu_1)’\Sigma_2^{-1}(x-\mu_1)$按照距离最近原则，判别准则为：如果W(x)&gt;0即d(x,$G_1$) &lt; d(x,$G_2$)则$x\in G_1$如果W(x) d(x,$G_2$)则$x\in G_2$如果W(x)=0即d(x,$G_1$) = d(x,$G_2$)则待判。 多总体情况 多总体情况：协方差相同假设有k个总体$G_1,G_2,\cdots,G_k$，它们的均值向量分别为$\mu_1,\mu_2,\cdots,\mu_k$,协方差阵为$\Sigma$，类似于两总体的讨论，判别函数为：$W_{ij}(x)=[x-(\mu_1+\mu_2)/2]’\Sigma^{-1}(\mu_i-\mu_j),i,j=1,\cdots,k$判别规则：如果存在i，对所有j≠i，有$W_{ij}(x)&gt;0$，则$x\in G_i$，否则待判。如果服从多元正态分布，且各组协方差相同$\begin{aligned} d^2(x,G_i)&amp; =(x-\mu_i)’\Sigma^{-1}(x-\mu_i) \ &amp; =x’\Sigma^{-1}x-2(x’\Sigma^{-1}\mu_i-\mu_i’\Sigma^{-1}\mu_i/2) \ &amp; =x’\Sigma^{-1}x-f_i(x)\end{aligned}$在所有的$f_i(x)$中，哪个$f_i(x)$的值大，x到相应的组i的马氏距离小，判$x\in G_i$ 多总体情况：协方差不等假设有k个总体$G_1,G_2,\cdots,G_k$，它们的均值向量分别为$\mu_1,\mu_2,\cdots,\mu_k$,协方差阵为$\Sigma_1,\Sigma_2,\cdots,\Sigma_k$，类似于两总体的讨论，判别函数为：$W(x)=(x-\mu_j)’\Sigma_j^{-1}(x-\mu_j)-(x-\mu_i)’\Sigma_i^{-1}(x-\mu_i),i,j=1,\cdots,k$判别规则：如果存在i，对所有j≠i，有$W_{ij}(x)&gt;0$，则$x\in G_i$，否则待判。如果总体均值、协方差未知，用样本均值、协方差估计。 若总体不服从正态分布，直接从马氏距离来做判别分析，失去了概率意义，仅仅是一直观的经验判断而已，可能偏误较大。 2.2 Fisher判别法Fisher判别法的思想就是投影，将k组p维数据投影到某一个方向，使得它们的投影组与组之间尽可能的分开。考虑只有两个(预测)变量的判别问题。假定只有两类。数据中的每个观测值是二维空间的一个点。这里只有两种已知类型的训练样本。一 类 有 38 个 点 ( 用“o”表示)，另一类有44个点(用“*”表示)。按原来变量(横坐标和纵坐标)，很难将这两种点分开。 但是沿着图上的虚线方向朝和这个虚线垂直的一条直线进行投影会使得这两类分得最清楚。可以看出，如果向其他方向投影，判别效果不会比这个好。有了投影之后，再用前面讲到的距离远近的方法得到判别准则。这种先投影的判别方法就是Fisher判别法。Fisher判别法 不要求总体分布类型； 工作原理就是对原数据系统进行坐标变换，寻求能够将总体尽可能分开的方向； a为$R^p$中的任一向量，点x在以a为法方向的投影为a’x; 各组数据的投影为：$$ G_i:a’x_1^{(i)}\cdots a’x_n^{(i)},i=1,2,\cdots,k$$ 这些数据正好组成一元方差分析的数据。 将$G_m$组中数据投影的均值记为$ a’\bar x^{(m)} $,有：$$ a’\bar x^{(m)}=\frac{1}{n_m}\sum_{i=1}^{n_m}a’\bar x_i^{(m)} ,m=1,\cdots,k$$记k组数据投影的总均值为$a’\bar x$，有：$$ a’\bar x=\frac{1}{n}\sum_{m=1}^{k}\sum_{i=1}^{n_m}a’\bar x_i^{(m)} $$组间离差平方和为：$$ SSG=\sum_{m=1}^{k}n_m(a’\bar x^{(m)}-a’\bar x)^2=a’[\sum_{m=1}^{k}n_m(\bar x^{(m)}-\bar x)(\bar x^{(m)}-\bar x)’]a=a’Ba; $$$$ B=\sum_{m=1}^{k}n_m[(\bar x^{(m)}-\bar x)(\bar x^{(m)}-\bar x)’] $$组内离差平方和为：$$ SSE=\sum_{m=1}^k \sum_{i=1}^{n_m}(a’\bar x^{(m)}-a’\bar x)^2=a’[\sum_{m=1}^k \sum_{i=1}^{n_m}(\bar x^{(m)}-\bar x)(\bar x^{(m)}-\bar x)’]a=a’Ea $$$$ E=\sum_{m=1}^k \sum_{i=1}^{n_m}(\bar x^{(m)}-\bar x)(\bar x^{(m)}-\bar x)’ $$如果K组有显著差异，则$$ F=\frac{SSG/(k-1)}{SSE/(n-k)}=\frac{n-k}{k-1}\frac{a’Ba}{a’Ea} $$F应充分大，即希望找到a使得SSG尽可能大而SSE尽可能小。$$ \Delta (a)=\frac{a’Ba}{a’Ea}\rightarrow max $$使$\frac{a’Ba}{a’Ea}$最大的值为方程$\left|B-\lambda E\right|=0$的最大特征根$\lambda_1$。记方程$\left|B-\lambda E\right|=0$的全部特征根为$\lambda_1\ge \cdots \ge \lambda_r \gt 0$，相应的特征向量为$v_1,\cdots,v_r$。$\Delta (a)$的大小可以估计判别函数$y_i (x)=v_i’x(=a’x)$的效果。记$p_i$为判别能力（效率），有：$$ p_i=\frac{\lambda_i}{\sum_{h=1}^r \lambda_h} $$在有些问题中，仅用一个线性判别函数不能很好区别各个总体，可取第二个、第三个，以此类推。 m个判别函数的判别能力定义为：$$ \sum_{i=1}^mp_i=\frac{\sum_{i=1}^m\lambda_i}{\sum_{h=1}^r \lambda_h} $$据此来确定选择多少判别函数。判别准则选择i使得：$$ v_1’(x-\mu_i)+\cdots+v_m’(x-\mu_i) $$的值最小Fisher判别法实质 选几个新的综合性指标，代替原来的p个指标。 构成新的综合性指标的条件：（1）不同类的均值差距尽可能大；（2）各类中的方差尽可能小。 Fisher判别法的依据不是x属于哪个总体的概率的大小，而是类别之间具有最大的可分性，也没有考虑错判带来的损失大小（错报台风登陆vs.漏报台风登陆）。 2.3 Bayes判别法 不用判别式，而是比较新给样品属于各个总体的条件概率p(g|x)，$g=1,\cdots,k$的大小，将新样品判归为来自条件概率最大的总体。 先给出 k 个总体的先验概率$q_1,\cdots,q_k$（实践中通常把频率作为先验概率）。如各总体密度为${f_k(x)}$，则后验概率为($g=1,\cdots,k$):$P(g|x)=q_gf_g(x)/\Sigma_i q_if_i(x)$。 当且仅当$P(h|x)= max_gP(g|x)$，判x来自第h总体。 也可以用使错判的损失最小的准则来判别。 设($D_1,D_2,\cdots,D_K$)是$R_p$的一个完备的划分，当样品x属于$D_i$,就判x来自$G_i$。 记$p(j|i), c(j|i)$分别为来自i总体的个体被错判到第j总体的概率和损失。定义平均错判损失(ECM: expected cost of misclassification)为$ECM(D)=\Sigma_{i=1\cdots k}q_i[\Sigma_{j=1\cdots k}p(j|i)c(j|i)]$ Bayes判别法就是要选择划分D使得ECM(D)最小。 3 建立判别函数的方法与多元回归类似，变量选择的好坏直接影响判别分析的效果。常遇问题：（1）忽略最主要的指标；（2）引入太多指标，计算量既大又干扰分析。 全模型法(SPSS系统默认方法） 前向选择法从没有变量的模型开始 每一部逐步把对判别函数贡献最大的变量加入模型，直到模型外没有一个变量符合条件为止。当希望有较多变量进入判别函数时，选用此方法（在Syntax中实现）。选择使威尔克斯统计量最小且显著的变量加入。 后向选择法从包含用户指定的所有变量的模型开始。每一部逐步把对判别函数贡献最小的变量从模型中剔除出去，直到留在模型中的变量都符合条件为止。当希望判别函数含有较少变量时，选用此方法。选择使威尔克斯统计量最大且不显著的变量剔除。 逐步选择法前向选择和后向选择的结合。从没有变量的模型开始。每一部逐步把对判别函数贡献最大的变量加入模型，同时，对模型中的变量进行检验，把不符合条件的变量从模型中删除。是一种较好的方法。选择使威尔克斯统计量最小且显著的变量加入。选择使威尔克斯统计量最大且不显著的变量剔除。 4 判别分析的步骤及注意事项判别分析的步骤 第1步：确定研究的问题与目的判别分析适合将个体归类的问题，特别适合一个定性的被解释变量和多个定量的解释变量的情形。 第2步：判别分析研究设计解释变量与被解释变量的选择：被解释变量的组数可以是两个或更多，但必须互斥和完备。样本容量：判别分析对样本量与预测变量的比率敏感。总样本量：建议比率为每个解释变量20个观测，最小的总样本量为每个变量5个观测。最小的组的大小必须超过解释变量的个数，建议每组至少有20个观测，还要注意组的相对大小（大的组有不相称的高的分类机会）。样本分割：需要将样本分割为两个子样本，一个用于估计判别函数，另一个用于验证。随机分组，最常见的是随机分为两半。通常各组比率相同。 第3步：判别分析的假定多元正态性，如不满足建议使用Logistic回归。Box’s Test 检验各组协方差阵是否相等，不等的协方差矩阵可能会负面影响分类过程，观测会被“过度归类”到大的协方差阵组中。解释变量的多重共线性。 第4步：估计判别模型和评估整体拟和统计显著性： Wilks’ Lambda， Hotelling迹和Pillai评估判别函数的判别效力的显著性。评估整体拟和：计算每个观测的判别Z得分，检验各组在判别Z得分上的差异，评估组，关系的预测精度。 第5步：结果的解释解释判别分析中每个解释变量的相对重要性。标准化判别权重（判别系数）：如存在多重共线性时不合适，可能不稳定。判别载荷，又称结构相关系数，是每个解释变量与判别函数的简单相关系数，也可能不稳定。偏F值。能力指数：当保留多个判别函数时。 第6步：结果的验证分隔样本或交叉验证法。 判别分析注意事项 解释变量（判别变量）必须是可测量的。 每一个判别变量不能是其它判别变量的线性组合（不能提供新的信息，无法估计判别函数）。 判别变量不能高度相关，否则导致估计的标准误差很大。 训练样本中必须包含所有要判别的类型，分类必须清楚（在判别分析前最好应当做假设检验，确定各个类的有关变量的均值是显著不同的）。 要选择好可能用于判别的预测变量。判别分析是为了正确地分类，但同时也要注意使用尽可能少的预测变量来达到这个目的。使用较少的变量意味着节省资源和易于对结果作解释。 检验结果(在SPSS选项中选择Wilks’ Lambda、Rao’s V、 The Squared Mahalanobis Distance或The Sum of Unexplained Variations等检验的计算机输出)，以确定是否分类结果仅由于随机因素。 对于多个判别函数，要弄清各自的重要性。 注意训练样本的正确和错误分类率。研究被误分类的观测值，看是否能找出原因。 5 R语言中判别分析实现正如上文提到的，我们以一个简单的地物分类的例子来进行实践。原始的遥感影像如图所示(高分一号卫星16 m数据）。 高分一号卫星有四个波段，分别显示如下： 我们随机在区域内生成了55个样本点，并根据目视解译做了分类，由于所处研究区位于新城且仅作测试，用地类型仅选择了两类：建设用地/不透水面和植被。前面已经用4，3，2显示了原始影像，红色部分即为植被。植被为类型1，建设用地/不透水面为类型2。 另外我们随机在区域内还生成了10个样本点作为验证点。 接着下来我们读取数据并且利用三种不同的判别分析方法进行判别分析地物类别。判别分析可以自己通过dist函数计算距离得到。现在已经有对应的包可以直接分析。这里推荐两个包（WMDB和MASS）。WMDB可以实现加权马氏距离判别分析和Bayes判别分析，MASS可以实现Fisher判别分析。距离判别分析的函数为wmd。具体参数如下： wmd(Trnx,TrnG,Tweight=NULL,Tstx=NULL,var.equal=F) Trnx是训练样本数据。TrnG为分类结果，Tweight为指定权重，可以根据主成分贡献计算或者取相等（原始的判别分析法），Tstx为待测样本数据，var.equal指定协方差矩阵是否相等。Fisher判别分析的函数为lda。具体参数如下： lda(formula,data,……,subset,na.action) formula形如groups~x1+x2+……的形式，data为数据集，subset指定训练样本，na.action指定有缺失值处理方式。Bayes判别分析的函数为dbayes。具体参数如下： dbayes(Trnx,TrnG,p=rep(1,length(levels(TrnG))),Tstx=NULL,var.equal=F) Trnx是训练样本数据。TrnG为分类结果，p为指定先验概率的向量，Tstx为待测样本数据，var.equal指定协方差矩阵是否相等。接下来就是基于高分影像的四个波段进行训练和判别分析。距离判别分析结果。 Fisher判别分析结果。 列联表分析及判别准确率。 Bayes判别分析结果。 从样本数据来看，Fisher结果是最好的。接下来即按照训练好的判别规则进行分类。这里发现WMDB包的两个函数并没有提供预测功能，这里选用了另一个包klaR来做贝叶斯分类（朴素贝叶斯）。分类结果对比： 为了验证准确率，这里利用随机生成的10个验证点进行精度验证。 由于选取验证点较少，准确率都达到了100%。从实际影像对比来看，似乎Bayes方法将更多细小的植被提取出来了，但是也有一部分道路错分。Fisher方法少提取了一部分，但错分的部分几乎没有。这部分的代码和数据后面会一起放出来。]]></content>
      <categories>
        <category>Statistics &amp; Model</category>
      </categories>
      <tags>
        <tag>R</tag>
        <tag>Theory</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[应用统计学与R语言实现学习笔记（十）——聚类分析]]></title>
    <url>%2F2017%2F06%2F21%2F%E5%BA%94%E7%94%A8%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B8%8ER%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%8D%81%EF%BC%89%E2%80%94%E2%80%94%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[Chapter 10 Cluster Analysis本篇是第十章，内容是聚类分析。由于之后的几章是典型的分析方法。而且在14章的案例里面可能不会体现，所以内容里会渗透较多的R语言操作。 1 多元分布基本概念在研究实际问题的时候，我们经常遇到的是多变量的问题，由于指标间相互不独立，单独割裂开来分别研究分析，不能从整体上把握所研究问题的实质。所以我们必须对多元变量及其分布进行统计和分析，在地学领域这种问题比比皆是，这里就不展开阐述了，接下来是一堆纯数学概念，数学恐惧者慎入，这部分的重点应该是关于协方差矩阵。一般来说，假设所研究的问题有p个指标，进行了n次独立观测，得到了np个数据。那么对于单次独立观测，我们定义随机向量（Random Vector）为：$$ x=(x_1,x_2,\cdots,x_p)’ $$其概率分布函数定义为$$ F(a_1,a_2,\cdots,a_p)=P(x_1\le a_1,x_2\le a_2,\cdots,x_p\le a_p) $$分布函数的性质 非降的右连续函数 分布函数的取值范围为[0，1]，即$$ 0\le F(a_1,a_2,\cdots,a_p)\le 1 $$ 分布函数当变量取值为无穷大时，函数值收敛到1，即$$ F(\infty,\infty,\cdots,\infty)=1 $$ 多元概率密度函数随机向量$x=(x_1,x_2,\cdots,x_p)’$的分布函数可以表示为$$F(a_1,a_2,\cdots,a_p)=P(x_1\le a_1,x_2\le a_2,\cdots,x_p\le a_p)=\int_{-\infty}^{a_1}\cdots\int_{-\infty}^{a_p}f(x_1,x_2,\cdots,x_p)dx_1\cdots dx_p $$则称$ x=(x_1,x_2,\cdots,x_p)’ $为连续型随机变量，称$f(x_1,x_2,\cdots,x_p)$为其多元概率密度函数。若$F(a_1,a_2,\cdots,a_p)$在点$(x_1,x_2,\cdots,x_p)$连续，则$f(x_1,x_2,\cdots,x_p)=\frac{\partial^p}{\partial x_1\partial x_2\cdots\partial x_p}F(x_1,x_2,\cdots,x_p)$且有$1\ge F(x_1,x_2,\cdots,x_p)\ge 0$，$\int_{-\infty}^{a_1}\cdots\int_{-\infty}^{a_p}f(x_1,x_2,\cdots,x_p)dx_1\cdots dx_p=1$。数学期望定义$$ \begin {bmatrix} x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1q}\\x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2q}\\\vdots &amp; \vdots &amp; &amp; \vdots\\x_{p1} &amp; x_{p2} &amp; \cdots &amp; x_{pq} \end {bmatrix} $$是由随机变量构成的随机矩阵，定义X的数学期望为$$ \begin {bmatrix} E(x_{11}) &amp; E(x_{12}) &amp; \cdots &amp; E(x_{1q})\\E(x_{21}) &amp; E(x_{22}) &amp; \cdots &amp; E(x_{2q})\\\vdots &amp; \vdots &amp; &amp; \vdots\\E(x_{p1}) &amp; E(x_{p2}) &amp; \cdots &amp; E(x_{pq}) \end {bmatrix} $$特别当q=1时，便可得到随机向量$(x_1,x_2,\cdots,x_p)’$的数学期望为$E(x)=(E(x_1),E(x_2),\cdots,E(x_p))’$协方差矩阵设$x=(x_1,x_2,\cdots,x_p)’$和$y=(y_1,y_2,\cdots,y_q)’$分别为p维和q维随机向量，则其协方差矩阵为$$ E\begin {bmatrix} \begin {pmatrix} x-E(x_1) \ x-E(x_2)\\\vdots\\x-E(x_p) \end{pmatrix} (y-E(y_1),(y-E(y_2),\cdots,(y-E(y_q) \end {bmatrix} $$ $$ =\begin {pmatrix} cov(x_1,y_1) &amp; cov(x_1,y_2) &amp; \cdots &amp; cov(x_1,y_q)\\cov(x_2,y_1) &amp; cov(x_2,y_2) &amp; \cdots &amp; cov(x_2,y_q)\\\vdots &amp; \vdots &amp; &amp; \vdots\\cov(x_p,y_1) &amp; cov(x_p,y_2) &amp; \cdots &amp; cov(x_p,y_q) \end {pmatrix}=cov(X,Y) $$$x=(x_1,x_2,\cdots,x_p)’$的协方差矩阵为$$\Sigma=Var(x)=\begin {pmatrix} var(x_1) &amp; cov(x_1,x_2) &amp; \cdots &amp; cov(x_1,x_p)\\cov(x_2,x_1) &amp; var(x_2) &amp; \cdots &amp; cov(x_2,x_p)\\\vdots &amp; \vdots &amp; &amp; \vdots\\cov(x_p,x_1) &amp; cov(x_p,x_2) &amp; \cdots &amp; var(x_p) \end {pmatrix} $$随机向量X的协方差矩阵Σ是非负定矩阵。设A是常数矩阵，b为常数向量，则$$ Var(AX+b)=AV(X)A’=A\Sigma A’ $$若$(x_1,x_2,\cdots,x_p)’$的分量相互独立，则协方差矩阵除主对角线上的元素外均为零，即$$\Sigma=Var(x)=\begin {pmatrix} var(x_1) &amp; 0 &amp; \cdots &amp; 0\\0 &amp; var(x_2) &amp; \cdots &amp; 0\\\vdots &amp; \vdots &amp; &amp; \vdots\\0 &amp; 0 &amp; \cdots &amp; var(x_p) \end {pmatrix} $$相关系数矩阵若$x=(x_1,x_2,\cdots,x_p)’$和$y=(y_1,y_2,\cdots,y_q)’$分别是p维和q维随机向量，则其相关系数矩阵为$$ \rho (x,y)=\begin {pmatrix} \rho (x_1,y_1) &amp; \rho (x_1,y_2) &amp; \cdots &amp; \rho (x_1,y_q)\\\rho (x_2,y_1) &amp; \rho (x_2,y_2) &amp; \cdots &amp; \rho (x_2,y_q)\\\vdots &amp; \vdots &amp; &amp; \vdots\\\rho (x_p,y_1) &amp; \rho (x_p,y_2) &amp; \cdots &amp; \rho (x_p,y_q) \end {pmatrix} $$若$ \rho (x,y)=0 $，两随机向量相互独立。 2 数据的变换处理数据变换是将原始数据矩阵中的每个元素按照某种特定的运算把它变成为一个新值，而且数值的变化不依赖于原始数据集合中其它数据的新值。事实上多元数据的变换处理通常是为了消除不同量纲的差异。较常用的数据变换如下： 中心化变换中心化变换是一种坐标轴平移处理方法，它是先求出每个变量的样本平均值，再从原始数据中减去该变量的均值，就得到中心化变换后的数据。设原始观测数据矩阵为：$$ X= \begin {bmatrix} x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1q}\\x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2q}\\\vdots &amp; \vdots &amp; &amp; \vdots\\x_{n1} &amp; x_{n2} &amp; \cdots &amp; x_{nq} \end {bmatrix} $$$$ x_{ij}^*=x_{ij}-\bar x_j (i=1,2,\cdots,n;j=1,2,\cdots,p) $$中心化变换的结果是使每列数据之和均为0，即每个变量的均值为0，而且每列数据的平方和是该列变量样本方差的(n-1)倍，任何不同两列数据之交叉乘积是这两列变量样本协方差的(n-1)倍，所以这是一种很方便地计算方差与协方差的变换。 极差规格化变换极差规格化变换是从数据矩阵的每一个变量中找出其最大值和最小值，这两者之差称为极差，然后从每个变量的每个原始数据中减去该变量中的最小值，再除以极差，就得到规格化数据。$$ x_{ij}^*=\frac{x_{ij}-min_{k=1,2,\cdots,n} (x_{kj})}{R_j} (i=1,2,\cdots,n;j=1,2,\cdots,p) $$ 极差：$$ R_j= max_{i=1,2,\cdots,n} (x_{ij})-min_{i=1,2,\cdots,n} (x_{ij})，0\le x_{ij}^*\le 1 $$经过极差规格化变换后，数据矩阵中每列即每个变量的最大数值为1，最小数值为0，其余数据取值均在0和1之间；并且变换后的数据都不再具有量纲，便于不同的变量之间的比较。 标准化变换标准化变换首先对每个变量进行中心化变换，然后用该变量的标准差进行标准化。$$ x_{ij}^*=\frac{(x_{ij}-\bar x)}{S_j} (i=1,2,\cdots,n;j=1,2,\cdots,p) $$$$ S_j=\sqrt{\frac{1}{n-1}\sum_{i=1}^n(x_{ij}-\bar x_j)^2} $$经过标准化变换处理后，数据矩阵中每列数据即每个变量的平均值为0，方差为1，且不再具有量纲，便于不同变量之间的比较。变换后，数据矩阵中任何两列数据乘积之和是所对应的两个变量相关系数的（ n-1）倍，所以这是一种很方便地计算相关矩阵的变换。 对数变换对数变换是将各个原始数据取对数，将原始数据的对数值作为变换后的新值。$$ x_{ij}^*=log(x_{ij}) $$ 3 聚类分析聚类分析是一种分类技术。与多元分析的其他方法相比，该方法较为粗糙，理论上还不完善，但应用方面取得了很大成功。与回归分析、判别分析一起被称为多元分析的三大方法。聚类的目的——根据已知数据（ 一批观察个体的许多观测指标） ， 按照一定的数学公式计算各观察个体或变量（指标）之间亲疏关系的统计量（距离或相关系数等）。 根据某种准则（ 最短距离法、最长距离法、中间距离法、重心法等），使同一类内的差别较小，而类与类之间的差别较大，最终将观察个体或变量分为若干类。聚类的种类——根据分类的方法可将聚类分析分为：系统聚类、快速聚类、有序聚类。根据分类的对象可将聚类分析分为：Q型——样品聚类clustering for individuals；R型——指标聚类clustering for variables。数据结构 individuals $ X_1 $ $ X_2 $ $\cdots$ $ X_l $ $\cdots$ $ X_p $ 1 28 1.0 $\cdots$ 114 $ \cdots$ 0.15 2 29 2.0 $\cdots$ 117 $\cdots$ 0.20 $ \cdots$ $\cdots$ $\cdots$ $\cdots$ $\cdots$ $\cdots$ $\cdots$ i $x_{i1}$ $x_{i2}$ $\cdots$ $x_{il}$ $\cdots$ $x_{ip}$ $\cdots$ $\cdots$ $\cdots$ $\cdots$ $\cdots$ $\cdots$ $\cdots$ 47 15 8 $\cdots$ 64 $\cdots$ 0.51 48 16 7.5 $\cdots$ 65 $\cdots$ 0.50 $\cdots$ $\cdots$ $\cdots$ $\cdots$ $\cdots$ $\cdots$ $\cdots$ n $x_{n1}$ $x_{n2}$ $\cdots$ $x_{nl}$ $\cdots$ $x_{np}$ 4 样品间亲疏程度的测度样品间亲疏程度的测度研究样品或变量的亲疏程度的数量指标有两种，一种叫相似系数，性质越接近的变量或样品，它们的相似系数越接近于1，而彼此无关的变量或样品它们的相似系数则越接近于0，相似的为一类，不相似的为不同类；另一种叫距离，它是将每一个样品看作p维空间的一个点，并用某种度量测量点与点之间的距离，距离较近的归为一类，距离较远的点属于不同的类。变量之间的聚类即R型聚类分析，常用相似系数来测度变量之间的亲疏程度。而样品之间的聚类即Q型聚类分析，则常用距离来测度样品之间的亲疏程度。距离假使每个样品有p个变量，则每个样品都可以看成p维空间中的一个点， n个样品就是p维空间中的n个点，则第i样品与第j样品之间的距离记为$d_{ij}$。定义距离的准则定义距离要求满足第i个和第j个样品之间的距离如下四个条件（距离可以自己定义，只要满足距离的这四个条件） $d_{ij}\ge 0$对一切的i和j成立; $d_{ij}=0$当且仅当$x_i=x_j$成立; $d_{ij}=d_{ji}$对一切的i和j成立; $d_{ij}\le d_{ik}+d_{kj}$对于一切的i和j成立。常用距离 明氏距离(Minkowski)设$x_i=(x_{i1},x_{i1},\cdots,x_{ip})’$和$x_j=(x_{j1},x_{j1},\cdots,x_{jp})’$是第i和j个样品的观测值，则二者之间的距离。明氏距离：$$ d_{ij}=(\sum_{k=1}^p \left |x_{ik}-x_{jk}|^q\right)^{\frac{1}{q}} $$欧氏距离：$$ d_{ij}=\sqrt{\sum_{k=1}^p(x_{ik}-x_{jk})^2} $$绝对距离：$$ d_{ij}=\sum_{k=1}^p|x_{ik}-x_{jk}| $$Chebychev距离：$$ d_{ij}=max_{k=1}^p|x_{ik}-x_{jk}| $$明氏距离主要有以下两个缺点明氏距离的值与各指标的量纲有关，而各指标计量单位的选择有一定的人为性和随意性，各变量计量单位的不同不仅使此距离的实际意义难以说清，而且，任何一个变量计量单位的改变都会使此距离的数值改变从而使该距离的数值依赖于各变量计量单位的选择。明氏距离的定义没有考虑各个变量之间的相关性和重要性。实际上，明氏距离是把各个变量都同等看待，将两个样品在各个变量上的离差简单地进行了综合。 兰氏距离(Lance &amp; Williams)这是兰思和维廉姆斯(Lance &amp; Williams)所给定的一种距离，其计算公式为：$$ d_{ij}(L)=\sum_{k=1}^p\frac{|x_{ik}-x_{jk}|}{x_{ik}+x_{jk}} $$这是一个自身标准化的量，由于它对大的奇异值不敏感，这样使得它特别适合于高度偏倚的数据。虽然这个距离有助于克服明氏距离的第一个缺点，但它也没有考虑指标之间的相关性。 马氏距离(Mahalanobis)这是印度著名统计学家马哈拉诺比斯(P.C． Mahalanobis)所定义的一种距离，其计算公式为：$$ d_{ij}^2=(x_i-x_j)’\Sigma^{-1}(x_i-x_j) $$Σ表示观测变量之间的协方差短阵。在实践应用中，若总体协方差矩阵Σ未知，则可用样本协方差矩阵作为估计代替计算。马氏距离又称为广义欧氏距离。显然，马氏距离与上述各种距离的主要不同就是马氏距离考虑了观测变量之间的相关性。如果假定各变量之间相互独立，即观测变量的协方差矩阵是对角矩阵，则马氏距离就退化为用各个观测指标的标准差的倒数作为权数进行加权的欧氏距离。因此，马氏距离不仅考虑了观测变量之间的相关性，而且也考虑到了各个观测指标取值的差异程度。 斜交空间距离由于各变量之间往往存在着不同的相关关系，用正交空间的距离来计算样本间的距离易变形，所以可以采用斜交空间距离。$$ d_{ij}=[\frac{1}{p^2}\sum_{h=1}^p\sum_{k=1}^p(x_{ih}-x_{jh})(x_{ik}-x_{jk})r_{hk}]^{\frac{1}{2}} $$当各变量之间不相关时，斜交空间退化为欧氏距离。 配合距离$$ X_1=(V,Q,S,T,K) X_2=(V,M,S,F,K)$$$$ d_{12}=\frac{m_1}{m_1+m_2}=\frac{不配合数}{配合数+不配合数}=\frac{2}{2+3}=\frac{2}{5} $$适用于分类变量，尤其是名义尺度变量。相似系数研究样品间的关系常用距离，研究指标间的关系常用相似系数。相似系数常用的有夹角余弦和相关系数。 夹角余弦(Cosine)夹角余弦是从向量集合的角度所定义的一种测度变量之间亲疏程度的相似系数。设在n维空间的向量。$$ x_i=(x_{1i},x_{2i},\cdots,x_{ni})’，x_j=(x_{1j},x_{2j},\cdots,x_{nj})’ $$$$ c_{ij}=\cos \alpha_{ij}=\frac{\sum_{k=1}^nx_{ki}x_{kj}}{\sqrt{\sum_{k=1}^nx_{ki}^2\sum_{k=1}^nx_{kj}^2}}，d_{ij}^2=1-c_{ij}^2$$ 相关系数是将数据标准化后的夹角余弦$$ x_i=(x_{1i},x_{2i},\cdots,x_{ni})’，x_j=(x_{1j},x_{2j},\cdots,x_{nj})’ $$$$ c_{ij}=\frac{\sum_{k=1}^n(x_{ki}-\bar x_i)(x_{kj}-\bar x_j)}{\sqrt{\sum_{k=1}^n(x_{ki}-\bar x_i)^2\sum_{k=1}^n(x_{kj}-\bar x_j)^2}} $$距离和相似系数选择的原则一般说来，同一批数据采用不同的亲疏测度指标，会得到不同的分类结果。产生不同结果的原因，主要是由于不同的亲疏测度指标所衡量的亲疏程度的实际意义不同，也就是说，不同的亲疏测度指标代表了不同意义上的亲疏程度。因此我们在进行聚类分析时，应注意亲疏测度指标的选择。通常，选择亲疏测度指标时，应注意遵循的基本原则主要有：所选择的亲疏测度指标在实际应用中应有明确的意义。如在经济变量分析中，常用相关系数表示经济变量之间的亲疏程度。适当地考虑计算工作量的大小。如对大样本的聚类问题，不适宜选择斜交空间距离，因采用该距离处理时，计算工作量太大。亲疏测度指标的选择要综合考虑已对样本观测数据实施了的变换方法和将要采用的聚类分析方法。如在标准化变换之下，夹角余弦实际上就是相关系数；又如若在进行聚类分析之前已经对变量的相关性作了处理，则通常就可采用欧氏距离，而不必选用斜交空间距离。此外，所选择的亲疏测度指标，还须和所选用的聚类分析方法一致。如聚类方法若选用离差平方和法，则距离只能选用欧氏距离。样品间或变量间亲疏测度指标的选择是一个比较复杂且带主观性的问题，我们应根据研究对象的特点作具体分析，以选择出合适的亲疏测度指标。实践中，在开始进行聚类分析时，不妨试探性地多选择几个亲疏测度指标，分别进行聚类，然后对聚类分析的结果进行对比分析，以确定出合适的亲疏测度指标。 5 类与类之间的距离 最短距离法(Nearest Neighbor) 最长距离法(Furthest Neighbor) 重心法(Centroid method) 类平均法(average linkage)——组间连接法(Between-groups Linkage)和组内连接法(Within-groups Linkage) Ward离差平方和法(Ward’s minimumvariance method) 6 系统聚类(hierarchical clustering method)系统聚类的步骤 （1） 开始将n个样品各作为一类。（2） 根据样品的特征，选择合适的距离公式，计算n个样品两两之间的距离，构成距离矩阵。（3） 选择距离矩阵中最小的非对角线元素$d_{pq}$，将相应的两类$G_p$和$G_q$合并为一新类$G_r$={$G_p, G_q$}。（4） 利用递推公式计算新类与当前各类的距离。 分别删除原矩阵的第p，q行和第p，q列，并新增一行和一列添上的结果，产生新的距离矩阵。（5） 再合并、计算，直至只有一类为止。（6） 画聚类图，解释。 最短距离法定义距离：$D_{pq}$=$Min${$d_{ij}：x_i\in G_p， x_j\in G_q$}假设第p类和第q类合并成第r类，第r类与其它各旧类的距离按最短距离法为：递推公式：$D_{rl}$=$Min${$D_{pl}，D_{ql}$} $l\neq p,q$ 最长距离法定义距离：$D_{pq}$=$Max${$d_{ij}：x_i\in G_p， x_j\in G_q$}假设第p类和第q类合并成第r类，第r类与其它各旧类的距离按最长距离法为：递推公式：$D_{rl}$=$Max${$D_{pl}，D_{ql}$} $l\neq p,q$ 中间距离法递推公式：$$ D_{lr}^2=\frac{1}{2}D_{lp}^2+\frac{1}{2}D_{lq}^2-\frac{1}{4}D_{pq}^2 $$$$ D_{kr}^2=\frac{1}{2}D_{kp}^2+\frac{1}{2}D_{kq}^2+\beta D_{pq}^2，-\frac{1}{4}\lt \beta \lt 0 $$ 可变方法如果让中间距离法的递推公式前两项的系数也依赖于β，则递推公式为：$$ D_{kr}^2=\frac{1-\beta}{2}(D_{kp}^2+D_{kq}^2)+\beta D_{pq}^2，\beta \lt 1 $$用上式作为递推公式的系统聚类法称为可变法。 重心法假设第p类和第q类合并成第r类，第r类与其它各旧类的距离按重心法为：$$ D_{rl}^2=\frac{n_p}{n_r}D_{pl}^2+\frac{n_q}{n_r}D_{ql}^2-\frac{n_pn_q}{n_r^2}D_{pq}^2 $$ 类平均方法类平均法定义类间的距离是两类间样品的距离的平均数，递推公式：$$ D_{rk}^2=\frac{n_pD_{kp}^2+n_qD_{kq}^2}{n_p+n_q} $$ 可变类平均法类平均法的递推公式中，没有反映$G_p$类和$G_q$类的距离有多大，进一步将其改进，加入$D_{pq}^2$，并给定系数β&lt;1， 则类平均法的递推公式改为：$$ D_{rl}^2=(1-\beta)\frac{n_pD_{pl}^2+n_qD_{ql}^2}{n_p+n_q}+\beta D_{pq}^2 $$用此递推公式进行聚类就是可变类平均法。递推公式由p类和q类与l类的距离的加权平均数、p类和q类的距离两项的加权和构成，β的大小根据哪项更重要而定。 离差平方和法类似于方差分析的想法，如果类分得恰当，同类内的样品之间的离差平方和应较小，而类间的离差平方和应当较大。当k固定时，选择使SST达到最小的分类。分类可能指数级增长，寻找最优难以完成。离差平方和法的思路：先让n个样品各自成一类，然后缩小一类，每缩小一类离差平方和就要增大，选择使SST增加最小的两类合并，直到所有的样品归为一类为止（局部最优）。定义距离为离差平方和的增量：$$ D_{pq}=S_r^2-S_p^2-S_q^2 $$其中 是由$G_p$和$G_q$合并成的$G_r$类的类内离差平方和。可以证明离差平方和的聚类公式为。递推公式：$$ D_{rk}^2=\frac{n_k+n_p}{n_r+n_k}D_{pk}^2+\frac{n_k+n_q}{n_r+n_k}D_{qk}^2-\frac{n_k}{n_k+n_r}D_{pq}^2 $$以上聚类方法的计算步骤完全相同，仅类与类之间距离的定义不同。 Lance和Williams于1967年将其统一为：$$ D_{MJ}^2=\alpha_KD_{KJ}^2+\alpha_LD_{KJ}^2+\beta D_{KL}^2+\gamma|D_{KJ}^2-D_{KJ}^2| $$ 确定类的个数从系统聚类的计算机结果可以得到任何可能数量的类。但是，聚类的目的是要使各类之间的距离尽可能地远，而类中点的距离尽可能的近， 并且分类结果还要有令人信服的解释。往往做系统聚类的时候，大部分情况下我们都是依靠人的主观判断确定最后分类的个数。这里给出了一些统计方法来确定类的个数。 给定阈值通过观测聚类图， 给出一个合适的阈值T。要求类与类之间的距离要超过T值。 例如我们给定T=0.35， 当聚类时， 类间的距离已经超过了0.35， 则聚类结束。 统计量R²总离差平方和的分解$$ \begin{bmatrix} x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1p}\\x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2p}\\\vdots &amp; \vdots &amp; &amp; \vdots\\x_{n1} &amp; x_{n2} &amp; \cdots &amp; x_{np} \end{bmatrix} $$ $$ 总离差平方和=(x_{11}-\bar x_1)^2+\cdots+(x_{n1}-\bar x_1)^2+\cdots+(x_{1p}-\bar x_p)^2+\cdots+(x_{np}-\bar x_p)^2 $$ 如果这些样本被分为两类$$ \begin{bmatrix} x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1p}\\x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2p}\\\vdots &amp; \vdots &amp; &amp; \vdots\\x_{n_11} &amp; x_{n_12} &amp; \cdots &amp; x_{n_1q} \end{bmatrix} \begin{bmatrix} x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1p}\\x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2p}\\\vdots &amp; \vdots &amp; &amp; \vdots\\x_{n_21} &amp; x_{n_22} &amp; \cdots &amp; x_{n_2p} \end{bmatrix} $$$$ 一组离差平方和=(x_{11}-\bar x_1^{(1)})^2+\cdots+(x_{n_11}-\bar x_1^{(1)})^2+\cdots+(x_{1p}-\bar x_p^{(1)})^2+\cdots+(x_{n_1p}-\bar x_p^{(1)})^2 $$$$ 二组离差平方和=(x_{11}-\bar x_1^{(2)})^2+\cdots+(x_{n_11}-\bar x_1^{(2)})^2+\cdots+(x_{1p}-\bar x_p^{(2)})^2+\cdots+(x_{n_1p}-\bar x_p^{(2)})^2 $$可以证明：总离差平方和＝组内离差平方和＋组间离差平方和。令T为总离差平方和，令$P_G$为分为G类的组内离差平方和。统计量$$ R^2=1-\frac{P_G}{T} $$其中T是数据的总离差平方和， 是组内离差平方和。R²比较大，说明分G个类时组内离差平方和比较小，也就是说分G类是合适的。但是，分类越多，每个类的组内离差平方和就越小，R²也就越大；所以我们只能取合适的G，使得R²足够大，而G本身很小，随着G的增加，R²的增幅不大。比如，假定分4类时，R²=0.8；下一次合并分三类时，下降了许多，R²=0.32，则分4类是合适的。 伪F统计量伪F统计量的定义为$$ F=\frac{(T-P_G)/(G-1)}{P_G/(n-G)} $$伪F统计量用于评价聚为G类的效果。如果聚类的效果好，类间的离差平方和相对于类内的离差平方和大，所以应该取伪F统计量较大而类数较小的聚类水平。 伪t²统计量伪t²统计量的定义为$$ t^2=\frac{B_{KL}}{(W_K+W_L)/(N_K+N_L-2)} $$其中$W_L$和$W_K$分别是类内离差平方和， $W_M$是将K和L合并为第M类的离差平方和，$B_{KL}=W_M-W_K-W_L$为合并导致的类内离差平方和的增量。用它评价合并第K和L类的效果，伪t²统计量大说明不应该合并这两类，应该取合并前的水平。 7 快速聚类(k-means clustering method)系统聚类法的缺陷——系统聚类法是一种比较常用的聚类方法。然而当样本点数量十分庞大时，则是一件非常繁重的工作，聚类的计算速度也比较慢。比如在市场抽样调查中，有4万人就其对衣着的偏好作了回答，希望能迅速将他们分为几类。这时， 用系统聚类法计算的工作量极大，作出的树状图也十分复杂，不便于分析。quick cluster method， k-means method也叫动态聚类、逐步聚类、迭代聚类、k-均值聚类，快速聚类适用于大型数据。快速聚类（K-means）流程图 用一个简单的例子来说明快速聚类法的工作过程。例如我们要把图中的点分成两类。 快速聚类的步骤：1、随机选取两个点$x_1^{(1)}$和$x_2^{(1)}$作为聚核。2、对于任何点$x_k$，分别计算$d(x_k,x_1^{(1)})$和$d(x_k,x_2^{(1)})$3、若$d(x_k,x_1^{(1)})\lt d(x_k,x_2^{(1)})$，则将$x_k$划为第一类，否则划给第二类。于是得图（b）的两个类。4、分别计算两个类的重心，则得$x_1^{(2)}$和$x_2^{(2)}$，以其为新的聚核，对空间中的点进行重新分类，得到新分类。 选择凝聚点初始凝聚点（聚类种子、initial cluster seeds/clustercenters）就是一批有代表性的点，是欲形成类的中心。初始凝聚点的选择直接决定初始分类，对分类结果也有很大的影响，由于凝聚点的不同选择，其最终分类结果也将出现不同，故选择时要慎重。通常选择初始凝聚点的方法有：人为选择，当人们对所欲分类的问题有一定了解时，根据经验，预先确定分类个数和初始分类，并从每一类中选择一个有代表性的样品作为凝聚点。将数据人为地分为A类，计算每一类的重心，就将这些重心作为凝聚点。用密度法选择凝聚点。以某个正数d为半径，以每个样品为球心，落在这个球内的样品数（不包括作为球心的样品）就叫做这个样品的密度。计算所有样品点的密度后，首先选择密度最大的样品作为第一凝聚点，并且人为地确定一个正数D（一般D＞d，常取D＝2d）。然后选出次大密度的样品点，若它与第一个凝聚点的距离大于D，则将其作为第二个凝聚点；否则舍去这点，再选密度次于它的样品。这样，按密度大小依次考查，直至全部样品考查完毕为止．此方法中，d要给的合适，太大了使凝聚点个数太少，太小了使凝聚点个数太多。人为地选择一正数d，首先以所有样品的均值作为第一凝聚点。然后依次考察每个样品，若某样品与已选定的凝聚点的距离均大于d，该样品作为新的凝聚点，否则考察下一个样品。随机地选择，如果对样品的性质毫无所知，可采用随机数表来选择，打算分几类就选几个凝聚点。或者就用前A个样品作为凝聚点（假设分A类）。这方法一般不提倡使用。 衡量聚类结果的合理性指标设$P_i^n$表示在第n次聚类后得到的第i类集合，$i=1,2,3,\cdots,k,A_i^{(n)}$为第n次聚类所得到的聚核。定义：$$ u_n\triangleq \sum_{i=1}^k\sum_{x\in P_i^n}d^2(x,A_i^{(n)}) $$为所有K个类中所有元素与其重心的距离的平方和。若分类不合理时，$u_n$会很大，随着分类的过程，逐渐下降并趋于稳定。算法终止的标准定义算法终止的标准是：$$ \frac{|u_{n+1}-u_n|}{u_{n+1}}\le \varepsilon $$ε是事前给定的一个充分小量。快速聚类步骤第一，选择若干个观测值点为“凝聚点”；第二，通过分配每个“凝聚点”最近的类来形成临时分类。每一次对一个观测值点进行归类，“凝聚点”更新为这一类目前的均值；所有的观测值点分配完后，这些类的“凝聚点”用临时类的均值代替；该步骤可以一直进行直到“凝聚点”的改变很小或为零时止；第三，最终的分类由分配每一个观测到最近的“凝聚点”而形成。 8 有序聚类有序样本聚类法 有序样本聚类法又称为最优分段法。该方法是由费歇在1958年提出的。它主要适用于样本由一个变量描述，或者将多变量综合成为一个变量来分析的情况。对于有序样本聚类，实际上是需要找出一些分点，将它们划分为几个分段，每个分段看作一类，这样的分类又称分割。分点位置不同得到的分割不同，有序样本聚类是要找到一个分割使得各段内部样本差异很小，而各段之间样本的差异很大。有序样本聚类法常常被用于系统的评估问题，被用来对样本点进行分类划级。这种行政上的规定往往是不客观、不合理的。合理的分类应该把发展情况最近似的地区划入同一类。这就是有序样本聚类的工作思路。系统聚类开始n个样品各自自成一类，然后逐步并类，直至所有的样品被聚为一类为止。而有序聚类则相反，开始所有的样品为一类，然后分为二类、三类等，直到分成n类。每次分类都要求产生的离差平方和最小。 有序样本聚类算法步骤设有序样品$x_{(1)},x_{(2)},\cdots,x_{(n)}$。它们可以是从小到大排列，也可以是按时间的先后排列。 定义类的直径；设某类G中包含的样品有{$ x_{(i)},x_{(i+1)},\cdots,x_{(j)} $} $(j\gt i)$该类的均值向量为$$ \bar X_G=\frac{1}{j-i+1}\sum_{i=1}^jx_{(t)} $$用D(i,j)表示这一类的直径，常用的直径有欧氏距离：$$ D(i,j)=\sum_{t=i}^j(x_{(t)}-\bar X_G)’(x_{(t)}-\bar X_G) $$当是单变量时，也可以定义直径为：$$ D(i,j)=\sum_{t=i}^j|x_{(t)}-\tilde X_G|，其中\tilde X_G是中位数$$ 定义分类的损失函数L[p(n,k)]；用b(n,k)表示将n个有序的样品分为k类的某种分法($j_1$=1)：$$ \begin{array}{lcl}G_1=[j_1,j_1+1,\cdots,j_2-1]\\G_2=[j_2,j_2+1,\cdots,j_3-1]\\\cdots\qquad\cdots\\G_k=[j_k,j_k+1,\cdots,n] \end{array} $$定义这种分类法的损失函数为各类的直径之和。$$ L[b(n,k)]=\sum_{t=1}^kD(j_t,j_{t+1}-1) $$由损失函数的构造可以看出，损失函数是各类的直径之和。如果分类不好，则各类的直径之和大，否则比较小。当n和k固定时， L[b(n,k)]越小表示各类的离差平方和越小，分类是合理的。因此要寻找一种分法b(n,k)，使分类损失函数L[b(n,k)]达到最小。记该分法为p[n,k]。 L[p(n,k)]的递推公式；$$ \begin{cases}L[p(n,2)]=\min_{2\le j\le n}(D(1,j-1)+D(j,n))\\L[p(n,k)]=\min_{k\le j\le n}(L[p(j-1,k-1)]+D(j,n)) \end{cases} $$以上的两个公式的含义是，如果要找到n个样品分为k个类的最优分割，应建立在将j-1（j＝2,3,…,n)个样品分为k-1类的最优分割的基础上。 寻找最优解。 9 聚类分析的主要步骤 （1）选择变量和聚类分析的目的密切相关；在不同研究对象上的值有明显的差异；变量之间不能高度相关。（2）计算相似性相似性是聚类分析中的基本概念，它反映了研究对象之间的亲疏程度，聚类分析就是根据对象之间的相似性来分类的。（3）聚类选定了聚类的变量，计算出样品或指标之间的相似程度后，构成了一个相似程度的矩阵。这时主要涉及两个问题：选择聚类的方法和确定形成的类数。（4）聚类结果的解释和证实对聚类结果进行解释是希望对各个类的特征进行准确的描述，给每类起一个合适的名称。这一步可以借助各种描述性统计量进行分析，通常的做法是计算各类在各聚类变量上的均值，对均值进行比较，还可以解释各类差别的原因。（5）有关问题几种聚类方法获得的结果不一定相同，指标聚类采用相似系数，相似系数大或距离小则表示类间关系密切。为了统一，可采用以下公式变换：$$ d_{ij}^2=1-r_{ij}^2 $$（6）变量聚类分析对于变量聚类分析，聚类分析做完之后，各类中有较多的指标。 为了达到降维的目的， 需要在每类中选出一个代表指标。 具体做法是：假设某类中有k个指标， 首先分别计算类内指标之间的相关指数， 然后计算某个指标与类内其它指标之间相关指数的平均数， 即$$ \bar R_i^2=\frac{\sum_{i\neq j}r_{ij}}{k-1} $$取$\bar R_i^2$最大的$x_i$，作为该类的代表。 10 R语言中聚类分析实现R语言自带的聚类分析函数包括了hclust和k-means。所以本篇主要介绍这两个函数的使用。而首先hclust是基于距离进行的聚类分析，所以事实上在做层次聚类的时候，第一步是先计算距离。当然前期说明下，这里的样例数据是北京市12个大气污染监测站点在2017年6月7日和6月8日全天的PM2.5数据（数据来自笔者自己写的代码获取而得，调用了环境云的API），样例数据连同完整的代码会在笔记写完后统一给出。 环境云官网：http://www.envicloud.cn/ 数据： 12dist.pm25&lt;-dist(airnew[,-1],method=&apos;euclidean&apos;)heatmap(as.matrix(dist.pm25),labRow=stationname,labcol=F) 我们做的分析是对一天内24小时下12个站点的PM2.5聚类分析。所以这个问题的多元变量，是不同时间段的PM2.5值，前期已经把数据结构也已经成功做成矩阵形式，接下来就需要计算距离了。距离矩阵在R里面是比较好求取的。dist函数。dist函数的参数事实上有不少，但是其实一般重点用的就是输入矩阵的参数（代码中的airnew[,-1]，-1代表去掉第一列数据（站点名称）），还有计算距离的方式——method。这里选的是欧氏距离。这个参数的可选取值还包括maximum（最大距离）、manhattan（曼哈顿距离）、canberra（兰氏威廉姆斯距离）、binary（定性距离，其实就是配合距离）、minkowski（闵可夫斯基距离——明氏距离）。还有用得多些的参数——diag和upper。diag为TRUE的时候给出对角线上的距离。upper为TURE的时候给出上三角矩阵上的值。默认都是FALSE。函数计算完之后得到的是一个距离矩阵。我们用热力图的方式进行可视化，这就是上面的第二句代码。heatmap函数是个热图可视化函数，要求输入一个矩阵。labRow其实是输入列名，labcol是与labRow相关，用来映射输入的值的。结果如下图。 计算完矩阵，即可进行聚类分析了。hclust函数的必要参数与前面距离的参数类似——输入矩阵参数，方法参数（这里聚类的方法前面也有提到，这里就不赘述了，有兴趣的可以自己看官方帮助文档）。而聚类完的结果存储在model1里面，用plot即可画出聚类谱系图。事实上，plclust也是相同的作用，参数基本是统一的，labels填写我们聚类的变量。而聚类完的结果则可以用cutree来获得，输入的model1——聚类结果，k是要求的类数。 123model1=hclust(dist.pm25,method=&quot;ward&quot;)plot(model1,labels=stationname,hang=-1,las=1)plclust(model1,labels=stationname,hang=-1) 对聚类结果做个简单可视化。以0点和1点的PM2.5值分别为x和y轴，以聚类结果做划分。 12result=cutree(model1,k=3)plot(airnew[,2],airnew[,3],col=result,pch=as.integer(result)) 接下来是K-means的方法。函数并不复杂，输入数据框或者矩阵（做聚类的数据），center就是聚类数，nstart是迭代次数。迭代次数高，聚类可信度高些。后面的这个函数是聚类可视化的函数，是fpc包下面的，使用前请先确认是否安装。12kres&lt;-kmeans(airnew[,-1],centers=3,nstart=10)plotcluster(airnew[,-1],kres$cluster) 对比了二者的分类结果，是一致的。 聚类结束后，我们就这个数据和结果做些简单的分析。事实上作为地学人员，我们就简单地画个站点分布图来对应看看具体情况。从这张图来看，PM2.5的聚类结果显示了它具有很好的空间分异性。当然下面的图有点简陋，给出一个对比的，基于leaflet和R Notebook的交互式小地图（老规矩）。 st=>start: 选择凝聚点（聚类中心） e=>end: 分类结果 sub=>subroutine: 分类 cond=>condition: 分类结果是否合理？ op=>operation: 调整分类 st->sub->cond(yes)->e cond(no)->op(right)->sub{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12} var code = document.getElementById("flowchart-0-code").value; var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-0-options").value)); var diagram = flowchart.parse(code); diagram.drawSVG("flowchart-0", options);]]></content>
      <categories>
        <category>Statistics &amp; Model</category>
      </categories>
      <tags>
        <tag>R</tag>
        <tag>Theory</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[应用统计学与R语言实现学习笔记（九）——线性回归]]></title>
    <url>%2F2017%2F06%2F13%2F%E5%BA%94%E7%94%A8%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B8%8ER%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B9%9D%EF%BC%89%E2%80%94%E2%80%94%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%2F</url>
    <content type="text"><![CDATA[Chapter 9 Linear Regression本篇是第九章，内容是回归分析（主要以线性回归为主）。回归分析是数理统计、数理分析中最基础（也可以说是最重要）的一个分析，所以这一章内容相对来说也较多。 1 变量间的关系 确定型关系vs不确定型关系函数关系——一一对应的确定型关系设有两个变量x和y，变量y随变量x一起变化， 并完全依赖于x，当变量x取某个数值时，y依确定的关系取相应的值，则称y是x的函数，记为y=f(x)，其中x称为自变量，y称为因变量各观测点落在一条线上。相关关系(correlation)——变量间关系不能用函数关系精确表达。一个变量的取值不能由另一个变量唯一确定。当变量x取某个值时， 变量y的取值可能有几个。各观测点分布在直线周围。 相关关系包括了线性相关（正相关、负相关）、非线性相关、完全相关（正相关、负相关）、不相关。 除了如上的图，可以看下面的链接——关于相同统计量不同数据的一篇外文。 https://www.autodeskresearch.com/publications/samestats 相关系数(correlation coefficient) 对变量之间关系密切程度的度量（只关心密切程度，无关因果关系）； 对两个变量之间线性相关程度的度量称为简单相关系数； 若相关系数是根据总体全部数据计算的，称为总体相关系数，记为ρ； 若是根据样本数据计算的，则称为样本相关系数，记为 r。 总体相关系数的计算公式：$$ \rho=\frac{\sigma_{xy}}{\sigma_x\sigma_y}=\frac{E[(X-E(X))(Y-E(Y))]}{\sqrt{E(X-E(X))^2}\sqrt{E(Y-E(Y))^2}} $$相关系数特点 无量纲(Unitfree)； ρ的取值范围是 [-1,1]； |ρ|=1，为完全相关（ρ=1为完全正相关；ρ=-1为完全负相关）； ρ=0，不存在线性相关关系； -1≤ρ&lt;0，为负相关，0&lt;ρ≤1，为正相关； |ρ|越趋于1表示线性关系越密切；|ρ|越趋于0表示线性关系越不密切； 若X与Y相互独立，则ρ=0，但ρ=0，X与Y不一定相互独立； 若ρ= 0，且X与Y服从正态分布，则X与Y相互独立。 样本相关系数计算公式：$$ r=\frac{\sum(x_i-\bar x)(y_i-\bar y)}{\sqrt{\sum(x_i-\bar x)^2\cdot\sum(y_i-\bar y)^2}}或r=\frac{n\sum x_iy_i-\sum x_i\sum y_i}{\sqrt{n\sum x_i^2-(\sum x_i)^2}\cdot\sqrt{n\sum x_i^2-(\sum x_i)^2}} $$样本相关系数特点 无量纲(Unitfree)； r的取值范围是 [-1,1]； |r|=1，为完全相关（r=1为完全正相关；r=-1为完全负相关）； r=0，不存在线性相关关系； -1≤r&lt;0为负相关，0&lt;r≤1为正相关； |r|越趋于1表示线性关系越密切；|r|越趋于0表示线性关系越不密切； 对变量之间关系密切程度的度量，只关心密切程度，无关因果关系。比如撑伞的人数和降雨量的相关系数非常高。但是我们不能说因为撑伞的人多了，所以降雨量大。 r的抽样分布r的抽样分布随总体相关系数和样本容量的大小而变化。当样本数据来自服从正态分布的总体时，随着n的增大，r的抽样分布趋于正态分布，尤其是在总体相关系数ρ很小或接近0时，趋于正态分布的趋势非常明显。而当ρ远离0时，除非n非常大，否则r的抽样分布呈现一定的偏态。当ρ为较大的正值时， r呈现左偏分布；当ρ为较小的负值时， r 呈现右偏分布。只有当ρ接近于0，而样本容量n很大时，才能认为r是接近于正态分布的随机变量。相关系数的显著性检验步骤检验两个变量之间是否存在线性相关关系，等价于对回归系数$β_1$的检验。采用R. A. Fisher提出的t检验。检验的步骤为： （1） 提出假设：$H_0：\rho=0；H_1：\rho \neq0$（2） 计算检验的统计量： $t=r\sqrt{\frac{n-2}{1-r^2}}\sim t(n-2)$（3） 确定显著性水平α，并作出决策。 若$|t|&gt;t_{α/2}$，拒绝$H_0$。 若$|t|&lt;t_{α/2}$，不能拒绝$H_0$。 2 回归分析和简单线性回归分析2.1 回归分析什么是回归分析(Regression)? 从一组样本数据出发，确定变量之间的数学关系式。对这些关系式的可信程度进行各种统计检验，并从影响某一特定变量的诸多变量中找出哪些变量的影响显著， 哪些不显著。利用所求的关系式，根据一个或几个变量的取值来预测或控制另一个特定变量的取值， 并给出这种预测或控制的精确程度。 回归分析与相关分析的区别 相关分析中，变量x变量y处于平等的地位；回归分析中，变量y称为因变量，处在被解释的地位，x称为自变量，用于预测因变量的变化；相关分析中所涉及的变量x和y都是随机变量；回归分析中，因变量y是随机变量，自变量x可以是随机变量，也可以是非随机的确定变量；相关分析主要是描述两个变量之间线性关系的密切程度；回归分析不仅可以揭示变量x对变量y的影响大小，还可以由回归方程进行预测和控制。 回归模型(regression model)——回答“变量之间是什么样的关系？”方程中运用1个数值型因变量(响应变量)作为被预测的变量；1个或多个数值型或分类型自变量 (解释变量)作为用于预测的变量。主要用于预测和估计。回归模型的类型包括一元回归模型（线性和非线性）和多元回归模型（线性和非线性）。接下来先从简单线性回归分析讲起。 2.2 简单线性回归分析简单线性回归(Simple Linear Regression)——涉及一个自变量的回归，因变量y与自变量x之间为线性关系。被预测或被解释的变量称为因变量(dependent variable)，用y表示；用来预测或用来解释因变量的一个或多个变量称为自变量(independent variable)，用x表示。因变量与自变量之间的关系用一个线性方程来表示。描述因变量y如何依赖于自变量x和误差项ε的方程称为回归模型(Regression Model，定义如前)。（1）简单线性回归模型的表示形式$$ y=\beta_0+\beta_1 x+\varepsilon $$y是x的线性函数(部分)加上误差项(residual/random error term)。线性部分反映了由于x的变化而引起的y的变化。误差项ε是随机变量。反映了除x和y之间的线性关系之外的随机因素对y的影响，是不能由x和y之间的线性关系所解释的变异性。$β_0$和$β_1$称为模型的参数(interception, slope)。（2）简单线性回归模型的基本假定误差项ε是一个期望值为0的随机变量，即E(ε)=0。对于一个给定的x值，y的期望值为$$ E(y)=\beta_0+\beta_1x $$对于所有的x值，ε的方差$σ^2$都相同；误差项ε是一个服从正态分布的随机变量，且相互独立。即ε~N(0,$σ^2$);独立性意味着对于一个特定的x值，它所对应的ε与其他x值所对应的ε不相关；对于一个特定的x值， 它所对应的y值与其他x所对应的y值也不相关。（3）简单线性回归方程(regression equation)描述y的平均值或期望值如何依赖于x的方程称为回归方程；简单线性回归方程的形式如下$$ E(y)=\beta_0+\beta_1x $$方程的图示是一条直线，也称为直线回归方程。$β_0$是回归直线在y轴上的截距(interception)，是当x=0时y的期望值。$β_1$是直线的斜率(slope)，称为回归系数，表示当x每变动一个单位时，y的平均变动值。（4）估计的回归方程(estimated regression equation)总体回归参数$β_0$和$β_1$是未知的，必须利用样本数据去估计。用样本统计量$b_0$和$b_1$代替回归方程中的未知参数$β_0$和$β_1$，就得到了估计的回归方程。简单线性回归中估计的回归方程为$$ \hat y=b_0+b_1x $$其中：$b_0$是估计的回归直线在y轴上的截距，$b_1$是直线的斜率，也表示x每变动一个单位时，y的平均变动值，$\hat y$表示一个给定的x的值对应的y的估计值。（5）最小二乘估计使因变量的观察值与估计值之间的离差平方和达到最小来求得$b_0$和$b_1$的方法。即$$ argmin \sum_{i=1}^n(y_i-\hat y_i)^2=\sum_{i=1}^n(y_i-b_0-b_ix_i)^2 $$用最小二乘法拟合的直线来代表x与y之间的关系与实际数据的误差平方和比其他任何直线都小。根据最小二乘法的要求，可得到如下的公式：$$ \begin{cases}b_1=\frac{n\sum_{i=1}^nx_iy_i-(\sum_{i=1}^nx_i)(\sum_{i=1}^ny_i)}{n\sum_{i=1}^nx_i^2-(\sum_{i=1}^nx_i)^2}\\b_0=\bar y-b_1\bar x\end{cases} $$最小二乘估计的性质 所有残差的和为0。所有残差的平方和最小； 回归直线经过变量X与Y的均值； 是$β_0和β_1$的无偏估计。 在r语言中，简单线性回归的代码如下：1modele&lt;-lm(e~a) （7）回归直线的拟合优度变差因变量 y 的取值是不同的， y 取值的这种波动称为变差。 变差来源于两个方面： 由于自变量 x 的取值不同造成的。 除 x 以外的其他因素(如x对y的非线性影响、测量误差等)的影响。对一个具体的观测值来说， 变差的大小可以通过该实际观测值与其均值之差$y-\bar y$来表示。 离差平方和的分解(三个平方和的关系与意义)$$ \sum_{i=1}^n(y_i-\bar y)^2=\sum_{i=1}^n(\hat y_i-\bar y)^2+\sum_{i=1}^n(y_i-\hat y)^2 $$从左至右分别为SST，SSR，SSE。所以就有SST=SSR+SSE。总平方和(SST)——反映因变量的 n 个观察值与其均值的总离差；回归平方和(SSR)——反映自变量 x 的变化对因变量 y 取值变化的影响，或者说，是由于x与y之间的线性关系引起的y的取值变化，也称为可解释的平方和；残差平方和(SSE)——反映除x以外的其他因素对y取值的影响，也称为不可解释的平方和或剩余平方和。 判定系数R²(coefficient of determination)回归平方和占总离差平方和的比例。$$R^2=\frac{SSR}{SST}=\frac{\sum_{i=1}^n(\hat y_i-\bar y)^2}{\sum_{i=1}^n(y_i-\bar y)^2}=1-\frac{\sum_{i=1}^n(y_i-\hat y)^2}{\sum_{i=1}^n(\hat y_i-\bar y)^2}$$ 反映回归直线的拟合程度； 取值范围在[0,1]之间； $R^2\rightarrow1$，说明回归方程拟合的越好；$R^2\rightarrow0$，说明回归方程拟合的越差； 对简单线性回归，判定系数等于相关系数的平方，r=(b1的符号)sqrt(R²)。 估计标准误差(standard error of estimate) 实际观察值与回归估计值离差平方和的均方根； 反映实际观察值在回归直线周围的分散状况； 对误差项ε的标准差σ的估计， 是在排除了x对y的线性影响后，y随机波动大小的一个估计量； 反映用估计的回归方程预测y时预测误差的大小。计算公式为$$ s=\sqrt{\frac{\sum_{i=1}^n(y_i-\hat y_i)^2}{n-2}}=\sqrt{\frac{SSE}{n-2}}=\sqrt{MSE} $$ 显著性检验 线性关系的显著性检验：检验自变量与因变量之间的线性关系是否显著，即检验x与y之间是否具有线性关系，或者说，检验自变量x对因变量y的影响是否显著； 回归系数的显著性检验：检验回归系数是否不等于0； 在简单线性回归中，线性关系的显著性检验等价于回归系数的显著性检验。线性关系的检验将回归均方(MSR)同残差均方(MSE)加以比较， 应用F检验来分析二者之间的差别是否显著。回归均方：回归平方和SSR除以相应的自由度(自变量的个数p)；残差均方：残差平方和SSE除以相应的自由度(n-p-1)。 提出假设：$H_0：\beta_1=0$ 线性关系不显著； 计算检验统计量F：$$ F=\frac{SSR/1}{SSE/(n-2)}=\frac{MSR}{MSE}\sim F(1,n-2) $$ 确定显著性水平α，并根据分子自由度1和分母自由度n-2找出临界值$F_\alpha$。 作出决策：$若F&gt;F_\alpha，拒绝H_0； 若F&lt;F_\alpha，不拒绝H_0$。回归系数的检验(检验步骤) 提出假设$$H_0:\beta_1=0(没有线性关系)$$$$H_1:\beta_1\neq 0(有线性关系)$$ 计算检验的统计量$$ t=\frac{b_1}{s_{b_1}}\sim t(n-2) $$ 确定显著性水平$\alpha$，并进行决策：$$ \left|t\right|\gt t_{\alpha/2}，拒绝H_0；\left|t\right|\lt t_{\alpha/2}，不拒绝H_0 $$显著性检验的几点注意显著性关系的结论不意味着因果关系。显著性关系的结论也不能推出线性关系的结论，仅能说在x的样本观测之范围内，x和y是相关的，而且一个线性关系只揭示了y的变异的主要部分。当样本容量很大时，对于小的b1值也能得到统计上是显著的结果。 3 利用回归方程进行估计和预测根据自变量x的取值估计或预测因变量y的取值。估计或预测的类型 （1）点估计：y的平均值的点估计，y的个别值的点估计；（2）区间估计：y的平均值的置信区间估计，y的个别值的预测区间估计。 （1）点估计对于自变量x的一个给定值$x_0$，根据回归方程得到因变量y的一个估计值$\hat y_0$。点估计值有y的平均值的点估计和y的个别值的点估计。在点估计条件下，平均值的点估计和个别值的的点估计是一样的，但在区间估计中则不同。 y的平均值的点估计利用估计的回归方程， 对于自变量 x 的一个给定值$x_0$，求出因变量y的平均值的一个估计值$E(y_0)$，就是平均值的点估计。y的个别值的点估计利用估计的回归方程，对于自变量x的一个给定值$x_0$，求出因变量y的一个个别值的估计值$\hat y_0$，就是个别值的点估计。 （2）区间估计点估计不能给出估计的精度， 点估计值与实际值之间是有误差的， 因此需要进行区间估计。对于自变量x的一个给定值$x_0$，根据回归方程得到因变量y的一个估计区间。区间估计有两种类型：置信区间估计(confidence interval estimate)和预测区间估计(prediction interval estimate)。置信区间估计利用估计的回归方程，对于自变量x的一个给定值$x_0$，求出因变量y的平均值的估计区间，这一估计区间称为置信区间(confidence interval)。$E(y_0)$在$1-\alpha$置信水平下的置信区间为:$$ \hat y_0\pm t_{\alpha/2}(n-2)s\sqrt{\frac{1}{n}+\frac{(x_0-\bar x)^2}{\sum_{i=1}^n(x_i-\bar x)^2}} $$式中s为估计标准误差。x=均值时能得到y的平均值的最精确估计。预测区间估计利用估计的回归方程,对于自变量x的一个给定值$x_0$,求出因变量y的一个个别值的估计区间，这一区间称为预测区间(prediction interval)。$E(y_0)$在$1-\alpha$置信水平下的预测区间为:$$ \hat y_0\pm t_{\alpha/2}(n-2)s\sqrt{1+\frac{1}{n}+\frac{(x_0-\bar x)^2}{\sum_{i=1}^n(x_i-\bar x)^2}} $$影响区间宽度的因素 置信水平(1-α)——区间宽度随置信水平的增大而增大； 数据的离散程度s——区间宽度随离散程度的增大而增大； 样本容量——区间宽度随样本容量的增大而减小； 用于预测的$x_p$与$\bar x$的差异程度，区间宽度随$x_p$与$\bar x$的差异程度的增大而增大。 其实在R语言里主要用predict.lm函数来进行区间估计。代码样例如下：1con&lt;-predict.lm(modele,h,interval="confidence",level=0.95) 其中interval控制是置信区间（参数填confidence）、预测区间（参数填prediction）或者是不做区间估计，level是置信水平，接着用R绘制一个简单的回归和置信区间的图，这里先给出如何绘制置信区间band的代码，完整代码还是老规矩，在这一部分笔记写完后给出。1polygon(c(h[,1], rev(h[,1])), c(con[,3], rev(con[,2])),border="red",lwd=1,lty = c("dashed", "solid")) 4 残差分析残差(residual)——因变量的观测值与根据估计的回归方程求出的预测值之差，用e表示。$$e_i=y_i-\hat y_i$$反映了用估计的回归方程去预测而引起的误差。残差检验的目的 检验线性的假设是否成立； 确定有关误差项ε的假定是否成立（正态分布；方差为常数；独立性）。 检测有影响的观测值。 残差图(residual plot) 表示残差的图形（关于x的残差图，关于y的残差图，标准化残差图）。 用直方图或正态概率图检验正态性。 标准化残差(standardized residual) 残差除以它的标准差后得到的数值。 计算公式为$$ z_{e_i}=\frac{e_i}{s_{e_i}}=\frac{y_i-\hat y_i}{s_{e_i}} $$ $e_i$是第i个残差的标准差， 其计算公式为$$ s_{e_i}=s_y\sqrt{1-h_i}=s_y\sqrt{1-(\frac{1}{n}+\frac{(x_i-\bar x)^2}{\sum(x_i-\bar x)^2})} $$ 标准化残差图用以直观地判断误差项服从正态分布这一假定是否成立。 若假定成立， 标准化残差的分布也应服从正态分布。 在标准化残差图中， 大约有95%的标准化残差在-2到+2之间。 变换数据变换的问题在前面第七章拟合优度检验提过，那么什么时候做变换?如果从散点图观察发现残差是自变量的函数，通过变换可能可以解决问题。做什么变换？观察残差与因变量观测值的均值的关系： 如果残差的标准差与因变量观测值的均值有线性关系，用log变换； 如果残差的方差与因变量观测值的均值有线性关系，用square root变换； 如果残差的标准差与因变量观测值的均值的平方有线性关系，用inverse变换； 如果残差的标准差与因变量观测值的均值的幂有线性关系，用power变换。 序列相关（自相关）当数据是按时间顺序采集的，有可能引起误差项之间的相关(Serial correlation,autocorrelation)。这里介绍一个相关的杜宾-瓦特森(Durbin-Watson)检验统计量：$$ d=\frac{\sum_{t=2}^n(e_t-e_{t-1})^2}{\sum_{t=1}^ne_t^2} $$是否遗漏了重要的对因变量有时序影响的自变量，有时可通过引入度量观测次数的自变量解决该问题。这部分属于时间序列分析的范畴，这里就不进一步阐述了。 在R语言中，线性回归方程残差图绘制非常简单。模型拟合过程会自动给出四个残差可视化相关的图。绘制方法如下：12layout(matrix(c(1,2,3,4),nrow=2,byrow=T))plot(modele) 结果如图 异常值(outlier)与识别如果某一个点与其他点所呈现的趋势不相吻合，这个点就有可能是异常点。 如果异常值是一个错误的数据， 比如记录错误造成的， 应该修正该数据， 以便改善回归的效果； 如果是由于模型的假定不合理， 使得标准化残差偏大， 应该考虑采用其他形式的模型，比如非线性模型； 如果完全是由于随机因素而造成的异常值， 则应该保留该数据。 在处理异常值时， 若一个异常值是一个有效的观测值， 不应轻易地将其从数据集中予以剔除。 异常值也可以通过标准化残差来识别； 如果某一个观测值所对应的标准化残差较大， 就可以识别为异常值； 一般情况下，当一个观测值所对应的标准化残差小于-2或大于+2时，就可以将其视为异常值。 有影响的观测值如果某一个或某一些观测值对回归的结果有强烈的影响，那么该观测值或这些观测值就是有影响的观测值。一个有影响的观测值可能是：一个异常值， 即有一个值远远偏离了散点图中的趋势线；对应一个远离自变量平均值的观测值；或者是这二者组合而形成的观测值。如果有影响的观测值是一个错误的数据，比如记录错误造成的， 应该修正该数据，以便改善回归的效果。如果有影响的观测值是一个有效的数据则应该保留它， 可以帮助我们分析模型的假定是否合理。杠杆率点(leverage point)如果自变量存在一个极端值， 该观测值则称为高杠杆率点(high leverage point)，在简单回归中，第i个观测值的杠杆率用$h_i$表示，其计算公式为：$$h_i=\frac{1}{n}+\frac{(x_i-\bar x)^2}{\sum(x_i-\bar x)^2}$$如果一个观测值的杠杆率$h_i&gt;n/6$，就可以将该观测值识别为有高杠杆率的点；一个有高杠杆率的观测值未必是一个有影响的观测值， 它可能对回归直线的斜率没有什么影响。 5 多元线性回归(multiple regression model)多元线性回归(multiple regression model) 一个因变量与两个及两个以上自变量的回归。 描述因变量y如何依赖于自变量$x_1,x_2,\cdots,x_p$和误差项$\varepsilon$的方程，称为多元回归模型。 涉及 p 个自变量的多元回归模型可表示为$$y=\beta_0+\beta_1x_1+\beta_2x_2+\cdots+\beta_px_p+\varepsilon$$ $\beta_0,\beta_1,\beta_2,\cdots,\beta_p$是参数。 $\varepsilon$是被称为误差项的随机变量。 y是$x_1,x_2,\cdots,x_p$的线性函数加上误差项$\varepsilon$。 $\varepsilon$包含在y里面但不能被p个自变量的线性关系所解释的变异性。 多元回归模型的基本假定 误差项ε是一个期望值为0的随机变量， 即E(ε)=0。 对于自变量$x_1,x_2,\cdots,x_p$的所有值，ε的方差$\sigma^2$都相同。 误差项ε是一个服从正态分布的随机变量，即$ε~N(0,\sigma^2)$，且相互独立。 多元回归方程(multiple regression equation)描述因变量y的平均值或期望值如何依赖于自变量$x_1,x_2,\cdots,x_p$的方程。多元线性回归方程的形式为$$E(y)=\beta_0+\beta_1x_1+\beta_2x_2+\cdots+\beta_px_p+\varepsilon$$ $\beta_1,\beta_2,\cdots,\beta_p$称为偏回归系数。 $\beta_i$表示假定其他变量不变，当$x_i$每变动一个单位时，y的平均变动值。 二元回归方程的几何表达——回归面。 估计的多元回归的方程(estimated multiple regression equation)用样本统计量$b_0,b_1,b_2,\cdots,b_p$估计回归方程中的参数$\beta_0,\beta_1,\beta_2,\cdots,\beta_p$时得到的方程。一般形式为。$$\hat y=b_0+b_1x_1+b_2x_2+\cdots+b_px_p$$参数的最小二乘法使因变量的观察值与估计值之间的离差平方和达到最小来求得$b_0,b_1,b_2,\cdots,b_p$，即：$$argmin Q(b_0,b_1,b_2,\cdots,b_p)=\sum_{i=1}^n(y_i-\hat y_i)^2=\sum_{i=1}^ne_i^2$$求解各回归参数的标准方程如下：$$ \begin{cases}\left. \frac{\partial Q}{\partial \beta_0} \right| _{\beta_0=b_0}=0\\\left. \frac{\partial Q}{\partial \beta_i} \right| _{\beta_i=b_i}=0(i=1,2,\cdots,p)\end{cases} $$多重判定系数(multiple coefficient of determination)回归平方和占总平方和的比例，计算公式为$$ R^2=\frac{\sum_{i=1}^n(\hat y_i-\bar y)^2}{\sum_{i=1}^n(y_i-\bar y)^2}=\frac{SSR}{SST}=1-\frac{SSE}{SST} $$因变量取值的变差中， 能被估计的多元回归方程所解释的比例。修正多重判定系数(adjusted multiple coefficient of determination)用样本容量n和自变量的个数p去修正$R^2$得到。计算公式为$$R_a^2=1-(1-R^2)\times\frac{n-1}{n-p-1}$$避免增加自变量而高估$R^2$，意义与$R^2$类似，数值小于$R^2$。估计标准误差s对误差项ε的标准差σ的一个估计值。衡量多元回归方程的拟合优度。计算公式为$$ s=\sqrt{\frac{\sum_{i=1}^n(y_i-\hat y_i)^2}{n-p-1}}=\sqrt{\frac{SSE}{n-p-1}}=\sqrt{MSE} $$线性关系检验检验因变量与所有自变量之间的线性关系是否显著，也被称为总体的显著性检验。检验方法是将回归均方和(MSR)同离差均方和(MSE)加以比较，应用F检验来分析二者之间的差别是否显著。 如果是显著的， 因变量与自变量之间存在线性关系； 如果不显著， 因变量与自变量之间不存在线性关系。（1）提出假设：$H_0：\beta_1=\beta_2=\cdots=\beta_p=0$ 线性关系不显著；$H_1：\beta_1,\beta_2,\cdots,\beta_p $ 至少有一个不等于0。（2）计算检验统计量F：$$ F=\frac{SSR/p}{SSE/(n–p-1)}=\frac{MSR}{MSE}\sim F(p,n-p-1) $$（3）确定显著性水平α，并根据分子自由度p和分母自由度n-p-1找出临界值$F_\alpha$。（4）作出决策：$若F&gt;F_\alpha，拒绝H_0$。 回归系数的检验(检验步骤) 线性关系检验通过后，对各个回归系数进行检验。 对每一个自变量单独应用 t 检验统计量进行检验。（1）提出假设$$H_0:\beta_i=0(自变量x_i与因变量y没有线性关系)$$$$H_1:\beta_i\neq 0(自变量x_i与因变量y有线性关系)$$（2）计算检验的统计量$$ t=\frac{b_i}{s_{b_i}}\sim t(n-p-1)，s_{b_i}=\frac{s}{\sqrt{\sum(x_i-\bar x)^2}}$$（3）确定显著性水平$\alpha$，并进行决策：$$ \left|t\right|\gt t_{\alpha/2}，拒绝H_0；\left|t\right|\lt t_{\alpha/2}，不拒绝H_0 $$ 回归系数的推断(置信区间)回归系数在(1-α)%置信水平下的置信区间为$$ b_i\pm t_{\alpha/2}(n-p-1)s_{b_i} $$回归系数的抽样标准差$$ s_{b_i}=\frac{s}{\sqrt{\sum(x_i-\bar x)^2}}$$ 6 多重共线性(multicollinearity)回归模型中两个或两个以上的自变量彼此相关。多重共线性带来的问题有：可能会使回归的结果造成混乱， 甚至会把分析引入歧途；可能对参数估计值的正负号产生影响， 特别是各回归系数的正负号有可能同我们预期的正负号相反。多重共线性的识别 检测多重共线性的最简单的一种办法是计算模型中各对自变量之间的相关系数， 并对各相关系数进行显著性检验；若有一个或多个相关系数显著， 就表示模型中所用的自变量之间相关，存在着多重共线性。 如果出现下列情况，暗示存在多重共线性：模型中各对自变量之间显著相关。当模型的线性关系检验(F检验)显著时，几乎所有回归系数的t检验却不显著。回归系数的正负号与预期的相反。 检测多重共线性(Variance Inflationary Factor)VIF (variance inflation factor) 用以测量如果自变量相关对估计的回归系数的变异程度的影响。$VIF_j$的定义:$$VIF_j=\frac{1}{1-R_j^2}$$$R_2^j$是第j个自变量对其它自变量进行回归的判定系数。VIF=1表示所对应自变量与其它自变量无线性关系。VIF值越大，多重共线性越严重。如果$VIF_j$&gt;5，$x_j$与其它自变量高度相关。多重共线性(问题的处理)将一个或多个相关的自变量从模型中剔除，使保留的自变量尽可能不相关。如果要在模型中保留所有的自变量，则应避免根据t统计量对单个参数进行检验，对因变量值的推断(估计或预测)的限定在自变量样本值的范围内。 7 定性自变量的回归虚拟变量(dummy variable)定性自变量————只有两个水平的定性自变量或有两个以上水平的定性自变量。虚拟变量——用数字代码表示的定性自变量。虚拟变量的取值为0，1。虚拟变量的个数当定性自变量只有两个水平时，可在回归中引入一个虚拟变量。一般而言，如果定性自变量有k个水平，需要在回归中模型中引进k-1个虚拟变量。当定性自变量只有两个水平并引进虚拟变量时，回归方程可写$E(y)=\beta_0+ \beta_1x$。当指定虚拟变量0，1时,$\beta_0$总是代表与虚拟变量值0所对应的那个分类变量水平的平均值；$\beta_1$总是代表与虚拟变量值1所对应的那个分类变量水平的平均响应与虚拟变量值0所对应的那个分类变量水平的平均值的差值，即平均值的差值=$(\beta_0+\beta_1)-\beta_0=\beta_1$当定性自变量超过两个水平（假定三个水平）并引进虚拟变量时，回归方程可写$E(y)=\beta_0+ \beta_1x_1+\beta_2x_2$。方差分析同样可以通过引入虚拟变量做回归分析。 8 非线性回归（1）二阶回归模型(Quadratic Regression Model)——当散点图如下所示，可考虑二次回归模型。$$y_i=\beta_0+\beta_1x_i+\beta_2x_i^2+\varepsilon$$ 二阶回归模型的显著性检验 总体显著性检验$$F test statistic=\frac{MSR}{MSE}$$ 二阶检验比较二阶模型$$ y=\beta_0+\beta_1x_1+\beta_2x^2+\varepsilon $$线性模型$$ y=\beta_0+\beta_1x_1+\varepsilon $$假设：$H_0:β_2=0 (没有二阶项)$$H_1:β_2\neq 0 (需要二阶项)$ （2）交互作用交互作用——两个自变量共同作用对因变量产生的潜在影响。 假设：$$ y=\beta_0+\beta_1x_1+\beta_2x_2+\beta_3x_1x_2+\varepsilon $$没有交互项, $x_1$对y的影响用$β_1$测量；有交互项,$x_1$对y的影响用$β_1+β_3x_2$测量。影响随$x_2$的改变而改变。 交互作用显著性检验 交互作用模型:$$ y=\beta_0+\beta_1x_1+\beta_2x_2+\beta_3x_1x_2+\varepsilon $$ 假设：$$ H_0：\beta_3=0 （x_1和x_2无交互作用）$$$$ H_1：\beta_3\neq 0 （x_1和x_2有交互作用）$$ （3）其他非线性回归因变量y与x之间不是线性关系，可通过变量代换转换成线性关系，用最小二乘法求出参数的估计值。但是并非所有的非线性模型都可以化为线性模型。 双曲线基本形式：$y=\frac{x}{\alpha x+\beta}$线性化方法：$令y’=\frac{1}{y}，x’=\frac{1}{x}，则有y’=\alpha+\beta x’$ 幂函数曲线基本形式：$y=\alpha x^\beta$线性化方法：$两端取对数得：lgy=lg\alpha+\beta lgx，y’=lgy，x’=lgx，则有y’=lg\alpha+\beta x’$ 对数曲线基本形式：$y=\alpha+\beta lnx$线性化方法：$x’=lnx，则有y’=\alpha+\beta x’$ 指数曲线基本形式：$y=\alpha^{\beta x}$线性化方法：$两端取对数得：lny=ln\alpha+\beta x，y’=lny，则有y’=ln\alpha+\beta x$ S型曲线基本形式：$y=\frac{1}{\alpha+\beta e^{-x}}$线性化方法：$令y’=1/y，x’=e^{-x}，则有y’=\alpha+\beta x’$ 9 建立回归模型得到描述因变量与一个或一个以上自变量之间关系的估计的回归方程。目的是建立一个基于最好自变量集合的模型。找到一个适合的描述变量关系之间关系的函数。选择模型应包含的变量。 俭约的模型–用尽可能少的变量来提供足够精度的预测。 将不重要的变量除去更容易对模型进行解释。 发生多重共线性的可能变小。 变量选择Variable Selection 有些变量的作用不是很大，SSE 不会随着变量个数的增加而增加，但MSE=SSE/(n-k-1) 有可能会随着变量个数的增加而增加。最小的MSE可作为最优变量选择的一个准则，但需考虑所有子集 (2^p个)。 检验增加变量是否适宜的F统计$$F=\frac{SSE(x_1,x_2,\cdots,x_p)-SSE(x_1,x_2,\cdots,x_q,x_{q+1},\cdots,x_p)}{\frac{SSE(x_1,x_2,\cdots,x_q,x_{q+1},\cdots,x_p)}{n-p-1}}$$$$ F\sim F(p-q,n-p-1) $$F越大，说明增加变量减少预测误差的效果越显著。变量选择过程 向前选择(Forward Selection) 从没有自变量的模型开始。 如果所有的F统计量的p-值大于预先设定的终止值，说明增加任一变量效果不显著，停止。 否则，加入具有最大F统计量值的变量。 重新回归， Go to Step 2。 后向消元(Backward Elimination) 从包含所有自变量的模型开始。 如果所有的F统计量的p-值小于预先设定的终止值，说明减少任一变量效果显著，停止。 否则，删除具有最小F统计量值的变量。 重新回归， Go to Step 2。 逐步回归(Stepwise regression procedure)向前选择和后向消元的结合。1.先检查是否有变量需从模型中删除。2.再检查增加一个变量是否能改善模型。3.重复以上过程。注意： α进≤α出，否则F进&lt;F&lt;F出，会导致无限循环。 最佳子集回归(Best-subset approach)对所有可能的自变量组合进行估计。找出具有最大的修正判定系数$adj.R^2$和最小的估计误差标准差$s_ε$。 10 回归中的常见错误（1）没有检验线性关系假设 画散点图。如果不是线性的，检验其它非线性。用线性关系描述非线性关系会引起误导。 （2）只看结果不看图表 要将画散点图作为回归分析的一部分。检验回归直线与实际观测值间的关系。对自动回归来说这一步更为重要。 （3）用回归系数判定变量的重要性 回归系数依赖于自变量的量纲，因此系数的大小与变量的重要性无关。例如，将秒变为微秒没有改变任何事实，但是变量的系数却有所改变。 （4）没有确定置信区间 观察值是随机样本，所以回归结果有一定随机性。不确定置信区间，不可能理解参数的真正含义。 （5）没有计算判定系数 没有$R^2$，很难确定多少变异是由回归解释的。即使$R^2$看起来很好，安全起见还应做F-test。 （6）错误解释相关系数 判定系数是$R^2$。相关系数是R。$R^2$给出变异由回归解释的百分比，不是R。如：R =0.5,$R^2$=0.25——回归解释了25%的变异，不是50%。 （7）使用强相关的自变量 模型同时包括两强相关的自变量会降低回归模型的显著性。要尽可能的了解自变量间的关系。 （8）用回归模型预测观测值范围之外的区域 回归是基于某一特定观测样本的。在样本观测值范围内能提供较为精确的估计。 （9）观测值取值范围太小 回归只有在观测值取值范围附近预测的结果比较好。如果不在常用的范围内取值，回归模型用处不大。 (10)包括太多的自变量 变量越多的模型不一定越好。有可能出现多重共线性。 （11）认为好的预测变量是好的控制变量相关关系不一定因果关系：A与B相关，并不意味着可以通过改变A来控制B。 （12）线性回归结果会给人以误导 为了提供一个简练的总结，回归过程中舍弃了一些信息。有时一些重要的特征也舍弃了——看图形表示可以告诉我们是否有问题。 11 Logistic 回归Logistic回归提出的目的是为了解决二值化数据的回归问题。那么为什么简单线性回归模型不适合二值化数据的回归呢？详细原因可见如下图。 二值化变量是“yes”或者”no”的数据。可以被编码为1和0，也就是说不会有其他的变异数值。所以对于这种情况模型的要求是：模型的边界为0和1，模型可以输出的是一个在这类或者另一类的概率。我们想要的是一个实际值落入这类或者另一类的概率大小。而理想的模型是很好的估计0和1，或者换句话说，结果是0或1。所以解决方案就是Logistic回归。 Logistic的基本形式为$$ \pi_i’=ln(\frac{\pi_i}{1-\pi_i})=\beta_0+\beta_1x_i $$通过观测值估计$n_i$的概率$p_i$，并且用$ln(\frac{p_i}{1-p_i})$估计。典型案例：城市增长问题，城市化预测模拟， 常见的问题 都有一个二值化（或分类）变量： 都涉及到预测的思想机会，概率，比例或百分比。 不像其他的预测情况，y值是有界的。 Logistic 回归与简单线性回归 logistic回归是一种统计技术，可以用二值化变量问题中。回归虽有相似之处，但它不同于普通最小二乘法。识别重要和相似之处是两种技术的区别。]]></content>
      <categories>
        <category>Statistics &amp; Model</category>
      </categories>
      <tags>
        <tag>R</tag>
        <tag>Theory</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[应用统计学与R语言实现学习笔记（八）——方差分析]]></title>
    <url>%2F2017%2F06%2F11%2F%E5%BA%94%E7%94%A8%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B8%8ER%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%85%AB%EF%BC%89%E2%80%94%E2%80%94%E6%96%B9%E5%B7%AE%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[Chapter 8 ANOVA本篇是第八章，内容是方差分析。前一段考试，汇报，作业。忙不过来，停更了一段时间，现在重新开始更这一部分内容。方差分析是很多实验的基础以及很重要的分析手段，这一章内容相比较而言比较多。 1.方差分析的引论方差分析其实对我们来说并不陌生，因为大学搞生态的那群同学，实验中无数次出现了单方差因素分析的方法。那么方差分析究竟是什么呢？从引论来说，我们举个跟地学领域相关的例子。不同地貌对土壤有机质是否有影响？简单地说方差分析实质适合分析的是一系列数值型数据存在某个属性（也可以是某些），然后这个属性可以按照一定的规则分成几个类别（或者叫水平），我们想了解的就是，不同类别或者不同水平的这个数值是否存在显著性差异。简单的理解，它是处理分类型数据的。这里需要跟上一章提到的拟合优度检验、后面讲到的回归分析做些区别，拟合优度检验通常是分析两个分类变量的关系，回归分析则分析的是一个数值型变量（或多个数值型变量）对一个数值型变量的影响（或者说二者的关系）。而方差分析则是分析一个分类变量（或多个分类变量）对于一个数值变量的影响（或者说二者的关系）。这里给出一些定义和术语（不喜好数学的同学可以跳过，但请记住我上面的内容）：方差分析(Analysis of Variance，ANOVA)研究分类型自变量对数值型因变量的影响 一个或多个分类型自变量 两个或多个 (k 个) 处理或分类 一个数值型因变量 通过检验多个总体均值是否相等来判断是否有显著影响 通过分析数据的误差判断各总体均值是否相等 有单因子方差分析和双因子方差分析 单因子方差分析：涉及一个分类型自变量 双因子方差分析：涉及两个分类型自变量 方差分析 vs 假设检验（1）假设检验：一次只能研究两个样本 需要比较的次数随因子的数量增多而增多； 第一类错误发生的可能性增大。 （2）方差分析：同时分析多个样本 提高检验效率； 将所有信息结合在一起， 增加了分析的可靠性。 1.1 方差分析的部分概念： 因子或因素 (factor)——所要检验的对象，要分析行业对投诉次数是否有影响， 行业是要检验的因子或因素。 水平或处理(treatment):因子的不同表现,零售业、 旅游业、 航空公司、 家电制造业就是因子的处理。 观察值：在每个因子处理下得到的样本数据，每个行业被投诉的次数就是观察值。 试验：涉及一个因子多水平， 可称为单因子多处理的试验。 总体：因子的每一个处理看作是一个总体。 样本数据：观察值可以看作是从着多个总体中抽取的样本数据 也就是说分类变量是因子或因素，而分的类别就可以称为水平或处理，观察值则是数值型变量。试验就是就是分类的过程，总体其实就是水平，样本数据就是观测值。接下来讲讲方差分析的基本思想和原理。 1.2 方差分析的基本思想和原理方差分析的基本思想和原理基于两类误差。也就是随机误差和系统误差。 随机误差——因子的同一处理(总体)下， 样本各观察值之间的差异，这种差异可以看成是随机因素的影响， 称为随机误差。 系统误差——因子的不同处理(不同总体)下， 各观察值之间的差异，这种差异可能是由于抽样的随机性所造成的， 也可能是由于行业本身所造成的， 后者所形成的误差是由系统性因素造成的， 称为系统误差。 所以方差分析的实质是——比较两类误差，以检验均值是否相等；比较的基础是方差比；如果系统（处理）误差明显地不同于随机误差，则均值就是不相等的；反之，均值就是相等的。这里数据的误差用平方和(sum of squares)表示。 组内平方和(within groups)——因子的同一处理(同一个总体)下样本数据的平方和。组内平方和只包含随机误差。 组间平方和(between groups)——因子的不同处理(不同总体)下各样本之间的平方和。组间平方和既包括随机误差， 也包括系统误差。 所以若原假设成立， 组间平方和与组内平方和经过平均后的数值就应该很接近， 它们的比值就会接近1。 若原假设不成立， 组间平方和平均后的数值就会大于组内平方和平均后的数值， 它们之间的比值就会大于1。 当这个比值大到某种程度时， 就可以说不同处理之间存在着显著差异， 也就是自变量对因变量有影响。 1.3 方差分析的基本假定（1）每个总体都应服从正态分布： 对于因子的每一个处理， 其观察值是来自服从正态分布总体的简单随机样本。 （2）各个总体的方差必须相同： 各组观察数据是从具有相同方差的总体中抽取的。 （3）观察值是独立的。（4）在上述假定条件下， 判断行业对投诉次数是否有显著影响， 实际上也就是检验具有同方差的四个正态总体的均值是否相等。（5）如果四个总体的均值相等， 可以期望四个样本的均值也会很接近： 四个样本的均值越接近， 推断四个总体均值相等的证据也就越充分； 样本均值越不同， 推断总体均值不同的证据就越充分。 这里要注意的是，往往很多人做统计的时候往往不考虑前提和假设，这是一个错误。经典统计学中很多模型都有严密的数学推导和前提假设，就笔者从事的地学领域里其实有很多现象不是太遵循经典统计学的前提，由此也衍生出了空间统计学理论，所以在做统计研究时需要考量自己数据的特征，了解统计学与模型的基本前提与假设。 原假设：$H_0：\mu_1=\mu_2=\mu_3=\cdots=\mu_n $ n个水平被投诉次数的均值都相等； 意味着每个样本都来自均值为$\mu$、方差为$\sigma^2$的同一正态总体。 若备择假设成立，即$H_1：\mu_i(i=1,2,3,\cdots,n)$不全相等 至少有一个总体的均值是不同的； 样本分别来自均值不同的多个个正态总体。 2.单因子方差分析（One-way ANOVA)从这章开始后面的部分基本是典型数据分析，故我会渗透更多的数据分析的一些经验和理念。在这里因为要正式进入方差分析的具体内容里，所以我想谈的一点是我曾经说过的一句话——编程先学数据结构。数据结构的重要性可以参加下面的知乎。 https://www.zhihu.com/question/29587605 当然对于R或是其他数据处理语言来说，我觉得最关键的是你在使用分析数据（调用各种包）时需要了解你所调用的包或者函数处理的是什么样的数据（你要把数据处理成你的函数可以读的形式）。当然这是题外话，还是回到标题的单因子方差分析。 如果一个试验中，只有一个因子在变，而其它因素保持不变，称此试验为单因子试验（只涉及一个分类型自变量）。那么它的数据结构如下所示： 当然事实上在分析的时候，个人觉得R和其他数据所能读取的数据结构或者说组织方式还是2列的变量（数值型变量与分类变量）。 分析步骤则是统计学的经典三部曲： 提出假设； 构造检验统计量； 统计决策。 假设的提法在前面已经提过了。$H_0：\mu_1=\mu_2=\mu_3=\cdots=\mu_n $（自变量对因变量没有显著影响）。$H_1：\mu_1,\mu_2,\mu_3,\cdots,\mu_n不全相等$（自变量对因变量有显著影响）。 构造统计量需要计算（1）处理的均值（2）全部观察值的总均值（3）平方和（4）均方(MS) （接下来是公式大全，公式恐惧症者请跳过）（1）处理的均值假定从第i个总体中抽取一个容量为$n_i$的简单随机样本， 第i个总体的样本均值为该样本的全部观察值总和除以观察值的个数。$$ \bar x_i=\frac{\sum_{j=1}^nx_{ij}}{n_i} (i=1,2,\cdots,k)$$式中： $n_i$为第 i 个总体的样本观察值个数，$x_{ij}$为第i个总体的第j个观察值。 （2）全部观察值的总均值全部观察值的总和除以观察值的总个数。$$ \bar x’=\frac{\sum_{i=1}^k\sum_{j=1}^nx_{ij}}{n}=\frac{\sum_{i=1}^kn_i\bar x_i}{n}$$ （3）平方和方差分析需要计算三个平方和。 总平方和 (Sum of Squares for Total), SST。全部观察值与总平均值的离差平方和，反映全部观察值的离散状况。$$ SST=\sum_{i=1}^k\sum_{j=1}^n(x_{ij}-\bar x’)^2 $$ 处理平方和 (Sum of Squares due to Treatment), SSTR，又叫组间平方和。各组平均值与总平均值的离差平方和，反映各总体的样本均值之间的差异程度， 又称处理平方和或组间平方和，该平方和既包括随机误差， 也包括系统误差。$$ SSTR= \sum_{i=1}^k\sum_{j=1}^n(\bar x_i-\bar x’)^2=\Sigma_{i=1}^kn_i(\bar x_i-\bar x’)^2 $$ 误差平方和 (Sum of Squares due to Error),SSE，又叫组内平方和。每个处理或组的各样本数据与其组平均值的离差平方和，反映每个样本各观察值的离散状况，又称组内平方和或残差平方和，该平方和反映的是随机误差的大小。$$ SSE=\sum_{i=1}^k\sum_{j=1}^n(x_ij-\bar x_i）^2 $$实际上，SST=SSTR+SSESST反映全部数据总的误差程度； SSE反映随机误差的大小； SSTR反映随机误差和系统误差的大小。如果原假设成立， 则表明没有系统误差， 处理平方和SSTR除以自由度后的均方与误差平方和SSE和除以自由度后的均方差异就不会太大；如果处理均方显著地大于误差均方， 说明各处理(总体)之间的差异不仅有随机误差， 还有系统误差。判断因子的处理是否对其观察值有影响， 实际上就是比较处理均方与误差均方之间差异的大小。 （4）均方——构建检验统计量各平方和的大小与观察值的多少有关， 为消除观察值多少对平方和大小的影响， 需要将其平均， 这就是均方， 也称为方差。计算方法是用平方和除以相应的自由度，三个平方和对应的自由度分别是： SST 的自由度为n-1， 其中n为全部观察值的个数，SSTR的自由度为k-1， 其中k为因子处理(总体)的个数，SSE 的自由度为n-k。处理均方：SSTR的均方， 记为MSTR， 计算公式为:$$ MSTR=\frac{SSTR}{k-1} $$误差均方：SSE的均方，记为MSE， 计算公式为:$$ MSE=\frac{SSE}{n-k} $$计算检验统计量F：将MSTR和MSE进行对比， 即得到所需要的检验统计量F，当$H_0$为真时， 二者的比值服从分子自由度为k-1、分母自由度为n-k的F分布， 即$$ F=\frac{MSTR}{MSE}\sim(k-1,n-k) $$。最后是统计决策将统计量的值F与给定的显著性水平$\alpha$的临界值$F_\alpha$进行比较，作出对原假设$H_0$的决策。 根据给定的显著性水平$\alpha$， 在F分布表中查找与第一自由度$df_1＝k-1$、 第二自由度$df_2=n-k$ 相应的临界值$F_\alpha$。 若F&gt;$F_\alpha$，则拒绝原假设$H_0$，表明均值之间的差异是显著的，所检验的因子对观察值有显著影响。 若F&lt;$F_\alpha$，则不能拒绝原假设$H_0$， 无证据支持表明所检验的因子对观察值有显著影响。 对前面的三部曲做一个进一步的总结： （1）提出假设；（2）构造检验统计量；均值：全部观察值的总均值、处理的均值。平方和：总平方和SST，处理平方和SSTR，误差平方和SSE。均方：处理均方MSTR，误差均方MSE。均方比：MSTR/MSE~F分布。（3） 统计决策。 在R语言中，方差分析函数较为简单，具体应用后面再说。value为观察值，factor为因素。 12a.aov&lt;-aov(value~factor,data=a)summary(a.aov) 误差来源（方差来源） 平方和(SS) 自由度(df) 均方(MS) F 组间（处理） SSTR k-1 MSTR=SSTR/(k-1) MSTR/MSE 组内（误差） SSE n-k MSE=SSE/(n-k) 总计（合计） SST n-1 当然仅仅证明有显著性差异，可能还不能满足我们的需求，所以需要测度方差分析的关系强度。关系强度的测量拒绝原假设表明因子(自变量)与观测值之间有关系，而处理平方和(SSTR)度量了自变量(行业)对因变量(投诉次数)的影响效应。 当处理平方和比误差平方和(SSE)大， 而且大到一定程度时， 就意味着两个变量之间的关系显著， 大得越多， 表明它们之间的关系就越强。 反之， 就意味着两个变量之间的关系不显著， 小得越多， 表明它们之间的关系就越弱。 变量间关系的强度用处理平方和(SSTR)及误差平方和(SSE)占总平方和(SST)的比例大小来反映。处理平方和占总平方和的比例记为$R^2$ ,即$$R^2=\frac{SSTR（处理平方和）}{SST（总平方和）}$$其平方根R就可以用来测量两个变量之间的关系强度。 3.方差分析中的多重比较多重比较（multiple comparison procedures）——通过对总体均值之间的配对比较来进一步检验到底哪些均值之间存在差异。 可采用Fisher提出的最小显著差异方法， 简写为LSD-least significant difference。LSD方法是对检验两个总体均值是否相等的t检验方法的总体方差估计加以修正（ 用MSE来代替） 而得到的。 方差分析中的多重比较分析步骤 （1）提出假设$H_0: \mu_i=\mu_j (第i个总体的均值等于第j个总体的均值)$$H_1: \mu_i\neq\mu_j (第i个总体的均值不等于第j个总体的均值)$（2）计算检验的统计量: $\bar x_i-\bar x_j$（3）计算LSD,t分布的自由度为n-k（MSE的自由度为n-k）。$$ LSD=t_{\alpha/2}\sqrt{MSE(\frac{1}{n_i}+\frac{1}{n_j})} $$（4）决策：若$\left|{\bar x_i-\bar x_j}\right|\gt LSD $，拒绝$H_0$；若$\left|{\bar x_i-\bar x_j}\right|\lt LSD $，不拒绝$H_0$。 4.双因子方差分析（Two-way ANOVA）前面介绍完了单因子方差分析，但是当我们的因子大于一个的时候，我们又该怎么分析呢？同样抛个样例问题出来。假设现在我们想了解北京城市人口空间分布是否受不同环路（一环、二环、三环乃至四、五、六环）或新老城区的显著影响。所以该问题是一个典型的双因子问题，可以拆分为如下的情况： 因子 新城区 老城区 一环 人口 人口 二环 人口 人口 三环 人口 人口 对于该问题我们可以考虑用单因子方差分析来解决——即通过考虑两个因子间所有的组合来分析是否有显著影响。（二环+新城区，二环+老城区，三环+新城区，……，六环+老城区）通过这样组合来得到最后的单因子水平。但是这样处理的问题是，我们无法了解到底是新老城区的因素影响了人口的空间分布，或者是不同的环路影响了人口的空间分布，亦或是二者共同影响。所以我们需要新的方法来分析。这就是题目所述的双因子方差分析。 4.1 双因子方差分析的基本假定 （1） 每个总体都服从正态分布（对于因素的每一个水平， 其观察值是来自正态分布总体的简单随机样本）。（2） 各个总体的方差必须相同（对于各组观察数据， 是从具有相同方差的总体中抽取的）。（3） 观察值是独立的。 双因子方差分析实质是分析两个因素(行因素Row和列因素Column)对试验结果的影响。如果两个因素对试验结果的影响是相互独立的， 分别判断行因素和列因素对试验数据的影响， 这时的双因素方差分析称为无交互作用的双因素方差分析或无重复双因素方差分析(Two-factor without replication)。如果除了行因素和列因素对试验数据的单独影响外，两个因素的搭配还会对结果产生一种新的影响， 这时的双因素方差分析称为有交互作用的双因素方差分析或可重复双因素方差分析 (Two-factor with replication )。 4.2 无交互作用双因子方差分析如果在一项试验中，有两个因子在变，而其余因子保持不变，则称之为双因子试验。 设因子A有a个水平$A_1，A_2，···，A_a$，因子Ｂ有b个水平$B_1，B_2，···，B_b$，每组因子组合进行1次试验，其结果为$x_{ij}$，$x_{ij}\sim N(\mu_{ij},\sigma^2)$,现在要研究它们对因变量X的影响。 （1）无交互作用双因子方差分析：模型$$ X_{ij}=\mu+\alpha_i+\beta_j+\varepsilon_{ij} $$这里$\varepsilon_{ij}\sim iid$ $N(0,\sigma^2) $（2）无交互作用双因子方差分析：假设因子A原假设：$H_0:α_1= α_2=… = α_a=0$备择假设：$H1:至少一个α_i不等于0$因子B原假设：$H_0: β_1 = β_2 = … = β_b=0$备择假设：$H1:至少一个β_i不等于0$（3）计算步骤（公式大全） 均方：$\bar x_{i.}$是A因素的第i个水平下各观察值的平均值$$ \bar x_{i.}=\frac{\sum_{j=1}^bx_{ij}}{b}（i=1,2,\cdots,a） $$$\bar x_{.j}$是B因素的第j个水平下各观察值的平均值$$ \bar x_{.j}=\frac{\sum_{i=1}^ax_{ij}}{a}（i=1,2,\cdots,b） $$$\bar x’$是B因素的第j个水平下各观察值的平均值$$ \bar x’=\frac{\sum_{i=1}^a\sum_{j=1}^bx_{ij}}{ab} $$ 平方和：$$ SST=\sum_{i=1}^a\sum_{j=1}^b(x_{ij}-\bar x’)^2 $$$$ SSA=b\sum_{i=1}^a(x_{i.}-\bar x’)^2 $$$$ SSB=a\sum_{j=1}^b(x_{.j}-\bar x’)^2 $$$$ SSE=\sum_{i=1}^a\sum_{j=1}^b(x_{ij}-x_{i.}-x_{.j}+\bar x’)^2 $$$$ SST=SSA+SSB+SSE $$ 计算均方（MS）构造检验统计量:误差平方和除以相应的自由度，四个平方和的自由度分别是：总离差平方和SST的自由度为 ab-1；A因素的离差平方和SSA的自由度为 a-1；B因素的离差平方和SSB的自由度为 b-1；随机误差平方和SSE的自由度为 (a-1)×(b-1)。A因素的均方，记为MSA，计算公式为：$$ MSA=\frac{SSA}{a-1} $$B因素的均方，记为MSB，计算公式为：$$ MSB=\frac{SSB}{b-1} $$随机误差项的均方，记为MSE，计算公式为：$$ MSE=\frac{SSE}{(a-1)(b-1)} $$ 计算检验统计量(F)检验行因素的统计量$$ F_A=\frac{MSA}{MSE}\sim F(a-1,(a-1)(b-1)) $$检验列因素的统计量$$ F_B=\frac{MSB}{MSE}\sim F(b-1,(a-1)(b-1)) $$ 统计决策将统计量的值F与给定的显著性水平$\alpha$的临界值$F_\alpha$进行比较， 作出对原假设$H_0$的决策：根据给定的显著性水平a在F分布表中查找相应的临界值$F_\alpha$；若$F_A&gt;F_\alpha$，则拒绝原假设，表明均值之间的差异是显著的， 即所检验的A因素对观察值有显著影响；若$F_A&gt;F_\alpha$，则拒绝原假设，表明均值之间有显著差异，即所检验的B因素对观察值有显著影响。 误差来源（方差来源） 平方和 自由度 均方 F 因子A SSA a-1 MSA=SSA/(a-1) MSA/MSE 因子B SSB b-1 MSB=SSB/(b-1) MSB/MSE 误差 SSE (a-1)(b-1) MSE=SSE/(a-1)(b-1)) 总计 SST ab-1 4.3 有交互作用双因子方差分析除了上面的无交互作用双因子方差分析之外，可能存在的一种情况就是二者同时作用，这就是有交互作用的双因子方差分析。即（$A_i,B_j$）下作了r个试验，所得结果记作$x_{ijk}$,$x_{ijk}$服从$N(\mu_{ij},\sigma^2)，i=1,\cdots,a,j=1,\cdots,b,k=1,\cdots,r$。且相互独立。（1）有交互作用双因子方差分析：模型$$ X_{ijk}=\mu+\alpha_i+\beta_j+(\alpha\beta)_{ij}+\varepsilon_{ijk} $$这里$\varepsilon_{ijk}\sim iid$ $N(0,\sigma^2) $（2）交互作用双因子方差分析：假设因子A原假设：$H_0:α_1= α_2=… = α_a=0$备择假设：$H_1:至少一个α_i不等于0$因子B原假设：$H_0: β_1 = β_2 = … = β_b=0$备择假设：$H_1:至少一个β_i不等于0$交互作用原假设：$H_0: αβ_{11} = αβ_{12} = … = αβ_{ab}=0$备择假设：$H1:至少一个αβ_{ij}不等于0$计算步骤（公式大全） 平方和$$ SST=\sum_{i=1}^a\sum_{j=1}^b\sum_{k=1}^r(x_{ij}-\bar x’)^2 $$$$ SSA=br\sum_{i=1}^a(x_{i.}-\bar x’)^2 $$$$ SSB=ar\sum_{j=1}^b(x_{.j}-\bar x’)^2 $$$$ SSAB=r\sum_{i=1}^a\sum_{j=1}^b(\bar x_{ij}-\bar x_{i.}-\bar x_{.j}+\bar x’)^2 $$$$ SSE=\sum_{i=1}^a\sum_{j=1}^b\sum_{k=1}^r(x_{ijk}-\bar x_{ij})^2 $$$$ SST=SSA+SSB+SSAB+SSE $$ 计算检验统计量(F)$$ F_A=\frac{MSA}{MSE}\sim F(a-1,ab(r-1)) $$$$ F_B=\frac{MSB}{MSE}\sim F(b-1,ab(r-1)) $$$$ F_{AB}=\frac{MSAB}{MSE}\sim F((a-1)(b-1),ab(r-1)) $$拒绝域$$ F_A\gt F_\alpha(a-1,ab(r-1)) $$$$ F_B\gt F_\alpha(b-1,ab(r-1)) $$$$ F_{AB}\gt F_\alpha((a-1)(b-1),ab(r-1)) $$ 误差来源（方差来源） 平方和 自由度 均方 F 因子A SSA a-1 MSA=SSA/(a-1) MSA/MSE 因子B SSB b-1 MSB=SSB/(b-1) MSB/MSE 交互作用 SSAB (a-1)(b-1) MSB=SSAB/(a-1)(b-1) MSAB/MSE 误差 SSE ab(r-1) MSE=SSE/ab(r-1)) 总计 SST abr-1 5.实验设计初步谈完了方差分析的各种理论，回顾开头我们提到的“搞实验的同学经常使用单因素方差分析”，所以在实验设计里，方差分析的应用是非常普遍的。所以这里也谈谈实验设计的一些内容（笔者非实验设计人员，所以仅谈谈一些理念）。一个实验必须施加一些处理，来观察这些处理会不会对实验结果或者测量值有影响。不同的处理是用来比较不同的总体。而好的实验，这些处理必须是随机的。所谓的随机就是指，每个样本有同等的机会（等概率事件）接收这些处理。所以对于这个随机化的比喻就是，你必须闭着眼睛选，才能保证你选的水平是随机的。实验相比于观察的优点也在于此，随机化使的两个比较总体尽可能相似，一切东西都是一样的除了选择处理的水平，如果实验结果存在差异的话，我们就能得出结论，这个处理是否会造成实验结果的不同。实验是我们设计的，可以控制实验的变量（很熟悉的控制变量法）——我们能保证我们比较的两个总体除了处理之外大致是一样的，而观察则无法保证我们所观察的两个总体仅仅存在某个处理上的差异，其他都是一致的。从这个角度来说，实验设计的注意要点如下： （1） 因子数量（单因子方差分析，双因子方差分析……）；（2） 因子处理的数量。（3） 实验设计类型 前两个点大家可能都很清楚了，主要谈谈第三个点。实验设计类型严格来说包括如下： （1）完全因素位级组合（Full factorial design） 完全随机化设计 随机化区组设计（2）部分因素位级组合（Fractional factorial design） （1）完全因素位级组合（Full factorial design）顾名思义，就是讲所有因子的所有组合考虑一遍，造成的问题就是——实验规模巨大。以下几个要点： 如果有k个因子，对于k个因子的第i个水平来说，会有$n_i$个水平的观测值：$$ n=\prod_{i=1}^k n_i $$ 必须实验每个可能的因子水平的组合。 必须捕获有关交互的全部信息。 大量的工作。 主要还包括两种类型。 完全随机化设计(completely randomized design)——“处理” 被随机地指派给试验单元的一种设计，“处理” 是指可控制的因子的各个水平 “试验单元(experiment unit)”是接受“处理”的对象或实体。 随机化区组设计(randomized block design)——先按一定规则将试验单元划分为若干同质组， 称为“ 区组(block)”，再将各种处理随机地指派给各个区组,分组后再将每个品种（ 处理） 随机地指派给每一个区组的设计就是随机化区组设计。如果可能， 我们应选择随机化区组设计。 （2）部分因素位级组合（Fractional factorial design） 仅测量部分因子水平的组合的结果。 必须认真设计来捕获所有可能的交互作用。 相比而言，工作量降低了，不确定性增大了。 在知道一些因子不存在交互作用的前提下特别有效。 典型的是正交试验设计——利用“正交表”进行科学地安排与分析多因子试验的方法。其主要优点是能在很多试验方案中挑选出代表性强的少数几个试验方案，并且通过这少数试验方案的试验结果的分析，推断出最优方案，同时还可以作进一步的分析，得到比试验结果本身给出的还要多的有关各因子的信息。 正交表的性质（正交性）每列中不同数字出现的次数是相等的。每个因子不同的水平出现的次数相同。表示：在试验安排中，所挑选出来的水平组合是均匀分布的（每个因子的各水平出现的次数相同）——整齐可比性。对于任意两列，将同一行的两个数字看成有序数对时，每种数对出现的次数是相等的。任意两个因子都全面试验。表示：任意两因子的各种水平的搭配在所选试验中出现的次数相等——均衡分散性。正交表的优点：各因子的各水平的搭配是均衡的。试验点均衡分散在全部试验条件之中，使得它的代表性很强，能够比较全面地反映、分析出全面试验的最优点来。 用正交表安排试验的步骤明确试验目的，确定试验指标。确定要考察的（主要）因子和水平——各水平次序最好随机排列（因为正交试验不是全面试验）。选用合适的正交表，安排试验计划：根据因子的水平，选择相应水平的正交表；再根据欲考察因子的个数选定正交表中因子的个数。根据计划进行试验，确定试验指标。对试验结果进行分析，得出合理的结论。 正交试验结果的分析方法直观分析法：简单、直观、容易操作，计算量少。方差分析：理论根据可靠，结果可信度高，计算量比较大。正交试验的直观分析法计算各因子各水平的综合平均值，选出各因子的最优水平。对给定因子的每个水平，其它因子对试验指标的影响是相同的，因此可用综合平均值来比较各指标对试验指标的影响（综合可比性）。计算个因子综合平均值的极差，分清因子的主次（在平均值中最大数与最小数之差，称为极差。极差的大小序列，表示因子的重要性大小）。选定最优组合——选定最优组合的原则：对于重要因子，一定要选最优水平，以期达到较好试验效果；对于不重要因子，由于它们的水平变动对试验结果影响不大，可根据节约、高效、简便易行等实际情况灵活选定其水平。正交试验的方差分析假定试验指标服从正态分布基本思想与双因子方差分析方法一致：将总的离差平方和分解成各因子及各交互作用的离差平方和，构造F统计量，对各因子是否对试验指标具有显著影响，作F检验。]]></content>
      <categories>
        <category>Statistics &amp; Model</category>
      </categories>
      <tags>
        <tag>R</tag>
        <tag>Theory</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[应用统计学与R语言实现学习笔记（七）——拟合优度检验]]></title>
    <url>%2F2017%2F05%2F10%2F%E5%BA%94%E7%94%A8%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B8%8ER%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%83%EF%BC%89%E2%80%94%E2%80%94%E6%8B%9F%E5%90%88%E4%BC%98%E5%BA%A6%E6%A3%80%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[Chapter 7 Goodness of Fit本篇是第七章，内容是拟合优度检验。 1.多项分布拟合优度检验的第一个应用是关于多项总体。那么多项总体（或者多项分布）是什么呢？ 多项分布是二项分布的推广。 总体被分为几个互不相交的类别。 多项分布假设：每次试验有且仅有一个结果发生；每次试验独立；每次试验概率不变。 拟合优度检验-多项总体步骤 将所观测到的数据与理论上的期望值进行比较。 步骤：1.计算每一类实际观测到的频次$f_i$；2.计算每一类理论上的期望频次$e_i$；3.计算 Chi-square 统计量——$\chi^2=\sum(f_i-e_i)^2/e_i$。其中自由度 (df) = k-1， k 是多项总体的类别数。 拟合优度检验用于多项总体检验没有直接的函数，这里用R语言的自编函数实现，体会下具体的算法（当然感觉自己写的略复杂）。代码依旧是后面放出，函数具体使用说明也会附上。 2.独立性依旧是从问题出发——性别与购物频率是否有关系独立性检验——该统计方法常用于检验两个分类变量是否有关系。那么首先要提到两个概念——独立事件和非独立事件（independent and dependent events)。 独立事件——一个事物发生不会对其他事物发生概率造成影响。 非独立事件——一个事物发生会影响其他事物发生概率。 接着统计学构建出了一个表来进行独立性检验。这就是联立表（Contingency Tables)。 解决多总体比例问题。 之前通常用两个或两个以上特征来对样本观测值分类。 也被称为交叉表。 一般在R中，使用Table函数即可生成两个特征（分类变量）的联立表，xtabs则是根据公式创立联立表，prop.table则可以直接计算出比例。联立表如何做独立性检验呢？首先提出假设（这里不详述，相信大家应该懂怎么建立了），接着计算期望的联立表每个单元格的期望频次。$$ e_{ij}=\frac{(i^{th} Rowtotal)(j^{th} Columtotal)}{Total SampleSize}。 $$接着就可以对比实际频次和期望频次，然后我们用卡方（chi-square)统计量进行检验。$$ \chi^2=\sum_{i=1}^n\sum_{j=1}^m\frac{(f_{ij}-e_{ij})^2}{e_{ij}} with, df=(n-1)(m-1)。 $$n为行数，m为列数，$f_{ij}$,$e_{ij}$分别为第i行和第j列的$单元格_{ij}$实际频次和期望频次。当然这个方法也可以用来检验顺序变量和分类变量。方法类似，这里不赘述。 3.概率分布拟合优度检验的最重要的应用其实是探测一个数据具体的概率分布。当然探测数据分布的第一方式——是可见即可得的可视化。主要包括前面提到过的直方图和QQ图。QQ图——Quantile-Quantile Plots（分位数图）： 适用于小数据集。 猜测分布的基础方法。 用来绘制QQ图的数据必须落在该分布内。 如果散点图接近直线，说明数据分布接近正态分布。 这里给出绘制QQ图的原理： 对样本容量为N的样本数据按照升序排序。 计算从1到N排序的百分比。 从百分位数得分的关系找到中心分数。 找到对应于中心分数的z值（标准正态分布）。 绘制对应z值的观测点数据。 接着用R语言实现123456789#QQ plot#generation of random number that fall in normal distributiona&lt;-rnorm(200,0,1)#plotjpeg("plot1.jpg",width = 5000,height = 4000,units = "px",res = 1000)qqnorm(a)qqline(a,col="red")dev.off() 除了QQ图之外，另外一类方法就是通过统计方法——拟合优度检验来探测数据是否正态分布。以正态分布为例。过程： 获取样本数据。 将样本结果分组（单元格）。 比较实际与预期值。 统计量如下：$$ \chi^2=\sum_{i=1}^k\frac{(f_i-ei-)^2}{e_i}。 $$R语言中可以用chisp.test函数进行正态分布测验。 此外对于有某种特定分布的非正态数据可以通过数学变换转变为正态分布数据。常用的一般包括： 对数变换。 开方变换。 指数或平方变换。 这里的数学变换需要根据大家实际研究需求决定。]]></content>
      <categories>
        <category>Statistics &amp; Model</category>
      </categories>
      <tags>
        <tag>R</tag>
        <tag>Theory</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[应用统计学与R语言实现学习笔记（六）——假设检验]]></title>
    <url>%2F2017%2F05%2F08%2F%E5%BA%94%E7%94%A8%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B8%8ER%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%85%AD%EF%BC%89%E2%80%94%E2%80%94%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[Chapter 6 Hypothesis Test本篇是第6章，内容是假设检验。 1.基本思想我们还是从问题开始讨论。这回提个接地气的问题——雄安新区批复前后对该地区房价是否有差异？嗯，假设检验其实就是为了解决这类问题。假设检验的基本思想——我们有样本，但是无法获得总体，需要对总体的分布形式或分布参数事先作出某种假设，然后根据样本观测值，运用统计分析的方法来检验这一假设是否正确。分解开来，假设检验=假设+检验（或者假设检验）。假设(hypothesis)——对总体的参数的具体数值（或分布形式）所作的陈述（总体参数包括总体均值、比例、 方差等，分析之前必需陈述）。假设检验(hypothesis test)—先对总体的参数（ 或分布形式） 提出某种假设，然后利用样本信息判断假设是否成立的过程（有参数检验和非参数检验；逻辑上运用反证法， 统计上依据小概率原理）。如图。 假设检验的思想还可以去搜索Fisher 显著性检验的思想(女士品茶试验)的故事深深体会，这里就不详述了。有兴趣的同学可以点击下文的科学网链接查看。 http://blog.sciencenet.cn/blog-624263-795715.html 2.原假设和备择假设从前面的介绍我们知道，假设检验的第一步是建立假设。那么假设分为两种（原假设和备择假设）。那么这二者具体又是什么呢？ 原假设(null hypothesis)——原假设又称“ 0假设”，总是有符号 =， ≥ 或≤，表示为 $H_0$。是研究者想收集证据予以反对的假设（生产实践中常对应正常情形，如均值与设计一致）；一般来说，原假设是一旦拒绝便要采取行动的假设。因此， 原假设总是“受到保护的假设” ，没有充分的证据是不能拒绝原假设的。例如，对一家信誉很好的工厂的产品进行检验，原假设一般是“ 产品合格”。 备择假设(alternative hypothesis)——研究者想收集证据予以支持的假设， 一旦发生就要采取行动， 是与原假设对立的假设，也称“研究假设”，总是有符号 ≠， &gt; 或 &lt;，表示为 $H_1$。 总结起来就是，原假设是统计学史上最悲催角色——它从一开始诞生，就是为了被科学家们发好人卡拒绝而存在的一个假设。备择假设才是科学家们追求的白富美。搞明白了这两个假设，下一步我们做假设检验的时候，就要先提出假设了，这里给了一些提出假设的要点： 原假设和备择假设是一个完备事件组， 而且相互对立（在一项假设检验中， 原假设和备择假设必有一个成立， 而且只有一个成立）。 先确定备择假设， 再确定原假设。 等号“ =” 总是放在原假设上。 因研究目的不同， 对同一问题可能提出不同的假设（ 也可能得出不同的结论）。 同时在实际应用中，我们有不同的需求，因此又有双侧检验和单侧检验的区分。 双侧检验——备择假设没有特定的方向性，并含有符号“=”的假设检验，称为双侧检验或双尾检验(two-tailed test) 单侧检验——备择假设具有特定的方向性，并含有符号“&gt;”或“&lt;”的假设检验，称为单侧检验或单尾检验(one-tailed test)。其中备择假设的方向为“&lt;”，称为左侧检验，备择假设的方向为“&gt;”，称为右侧检验。 原假设与备择假设形式： 双边检验：$ H_0: \mu=2，H_1: \mu\neq2 $。 单边检验：左侧检验——$ H_0: \mu\le2，H_1: \mu>2 $，右侧检验——$ H_0: \mu\ge2，H_1: \mu&lt;2 $。 所见即所得，用一张图来表示假设检验过程。 所以拒绝原假设的理由是假设检验中的小概率原理。那么什么是小概率？ 在一次试验中， 一个几乎不可能发生的事件发生的概率。 在一次试验中小概率事件一旦发生， 我们就有理由拒绝原假设。 小概率由研究者事先确定。 所以拒绝$H_0$的理由就是 3.第一类错误和第二类错误上文介绍了假设检验的过程，但是假设检验过程会不会出现错误呢？其实大家仔细分析拒绝原假设的理由就会发现问题了。通常情况下原假设是小概率事件，但是小概率事件≠0概率事件。小概率事件不是不发生，而是发生概率较小。就像天气预报说明天有99%的可能不下雨，结果1%的可能性成为了事实，明天下雨了。因此假设检验中会有两类错误（弃真错误和取伪错误）经常出现。（1）第一类错误(弃真错误)： 原假设为真时拒绝原假设。 第一类错误的概率为α（没错，就是它，我们的好朋友，小α。咳咳咳，就是显著性水平，一般由研究者事先指定，常用的值有0.01, 0.05, 0.10）。 （2）第二类错误（取伪错误）： 原假设为假时未拒绝原假设。 第二类错误的概率记为β。 α和β的关系——α和β的关系就像翘翘板， α小β就大，α大β就小。所以两类错误不可能同时发生（第一类只在$H_0$为真时发生，第而类只在$H_0$为假时发生）。影响β的因素： 总体参数的真值。 显著性水平α（当α减少时增大）。 总体标准差σ（当σ增大时增大）。 样本容量n（当n减少时增大）。 4.统计量与拒绝域讲了这么多，但是还没有介绍假设检验的计算过程。假设检验的过程依赖于两个重要数学概念（统计量与拒绝域，前面已经有稍微提到了）。这里再做具体介绍。检验统计量(test statistic)——根据样本观测结果计算得到的， 并据以对原假设和备择假设作出决策的某个样本统计量，是对样本估计量的标准化结果（原假设$H_0$为真，点估计量的抽样分布）。标准化的检验统计量公式为：$$ 标准化的检验统计量=\frac{点估计量-假设值}{点估计量的抽样标准差} $$显著性水平和拒绝域的三种情况：双侧检验： 左侧检验： 右侧检验： 统计量落在拒绝域时，我们就可以拒绝原假设。具体如下： 给定显著性水平α，查表得出相应的临界值$z_{\alpha},z_{\alpha/2},t_{\alpha},t_{\alpha/2},\cdots$。 将检验统计量的值与α水平的临界值进行比较。 作出决策：双侧检验——|统计量| &gt; 临界值，拒绝$H_0$；左侧检验——统计量 &lt; 临界值，拒绝$H_0$；右侧检验——统计量 &gt; 临界值，拒绝$H_0$。 5.利用p值进行决策如何利用假设检验解决实际问题？很重要的一个应用是在决策上。就如标题说的，利用p值进行决策。那么什么是p值?p值(p-value)：在一个假设检验问题中，拒绝原假设的最小显著性水平。 在原假设为真的条件下，检验统计量的观察值大于或等于其计算值的概率(双侧检验为分布中检验统计量两侧面积的总和;单侧检验为分布中检验统计量相应单侧面积）。 反映实际观测到的数据与原假设$H_0$之间的一致程度。 被称为观察到的（或实测的）显著性水平。 决策规则： 若p值&lt;α， 拒绝$H_0$。 p值法步骤（以大样本均值为例）将样本统计量转换成检验统计量z 计算p值： Z为标准正态分布随机变量（$p值=(\left|Z\right|\ge z)(双侧),p值=(Z\le z)(左侧),p值=(Z\ge z)(右侧)$） 比较p值和α：如果α≥p值，拒绝$H_0$;如果$α&lt;$p值，不能拒绝$H_0$。 假设检验结论的表述假设检验的目的就在于试图找到拒绝原假设的证据， 而不在于证明什么是正确的。 拒绝原假设时结论是清楚的。 当不拒绝原假设时——并未给出明确的结论，不能说原假设是正确的， 也不能说它不是正确的。但也未说它不是10。 我们只能说样本提供的证据还不足以推翻原假设。 假设检验步骤的总结 陈述原假设和备择假设。 从所研究的总体中抽出一个随机样本。 确定一个适当的检验统计量， 并利用样本数据算出其具体数值。 确定一个适当的显著性水平， 并计算出其临界值， 指定拒绝域。 将统计量的值与临界值进行比较， 作出决策——统计量的值落在拒绝域，拒绝$H_0$，否则不拒绝$H_0$，也可以直接利用p值作出决策。 6.一个总体参数的检验前面的理论讲的差不多了，又到了典型总体参数的检验内容的介绍了。依旧是先一个总体参数的检验（总体均值、总体比例、总体方差）。总体均值的检验(大样本： n≥30)使用z检验统计量：$\sigma^2已知$：$$ z=\frac{\bar x-\mu_0}{\sigma/\sqrt{n}}\sim N(0,1)。 $$$\sigma^2未知$：$$ z=\frac{\bar x-\mu_0}{s/\sqrt{n}}\sim N(0,1)。 $$ 总体均值的检验(正态总体小样本)检验统计量：$\sigma^2已知$：$$ z=\frac{\bar x-\mu_0}{\sigma/\sqrt{n}}\sim N(0,1)。 $$$\sigma^2未知$：$$ t=\frac{\bar x-\mu_0}{s/\sqrt{n}}\sim t(n-1)。$$总体比例的检验假定条件： 总体服从二项分布； 可用正态分布来近似(大样本)。 检验的Z统计量：$$ z=\frac{\bar q-p_0}{\sqrt{\frac{p_0(1-p_0)}{n}}}\sim N(0,1)，p_0为假设的总体比例。 $$总体方差的检验检验一个总体的方差或标准差，假设总体近似服从正态分布，使用$\chi^2$分布。检验统计量：$$ \chi^2=\frac{(n-1)s^2}{\sigma_0^2}\sim \chi^2(n-1)。 $$ 这里顺带提下作为统计推断的两大分支的区间估计和假设检验的关系。 过程相似：如果假设均值在95%的置信区间之外，双边检验将拒绝原假设（显著性水平为5%）。 逻辑不同：置信区间——不知道均值多少而要估计它；假设检验: 假定一个均值要看数据是否支持这个假设。 另外还是要谈一谈统计学与实际问题——这里谈的是统计显著性和实际显著性。 一个被拒绝的原假设意味着有统计显著性，但未必有实际显著性。这种情况常发生在大样本或精确测量场合，如Kepler的行星运行第一定律：行星轨道是椭圆的，当时吻合程度很好，100年后，仪器更高级、测量更精确，该假设被拒绝，因为行星间交互作用导致摄动。因此不要盲目使用统计显著性。此外，显著性水平α的选择也是个很关键的问题。一般来说： α不宜过小，否则第二类错误概率会较大。 α的选择与判断发生错误时要付出的代价大小有关。 α的选择是决策问题。 7.两个总体参数的检验讲完了一个总体参数，照例来讲就两个总体参数（两个总体均值之差，两个总体比例之差，两个总体方差比）。独立大样本两总体均值之差检验假定条件： 两个样本是独立的随机样本。 大样本($n_1\ge30和n_2\ge30$)。 检验统计量：$$ \sigma_1^2，\sigma_2^2已知：z=\frac{(\bar x_1-\bar x_2)-(\mu_1-\mu_2)}{\sqrt{\frac{\sigma_1^2}{n_1}+\frac{\sigma_2^2}{n_2}}}\sim N(0,1)。 $$$$ \sigma_1^2，\sigma_2^2未知：z=\frac{(\bar x_1-\bar x_2)-(\mu_1-\mu_2)}{\sqrt{\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2}}}\sim N(0,1)。 $$正态总体独立小样本均值之差检验（$\sigma_1^2，\sigma_2^2已知$）假定条件： 两个独立的小样本。 两个总体都是正态分布。 $\sigma_1^2，\sigma_2^2已知。$ 检验统计量:$$z=\frac{(\bar x_1-\bar x_2)-(\mu_1-\mu_2)}{\sqrt{\frac{\sigma_1^2}{n_1}+\frac{\sigma_2^2}{n_2}}}\sim N(0,1)。 $$正态总体独立小样本均值之差检验($\sigma_1^2，\sigma_2^2$未知但$\sigma_1^2=\sigma_2^2$)假定条件： 两个独立的小样本。 两个总体都是正态分布。 $\sigma_1^2，\sigma_2^2未知但相等，即\sigma_1^2=\sigma_2^2。$ 检验统计量：$$t=\frac{(\bar x_1-\bar x_2)-(\mu_1-\mu_2)}{s_p\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}}，其中s_p=\frac{(n_1-1)s_1^2+(n_2-1)s_2^2}{n_1+n_2-2}，自由度：n_1+n_2-2。 $$ 两个总体均值之差的检验($\sigma_1^2，\sigma_2^2$未知且不相等$\sigma_1^2\ne\sigma_2^2$)假定条件： 两个总体都是正态分布。 $\sigma_1^2，\sigma_2^2未知且不相等，即\sigma_1^2\ne\sigma_2^2。$ 样本容量相等，$n_1=n_2=n$。 检验统计量：$$t=\frac{(\bar x_1-\bar x_2)-(\mu_1-\mu_2)}{\sqrt{\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2}}}=\frac{(\bar x_1-\bar x_2)-(\mu_1-\mu_2)}{\sqrt{\frac{s_1^2+s_2^2}{n}}}，自由度：n_1+n_2-2=2(n-1)。 $$ 两个总体均值之差的检验($\sigma_1^2，\sigma_2^2$未知且不相等$\sigma_1^2\ne\sigma_2^2$)假定条件： 两个总体都是正态分布。 $\sigma_1^2，\sigma_2^2未知且不相等，即\sigma_1^2\ne\sigma_2^2。$ 样本容量不相等，$n_1\ne n_2$。 检验统计量：$$t=\frac{(\bar x_1-\bar x_2)-(\mu_1-\mu_2)}{\sqrt{\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2}}}，自由度：最接近v的整数——v=\frac{(\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2})^2}{\frac{(s_1^2/n_1)^2}{n_1-1}+\frac{(s_2^2/n_2)^2}{n_2-1}}。 $$ 两个总体均值之差的检验(匹配样本)假定条件: 两个总体配对差值构成的总体服从正态分布。 配对差是由差值总体中随机抽取的。 数据配对或匹配(重复测量 (前/后))。 $$ 样本差值均值\bar d=\frac{\sum_{i=1}^n d_i}{n_d}, 样本差值标准差值 s_d=\sqrt{\frac{\sum_{i=1}^n(d_i-\bar d)^2}{n_d-1}}。 $$大样本检验统计量：$$ z=\frac{\bar d-d_0}{s_d/\sqrt{n_d}}\sim N(0,1)。 $$小样本检验统计量：$$ t=\frac{\bar d-d_0}{s_d/\sqrt{n_d}}\sim t(n-1)。 $$ 两个总体比例之差的检验假定条件： 两个总体都服从二项分布。 可以用正态分布来近似。 检验统计量：检验$H_0$： $p_1-p_2=0$$$ z=\frac{\bar p_1-\bar p_2}{\sqrt{\bar p(1-\bar p)(\frac{1}{n_1}+\frac{1}{n_2})}}，其中\bar p=\frac{x_1+x_2}{n_1+n_2}=\frac{\bar p_1n_1+\bar p_2n_2}{n_1+n_2}。 $$检验$H_0$： $p_1-p_2=d_0$$$ z=\frac{(\bar p_1-\bar p_2)-d_0}{\sqrt{\frac{\bar p_1(1-\bar p_1)}{n_1}+\frac{\bar p_2(1-\bar p_2)}{n_2}}}。 $$ 两个总体方差比的检验(F检验)假定条件： 两个总体都服从正态分布。 两个独立的随机样本。 检验统计量：$$ F=\frac{s_1^2}{s_2^2}\sim F(n_1-1,n_2-1)或 F=\frac{s_2^2}{s_1^2}\sim F(n_2-1,n_1-1)。 $$ 最后的总结就是如下图。 最后的最后，回到开头提的问题——雄安新区。该问题其实是两个总体参数的检验问题——两个总体均值之差的问题（两个总体分别是批复前的房价和批复后的房价）。所以如果要讨论该问题，可以考虑从批复前后的房价，抽取配对大样本或小样本(楼盘房价）进行假设检验，这样我们就能在统计学上证明这件事对雄安房价的显著影响啦。本篇涉及的R语言内容较少，还是老规矩，放到后面的第14章去讨论。]]></content>
      <categories>
        <category>Statistics &amp; Model</category>
      </categories>
      <tags>
        <tag>R</tag>
        <tag>Theory</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[应用统计学与R语言实现学习笔记（五）——参数估计]]></title>
    <url>%2F2017%2F05%2F07%2F%E5%BA%94%E7%94%A8%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B8%8ER%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%94%EF%BC%89%E2%80%94%E2%80%94%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[Chapter 5 Estimation本篇是第五章，内容是参数估计。 1.参数估计的一般问题正如前面介绍的，统计学的两大分支，分别是描述统计和推断统计。所以今天来谈谈推断统计的第一大问题——参数估计。当然一般叫统计推断的会更多些，二者是一样的。统计推断(Statistical Inference)——主要包括参数估计和假设检验，实质就是通过样本的均值、标准差、方差等去估计总体的均值、标准差、方差或者判断总体的分布形式和分布参数。 参数估计：根据从总体中抽得的样本所提供的信息，对总体分布中包含的未知参数作出数值上的估计。点估计：用样本的某一函数值来估计总体分布中的未知参数;区间估计：按照一定的可靠度估计出参数的一个范围，即确定一个区间，使这一个区间内包含参数真值的概率达到预先所要求的程度。 假设检验：需要对总体的分布形式或分布参数事先作出某种假设，然后根据样本观测值，运用统计分析的方法来检验这一假设是否正确。 上一篇提到的，获取样本之后，我们需要去猜总体，参数估计就是猜总体的参数（分布中所含的未知参数；分布特征：均值、方差等；事件的概率等）或者参数空间(参数的可能取值范围)。假设检验是下一章内容，这里就不细述了。首先明确两个概念：估计量（estimator）与估计值(estimated value)。 估计量： 用于估计总体参数的随机变量，一般为样本统计量（如样本均值、 样本比例、 样本方差等； 例如：样本均值就是总体均值$ \mu $的一个估计量）。 估计值： 估计参数时计算出来的统计量的具体值,如果样本均值=80， 则80就是总体均值的估计值。 既然是估计量，就必须有评价估计量的标准。一般包括以下几点： 无偏性：估计量的数学期望等于被估计的总体参数，样本的随机性导致估计偏差， 偏差平均值为0， 无系统误差（所以在这里又提出了渐进无偏估计：估计随着样本量的增加而逐渐趋近于真值。渐进无偏估计指系统偏差会随着样本量的增加而逐渐减小，趋于0，在大样本时可近似当无偏估计使用）。 有效性： 对同一总体参数的两个无偏点估计量， 有更小标准差的估计量更有效。 一致性： 随着样本容量的增大， 估计量的值越来越接近被估计的总体参数。 由于无偏性是最普遍的标准。这里再介绍部分无偏性的几个要点： 样本均值是总体期望的无偏估计。 诸观测值对样本均值的偏差可正可负，其和恒为0（n个偏差中只有n-1个是独立的）。 自由度：独立偏差个数。 偏差平方和（样本量相等情况下，偏差平方和的大小反映样本散布的大小， 样本量大，偏差平方和大趋近于平均偏差平方和，偏差平方和的期望小于方差，有偏估计，渐进无偏估计。 点估计（point estimate） 用样本估计量的某个取值直接作为总体参数的估计值（例如：用样本均值直接作为总体均值的估计；用两个样本均值之差直接作为总体均值之差的估计）。 无法给出估计值接近总体参数程度的信息（虽然在重复抽样条件下，点估计的均值可望接近总体真值，但由于样本是随机的，抽出一个具体的样本得到的估计值等同于总体真值的可能性很小，特别是在连续分布时，该概率几乎为0，一个点估计量的可靠性是由它的抽样标准误差来衡量的，这表明一个具体的点估计值无法给出估计的可靠性的度量）。 2.区间估计 Confidence Intervals正如前面提到的点估计可靠性较低，因此在点估计的基础上又提出了区间估计(interval estimate)，它能解决的问题包括： 为解决参数估计的精确度和可靠性问题， 在点估计的基础上给出总体参数估计的一个区间范围（该区间一般由样本统计量加减抽样误差而得到），使这一个区间内包含参数真值的概率大到预先所要求的程度。 它不具体指出总体参数等于什么，但能指出总体的未知参数落入某一区间的概率有多大。 二者的区别在于：点估计是一个数，区间估计给出一个区间，提供更多关于变异性的信息。通俗的解释，你女朋友买了件衣服，让你猜价格，你猜中准确价格很难，但是你猜一个范围还是准确度比较高的。 所以区间估计(interval estimate)的概念是——根据样本统计量的抽样分布能够对样本统计量与总体参数的接近程度给出一个概率度量。由概率度量则引出了置信区间（Confidence Intervals）的概念。 $$ 设x_1,x_2,\cdots,x_n是来自f(x,\theta)的样本，对于给定的\alpha，0&lt;\alpha&lt;1, $$ $$ 如能找到两个统计量\theta_1(x_1,x_2,\cdots,x_n)和\theta_2(x_1,x_2,\cdots,x_n) $$ $$ 使得P[(\theta_1(x_1,x_2,\cdots,x_n)&lt;\theta&lt;\theta_2(x_1,x_2,\cdots,x_n)]\ge1-\alpha, $$ $$ 称(\theta_1(x_1,x_2,\cdots,x_n),\theta_2(x_1,x_2,\cdots,x_n))是\theta的置信度为1-\alpha的置信区间(Confidence interval);$$ $$ \theta_1,\theta_2为置信上限与置信下限,1-\alpha为置信度,\alpha为显著性水平(Significance level)。 $$ 置信区间实质上是由样本统计量所构造的总体参数的估计区间。在某种程度上确信这个区间包含真正的总体参数（用一个具体的样本所构造的区间是一个特定的区间，我们无法知道这个样本所产生的区间是否包含总体参数的真值，我们只能是希望这个区间是大量包含总体参数真值的区间中的一个，但它也可能是少数几个不包含参数真值的区间中的一个）。置信区间表明了区间估计的精确性， 区间越小越精确，区间越大越不精确。置信水平——将构造置信区间的步骤重复很多次，置信区间包含总体参数真值的次数所占的比例称为置信水平（置信度）。置信水平表明了区间估计的可靠性， 表示为 $ (1 - \alpha) $($\alpha$是总体参数未在区间内的比例， 区间估计不可靠的概率为$\alpha$， 如$\alpha$=0.05， 表明结论犯错误的概率为0.05),常用的置信水平值有99%, 95%, 90%。那么什么样的置信区间是好的置信区间呢？也就是区间估计的评价标准是什么呢？一般包括如下两点： 置信度（置信系数）越大越好——概率越大越放心，但不能一味求大。 随机区间平均长度越短越好——估计精度越高。 但是在某些实际问题中，我们可能更关心置信上限或置信下限(合金钢强度，越大越好（望大特性），平均强度下限是个重要指标,药物毒性，越小越好（望小特性），平均毒性上限是个重要指标)。这就是单侧置信限问题。谈完了这么多理论，接下来进入实践，如何做一个总体参数的区间估计？按照前一章，我们还是讨论三个重要的总体参数：均值、比例、方差。也是先谈一个总体参数的区间估计。首先规定好符号对应统计量和参数。总体均值——$\mu$，总体比例——p，总体方差——$\sigma^2$;样本均值——$\bar x$，样本比例——$\bar p$，样本方差——$s^2$。一个总体均值的置信区间估计方法总结起来就是： 正态分布，且总体方差$\sigma$已知，用Z值； 正态分布，且总体方差$\sigma$未知，用t值； 非正态分布但是大样本，无论总体方差$\sigma$是否已知，用Z值。 第一种情况：正态分布统计量z——$z=\frac{\bar x-\mu}{\sigma/\sqrt{n}}\sim N(0,1)$，总体均值$\mu$在$1-\alpha$置信水平下的置信区间为$\bar x\pm z_{\alpha/2}\frac{\sigma}{\sqrt{n}}$，置信下限为$\bar x- z_{\alpha/2}\frac{\sigma}{\sqrt{n}}$，置信上限为$\bar x+ z_{\alpha/2}\frac{\sigma}{\sqrt{n}}$。第二种情况：t分布统计量——$t=\frac{\bar x-\mu}{s/\sqrt{n}}\sim t(n-1)$，总体均值$\mu$在$1-\alpha$置信水平下的置信区间为$\bar x\pm t_{\alpha/2}\frac{s}{\sqrt{n}}$，置信下限为$\bar x- t_{\alpha/2}\frac{s}{\sqrt{n}}$，置信上限为$\bar x+ t_{\alpha/2}\frac{s}{\sqrt{n}}$。第三种情况：正态分布统计量z——$z=\frac{\bar x-\mu}{\sigma/\sqrt{n}}\sim N(0,1)$，总体均值$\mu$在$1-\alpha$置信水平下的置信区间为$\bar x\pm z_{\alpha/2}\frac{\sigma}{\sqrt{n}}$（$\sigma$未知的话，把$\sigma$换成s即可）。 一个总体比例的置信区间估计方法如下：假定条件np≥5, n(1-p)≥5, n≥30。正态分布统计量z——$z=\frac{\bar p-p}{\sqrt{\frac{p(1-p)}{n}}}\sim N(0,1)$，总体比例的置信区间为$\bar p\pm z_{\alpha/2}\sqrt{\frac{p(1-p)}{n}}$或$\bar p\pm z_{\alpha/2}\sqrt{\frac{\bar p(1-\bar p)}{n}}$。 一个正态总体方差的置信区间估计方法如下：总体方差$\sigma^2$的点估计量为$s^2$，则$\frac{(n-1)s^2}{\sigma^2}\sim \chi^2(n-1) $，总体方差在$1-\alpha$置信水平下的置信区间为：$ \frac{(n-1)s^2}{\chi^2_{\alpha/2}(n-1)}\le \sigma^2 \le \frac{(n-1)s^2}{\chi^2_{1-\alpha/2}(n-1)}$ 接下来谈谈两个总体参数的置信区间的估计方法。估计的一般包括均值差、比例差、方差比，主要包括两种抽样方法——独立样本和配对样本。两个正态总体均值之差的置信区间（独立样本）： $\sigma_1^2$，$\sigma_2^2$已知，使用正态分布统计量z：$z=\frac{(\bar x_1-\bar x_2)-(\mu_1-\mu_2)}{\sqrt{\frac{\sigma_1^2}{n_1}+\frac{\sigma_2^2}{n_2}}}\sim N(0,1)$，两个总体均值之差$\mu_1-\mu_2$在$1-\alpha$置信水平下的置信区间为：$ (\bar x_1-\bar x_2)\pm z_{\alpha/2}\sqrt{\frac{\sigma_1^2}{n_1}+\frac{\sigma_2^2}{n_2}} $。 $\sigma_1^2$=$\sigma_2^2$未知，总体方差的合并估计量：$s_p^2=\frac{(n_1-1)s_1^2+(n_2-1)s_2^2}{n_1+n_2-2}$，估计量$ \bar x_1-\bar x_2 $的抽样标准差：$\sqrt{\frac{sp_1^2}{n_1}+\frac{sp_2^2}{n_2}}$，两个样本均值之差的标准化：$ t=\frac{(\bar x_1-\bar x_2)-(\mu_1-\mu_2)}{s_p\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}}\sim t(n_1+n_2-2) $，两个总体均值之差$\mu_1-\mu_2$在$1-\alpha$置信水平下的置信区间为：$ (\bar x_1-\bar x_2)\pm t_{\alpha/2}(n_1+n_2-2)\sqrt{s_p^2(\frac{1}{n_1}+\frac{1}{n_2})} $。$\sigma_1^2\neq\sigma_2^2$未知，$n_1=n_2$：$ (\bar x_1-\bar x_2)\pm t_{\alpha/2}(n_1+n_2-2)\sqrt{(\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2})} $。$\sigma_1^2\neq\sigma_2^2$未知，$n_1\neq n_2$：$ (\bar x_1-\bar x_2)\pm t_{\alpha/2}(v)\sqrt{(\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2})} $，$ v为自由度，v=\frac{(\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2})^2}{\frac{(s_1^2/n_1)^2}{n_1-1}+\frac{(s_2^2/n_2)^2}{n_2-1}} $。 两个总体均值之差的区间估计(独立大样本)两个总体均值之差的估计：$\sigma_1^2$，$\sigma_2^2$已知时，两个总体均值之差$\mu_1-\mu_2$在$1-\alpha$置信水平下的置信区间为：$ (\bar x_1-\bar x_2)\pm z_{\alpha/2}\sqrt{(\frac{\sigma_1^2}{n_1}+\frac{\sigma_2^2}{n_2})} $。$\sigma_1^2$，$\sigma_2^2$未知时，两个总体均值之差$\mu_1-\mu_2$在$1-\alpha$置信水平下的置信区间为：$ (\bar x_1-\bar x_2)\pm z_{\alpha/2}\sqrt{(\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2})} $。 两个总体均值之差的区间估计(匹配样本)匹配大样本的假定条件——两个匹配的大样本($n_1\ge30和n_2\ge30$)；两个总体均值之差$ \mu_d=\mu_1-\mu_2 $在$1-\alpha$置信水平下的置信区间为：$ \bar d\pm z_{\alpha/2}\frac{\sigma_d}{\sqrt{n}}或\bar d\pm z_{\alpha/2}\frac{s_d}{\sqrt{n}}$，$\bar d$为对应差值的均值，$\sigma_d$为对应差值的标准差。 匹配小样本的假定条件——两个匹配的小样本($n_1&lt;30和n_2&lt;30$)，两个总体各观察值的配对差服从正态分布。两个总体均值之差$ \mu_d=\mu_1-\mu_2 $在$1-\alpha$置信水平下的置信区间为：$ \bar d\pm t_{\alpha/2}(n-1)\frac{s_d}{n} $ 两个总体比例之差区间的估计假定条件——两个总体服从二项分布，可以用正态分布来近似，两个样本是独立的。两个总体比例之差$p_1-p_2$在$1-\alpha$置信水平下的置信区间为：$\bar p_1-\bar p_2\pm z_{\alpha/2}\sqrt{\frac{\bar q_1(1-\bar q_1)}{n_1}+\frac{\bar q_2(1-\bar q_2)}{n_2}}$。 两个正态总体方差比的置信区间实际应用如两种不同方法生产的产品性能的稳定性或两种不同测量工具的精度，需要我们去比较两个总体方差。 两个正态总体方差比的估计比较两个总体的方差比，用两个样本的方差比来判断（如果$s_1^2/s_2^2$接近于1，说明两个总体方差很接近；如果$s_1^2/s_2^2$远离1，说明两个总体方差存在差异）。总体方差比在$1-\alpha$置信水平下的置信区间为：$\frac{s_1^2/s_2^2}{F_{\alpha/2}}&lt;\frac{\sigma_1^2}{\sigma_2^2}&lt;\frac{s_1^2/s_2^2}{F_{1-\alpha/2}},F\sim F(n_1-1,n_2-1)$(F分布性质：$F_{1-\alpha/2}(n_1,n_2)=\frac{1}{F_{\alpha/2}(n_2,n_1)}$)。 总的来说，参数估计的东西很多，根据具体研究情况，我们可以根据自己需求选择不同的参数估计。当然据笔者所知，R语言在参数估计上，现成函数（指默认的基础包）比较少，一般需要自编函数或者有额外的包。这里先给出一个样例函数（14章中会涉及到一部分，这里不详述）。 conf.int=function(x,sigma,alpha) { mean=mean(x) n=length(x) z=qnorm(1-alpha/2,mean=0,sd=1,lower.tail = T) c(mean-sigma*z/sqrt(n),mean+sigma*z/sqrt(n)) } 3.样本容量的确定前一章我们提到统计学闻名于世的规定，样本容量一般必须＞30。但是这种规定，并不是万能的。所以样本容量的确定就成了一个问题。n过大费用高、时间长、人力多；n过小误差增大。事实上n的确定依赖于多大置信度（可靠性），什么样的精度（多宽的区间）。所以样本容量的确定需要根据置信区间的性质来决定。置信区间的性质——以正态总体小样本容量为例。首先置信区间的宽度:$ w=2z\frac{\sigma}{\sqrt{n}} $，因此很容易发现影响区间宽度的因素包括了： 样本容量：大样本容量——小区间。 总体数据的离散程度：小方差——小区间。 置信水平：高置信度——大t值——大区间。 边际误差（margin error)——置信区间上下限与点估计之间的距离。$$ E=z\frac{\sigma}{\sqrt{n}} $$给定边际误差E和置信水平$1-\alpha$，可以找到所需要的样本容量。 估计总体均值时样本容量的确定($\sigma^2$已知)：$n=\frac{(z_{\alpha/2})^2\sigma^2}{E^2}，其中E=z_{\alpha/2}\frac{\sigma}{\sqrt{n}}$样本容量n与总体方差$\sigma^2$、边际误差E、置信水平$1-\alpha$之间的关系为： 随总体方差增大而增大。 随边际误差减小而增大。 随$1-\alpha$增大而增大，随$\alpha$减小而增大。 $\sigma$未知，如有近期样本可用，用其样本标准差代替$\sigma$，用t分布分位数代替标准正态分布分位数，自由度为近期样本容量-1。否则，可以用一个至少比$\sigma$大的数来替代$\sigma$，抽一个样本，用s代替$\sigma$——Stein 两步法。 估计总体比例时样本容量的确定：根据比例区间估计公式可得样本容量n为$$ n=\frac{(z_{\alpha/2})^2\cdot p(1-p)}{E^2}，其中：E=z_{\alpha/2}\sqrt{\frac{p(1-p)}{n}} $$E的取值一般小于0.1，p 未知时， 可用之前样本比率估计，或保守的取最大值0.5。 估计两个总体均值之差时样本容量的确定：设$n_1$和$n_2$为来自两个总体的样本，并假定$n_1=n_2$。根据均值之差的区间估计公式可得两个样本的容量n为：$$ n_1=n_2=n=\frac{(z_{\alpha/2})^2\cdot (\sigma_1^2+\sigma_2^2)}{E^2}，其中E=z_{\alpha/2}\sqrt{\frac{(\sigma_1^2+\sigma_2^2)}{n}} $$。估计两个总体比例之差时样本容量的确定：设$n_1$和$n_2$为来自两个总体的样本，并假定$n_1=n_2$。根据比例之差的区间估计公式可得两个样本的容量n为：$$ n_1=n_2=n=\frac{(z_{\alpha/2})^2\cdot [p_1(1-p_1)+p_2(1-p_2)]}{E^2}，其中E=z_{\alpha/2}\sqrt{\frac{(p_1(1-p_1)+p_2(1-p_2))}{n}} $$。总的来说，样本容量的确定也是根据具体需要以及显著性水平计算得到的。]]></content>
      <categories>
        <category>Statistics &amp; Model</category>
      </categories>
      <tags>
        <tag>R</tag>
        <tag>Theory</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[应用统计学与R语言实现学习笔记（四）——抽样方法与抽样分布]]></title>
    <url>%2F2017%2F05%2F06%2F%E5%BA%94%E7%94%A8%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B8%8ER%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89%E2%80%94%E2%80%94%E6%8A%BD%E6%A0%B7%E6%96%B9%E6%B3%95%E4%B8%8E%E6%8A%BD%E6%A0%B7%E5%88%86%E5%B8%83%2F</url>
    <content type="text"><![CDATA[Chapter 4 Sampling And Sample Distribution本篇是第四章，内容主要是抽样方法与抽样分布。这一章内容比较多（从抽样方法一直到许多分布函数，尤其是介绍了四个重要分布——正态分布、卡方分布、t分布、F分布，以及部分统计推断的内容）。 1.抽样方法抽样调查的概念前面已经有所涉及到，这里就不详述了。大部分情况下，普查是不太可能的，所以抽样调查是科学研究中应用最为广泛的收集数据的方法。但是正如前面在谈论precision和accuracy问题的时候说的，我们希望数据的质量是Low Bias and Low Variance，抽样调查的样本既能很好地代表总体（非抽样误差小），同时多次抽样的话，也希望抽样的样本大致都接近，降低抽样误差。所以从统计学诞生至今，已经提出了很多的抽样方法。可以说并没有任何一种方法能完全避免这些误差，这些方法需要根据具体情境具体使用。总的来说，抽样方法可以分为两大类：概率抽样与非概率抽样。概率抽样包括了： 简单随机抽样 系统抽样 分层抽样 整群抽样 多阶段抽样 概率抽样是根据一个已知的概率来抽取样本单位（也称为随机抽样），概率抽样要求按照一定的概率随机抽取样本，也就是说每个样本都有一定的机会被抽中，同时每个样本被抽中的概率是可以已知或计算出来的，而当运用概率抽样的样本进行参数估计的时候必须考虑样本被抽中的概率（某种程度来说感觉类似贝叶斯，先验概率和后验概率的问题）。简单随机抽样——从总体N个单位里抽出n个单位作为样本（可以重复抽样，也可以不重复抽样），最常用的抽样方式，参数估计和假设检验主要依据的就是简单随机样本。系统抽样——将总体中的所有单位(抽样单位)按一定顺序排列， 在规定的范围内随机地抽取一个单位作为初始单位， 然后按事先规定好的规则确定其他样本单位（先从数字1到k之间随机抽取一个数字r作为初始单位，以后依次取r+k， r+2k…等单位）。分层抽样——将总体单位按某种特征或某种规则划分为不同的层(Strata)， 然后从不同的层中独立、 随机地抽取样本。整群抽样——将总体中若干个单位合并为组(群)， 抽样时直接抽取群， 然后对中选群中的所有单位全部实施调查。多阶段抽样——先抽取群， 但并不是调查群内的所有单位， 而是再进行一步抽样，从选中的群中抽取出若干个单位进行调查（群是初级抽样单位，第二阶段抽取的是最终抽样单位。将该方法推广， 使抽样的段数增多， 就称为多阶段抽样）非概率抽样包括了： 方便抽样 判断抽样 自愿样本 滚雪球抽样 配额抽样 非概率抽样则不是按照随机的原则选取样本，而是根据研究的具体需求选取调查样本。方便抽样——研究员依据方便的原则选取对应的样本。判断抽样——研究员根据自己的判断选择样本。自愿样本——被调查者自愿参加调查提供信息。举个跟地学相关的例子——志愿地理信息（Volunteer Geographcial Information,VGI），是指利用工具创建、组装和传播个人资源提供的地理数据，像社交媒体中的签到。滚雪球抽样——首先选择一组进行调查，让调查者提供另外一些属于调查总体的调查对象，然后持续下去。配额抽样——先将体中的所有单位按一定的标志（变量） 分为若干类， 然后在每个类中采用方便抽样或判断抽样的方式选取样本单位。总的来说，各种抽样方式各有各有的优缺点，根据研究具体情况进行选择。而实际研究中简单随机抽样的应用更多些，这边提供R语言中做简单随机抽样的代码示例。 #N表示总体的数据，n为抽样单位，replace=FALSE代表不重复抽样，replace=TRUE代表重复抽样。 n&lt;-sample(N,n,replace = FALSE) 2.正态分布正态分布由高斯作为描述误差相对频数分布的模型而提出的： 描述连续型随机变量的最重要的分布 许多现象都可以由正态分布来描述 可用于近似离散型随机变量的分布 经典统计推断的基础 正态分布的意义，多多少少大家都有了解，这里就不再详述了。随机变量服从$$ X\sim N (\mu,\sigma^2) $$则X的概率密度函数为$$ f(x)=\frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{1}{2}(\frac{x-\mu}{\sigma})^2} -\infty&lt;x&lt;\infty $$这就是正态分布的概率密度函数。正态分布具有如下性质： 关于x=μ的钟形对称性质，峰值在x=μ处。 均值和标准差一旦决定，该分布形式也就决定了。 均值决定分布函数位置，标准差决定函数的扁平程度。 X轴两侧无限延伸，f(x)无限逼近x轴,但理论上不可能相交。 正态随机变量在特定区间上的取值概率由正态曲线下的面积给出，而且其曲线下的总面积等于1 下图给出了两个图（一个是用核密度生成的曲线，一个是正态分布概率密度函数）来说明以上的部分性质（具体实现的R语言代码会在笔记写完后给出）。 标准正态分布就是指均值为0，标准差为1的正态分布。通过标准正态分布可以很方便地求算各种概率，所以实际应用中，往往将正态分布数据通过标准化的方式转化为标准正态分布求解具体概率。即令$$ Z=\frac{x-\mu}{\sigma} $$则Z服从标准正态分布。那么如何检验数据的正态性呢？一般有以下几种方法： 对数据画出频数分布的直方图或茎叶图（若数据近似服从正态分布， 则图形的形状与上面给出的正态曲线应该相似）。 求出样本数据的四分位差和标准差， 然后二者计算比值。 若数据近似服从正态分布，则有$$ Q_d/s\approx1/3 $$ 拟合优度检验 一般可以通过画这个图来进行检验（代码同在笔记写完后给出）。 或者计算四分位差和标准差比值。这里给出这个方法的R语言实现(用户自编函数）。 Normaltestindex&lt;-function(x) { q=fivenum(x) Qd=q[4]-q[2] s=sd(x) Normaltestindex=Qd/s cat(&quot;The Qd/s&quot;, Normaltestindex) } 拟合优度检验是后面章节内容，这里不详述。正态分布在各样本相互前提下存在线性可加性。$$ x_i\sim N(\mu_i,\sigma_i)，且x_i相互独立，则\Sigma a_ix_i\sim N(\Sigma a_i\mu_i,\Sigma a_i^2\sigma_i^2)$$同时样本量够大情况下，n个独立随机变量之和服从正态分布。 3.三种不同性质的分布统计量(statistic)——样本来自总体，必然携带有反映总体性质的各种信息。统计的基本任务就是通过对样本的研究来对总体的未知参数或分布类型作出估计，对有关总体的假设作出推断。样本是进行统计推断的依据。但在实际应用时，一般不是直接使用样本本身，而是对样本进行整理和加工, 即针对具体问题构造适当的函数—统计量， 利用这些函数来进行统计推断，揭示总体的统计特性。事实上统计量把分散在样本中的总体信息按需要集中在一个函数上，使该函数能反映总体方面的信息。概念很拗口，总结起来就是，我懒得分析（也没法分析，因为有些总体无法穷尽）总体的分布，我就偷懒地先抽样，并且认为样本能够代表总体特征，再偷懒地计算某些指标，这些指标可以反映样本数据分布特征，这些指标就叫统计量，然后再用统计量去推出（猜）总体的分布特征（第一章提到了，应该叫参数）——果然“懒”才是人类进步的动力。当然这里要区分两个概念——统计量与观察值。$$ 假设X_1,X_2, \cdots ,X_n是来自总体X的样本, x_1,x_2,\cdots ,x_n为其样本值, $$$$则称不含任何总体分布中未知参数的函数g(X_1,X_2,\cdots,X_n)为统计量，相应实数g(x_1,x_2,\cdots,x_n)为观察值 $$如何理解这二者区别呢？其实这里把样本看成了一组随机变量，因为在未抽样前，样本观察值未知，样本就是个随机变量（所以一般来说统计推断的基础是简单随机抽样），但是抽样之后，样本就是一组确定的观察值，这也可以说是样本的二重性。常用的统计量包括了样本均值、样本方差、样本标准差、样本k阶原点矩、样本k阶中心距（具体公式的话，文末附录给出）。从前面提到的统计推断基础是简单随机抽样，也就是要求样本是简单随机样本，那么简单随机样本又是什么呢？首先随机样本的概念：$$ 随机抽取的n个个体的集合(X_1,X_2, \cdots ,X_n),n为样本容量。 $$而简单随机样本则需要在随机样本的前提上满足以下两个条件： 随机性：总体中每个个体都有同等机会被选到样本中,即$$ X_i 与X同分布$$ 独立性：样本中每个个体的选取不影响其他个体的选取，即$$ X_1,X_2, \cdots ,X_n是相互独立的随机变量 $$ 接下来是标题提到的三种不同性质的分布：总体分布、样本分布、抽样分布。 总体分布——总体中各元素的观察值所形成的分布，分布通常是未知的，可以假定它服从某种分布。 样本分布——一个样本中各观察值的分布，也称经验分布，当样本容量 n 逐渐增大时，样本分布逐渐接近总体的分布。 抽样分布——样本统计量的概率分布， 是一种理论分布，又称为诱导分布，在重复选取容量为n 的样本时，由该统计量的所有可能取值形成的相对频数分布，随机变量是样本统计量（样本函数，如样本均值，样本比例，样本方差等），结果来自容量相同的所有可能样本，提供了样本统计量长远而稳定的信息，是进行推断的理论基础，也是抽样推断科学性的重要依据（ 点估计、 置信区间、假设推断等）。 用一个简单的例子来说明三者的区别。假设总体N=4，随机变量X=年龄。总体分布如下，均值为21，方差为2.236。这里提醒用R语言做统计的同学，R语言默认的var和sd都是求样本的标准差（分母是n-1和n的差别），当你的数据是总体时，建议另外计算，或者可以使用我下面的自编函数（给了个标准差的样例，方差的会在笔记写完后给出）。 Populationsd&lt;-function(x){ n=length(x) m=mean(x) Psd=sqrt(sum((x-m)^2)/n) cat(&quot;The Standard deviation of Population : &quot;,Psd) } 建立n=2的抽样分布，样本均值分布如下，均值为21，方差为1.58 可以发现总体分布是均匀分布，而样本均值的抽样分布却呈现了近似正态分布，均值是相同的，但是方差却有差异。根据总体分布以及样本容量可以将抽样分布分为以下三类： 精确抽样分布：当总体分布已知时，如果对任一自然数都能导出统计量分布的显示表达式，这样的抽样分布称为精确抽样分布（对小样本的统计推断特别有用，大多数是在正态总体下得到的， t分布、 F分布等）。 渐近抽样分布：样本量无限大时统计量的极限分布（大样本问题）。 近似抽样分布：注意获得近似分布的条件（用统计量的前二阶矩当作正态分布的前二阶矩获得正态近似，随机模拟法获得统计量的近似分布）。 4.一个总体样本统计量的抽样分布样本均值的抽样分布——在重复选取容量为 n 的样本时，由样本均值的所有可能取值形成的相对频数分布（一种理论概率分布，推断总体均值的理论基础）。 正态总体均值抽样分布——精确分布（均值无偏）。 样本均值的中心极限定理——渐进分布。中心极限定理：$$设从均值为\mu， 方差为\sigma^2的一个任意总体中抽取容量为n的样本，$$ $$ 当n充分大时，样本均值的抽样分布近似服从均值为\mu、 方差为\sigma^2/n的正态分布 $$ 用一张图来说明这个定理（摘自参考书目1：贾俊平，《统计学》（第五版），中国人民大学出版社，2012.）。 当然也在这里诞生了一个统计学闻名于世的规定，样本容量n一般至少要求&gt;30。因此样本均值的抽样分布中，样本均值的数学期望（也就是均值）和方差就有对应的公式了。样本均值的数学期望和方差：数学期望：$$ E(\bar x) =\mu $$方差： $$ \sigma_{\bar x}^2=\frac{\sigma^2}{n} （重复抽样）,$$ $$ \sigma_{\bar x}^2=\frac{\sigma^2}{n}\frac{N-n}{N-1} （样本总体有限，且n\ge 5\%N不重复抽样）$$ 总结来说，总体分布为正态分布的话，抽样分布也是正态分布，总体分布为非正态分布的话，大样本情况下也是近似正态分布，小样本则为非正态分布。 除了均值之外，实际生活中比例也是一个很重要的参数。比例——总体（或样本）中具有某种属性的单位与全部单位总数之比（如不同性别的人与全部人数之比，合格品(或不合格品) 与全部产品总数之比）总体比例可表示为$$ p=\frac{N_0}{N},1-p=\frac{N_1}{N} $$样本比例可表示为$$ p=\frac{n_0}{n},1-p=\frac{n_1}{n} $$样本比例的抽样分布——在重复选取容量为n的样本时，由样本比例的所有可能取值形成的相对频数分布。 一种理论概率分布。 当样本容量很大时（满足np≥5, n(1-p)≥5)，样本比例的抽样分布可用正态分布近似。 推断总体比例p的理论基础。 类似于均值的抽样分布我们可以得到样本比例的数学期望和方差：数学期望：$$ E(\bar p) =p $$方差： $$ \sigma_{\bar x}^2=\frac{p(1-p)}{n} （重复抽样）,$$ $$ \sigma_{\bar x}^2=\frac{p(1-p)}{n}\frac{N-n}{N-1} （不重复抽样）$$ 接下来介绍一个重要的分布——卡方分布。$$ 若随机变量\xi_1,\xi_2,\cdots,\xi_n是n个相互独立的标准正态变量（独立同分布于标准正态分布），$$ $$ 则这n个随机变量的平方和Y=\Sigma\xi_i^2构成的随机变量的分布称为自由度为n的\chi^2分布（chi-square distribution），$$ $$ 记为\chi^2(n)分布 $$卡方分布的性质和特点如下： 分布的变量值始终为正 分布的形状取决于其自由度n的大小， 通常为不对称的单峰右偏（ 正偏） 分布， 但随着自由度的增大逐渐趋于对称， 当n&gt;30时， 接近正态分布 期望为：$$ E(\chi^2)=n，$$方差为：$$ D(\chi^2)=2n (n为自由度) $$ 可加性：$$ 若U和V为两个独立的\chi^2分布随机变量，U\sim \chi^2(n_1)， V\sim \chi^2(n_2), $$ $$则U+V这一随机变量服从自由度为n_1+n_2的\chi^2分布$$ 卡方分布的性质可以根据这张图来看。 卡方分布一般用于样本方差的分布的计算。样本方差的分布——在重复选取容量为n的样本时， 由样本方差的所有可能取值形成的相对频数分布。对于来自正态总体的简单随机样本，则比值$$ \frac{(n-1)s^2}{\sigma^2} $$该比值的抽样分布服从$$ 自由度为(n-1)的\chi^2分布，即 \frac{(n-1)s^2}{\sigma^2}\sim \chi^2(n-1) $$ 接着再介绍一个耳熟能详的t分布。t 分布是类似正态分布的一种对称分布， 它通常要比正态分布平坦和分散。t分布的性质和特点如下： 自由度为1的t 分布为柯西分布，期望值不存在。 n&gt;1时，期望值为0。 n&gt;2时，方差存在，为n/(n-2)。 随着自由度的增大，分布也逐渐趋于标准正态分布。（t 分布的极限为标准正态分布，当n&gt;30时， t 分布可用标准正态分布近似） t分布的性质可以根据这张图来看。 t分布的应用是在求样本均值与样本标准差之比上样本均值与样本标准差之比的分布为：$$ t=\frac{\bar x-\mu}{s/\sqrt{n}}\sim t(n-1) $$自由度为(n-1)的t 分布 5.两个总体样本统计量的抽样分布其实从前面第4点内容可以看出，其实实际应用中，均值、比例、方差的估计是比较多的，因此这三个总体样本统计量的抽样分布特别提出来了。而第4点讨论的是一个总体的，两个总体的也可以类比，道理是一样的。两个样本均值之差的抽样分布： 两个总体均为正态分布，即$$ X_1\sim N(\mu_1,\sigma_1^2) ,X_2\sim N(\mu_2,\sigma_2^2)$$ 两个样本均值之差的抽样分布服从正态分布，其分布的数学期望为两个总体均值之差：$$ E(\bar x_1-\bar x_2)=\mu_1-\mu_2 $$ 方差为各自的方差之和：$$ \sigma_{\bar x_1-\bar x_2}^2=\frac{\sigma_1^2}{n_1}+\frac{\sigma_2^2}{n_2} $$ 两个样本比例之差的抽样分布： 两个总体都服从二项分布。 分别从两个总体中抽取容量为$n_1$和$n_2$的独立样本，当两个样本都为大样本时，两个样本比例之差的抽样分布可用正态分布来近似。 分布的数学期望为：$$ E(\bar p_1-\bar p_2)=p_1-p_2 $$ 方差为各自方差之和：$$ \sigma_{\bar p_1-\bar p_2}^2=\frac{p_1(1-p_1)}{n_1}+\frac{p_2(1-p_2)}{n_2} $$ 最后的最后，我们来介绍本片的最后一个重要的分布——F分布。F分布：$$ 设若U为服从自由度为n_1的\chi^2分布，即U\sim \chi^2(n_1), $$ $$ V为服从自由度为n_2的\chi^2分布，即V\sim \chi^2(n_2),且U与V相互独立, $$ $$ F=\frac{U/n_1}{V/n_2},F服从自由度n_1和n_2的F分布, $$ $$记为 F\sim F(n_1,n_2) $$不同自由度下的F分布 两个样本方差比的抽样分布： 两个总体都为正态分布，即$$ X_1\sim N(\mu_1,\sigma_1^2), X_2\sim N (\mu_2,\sigma_2^2） $$ 从两个总体中分别抽取容量为$n_1$和$n_2$的独立样本。 两个样本方差比的抽样分布， 服从分子自由度$(n_1-1)$， 分母自由度为$(n_2-1)$的F分布， 即$$ \frac{s_1^2/\sigma_1^2}{s_2^2/\sigma_2^2}\sim F(n_1-1,n_2-1) $$ 附录常用统计量公式样本均值：$$ \bar X=\frac{1}{n} \sum_{i=1}^n{X_i} $$ 样本方差：$$ S^2=\frac{1}{n-1} \sum_{i=1}^n(X_i-\bar X)^2 $$ 样本标准差：$$ S=\sqrt{\frac{1}{n-1} \sum_{i=1}^n(X_i-\bar X)^2} $$ 样本k阶原点矩： $$ A_k=\frac{1}{n} \sum_{i=1}^nX_i^k (k=1,2,\cdots) $$ 样本k阶中心矩： $$ B_k=\frac{1}{n} \sum_{i=1}^n(X_i-\bar X)^k (k=1,2,\cdots) $$ 各统计量的观察值： $$ \bar x=\frac{1}{n} \sum_{i=1}^n{x_i} $$ $$ s^2=\frac{1}{n-1} \sum_{i=1}^n(x_i-\bar x)^2 $$ $$ a_k=\frac{1}{n}\sum_{i=1}^nx_i^k (k=1,2,\cdots) $$ $$ b_k=\frac{1}{n} \sum_{i=1}^n(x_i-\bar x)^k (k=1,2,\cdots) $$]]></content>
      <categories>
        <category>Statistics &amp; Model</category>
      </categories>
      <tags>
        <tag>R</tag>
        <tag>Theory</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[应用统计学与R语言实现学习笔记（三）——描述性统计]]></title>
    <url>%2F2017%2F05%2F05%2F%E5%BA%94%E7%94%A8%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B8%8ER%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89%E2%80%94%E2%80%94%E6%8F%8F%E8%BF%B0%E6%80%A7%E7%BB%9F%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[Chapter 3 Descriptive Statistics本篇是第三章，内容是描述性统计。同时在这一章会开始渗透R语言的相关内容。但整体还是以理论为主。 1.数据的预处理本章正式进入统计学的一大分支——描述统计。很多人会疑惑做一个Project或者写一篇Paper，最难的是什么？我曾经不止一次说过，最难的是数据。数据收集完成，项目完成了50%。而数据收集完成之后，很多人就会马上开始进行数据处理和分析，事实上这是不对的。因为你不清楚你的数据是否有问题（什么问题都有可能，会导致你的分析出现各种问题）。所以你拿到数据后的第一步，应该是对数据做预处理，或者用大数据时代的话——叫数据清洗或者ETL（Extract-Transform-Load），我想预处理还会占掉Project花费时间的20%吧。那么接下来先介绍下预处理的内容。数据预处理： 数据审核 数据筛选 数据排序 数据透视 数据审核，包括直接数据的完整性审核以及准确性审核（是否客观），间接数据的适用性审核以及时效性审核；数据筛选，就是对于数据里面的异常值（存在错误，不符合调查要求等），在现在来说就是dirty data（脏数据），将这些数据剔除；数据排序，事实上数据排序更多的目的还是为了更方便地发现异常值，是做数据清洗的手段；数据透视，借鉴于Excel里的数据透视表，事实上就是数据的重铸，融合和汇总，从而得到我们需要的数据。总的来说，前期预处理需要对数据进行排序、汇总和观察发现相关的数据异常值等。在这个阶段，不喜编程的同学推荐用Excel来做数据预处理（通过数据透视图、替换数据、排序、Countif等工具和Excel函数高效完成预处理），更高级的一般可以考虑用R、Python等编程语言进行清洗预处理，或者像在数据库里用SQL语句也是可以的。响应一下本部分的标题，R语言实现，交代几个简单的语句进行数据清洗。 12345678#x为数据框、数组或矩阵，通过summary可以获取平均值、中位数、四分位数等，如果有缺失数据，则会显示NAN等。summary(x)#表示y是按照x的第一行先升序排列，然后再按x的第二列降序排列得到的数据，-表示降序。y&lt;-x[order(x[1],-x[2)]#去除NA所在行和列y&lt;-na.omit(x) 2.数据的整理与展示这部分的数据整理是在预处理完毕后，根据我们需要对数据进行整理和简单可视化（多画图，多可视化，你能发现很多事情）。那么第一步就是先把我们的数据类型搞清楚。因为不同类型数据，整理方式不同。对于分类数据和顺序数据主要是分类整理。对于数值数据主要是做分组整理。 分类数据的整理核心就是计算频数、比例、百分比、比率，一般可视化用条形图（柱状图）。此外还可以考虑使用帕累托图。帕累托图（Pareto chart）是以意大利经济学家V.Pareto的名字而命名的。这是一个双坐标轴图，一侧纵坐标是频率，另一侧纵坐标是累计频率。是在条形图基础上加上一条折线图（累计频率曲线）。通常用帕累托图来表示，就是研究事物特征是否存在二八定律（20/80规律，典型案例：20%的人拥有80%的财富）。除此之外，分类型数据还可以用饼图来进行可视化。 顺序数据则一般选用累计频率曲线和环状图进行可视化。 数值型数据的可视化方式是最多的。主要包括了直方图、折线图（频数多边形图）、打点图、茎叶图、箱线图、线图（时间序列数据）、双变量问题（二维散点图与散点图矩阵）、三变量问题（三维散点图或气泡图）、多变量问题（雷达图）。 其中这里面有一个直方图分组使用的经验公式。 $$ K=1+\frac{\lg {n}}{\lg {2}} $$ K为组数，n为样本数。确定组数，通过极差和组数求组距即可分组。这部分有很多可视化内容，暂时就不在这部分讲述了（第14章会重点讲解几个典型的可视化方式的R语言绘制)。最后小结下数据可视化的内容。 品质数据——先制作汇总表，然后可以采用条形图、饼图、环状图可视化； 数值数据中的原始数据——茎叶图、箱线图可视化； 数值数据中的分组数据——直方图、折线图； 数值数据中的时间序列数据——线图； 数值数据中的多元数据——散点图、气泡图、雷达图。 此外对于图表可视化来说，好的图表可视化应当具有如下特征： 显示数据； 让读者把注意力集中在图表的内容上，而不是制作图表的程序上； 强调数据之间的比较； 服务于一个明确的目的； 有对图表的统计描述和文字说明。 鉴别图表优劣的准则： 精心设计、 有助于洞察问题的实质； 使复杂的观点得到简明、 确切、 高效的阐述； 能在最短的时间内以最少的笔墨给读者提供最大量的信息； 表述数据的真实情况， 避免歪曲。 当然图表可视化不仅仅只有R，Excel、SPSS、Tableau都可以使用。 3.数据的概括性度量当你面对一堆数据时，你还是不知道从何下手，因为我们不可能强行记住每个数据，然后在脑海里对各个数据的分布进行比较，所以科学家们在处理数据的时候，都希望用数据规模尽可能小的一个指标去描述数据尽可能多的信息。那么从数据的角度出发，针对数据分布的不同方面，科学家们也都找出了不相同的指标来进行描述。简单来说，数据分布包括了集中趋势、离散程度、分布形状三个方面的内容。 集中趋势：众数、中位数、平均数； 离散程度：异众比率、四分位差、极差、方差或标准差、离散系数； 分布形状：偏态系数、峰态系数。 集中趋势的几个指标想必大家较为清楚，就不展开详述了。而离散程度中极差、方差和标准差也是如此，同上，不过单独解释下自由度的概念（一组数据中可以自由取值的数据的个数，与附加给独立观测值的约束或限制的个数有关，比如三个数据的均值已经知道，知道其中两个数据，第三个数据是固定的，也就是说在添加了均值这个约束之后，观测数据自由取值的个数是n-1=2个）。这里重点解释异众比率，四分位差、离散系数、偏态系数和峰态系数。异众比率——从字面理解即可，非众数的比率。也就是——不是众数的组的频数占总频数的比率。四分位差——上四分位数减去下四分位数。离散系数——也就是标准差系数，即用标准差除以平均值。偏态系数——用来描述数据分布特征（分布偏斜程度）的系数，该系数&gt;0为右偏分布，0为尖峰分布，&lt;0为扁平分布，=0为扁平峰度适中。最后单列出以上部分指标的公式（有数学恐惧症的同学请跳过）： 中位数： $$ x_{((n+1)/2)} （n为奇数）$$ 或 $$ (x_ {(n/2)}+x_{(n/2)+1})/2 （n为偶数）$$ 四分位数：$$ Q_ {L位置}=\frac{n}{4},Q_{U位置}=\frac{3n}{4} $$ $$ Q_ {L位置}=\frac{n+1}{4},Q_{U位置}=\frac{3（n+1）}{4} $$ $$ Q_ {位置}=\frac{[\frac{n+1}{2}]+1}{2} $$ $$ Q_ {L位置}=\frac{n+3}{4},Q_{U位置}=\frac{3n+1}{4} $$ 平均数： $$ \bar{x}=\frac{\sum_ {i=1}^n x_{i}}{n}(简单平均数), \bar{x}=\frac{\sum_{i=1}^k M_{i}f_{i}}{n}(加权平均数)$$ $$ G_{m}=\sqrt[n] {\prod_{i=1}^n {(1+x_{i})}}-1(几何平均数)$$ 异众比率：$$ v_r=1-\frac{f_m}{\sum f_i} $$ 极差： $$ R=max(x_i)-min(x_i) $$ 四分位差： $$ Q_d=Q_U-Q_L $$ 平均差：$$ M_d=\frac{\sum_{i=1}^n \left|{x_i-\bar {x}}\right|}{n} $$ 或 $$ M_d=\frac{\sum_{i=1}^k \left|{M_i-\bar {x}}\right|f_i}{n} $$ 总体方差： $$ \sigma^2=\frac{\sum_{i=1}^N (x_i-\mu)^2}{n} $$ 或 $$ \sigma^2=\frac{\sum_{i=1}^k (M_i-\mu)^2f_i}{n} $$ 总体标准差： $$ \sigma=\sqrt {\frac{\sum_{i=1}^N (x_i-\mu)^2}{n}} $$ 或 $$ \sigma=\sqrt{\frac{\sum_{i=1}^k (M_i-\mu)^2f_i}{n}} $$ 样本方差： $$ s^2=\frac{\sum_{i=1}^N (x_i-\mu)^2}{n-1} $$ 或 $$ s^2=\frac{\sum_{i=1}^k (M_i-\mu)^2f_i}{n-1} $$ 样本标准差：$$ s=\sqrt {\frac{\sum_{i=1}^N (x_i-\mu)^2}{n-1}} $$ 或 $$ s=\sqrt{\frac{\sum_{i=1}^k (M_i-\mu)^2f_i}{n-1}} $$ 标准分数： $$ z_i=\frac{x_i-\bar{x}}{s} $$ 标准差系数： $$ v_s=\frac{s}{\bar{x}} $$ 偏态系数： $$ SK=\frac{n\sum(x_i-\bar{x})^3}{(n-1)(n-2)s^3} $$ 或 $$ SK=\frac{\sum_{i=1}^k(M_i-\bar{x})^3f_i}{ns^3} $$ 峰态系数： $$ K=\frac{n(n+1)\sum{(x_i-\bar{x})^4}-3[\sum{(x_i-\bar{x})^2}]^2(n-1)}{(n-1)(n-2)(n-3)s^4} $$ 或 $$ K=\frac{\sum_{i=1}^k{(M_i-\bar{x})^4f_i}}{ns^4}-3 $$]]></content>
      <categories>
        <category>Statistics &amp; Model</category>
      </categories>
      <tags>
        <tag>R</tag>
        <tag>Theory</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[应用统计学与R语言实现学习笔记（二）——数据收集]]></title>
    <url>%2F2017%2F05%2F04%2F%E5%BA%94%E7%94%A8%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B8%8ER%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E6%94%B6%E9%9B%86%2F</url>
    <content type="text"><![CDATA[Chapter 2 Data Collection本篇是第二章，内容是数据收集。 1.数据来源做科学研究离不开数据，而数据的来源有哪些呢？这里比较简单地将数据来源分为两类：直接（一手）数据和间接（二手）数据。直接数据的数据获取来源包括：观测、调查、实验。间接数据的数据获取来源包括：出版物、互联网等。接下来分别谈谈这几个来源。观测——自然科学里有观测，如气象气候、植物生长期等，社会科学同样有观测，譬如像街区人的观测等。观测的数据可以说是纯粹第一手数据，在研究中是很宝贵的数据，但是很容易受到观测记录员主观因素的影响。调查——自然科学里的调查（室外样品采集，环境状况调查）一般是跟室内实验相结合，而社会科学的调查会更丰富，如典型的问卷调查、访谈、座谈会等。实验——实验是自然科学的核心，这里就不详述了（比如：土壤理化性质分析、植物生态生理特性分析）。不过近年来随着学科交叉增多，社会科学也开始更多地引入实验的方法（以笔者另一门公选课《初级社会网络》为例，耶鲁大学的社会心理学家米尔格兰姆(Stanley Milgram)就设计了一个连锁信件实验，这就是著名的六度分割理论的由来）。当然除了以上三种，我认为在现在的大数据时代，还存在一些新的直接数据来源。 物联网（Interest of Thing,IOT),以各类传感器（RFID、红外感应系统、GPS、通量塔等）为代表，代表数据就是如今火热的大数据——如RFID记录数据、浮动车与出租车GPS轨迹数据、通量塔测量的NEE等。 遥感（Remote Sensing，RS），某种程度上，遥感也是靠传感器接收数据，但是它与物联网还是有所差别，故单列出来。作为地学和生态学背景（尤其是GIS和RS相关方向的）的学生，对遥感会非常熟悉。遥感的特征就是，可以大范围快速获取地表信息数据（譬如地形、地表温度、气溶胶、albedo等，当然这些都需要进行反演等）。 总的来说，观测在自然科学和社会科学中都有渗透较多，但是观测往往受到记录人员主观因素影响导致误差。而且观测的数据结构一般来说呈现非结构化的特征。调查在社会科学中有较多应用，自然科学中较少，而实验则是在自然科学中应用广泛，社会科学则应用较少。这两类的实质是类似的，需要提前设计好调查的大纲或者实验方案，然后按照设计好的大纲和方案进行调查和实验。也因此这两类数据结构化特征比较明显。所谓的间接数据就是指已经经过他人整理的相关数据。这边列出来的主要包括：出版物：统计年鉴、书籍、论文等。统计年鉴是大部分社会科学相关研究的重要数据来源，这边就不详述了。书籍对于很多如社会研究的文本分析是重要的数据来源。论文作为数据，是近年来兴起的文献计量学的典型数据。此外对Meta分析，论文里的数据则是重要来源。互联网：百度指数、阿里指数、大众点评等数据。互联网数据可以利用网络爬虫获取。总的来说，间接数据易于获取，作用广泛，但使用的时候需要控制数据质量以及引用。 2.调查设计这边主要介绍的是数据的调查方式、调查方案的结构和设计以及调查问卷设计。（1）数据的调查方式数据的调查方式一般而言是遵循统计学规律的（我们称之为统计调查方式），这里列举了我国统计调查的常用方式：普查（人口普查、农业普查、甚至到最近刚刚发布成果的全国第一次地理国情普查）、抽样调查（概率抽样、非概率抽样，具体后面第三章会详述）、统计报表（统计公报）。而除了以上之外，当我们需要自己收集直接数据的时候又可以分为以下几种：询问调查类： 访问调查 邮寄调查 电话调查 电脑辅助 座谈会 个别深访 观察实验 观察 实验 （2）调查方案的结构和设计如何做调查？是很多人在科学研究中的第一道难关。这里给出一个关于做调查的普遍步骤流程图： 那么调查方案又是什么呢？我认为调查方案就是调查的策划书。明确你调查的一些目的、对象、项目以及调查方法等。一般结构如下： 调查目的 调查对象调查单位 调查项目 其他 （3）调查问卷设计最后这部分是谈谈调查问卷设计的一些内容（包括笔者自己的一些经验）。问卷结构 开头部分（问候语、填写说明、问卷编号 ） 甄别部分 主体部分 背景部分 其他部分就不详述了，甄别部分一般是针对过滤的问题，就是不符合条件的即可跳过部分调查题目。接下来主要针对主体部分简单介绍。主体部分其实就是问卷主要调查的部分。一般来说要注意一下几点。 提问内容尽可能简短 用词准确通俗（可按6W原则推敲：Who,Where,When,Why,What,How） 一项提问只包括一项内容 避免诱导性提问、否定形式提问、敏感性问题 而问题则又可以分为两大类：开放性问题（自由回答型）和封闭性问题（选择回答型）。封闭性问题包括了二项选择、多项选择（单项、多项、限制选择）、顺序选择法、评定尺度法、双向列联表法。 开放性问题——一般就是可以随便答，这类数据一般是问卷者的主观感受，不会受客观影响。但是最大的问题在于数据收集呈现非结构化特征，多以文本形式存在。研究时必须通过重编码、文本分析等方法。 封闭性问题——相当于是选择题或者填空题。二项选择就是，只有两个选项（A或B）；多项选择则是有多个选项，可以选至少一个（一个为单项、一个以上且不限制选择的数量为多项、一个以上且限制选择的数量为限制）；顺序选择法，就是给出多个选项，让你按照自己的认识对选项进行排序；评定尺度法，给出多个选项且是有等级划分的（如很差，差，一般，好，很好）进行选择；双向列联表法，将两类不同问题综合到一起，用表格形式，横向为一类问题，纵向为一类问题。 从笔者的经验来说，在设置问卷的时候，必须要先从自己想研究的问题出发，思索如何用数据分析证明自己的结论，然后大致思索需要用来分析的统计方法与统计指标，然后对应选择问题的形式，因为不同的问题形式对应的数据结构大不相同，而且统计方法也不尽相同。最后的最后安利大家一个软件：Survey123 for ArcGIS这是由esri北京研发中心开发的一款外业数据收集软件——获得“问卷好帮手”称号的application。 http://www.esri.com/products/survey123 主要包括了桌面端Survey123 connect和移动端Survey123 app两大软件。可以简便地建立问卷、分享问卷、搜集数据、分析数据，同时采集时受访者的GPS位置也将被记录。具体教程参照如下网址。 http://doc.arcgis.com/zh-cn/survey123/ 3.数据质量采集数据的时候必须考虑的就是数据的质量，即降低采集数据时产生误差。科学研究中的数据误差无可避免，而误差的来源主要包括：抽样误差、非抽样误差。抽样误差，在抽样方式确定时就无法避免，具体的方法可能还是统计学万能解药———增加样本量。非抽样误差则包括了如下的内容： 抽样框误差 回答误差 无回答误差 调查员误差 抽样框误差——其实就是抽取的样本无法代表总体；回答误差和无回答误差都是由于受访者导致的错误，而调查员误差则无须再介绍，即采集者自身的误差。那么控制误差的方法无非就在于样本大小以及合适的数据框（针对非抽样误差和抽样框误差），靠重访来进行修正（回答误差和无回答误差），调查员误差则需要对调查员进行培训。当然这里还得普及一个概念，在统计学里面，precision（精度）和accuracy（准确性）是不相同的。中文里面往往因为两个单词都翻译成精度，事实上这两个词指的是不一样的内容。二者的区别可以看下面的图。 这里做个简单的解释，事实上就是我们研究事物是个无法穷尽的总体，因此我们只能进行抽样调查，那么多次抽样调查研究之后，我们可以得到每次抽样调查的均值（也可以是其他统计量），在图中就是蓝色的点，那么在靶中心的绿色部分，可以认为是总体的真正均值。那么也就是说高精度一般指的是，我们的样本数据自身的变异性很小，也就是说，我们做了N次抽样调查，而每次抽样调查的样本均值基本是稳定的。我们抽的N次都是相近的数据，也就是说我们的抽样误差尽可能小了（因为抽了N次数据变化不会太大）。而高准确性一般指的是，我们N次抽样的样本数据的平均值与总体数据差异很小。也就是说我们的N次样本的均值与总体均值很接近，也就是说我们的非抽样误差尽可能小了（因为N次数据平均值与总体均值差异较小，说明我们抽的样本能够反映总体均值的特征）。最后，总结下数据质量的控制要求： 精度(precision)： 最低的抽样误差或随机误差 准确性(accuracy)： 最小的非抽样误差或偏差 关联性： 满足用户决策、 管理和研究的需要 及时性： 在最短的时间里取得并公布数据 一致性： 保持时间序列的可比性 最低成本： 以最经济的方式取得数据st=>start: 确定调查目的（Define the issue） op1=>operation: 确定感兴趣的总体和抽样单元（Define the population interest and sampling unit） op2=>operation: 规范调查问题（Formulate survey questions) op3=>operation: 构建抽样框（Construct sampling frame) op4=>operation: 选择样本（Select sample) op5=>operation: 收集数据（Collect data) e=>end: 分析数据（Analyze data) st->op1->op2->op3->op4->op5->e{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12} var code = document.getElementById("flowchart-0-code").value; var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-0-options").value)); var diagram = flowchart.parse(code); diagram.drawSVG("flowchart-0", options);]]></content>
      <categories>
        <category>Statistics &amp; Model</category>
      </categories>
      <tags>
        <tag>R</tag>
        <tag>Theory</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[应用统计学与R语言实现学习笔记（一）——简介]]></title>
    <url>%2F2017%2F05%2F02%2F%E5%BA%94%E7%94%A8%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B8%8ER%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89%E2%80%94%E2%80%94%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[Chapter 1 Introduction本部分内容是我这学期公选课《应用统计学》的学习笔记，主要参考书目为如下两本：贾俊平，《统计学》（第五版），中国人民大学出版社，2012.何晓群，《多元统计分析》（第三版），中国人民大学出版社，2012.本篇为第一章节，也就是Introduction（简介）部分。 1.从问题说起常常听到的一句话，好的科学论文解决一个科学问题，科学的诞生本身就和问题离不开。老生常谈的就是像牛顿被苹果砸了之后，就想到一个问题，为啥苹果不飞上天和太阳肩并肩呢？我答：因为会被烤焦。。。。嗯，幽默一下。总结下来说，科研中有很多问题跟统计学相关（笔者是地学和生态学背景，就提点接地气的问题）。譬如：（1)人口研究当中，我们希望了解65岁以上老年人所占的比例，以便于我们更好地研究老龄化的问题。（2)从几个监测站点的汽车尾气监测推断今天北京市的汽车尾气排放是否达到大气污染物排放标准。（3）影响植物光合作用的因素是什么，各个因素的影响有多大？以及等等等。总结来说，可以分为以下的几类：（1）统计量问题；（2）参数（推断统计）问题；（3）归因问题；（4）预测问题。 2.统计学及其研究过程那么统计学又是什么呢？ statistics: the science of collecting,analyzing, presenting, and interpreting data.Copyright 1994-2000 Encyclopaedia Britannica, In 翻译过来就是 统计学是收集、分析、表述和解释数据的科学（ 不列颠百科全书） 所以统计学包括了： 数据收集：取得数据 数据处理：整理与图表展示 数据分析：利用统计分析方法分析数据 数据解释：结果的说明 得到结论：从数据分析中得出客观结论。 同时跟统计学密切相关的就是概率论。这二者都是研究随机现象数量规律的学科。而二者的区别可以用一张图来形象体现： 也就是说，概率论是——我知道箱子里面是什么样的，我想知道我拿在手里的球是什么样的可能性分别有多大。统计学则是——我不知道箱子里面是什么样的，但是我已经知道我拿在手里的球是什么样的，我想靠我手里的球的样子去推断箱子是什么样的。有兴趣的也可以查看知乎上的回答。 https://www.zhihu.com/question/20269390 总结起来，统计学的研究过程就像下面的流程图。 当然这里面很容易出问题的是解释数据——数学上有意义，并不代表现实中有意义，非常容易出现很多的悖论。比如太阳升起的时间与每个人起床时间相关性很高，但是我不能说因为每个人都起床了，所以太阳升起了。 3.统计方法及其应用领域从前面提到的我们知道，统计方法是通过已知的观测数据去分析随机现象的数量规律。因此统计方法就包括了两大部分：描述统计与推断统计。其实核心就在于我们所观测的样本是否等于总体。样本=总体，那么使用描述统计就能够用来描述我们所研究的现象。样本≠总体，那么使用推断统计才能较为准确地描述我们所研究的现象。事实上，近年来火热的大数据就是因为技术（传感器等）发展，我们足够获取可以近似等于全样本甚至全样本的数据而不是以往的样本数据所引起的一场变革，也就是说是由数据驱动的变革。 统计学应用领域十分广泛，这里就不细谈了。 4.统计数据类型由于应用广泛，所以统计数据类型也是多样化的。不同的划分标准类型也不相同：（1）按照计量层次划分 分类数据 顺序数据 数值数据 （2）按收集方法划分 调查观察数据 试验数据 （3）按时间状况划分 截面数据 时序数据 5.统计学中的几个基本概念统计学中的基本概念分别是： 总体（population） 样本（sample) 参数（parameter) 统计量（statistic) 变量（variable) 总体——研究对象的全体样本——研究对象的部分个体，观测数据参数——用来描述总体的数学度量统计量——用来描述样本的数学度量变量——描述现象的某种特征 st=>start: 实际问题 op1=>operation: 收集数据（取得数据） op2=>operation: 整理数据（处理数据） op3=>operation: 分析数据（研究数据） op4=>operation: 解释数据（结果说明） st->op1->op2->op3->op4{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12} var code = document.getElementById("flowchart-0-code").value; var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-0-options").value)); var diagram = flowchart.parse(code); diagram.drawSVG("flowchart-0", options);st=>start: 统计方法 e=>end: 结论 sub=>subroutine: 描述统计 cond1=>condition: 样本=总体？ cond2=>condition: 分布已知？ op1=>operation: 推断统计 op2=>operation: 参数估计 op3=>operation: 假设检验 st->cond1(no)->op1->cond2(no)->op2->e cond1(yes)->sub->e cond2(yes)->op3->e{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12} var code = document.getElementById("flowchart-1-code").value; var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-1-options").value)); var diagram = flowchart.parse(code); diagram.drawSVG("flowchart-1", options);st=>start: 总体（参数） op=>operation: 样本（统计量） st(right)->op{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12} var code = document.getElementById("flowchart-2-code").value; var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-2-options").value)); var diagram = flowchart.parse(code); diagram.drawSVG("flowchart-2", options);]]></content>
      <categories>
        <category>Statistics &amp; Model</category>
      </categories>
      <tags>
        <tag>R</tag>
        <tag>Theory</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于Git使用的一些心得]]></title>
    <url>%2F2017%2F05%2F01%2F%E5%85%B3%E4%BA%8EGit%E4%BD%BF%E7%94%A8%E7%9A%84%E4%B8%80%E4%BA%9B%E5%BF%83%E5%BE%97%2F</url>
    <content type="text"><![CDATA[本篇稍微记录下Git使用的一些心得。对Git的使用，应该是从搭建自己的博客开始的。当时看到开源中国推荐的一篇基于码云+hexo搭建自己博客的文章。所以就花了一天时间鼓捣了下博客。顺带整理下目前能看到我写的博客文章的几个地址：自己搭建的博客（Hexo）： https://giserdaishaoqing.github.io/ CSDN博客： http://blog.csdn.net/esa_dsq 简书（相比而言，简书少了一篇关于桌面GIS连接Postgresql的文章）： http://www.jianshu.com/u/8bfccfb12c0d 开源中国： https://my.oschina.net/u/2424163、 以上地址均可看到我的博客文章。回到Git上，关于如何搭建hexo的静态博客。这里就不详述了。网上教程太多。我最早看得是下面的博客，当然后面参考了很多简书和各种平台的。 https://my.oschina.net/z707z/blog/824830 尽管最早是想在OSChina上搭建，不过老是出bug，最后还是选择了github。bug总结起来就是，https连接靠不住，git大法好。用github生成ssh秘钥，然后连接，更为方便。具体的过程下面这篇文章讲得已经很详细了。 http://blog.csdn.net/wfdtxz/article/details/8678982 关键的几个命令就是。 #查看是否有秘钥 cd ~/.ssh ls #没有的话就生成一下，引号里填你github账户的邮箱。 ssh-keygen -t rsa -C &quot;your_email@youremail.com&quot; 后面就去本地文件夹搜索下你的秘钥文件id_rsa.pub。复制内容，并打开github，从settings里面找到如下的选项。 接着点击New Key，然后把秘钥文件里的内容复制过去。启用即可。可以用下面的命令测试下是否成功。 ssh -T git@github.com 这个就是之前搭建博客时提交博客老出错的解决方案。顺带记录下hexo博客的典型命令。 hexo clean hexo generate hexo deploy hexo server -p 5000 同时，最近刚好完成了ArcGIS中OLS回归工具结果可视化的R语言版本代码（见上一篇博客），顺带就托管到github上，就尝试了下如何push。在需要托管的本地文件夹右击Git Bash，接着输入如下的命令。这里就每次都输下自己的账户密码吧。比较安全。 #添加需要更新上传的文件 git add . #commit一下 git commit -a -m &quot;备注信息&quot; #最后push上传 git push]]></content>
      <categories>
        <category>Coding</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[R语言读取空间数据以及ArcGIS中OLS工具回归结果可视化R语言版]]></title>
    <url>%2F2017%2F04%2F24%2FR%E8%AF%AD%E8%A8%80%E8%AF%BB%E5%8F%96%E7%A9%BA%E9%97%B4%E6%95%B0%E6%8D%AE%E4%BB%A5%E5%8F%8AArcGIS%E4%B8%ADOLS%E5%B7%A5%E5%85%B7%E5%9B%9E%E5%BD%92%E7%BB%93%E6%9E%9C%E5%8F%AF%E8%A7%86%E5%8C%96R%E8%AF%AD%E8%A8%80%E7%89%88%2F</url>
    <content type="text"><![CDATA[前面已经介绍过R语言读取excel的方法了，当然读取数据来说，个人还是推荐csv或txt存储（针对小数据量）。大数据量的数据的话建议还是用数据库，此外也可以考虑data.table包读取，这个包也是个神包，后面学习完可能来谈谈。这个都是题外话，今天主要目的还是来介绍R语言读取空间数据的方法。主要是之前有同学问过读取的方法。我就顺带整理下，另外虾神今天刚发了一篇关于ArcGIS的OLS工具回归结果可视化内容，并贴出了Python版可视化的代码（文末贴链接），所以对应写个R语言版。本文介绍的空间数据类型主要包括了三种：矢量数据（以最普遍的的shapefile为例），栅格（raster，这个格式就比较多了，不过大同小异）,地理数据库（geodatabase也就是.gdb文件，Esri的数据库）。 1.矢量数据矢量数据其实主要包括了三类：点，线和面，能读取的方式有很多种。下面列举几种。先从点线面分别读取的方式来看，主要包括readShapePoints（读取点），readShapeLines（读取线要素），readShapePoly（读取面要素）。这几个函数都是maptools包里面的。所以第一步如果没安装的话请先安装。 install.packages(&apos;maptools&apos;) library(maptools) 接着定位到我们所需读取数据的工作路径上，然后就可以开始读取对应的数据了。 fujian&lt;-readShapePoints(&apos;fujian.shp&apos;) nanhailine&lt;-readShapeLines(&quot;linesnation.shp&quot;) province&lt;-readShapePoly(&quot;province.shp&quot;) 如果不需要什么其他操作，读取数据只需要填入文件名字作为传入的参数即可。这几个函数完整的参数大体差不多，主要包括下面几个。fn——文件名，一般能读的是.shp文件，.shx文件和.dbf文件proj4string = CRS(as.character(NA))——坐标系的CRS字符串，关于坐标系的问题，这里不详讲。其实就是一个坐标系对应一个ID，把对应ID读进去，按照对应坐标系读取，这个是遵循规范的。一般前两个参数用得多。后面这些只介绍这三个函数共有的参数，其他参数就请参照帮助文档。verbose = FALSE——默认为False，这个主要是在读取数据后是否返回读入要素的类型和数量。repair=FALSE——这个参数的话，主要是考虑到.shx索引文件太大，默认False会跳过读取数据，TRUE的话，会进行内部修复，读取这类文件。而maptools同样提供了另外一个函数readShapeSpatial，这个就可以读以上的三类要素。 fujian&lt;-readShapeSpatial(&quot;fujian.shp&quot;) 当然除了maptools，还有其他包可以读取，事实上，maptools提供的函数读取只能传输较差分辨率的空间数据，所以更推荐的是用rgdal包的OGR驱动程序来读取。熟悉开源GIS的同学对GDAL会比较熟悉，事实上rgdal就是GDAL的R接口（当然没装还是要先装，方法同上），读取方式如下，参数也是传入文件名即可简单读取，不过这个参数可以读具体文件也可以读文件夹名。对应上面proj4string也有一个参数p4s，其他参数参照文档。 fujian&lt;-readOGR(&quot;fujian.shp&quot;) 此外还有shapefiles包也可以进行读取。读取方式（可以读取shp和shx，shx读取结果为空间索引）如下： fujian&lt;-read.shp(&quot;fujian.shp&quot;) 矢量数据读取主要通过以上几种方式就可以实现。 2.栅格数据栅格数据的话，格式还是多种多样的。这边主要提供几种不同格式的读取方法（.img文件，.tif文件，ASCII码文件和.asc文件）。栅格数据读取主要是基于rgdal包，读取方式如下，img和tif都可以通过readGDAL直接读取。 co2&lt;-readGDAL(&quot;CO22008.img&quot;) co2&lt;-readGDAL(&quot;CO22008.tif&quot;) 这里面的参数我就不详细介绍了，主要解释几个个人认为比较重要的参数。有兴趣的同学可以去查询官方文档。band——波段数，单纯栅格无所谓。做遥感影像数据处理时就会遇到需要几个波段的问题，如果缺省的话，是全部导入。p4s——等同于上面的proj4stringtype——像素深度：8bit，16bit等除了rgdal之外，也可以通过raster包进行读取.img文件和.tif文件，这个更方便些。读取方式如下 co2&lt;-raster(&quot;CO22008.img&quot;) co2&lt;-raster(&quot;CO22008.tif&quot;) 当然栅格数据还有较为普遍的以ASCII码文件存储的方式。这里也提供下如何读取ASCII码文件，这个方法是基于sp包的，所以需要先安装和载入sp包，这个包是R语言空间数据的基础包，指定了空间数据库的方法和对象。 co2&lt;-read.asciigrid(&quot;co22008.txt&quot;) 当然ASCII码文件可能是以.asc文件存储的，只需把后缀名改成.asc即可读取。栅格的读取大概就如上。 3.地理数据库（Geodatabase）数据读取Geodatabase是Esri在ArcInfo8之后引入的一种全新的面向对象的空间数据模型。具体简介可以自己搜索。也就是说Geodatabase是Esri官方提出的一种数据库，没有ArcGIS是无法创建Geodatabase的。读取的话其实也相对麻烦些。目前看到的只有Esri官方给出的一个R包可以读取Geodatabase数据。R语言与ArcGIS的结合在未来将很有潜力。目前Esri已经在github上开源了部分工具，2015年全球用户大会上也秀出了R-ArcGIS的Sample工具。具体开源地址： https://r-arcgis.github.io/ 本次用来读取Geodatabase的包就是R-ArcGIS中的一个关键包——arcgisbinding。这个包目前没有在cran上，建议下载之后离线安装。下载地址： https://github.com/R-ArcGIS/r-bridge/releases/tag/v1.0.0.125。 这个包的官方文档可以从官网下载，也可以从下面的连接下载。 http://download.csdn.net/detail/esa_dsq/9823403 具体安装，同时安装完之后需要先确认ArcGIS的许可（要求应该是ArcGIS10.4以上的版本或者ArcGIS pro1.1以上），具体代码如下： install.packages(&quot;G:/GIS/Esri/ArcGIS Plugin/arcgisbinding_1.0.0.125.zip&quot;, repos = NULL, type = &quot;win.binary&quot;) arc.check_product() 读取的方式稍微复杂些，用到了arc.open，arc.select，arc.data2sp三个函数，arc.open是打开gdb文件里的featureclass（支持的格式还包括layers等），arc.select是将打开的featureclass按照需要的字段和sql读成R语言中熟悉的数据框，arc.data2sp是将数据框转化成空间要素。使用方式如下。 china&lt;-arc.open(&quot;china.gdb/province&quot;) chinapop&lt;-arc.select(china,fields = c(&apos;Pop_Rural&apos;,&apos;Pop_Urban&apos;,&apos;POPU&apos;)) chinapopsp&lt;-arc.data2sp(chinapop) 当然读取完了我们还是要来可视化一下。用的是spplot函数，这里就不展开讲了，只贴出图（当然只是随手画的，色带啥的都没调）。 4.ArcGIS中OLS工具回归结果可视化（R语言版）最后的最后。对应虾神文章的Python版本ArcGIS中OLS工具回归结果可视化，写个R语言版本。 12345678910111213141516171819202122232425#载入包#如果没安装，请先安装，如果已安装，请注释#install.packages(".../arcgisbinding_1.0.0.125.zip", repos = NULL, type = "win.binary")…表示arcgisbinding离线包的路径#install.packages("car")#install.packages("GGally")#install.packages("ggplot2")library(arcgisbinding)library(car)library(GGally)library(ggplot2)#设置工作路径setwd("F:/R/demo/readdata")#检查ArcGIS产品许可arc.check_product()#读取数据并将数据转换为数据框olsdata&lt;-arc.open("china.gdb/olstest")olsdataolsdataframe&lt;-arc.select(olsdata,fields = c("gdp","Index_2000","Pop_Urban","POPU","PRODUCT","Estimated","Residual","StdResid"))#把因变量和自变量单独分离出来并用car包里的spm函数绘图variableframe&lt;-olsdataframe[,c(1:5)]spm(variableframe,diagonal="hist") 感觉似乎不是很好看，换个方式。 12#利用GGally的ggpairs函数画图ggpairs(variableframe,upper = list(continuous="cor"),lower = list(continuous="smooth"),diag = list(continuous="barDiag")) 12345#绘制标准残差的分布，用ggplot2画图a&lt;-ggplot(olsdataframe,aes(x=StdResid))+ geom_histogram(aes(y=..density..),binwidth = 0.5,colour="white",fill="grey")+ geom_line(stat='density',colour="#FF6666")a 1234567891011#绘制标准残差和观测值的散点图opar&lt;-par(no.readonly = T)par(fig=c(0,0.8,0,0.8))plot(olsdataframe$gdp,olsdataframe$StdResid,col="grey",pch=16)par(fig=c(0,0.8,0.7,1),new=T)hist(olsdataframe$gdp,col="grey")par(fig=c(0.75,1,0,0.8),new=T)hist(olsdataframe$StdResid,col="grey") 主要是为了和虾神最后的效果类似，事实上，在读取完数据框之后，纯属散点图矩阵可视化方面的内容。最后贴出虾神的公众号和博客。 微信公众号：虾神daxialu——以推广空间分析和空间数据挖掘为己任，致力于在GIS界传递分析价值。 虾神博客原文地址：《白话空间统计二十三：回归分析番外-ArcGIS中的OLS（三）》 http://blog.csdn.net/allenlu2008/article/details/70456024]]></content>
      <categories>
        <category>Coding</category>
      </categories>
      <tags>
        <tag>ArcGIS</tag>
        <tag>R</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从定性遥感到定量遥感——大数据时代的空间数据科学]]></title>
    <url>%2F2017%2F04%2F22%2F%E4%BB%8E%E5%AE%9A%E6%80%A7%E9%81%A5%E6%84%9F%E5%88%B0%E5%AE%9A%E9%87%8F%E9%81%A5%E6%84%9F%E2%80%94%E2%80%94%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%97%B6%E4%BB%A3%E7%9A%84%E7%A9%BA%E9%97%B4%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%2F</url>
    <content type="text"><![CDATA[笔者最近一周之内连续听了四场关于定量遥感前沿进展的讲座（内容遍布目前定量遥感的诸多热点领域）。这四场讲座分别从定量遥感信息技术整体的前沿进展、气溶胶（民众最关心的PM2.5）定量遥感、植被生态环境定量遥感（高光谱遥感、多光谱遥感）到最后一个雷达遥感（SAR）。可以说十分丰富，信息量也非常大。所以听完之后，有些想法和思考来谈一谈关于从定性遥感到定量遥感的发展以及必然。首先会有很多人会疑惑什么是定量遥感？和普通的遥感有啥区别？那么我想还是先从遥感的起源和定义说起。遥感，也就是Remote Sensing。最早是由这位美国海军的老太太提出的，具体的故事看下图介绍。 从广义来说，遥感就是以非直接接触形式探测物体的一种方法，最广泛的一种方式就是以电磁波来进行探测。物体之间的差异，造成了对不同波长的电磁波反射特性不尽相同，通过这个特点，通过传感器接收物体反射回来的电磁波信息，就是典型的遥感探测，当然我们也可以称之为被动遥感。而通过传感器主动发射电磁波并接收物体反射回来的电磁波，同样是遥感探测，也可以称之为主动遥感（有点像海豚的超声波定位原理）。被动遥感的典型案例包括目前多数光学卫星遥感，主动遥感则是近年来兴起的微波遥感、激光雷达遥感等。当然从广义角度来说，无人机航拍这类也可以算是遥感的一类，但是从狭义来说，我认为它还算不上遥感。而遥感的狭义定义就是定量遥感的基础，遥感的狭义定义应当是指通过接收记录物体反射电磁波特性来探测物体性质的方法。所以狭义的遥感的关键是物体反射的电磁波特性。嗯，敲黑板、划重点。三个字：电磁波！电磁波！电磁波！重要事情说三遍。遥感的价值就在于遥感探测得到的电磁波信息，那么电磁波信息能带给我们什么呢？初中老师（也有可能是高中老师吧）曾经曰过：“太阳光是白光（其实它五颜六色），物体在人的视觉里呈现不同颜色，就是因为它吸收了部分光，反射了部分光，这一部分信息被人的视觉所接收并生成图像。”事实上，卫星遥感同样是这个道理，卫星遥感大部分接受的电磁波信息就是地物反射的太阳光波谱信息，所以，不了解遥感的人总觉得它就是在给地球拍照。 图片来源：ArcGIS Earth 其实准确说来也没错。人类视觉接收到的也是地物反射的太阳光波谱信息，相机和卫星接收到的也是如此，只不过人类视觉接收的信息可能以某种生物信息或者信号方式记录存在，而相机（RGB值）和卫星则均使用数字来记录。所以我们会觉得卫星遥感影像有时候很直观，看着跟眼睛看到的真实事物或者拍出来的照片一样，三者者事实上也是一样的道理（盗用知乎的一句话：传感器接受到外界光子，要么形成电压信号，要么形成电流信号，然后转换成我们所熟悉的pixel，尽管三者有些许差别，总的来说核心的问题并没有太大差异，文末贴链接）。一个很核心的问题在于，人类视觉可以接受的波谱信息有限制，也就是我们说的可见光部分。但是卫星遥感数据接收的范围则远比这广得多——微波（合成孔径雷达）、热红外等。但是无论是可见光部分或者非可见光部分，卫星所接收的都是用来描述电磁波的信息，而电磁波的信息又是反映物体的物理特性的（前面提到过，物体间的差异导致的反射波谱不同）。所以遥感技术应用的核心就是将电磁波信息转化为对人类有用的Knowlegde。那么如何转化呢？熟悉遥感的同学会知道目视解译这个词。也就是说看图识物。就像前面提到的，由于遥感成像原理与人眼成像原理类似，我们可以把它当地球拍的一系列照片，通过看着一系列照片，我们可以做监测（就像警察叔叔看监控找犯人一样），监测地球发生的变化，也可以监测某种地物的变化（从监控视频中找出犯人）。就像下面的图片。 图片来源：Google Earth Engine 然而一切的发明都是从偷懒开始的，一定会开始想方设法降低自己看照片的工作量。这就出现了计算机上面的一大分支——图像识别与图像分类。正如我上文提到的，卫星遥感的原理跟相机成像原理最核心部分是类似的。那么也就是说卫星遥感影像某种程度上也可以看成是特殊的“图片”。嗯，讲了很久。貌似都是遥感的基础概念。接下来！！！敲黑板，再次划重点。什么是定性遥感？什么是定量遥感？定性遥感就是类似于看图识物，通过将遥感影像当做特殊的“图片”，通过诸如计算机的图像识别、分类的方法去进行分析和处理得到我们所需要的Knowledge。比如简单的土地利用分类、面向对象的分割与分类或者监测变化等，仅仅是定性的划分。 GLC30 m土地覆被 而定量遥感，我就套用一下李传荣老师讲座时的定义：向社会和公众提供有用信息的技术。要精准描述构成地物状态特征的物理化学要素，以及导致地物目标变化的物理化学动力驱动机制。事实上，它的核心就是第一个重点，遥感目前的根本在于电磁波。那么电磁波这么一个物理现象，要做的不仅仅是将电磁波谱映射成普通图像去做解译、分类。既然我们通过卫星接收到了很多人类无法肉眼观测到的电磁波信息，那么我们就希望通过建立具有物理意义的方程以及模型，将电磁波信息转化为对人类更有用的Knowledge。这就是定量遥感所要做的事情。而定量遥感的典型分析方法就是耳熟能详的遥感定量反演。为什么叫反演？其实就是我想知道B的具体值，但是我无法直接观测B的具体值，但是我能观测到A的具体值，而A和B相互之间的关系，可以通过物理学意义的模型或者是其他模型进行表达，那么我就同过A的值去反推出B的值，这就是反演。相信大家就会很清楚，在定量遥感里，A就是传感器接受的波谱信息，而B则可以有很多种东西。比如：1.二氧化碳探测——温室气体 来源：GOSAT卫星反演结果。 https://data2.gosat.nies.go.jp/index_en.html 动图链接：https://pan.baidu.com/s/1hsNyTrY 去年我们国家在12月26日刚刚发射了TanSAT卫星，使得中国成为了第三个发射监测温室气体排放卫星的国家（前两个是美国和日本，分别是OCO-2卫星和GOSAT卫星），这件事对于我们的意义是什么呢？过去我们没有自己的碳卫星，发达国家在气候变化和谈上说中国排放多，我们难以反驳。现在我们有了自己的碳卫星，我们就有了谈判的手段。同时TanSAT卫星尽管有些方面不如前两个卫星，但是有些方面性能远超前两个卫星。2.地表温度地表温度反演，探究城市热环境的影响因素与空间格局分布。探究冷热岛效应成因分布。 MODIS的LST产品 3.气溶胶反演气溶胶，可能如PM2.5，PM10这些更耳熟能详。但是要注意的就是气溶胶光学厚度≠PM2.5，它是介质消光系数在大气垂直方向上的积分（简单说它没有分离PM2.5、PM10等气溶胶物质）。所以不做垂直订正和湿度订正就拿来跟PM2.5建立关系的AOD都是耍流氓。 PM2.5分布图，来源：网络 MODIS气溶胶产品 4.生态环境定量遥感植被动态变化与生态环境相关要素如叶面积指数、NDVI、光合有效辐射、NPP、GPP等。 VPM模型求算的GPP 除了以上四个，还有很多对应的定量遥感产品——水体叶绿素浓度产品、雪深产品等等。那么定量遥感的核心就是如何通过卫星接收的数据和具有实际物理意义的模型去反演得到我们所需要的产品。而从模型来说，主要分为几类：经验模型、半经验模型、物理模型。经验模型可以被认为是统计意义上的模型，即无视具体的物理过程，单纯靠统计方法建立的模型。半经验模型一般是结合了部分的物理意义的统计模型。物理模型则是严格按照电磁波谱和辐射传输特性经过推导的到的机理模型。可以说物理模型才是定量遥感真正的核心，因为前面两个模型建立之后通常无法复制。物理模型其实有两大部分，即包括了辐射传输方程推导的模型以及几何光学模型（普及下，这就是布鞋院士李小文院士从事的研究）。然而，定量遥感的研究已经有一段时间，却依旧处在一个不为人知的和无法广泛应用的时代。主要是由于地表的复杂性、定量遥感反演目前出现的病态反演问题、定量遥感产品缺乏验证和质量控制的多重因素影响。复杂性——地表非朗伯体特性、地形起伏等影响；病态反演问题——参数求解过程大部分是求解参数大于方程数；缺乏验证和质量控制——不确定性，缺乏统一标准等。当然可以说现在这些问题开始有逐步的改善——毕竟一句话，问题都解决了，还要搞研究的人干什么。但是可以肯定的是，目前计算机技术的发展、卫星载荷的发展、传感器的发展、多颗卫星共同监测、高光谱遥感、激光雷达、合成孔径雷达的普及的情况下，定量遥感的很多问题将会得到改善。所以是时候从定性遥感走向定量遥感，因为这是必然。随着技术的发展和模型精度提高，遥感应用产品也将更加普及。毕竟现在是大数据时代，我们不断强调的是数据即服务和软件即服务，定量遥感作为地球观测的客观载体，将会迸发出更大的潜力。很多人都会这么说，遥感数据是GIS里面的天生大数据，确实遥感数据满足了大数据的4V或者说5V的特征，但是它又跟计算机意义上的大数据有所不同。计算机上的大数据普遍的格式是什么呢？比较典型包括像文本、图片、视频，而甚至像LBS这样的经纬度数据。简而言之，它是高频数据，时间间隔非常短（诸如5min这样的时间间隔）。而遥感数据却不同，卫星的重访周期基本上很难达到5min，所以它非高频数据，那么从这个角度来说，很多大数据算法是否适用呢？同时它具有非常丰富的物理信息，所以就像老师们说的，我们更应该考虑的是这个不太一般的大数据如何去用，不是简单的拿来主义，用这些所谓的机器学习、深度学习去看图识物，可能更值得考虑的事如何将定量遥感的物理模型与大数据的数据挖掘、机器学习等手段相结合。最后的最后，回到主题——大数据时代的空间数据科学。对于空间数据科学来说，这可能是个最好的时代。因为我们不缺数据，但是可能也是个最坏的时代，因为我们多的是黑箱的算法，更缺少的是内在机制的理论研究。毕竟，科学家还是要有梦去追。 关于卫星遥感影像与相机成像原理差异知乎解答： https://www.zhihu.com/question/29835925 后记——从这四场讲座中，了解到很多前沿，对于定量遥感了解可能会更透彻。也了解到自己很多不足。一些简单的想法。就当是学习之后的呓语。最后的最后，推荐两本定量遥感的书吧（京东和当当有满减活动，不用谢，叫我雷锋）。]]></content>
      <categories>
        <category>RS</category>
      </categories>
      <tags>
        <tag>Consideration of Ecology and Geography</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Google Earth网页初探]]></title>
    <url>%2F2017%2F04%2F19%2FGoogle%20Earth%E7%BD%91%E9%A1%B5%E7%89%88%E5%88%9D%E6%8E%A2%2F</url>
    <content type="text"><![CDATA[最近三维GIS界有个比较爆炸性的消息，嗯，没错，Google Earth Enterprise（谷歌地球企业版）宣告开源，47万行代码的大项目就此开放。（深深感觉谷歌就是要搞事情）。概括下GEE开源可以提供些啥。官方github的Readme文档如是写道： 1.Fusion（融合）——影像、矢量与地形（或者可以说集成）的多源数据融合，导入三维地球（可以漫游飞行）或者集成的二维地图。2.Server（服务器）——可以通过融合用户自定义的多源数据定制一个私人三维地球服务器（基于Apache或者Tornado）。3.Client（客户端）——谷歌地球企业版客户端和谷歌地图Javascript API V3版用来浏览三维地球和二维地图。可以说这个开源项目强大异常，感觉GEE开源对于GIS和Web三维开发者是个很大的福利。GEE开源地址： https://github.com/google/earthenterprise 接着近日，早前预告过会在世界地球日（4 月 22 日）前发布新版 Google Earth的 Google，今天公布了新消息，各位期待已久的网页版 Google Earth终于来了。现在 Google Earth在电脑端不再是只以应用形式存在，Google 为桌面浏览器推出了专门版本，不过目前只支持 Chrome，未来会增加对其它主流浏览器的支持。移动端方面，则是 Android 版先行，而 iOS 版会在未来得到更新（该段文字引自《Google 地球网页版上线，点击探索者按钮开启环球旅程吧》，文末贴链接）。嗯，终于进入了本篇的正题，虽然跑题的篇幅略长（其实我觉得也不算跑题）。首先贴主页面，感觉整个页面很舒服。 接下来介绍下功能。 主菜单其实包括了下面的几个功能，也可以登录你的谷歌账户。 定义地图样式。 而网页版最主要的两个功能（探索者和知识卡片，貌似官方把知识卡片称之为运气不错）。探索者是实现了在世界知名景点的虚拟旅游，包括嵌入了360°全景、VR以及谷歌街景。ps，给我一个谷歌地球，我能在跑步机上走遍世界。 这里尝试了下BBC的纪录片的这个虚拟旅游（在Youtube上，请自备梯子），这里只放了简单的gif图，后面有详细视频的链接。 知识卡片功能显示（随机到达2万个地点，都有知识卡片和简介） Google Earth在2005年推出之后，引起了全球对GIS、空间科学的新一轮思考与认知。是Google Earth真真正正让GIS、VGI（Volunteer Geographical information，志愿者地理信息）和空间科学的理念普及到了千家万户。而这一次Google Earth网页版的推出，又将驱动VR（Vitrual Reality，虚拟现实技术）与三维GIS的进一步发展。对于地理教学方面，Gooogle Earth真正提供了一个0门槛，高质量的集成。可以期待的是，随着GEE开源，接下来GEE的发展将再次焕发生机。 分享的链接： https://earth.google.com/web/@39.9388838,116.3974589,54.08506769a,142593.39805527d,35y,0h,0t,0r/data=CkwaShJECiUweDM1ZjA1Mjk2ZTcxNDJjYjk6MHhiOTYyNTYyMGFmMGZhOThhGXvXoC-980NAIXNjesISGl1AKgnljJfkuqzluIIYAiAB 谷歌地球网页版： https://earth.google.com/web/ 《Google 地球网页版上线，点击探索者按钮开启环球旅程吧》： http://cn.technode.com/post/2017-04-19/google-earth-voyager/ 体验视频链接： http://v.youku.com/v_show/id_XMjcxNzgyODYzMg==.html?spm=a2hzp.8253869.0.0&amp;from=y1.7-2#pactionhttp://v.youku.com/v_show/id_XMjcxNzgyNjIzMg==.html?spm=a2hzp.8253869.0.0&amp;from=y1.7-2#paction]]></content>
      <categories>
        <category>GIS</category>
      </categories>
      <tags>
        <tag>Google Earth</tag>
        <tag>3D-GIS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MODIS数据的简介和下载（三）——MODIS数据下载方式（基于MODIS Web Service）]]></title>
    <url>%2F2017%2F04%2F15%2FMODIS%E6%95%B0%E6%8D%AE%E7%9A%84%E7%AE%80%E4%BB%8B%E5%92%8C%E4%B8%8B%E8%BD%BD%EF%BC%88%E4%B8%89%EF%BC%89%E2%80%94%E2%80%94MODIS%E6%95%B0%E6%8D%AE%E4%B8%8B%E8%BD%BD%E6%96%B9%E5%BC%8F%EF%BC%88%E5%9F%BA%E4%BA%8EMODIS%20Web%20Service%EF%BC%89%2F</url>
    <content type="text"><![CDATA[这是MODIS数据的简介和下载的最后一篇，下载方式的进阶版——基于MODIS Web Service的下载方式。这篇是笔者课程上机实习内容之一，做些简要总结和整理。事实上MODIS产品系列就如前面提到的，由于搭载在Terra星和Aqua星上，所以产品就包括了Terra星、Aqua星以及二者集成的产品。分别以MOD（Terra星）、MYD（Aqua星）、MCD（二者集成）作区分。具体的产品查询网站除了前面文章简单提到的之外，还可以查看官网。 https://lpdaac.usgs.gov/dataset_discovery/modis/modis_products_table/ 当然这一次进阶版的下载方式是基于Web Service的。那么Web Service是什么呢？这边引用了课程ppt的一段话。 Web service是一个平台独立的，低耦合的，自包含的、基于可编程的web的应用程序，可使用开放的XML（标准通用标记语言下的一个子集）标准来描述、发布、发现、协调和配置这些应用程序，用于开发分布式的互操作的应用程序。 Web Service技术， 能使得运行在不同机器上的不同应用无须借助附加的、专门的第三方软件或硬件， 就可相互交换数据或集成。依据Web Service规范实施的应用之间， 无论它们所使用的语言、 平台或内部协议是什么， 都可以相互交换数据。Web Service是自描述、 自包含的可用网络模块， 可以执行具体的业务功能。Web Service也很容易部署， 因为它们基于一些常规的产业标准以及已有的一些技术，诸如标准通用标记语言下的子集XML、HTTP。Web Service减少了应用接口的花费。Web Service为整个企业甚至多个组织之间的业务流程的集成提供了一个通用机制。 简单说，这是个方便你下载的插件。具体的下载地址就在下面了。官方提供了多种语言的客户端，包括Java，Perl，Python，Kepler，Matlab和R。本篇主要介绍Matlab和R的客户端如何下载MODIS数据。 https://modis.ornl.gov/data/modis_webservice.html 先介绍Matlab的客户端，首先在官网下载Matlab的客户端。 客户端压缩包文件： 客户端在Matlab的部署非常简单。只需要拷贝到Matlab的工作目录即可。当然使用的时候要求位于如图的路径中。 接下来就可以愉快地使用了。当然，由于官方的镜像搬迁的问题，需要更新对应的镜像地址。 对应在Matlab客户端的modisClient.m文件中找到替换的镜像地址，保存后即可开始使用。 在Matlab中调用不含任何参数的modisClient，可以看到可供下载的MODIS产品列表。 modisClient() 用产品名称作为参数，则可以看到该产品下所有数据集。 modisClient(&apos;MOD15A2&apos;) modisClient(&apos;MOD15A2&apos;,&apos;Lai_1km&apos;,36.833,116.567) 加上数据集名称（以1 km的叶面积指数数据为例）以及经纬度坐标。结果为对应的数据集（该数据8天为间隔）所在的时间范围。 在前面的基础上加上时间范围即可用客户端下载对应的MODIS数据。数据的下载格式是一个多元结构体。包括了数据、转换因子、对应时间序列和单位等等。这样我们就用Matlab下载到了对应的MODIS数据。 YC_LAI2009=modisClient(&apos;MOD15A2&apos;,&apos;Lai_1km&apos;,36.833,116.567,2009000,2009365) 接下来我们讲的是R语言的客户端及其下载方式。R语言的客户端有两种配置方法，一个是基础设置（基于SSOAP来进行），一个是高级设置（MODISTools包）。笔者个人使用的是高级设置，基础设置没有配置过。只是对官方给出的例子做了下翻译，具体的demo如下： 123456789101112131415161718##确定你安装了SSOAP包，否则先安装SSOAP，用install.packages("SSOAP"）##接着你就可以尝试用命令行的方式来下载裁切你想要的MODIS影像数据了## 载入包library(SSOAP)## 获取SOAP服务ornlMODIS = processWSDL("http://daac.ornl.gov/cgibin/MODIS/GLBVIZ_1_Glb_subset/MODIS_webservice.wsdl")## 定义函数设置ornlMODISFuncs = genSOAPClientInterface(operations=ornlMODIS@operations[[1]], def=ornlMODIS)## 使用获取裁切影像的函数设定result = ornlMODISFuncs@functions$getsubset(40.115,-110.025,"MOD11A2","LST_Day_1km","A2001001","A2001025",1,1)##打印结果print(result) 基础设置R语言demo地址： https://modis.ornl.gov/files/modiswebservice/R_getsubset.r 接下来用MODISTools包来做测试，GetProducts函数类似于Matlab的moidsClient（）： GetProducts() 而对应的查看数据集的函数并不是在GetProdcuts函数中填入参数，而是使用GetBands函数。 GetBands(&quot;MOD15A2&quot;) 对应查看数据时间范围的函数为GetDates。 GetDates(36.833,116.567,&quot;MOD15A2&quot;) 而类似于Matlab客户端下载数据的函数则为GetSubset和MODISSubsets。 YC_LAI2009&lt;-GetSubset(36.833,116.567,&quot;MOD15A2&quot;,&quot;Lai_1km&quot;,&quot;A2009001&quot;,&quot;A2009081&quot;,KmAboveBelow = 0,KmLeftRight = 0) GetSubset函数较为简单。但笔者测试时，发现终止时间仅能到达第81天（LAI数据为8天合成产品）。目前尚不清楚具体原因，故最后使用MODISSubsets获取对应的数据。MODISSubsets必须先建立一个数据框作为经纬度（lat,long为字段名)，时间限制范围（start.date，end.date为字段名）的数据。而函数中比较重要的参数还包括了Size和TimeSeriesLength，Size可以用默认值（经纬度位置所处瓦片数量，c(0,0)表示像元中心值），TimeSeriesLength表示时间序列长度，等于1代表从一年的开头到结尾。运行程序，会发现在工作目录下生成了一个.asc文件（即对应MODIS下载下来的数据）。 yclai2009&lt;-data.frame(lat=36.833,long=116.567,start.date=2009,end.date=2009) MODISSubsets(LoadDat = yclai2009,Products = &quot;MOD15A2&quot;,Bands = &quot;Lai_1km&quot;,Size = c(0,0),StartDate = T,TimeSeriesLength = 1) 最后对获取的LAI数据进行绘图可视化。 123456#Matlab中Puredata=[YC_LAI2009.data(:,:)]plot([0:(length(Puredata)-1)]*8+1,Puredata*YC_LAI2009.scale,'b-')ylabel=(YC_LAI2009.units)xlabel=('day of year')title=('禹城站2009年LAI') 1234#R中a&lt;-read.table("Lat36.83300Lon116.56700Start2009-01-01End2009-12-31___MOD15A2.asc",sep = ",")lai&lt;-data.frame(day=seq(1,365,8),lai=a$V11*0.1)plot(lai,type="l",pch=16,col="blue",xlab="day of year",ylab="LAI",main="禹城站2009年LAI") Matlab绘图结果 R绘图结果 总的来说，Matlab和R的客户端下载各有优缺点，而基于MODIS Web Service的下载方式最大好处就是在于它的Subset功能，而不是需要先下载整景影像再处理。在做单点模型的时候是非常快捷的。当然客户端的其它函数还有很多，包括像质量控制。本文没有对数据进行质量控制。实际研究中这个是必须进行的步骤（也可以基于客户端的函数来进行，譬如R里面的QualityCheck函数，Matlab的modisClientGetQC等）。此外地理所也开发了在线平台，研究人员只需填写所需参数即可下载。 http://159.226.110.142/carboncloud/datetool/toolmethod?url=onlinedo&amp;pId=3]]></content>
      <categories>
        <category>RS</category>
      </categories>
      <tags>
        <tag>MODIS</tag>
        <tag>R</tag>
        <tag>Matlab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MODIS数据的简介和下载（二）——MODIS数据下载方式（FTP）]]></title>
    <url>%2F2017%2F04%2F14%2FMODIS%E6%95%B0%E6%8D%AE%E7%9A%84%E7%AE%80%E4%BB%8B%E5%92%8C%E4%B8%8B%E8%BD%BD%EF%BC%88%E4%BA%8C%EF%BC%89%E2%80%94%E2%80%94MODIS%E6%95%B0%E6%8D%AE%E4%B8%8B%E8%BD%BD%E6%96%B9%E5%BC%8F%EF%BC%88FTP%EF%BC%89%2F</url>
    <content type="text"><![CDATA[前一篇我们已经介绍了MODIS数据的简介、参数以及相关的典型应用。这一篇我们来介绍下MODIS数据的下载方式。当然这边主要是介绍国外网站的下载方式，国内网站的普遍是在地理空间数据云和遥感集市下载。国外网站（NASA官网）下载方式主要介绍两种。本篇主要针对第一种方式，基于完整的一景影像下载的过程（FTP工具）。后面一篇更新的是基于MODIS Web Service的客户端下载的方式（Matlab和R）。FTP下载工具以及完整影像下载的方法笔者最早也是参照网上某篇博客学习的下载方式，老规矩，文末贴链接，这里先感谢这位写博客的同学。同时NASA官网最近刚刚改版了网站，新版网站的下载方式暂时没有看到其他人整理，故稍作些整理。NASA官方遥感影像数据下载网址（里面不止有MODIS，还有ENVISAT，NPP-VIIRS等）： https://ladsweb.modaps.eosdis.nasa.gov/ 选择DATA DISCOVERY的Search&amp;Order： 进入这个页面： 找到你要下载的卫星传感器（这里以Terra星做例子）： 选择我们需要的产品（这里选了1 km、500 m的二级产品，以及经纬度校正的产品，具体产品介绍看上一篇博客的表格以及列出的链接）： 结束后直接点击 “TIME”，根据需要选择数据的时间跨度。 接着点击下一步，“LOCATION”。有不同选择需要影像范围的方法。 Country→按国家的行政边界来选择数据Tiles→按瓦片选择，或者说按照MODIS数据全球逐行逐列划分的格网（也可以说是MODIS观测时的行列号）来选择数据Validation Sites→按全球分布的验证的观测站点或者生态网络观测站点选择（可以结合观测站点数据做研究）Draw Custom Box（Classic）→按照用户自定义画出来的框选选择数据（用过老版网站下载的同学会对这个功能比较熟悉）Enter Coordinates→用经纬度坐标来选择数据（这个也是类似于老版网站的下载功能），其实就是研究区的四至坐标。这里选择了按瓦片选择的方式，点击箭头。下一步，“FILES”。这一步会把符合要求的所有数据列出来，但是由于前面搜索的时间跨度太长，web端无法完全显示，所以我们重新修改下相关的需求数据（仅选择2010年的数据，而且选择下载合成产品）。 接下来是新版网站的一个比较不同的地方，这里的”FILES“，可以直接下载数据。老版网站一般需要Order，提交订单之后才能下载。这样使用比原来更自由些。 现在选择所有数据，提交订单即可。 不过新版网站现在要求要注册账户。所以在下载数据前，记得先申请一个Earthdata的账户（这也就是比较麻烦的点了，目前笔者测试了163和qq邮箱，都没有办法收到激活邮件。目前只有谷歌邮箱能激活，所以必须去注册一个gmail的邮箱）。注意，需要在自己的账户中的“My Application”下面启动“LAADS Web”，最后才能提交订单。 FTP的下载必须等到订单出现availlable，才能下载。官方给出的等待时间是5min到10天左右。一般很快就OK了。FTP下载方式的话，需要用FlashFXP这类软件来下载，有需要这个软件的可以在评论区留邮箱或在我的主页搜索下我的邮箱。 地址根据你的订单来决定。ftp: ladsweb.modaps.eosdis.nasa.govusername:anoymouspassword:你账户申请用的邮箱（gmail邮箱）anoymous意为FTP里的匿名传输。接下来只需要简单地拖拽就可以将上面的数据拷贝到本地文件夹了。 这就是关于MODIS数据下载方式(FTP)的内容。最后附上旧版网站下载方式教程博客网址： http://blog.sina.com.cn/s/blog_8684880b010149ue.html]]></content>
      <categories>
        <category>RS</category>
      </categories>
      <tags>
        <tag>MODIS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MODIS数据的简介和下载（一）——MODIS数据简介]]></title>
    <url>%2F2017%2F04%2F13%2FMODIS%E6%95%B0%E6%8D%AE%E7%9A%84%E7%AE%80%E4%BB%8B%E5%92%8C%E4%B8%8B%E8%BD%BD%EF%BC%88%E4%B8%80%EF%BC%89%E2%80%94%E2%80%94MODIS%E6%95%B0%E6%8D%AE%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[借最近上课实习上机内容，来介绍MODIS数据相关方面内容。本部分主要包括了MODIS数据的简介和下载的问题。本篇是第一部分，MODIS的简介。主要分为三个部分：1.MODIS传感器简介及参数；2.MODIS产品及命名规则；3.MODIS的典型应用。1.MODIS传感器简介及参数首先来纠正件很容易被误解的事，MODIS是传感器而不是卫星，尽管我们平常称呼的时候更习惯叫MODIS数据（以传感器来称呼），Landsat数据（以卫星来称呼）。MODIS传感器的全称为中分辨率成像光谱仪（moderate-resolution imaging spectroradiometer）,主要搭载在Terra和Aqua星上。Terrra的简介如下（摘自百度百科和遥感集市）：EOS（Earth Observation System）卫星是美国地球观测系统计划中一系列卫星的简称。经过长达8年的制造和前期预研究准备工作，第一颗EOS的上午轨道卫星于1999年12月18日发射升空，发射成功的卫星命名为Terra（拉丁语“地球”的意思），主要目的是观测地球表面。它是一个用一系列低轨道卫星对地球进行连续综合观测的计划。它的主要目的是：实现从单系列极轨空间平台上对太阳辐射、大气、海洋和陆地进行综合观测，获取有关海洋、陆地、冰雪圈和太阳动力系统等信息；进行土地利用和土地覆盖研究、气候的季节和年际变化研究、自然灾害监测和分析研究、长期气候变率和变化以及大气臭氧变化研究等；进而实现对大气和地球环境变化的长期观测和研究的总体（战略）目标。EOS卫星轨道高度为距地球705公里，目前的第一颗上午轨道卫星（Terra）过境时间为地方时10:30am左右，一天最多可以获得4条过境轨道资料。Terra卫星于1999年12月18日发射成功，Aqua卫星于2002年5月4日发射成功。Terra为上午星，从北向南于地方时10:30左右通过赤道，Aqua为下午星，从南向北于地方时13：30左右通过赤道。两颗星相互配合每1-2天可重复观测整个地球表面，得到36个波段的观测数据 EOS系列卫星上的最主要的仪器是中分辨率成像光谱仪（MODIS），其最大空间分辨率可达250米。对应的MODIS传感器的简介如下（摘自百度百科和遥感集市）：MODIS是当前世界上新一代“图谱合一”的光学遥感仪器，有36个离散光谱波段，光谱范围宽，从0.4微米（可见光）到14.4微米（热红外）全光谱覆盖。MODIS的多波段数据可以同时提供反映陆地表面状况、云边界、云特性、海洋水色、浮游植物、生物地理、化学、大气中水汽、气溶胶、地表温度、云顶温度、大气温度、臭氧和云顶高度等特征的信息。可用于对地表、生物圈、固态地球、大气和海洋进行长期全球观测。中分辨率成像光谱仪（MODIS）最大空间分辨率可达250米，扫描宽度2330公里。MODIS是CZCS、AVHRR、HIRS和TM等仪器的继续。MODIS是被动式成像分光辐射计。共有490个探测器，分布在36个光谱波段，从0.4微米（可见光）到14.4微米（热红外）全光谱覆盖。 MODIS仪器的地面分辨率为250m、500m和1000m，扫描宽度为2330km。 在对地观测过程中，每秒可同时获得11兆比特的来自大气、海洋和陆地表面信息，日或每两日可获取一次全球观测数据。MODIS参数（摘自百度百科和遥感集市） 空间分辨率——250 m (1-2波段)；500 m (3-7波段)；1000 m (8-36波段) 扫描宽度——2330km 时间分辨率——1天 光谱波段——36个离散光谱波段，光谱范围宽，从0.4微米（可见光）到14.4微米（热红外）全光谱覆盖 。 轨道——705KM，降轨上午10:30过境，升轨下午1:30过境；太阳同步；近极地圆轨道 设计寿命——5年 2.MODIS产品及命名规则按处理级别划分，可以分为以下5种： 0级产品：也称原始数据; 1级产品：指L1A数据，已经被赋予定标参数; 2级产品：经过定标定位后数据，本系统产品是国际标准 的EOS-HDF格式。包含所有波段数据，是应用比较广泛的一类数据。; 3级产品：在1B数据的基础上，对由遥感器成像过程产生的边缘畸变(Bowtie效应)进行校正，产生L3级产品; 4级产品：由参数文件提供的参数，对图像进行几何纠正，辐射校正，使图像的每一点都有精确的地理编码、反射率和辐射率。L4级产品的MODIS图像进行不同时相的匹配时，误差小于1个像元。该级产品是应用级产品不可缺少的基础; 5级及以上产品：根据各种应用模型开发L5级产品。 MODIS命名规则如下（摘自CSDN博客）：MOD04 是产品名称，表示MODIS气溶胶产品。 L2 表示 产品级别，Level2。 A2005224 表示产品时间2005年第224天（以每年1月1日为第一天）。 0205 表示卫星过境时间，换算成北京时间要加8小时。 005表示产品版本，Version005，之前是v004，相比之前版本有很多改进。 2006225195920 表示的是产品处理时间。 3.MODIS的典型应用MODIS数据的简介大部分是从网上找的资源，链接都附在后面了，已经有很多人做了很多详细介绍，本篇就借花献佛，主要做简单地整理与引用，没有过多赘述。笔者自己写的核心内容主要是MODIS的一些典型应用和相关的一些研究进展。由于MODIS数据是免费获取的，并且具有高时间分辨率，在生态学和地理学研究中有很多广泛的应用。从产品就可以发现它可以监测的相关内容。植被动态监测以及植被生理生态的多种产品遥感反演典型的是NDVI合成产品、NPP（净初级生产力）、LAI（叶面积指数）、植被动态变化。这一部分内容主要应用生态环境监测中，尤其是生态学相关研究。因为NDVI和LAI是宏观尺度上可以反映植物生理生态的两个重要参数，目前演化出来的相关应用非常的多。在农学上，引入这两个参数来进行区域的农作物估产。在林学上，估算森林生物量、NPP、GPP以及光合有效辐射等。通过NDVI和LAI来进行物候变化监测。通过遥感数据去驱动生态模型，生态系统对于全球变化的响应的相关研究上，MODIS的这一系列产品都起到了很大的作用。 基于MODIS的LAI产品结合模拟退火算法和DSSAT模型进行玉米估产模型的参数优化（数据同化） 地表温度反演以及相关产品遥感反演运用MODIS的热红外波段，通过劈窗算法（类似AVHRR）可以反演地表温度。包括温度异常和林火产品。在林学上有广泛的应用。 基于劈窗算法的MODIS反演地表温度 光学气溶胶厚度反演这部分是近些年来关注的重点，由于PM2.5或者说雾霾的造成的环境问题日益严重，如何从遥感监测PM2.5是一个研究热点，现在比较普遍的使用MODIS产品来进行光学气溶胶（AOD)反演，然后反演PM2.5。 基于DDV算法的MODIS光学气溶胶厚度反演 其他应用MODIS的应用还有非常多，比如像海表温度反演——事实上这方面的温度反演精度要高于地表温度反演，主要是海水从性质上说属于近似黑体；叶绿素浓度反演；离水辐射；冰雪覆盖监测（以NDSI为例）等。 最后的部分我们用一个简单的知网检索结果、词云可视化以及列出了Web of Science上被引频次最高的10篇文章（MODIS作为keywords，可视化用HistCite）来看看目前MODIS研究的一些进展以及经典文献。 遥感集市MODIS简介： http://bbs.rscloudmart.com/forum.php?mod=viewthread&amp;tid=1761&amp;highlight=MODIS MODIS百度百科： http://baike.baidu.com/link?url=IdbXlrWPCG8JX8fUQRmrRSPWjWx4Q7-r_reaPgNTsL88llgGTFPjk_eXrS-5S_bTJwqBCvHJlNIA3MZiV3mbgK MODIS命名规则的CSDN博客： http://blog.csdn.net/xiaoxiang22/article/details/8363469 http://blog.csdn.net/rumswell/article/details/9003215 MODIS数据处理相关博客——以ENVI为主，ENVI/IDL官方博客： http://blog.sina.com.cn/s/articlelist_1984634525_0_1.html]]></content>
      <categories>
        <category>RS</category>
      </categories>
      <tags>
        <tag>MODIS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在Ubuntu中安装R的几种方式总结]]></title>
    <url>%2F2017%2F04%2F09%2F%E5%9C%A8Ubuntu%E4%B8%AD%E5%AE%89%E8%A3%85R%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E5%BC%8F%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[近来笔者由于研究需要，开始研究Linux系统，并动手安装了VMware和Ubuntu软件。 因缘际会（主要是自己开始入坑Github）发现之前在Windows下安装失败的一个R包bignmf无法安装原因。 这个包只能在Ubuntu上测试运行。所以之前在windows上根本无法编译和安装。所以笔者打算在Ubuntu上安装R并安装这个包进行使用。这里简单解释下bignmf包的用处，它是基于Rcpp和RcppEigen两个包，通过底层C++代码调用实现的一个R包，实现的算法是NMF（Nonnegative Matrix Factorization，非负矩阵分解)，作者是爱荷华州立大学的潘岚峰大神。当然R本身自带也有NMF包，不过语法不是很友好的感觉，此外最近笔者也发现了另外的可以在windows上运行的NMF的R包，NMF的理论和应用方面，包括bignmf的编译安装，后面有时间会更新（先挖坑），这里不做详细介绍。回到本篇的主要目的，如何在Ubuntu中安装R。这里提供三个方法：1.Linux安装软件的普遍方法——命令行；2.新立得软件包；3.从官网下载R语言环境源码，自行编译安装。1.基于命令行的方法首先先进入/etc/apt/sources.list，变换软件源，同时进入管理员权限 cd /etc/apt/ gedit sources.list 在最下面添加一行，deb后面的网址是镜像，根据你的喜好选一个（反正我推荐清华的，速度快，不过之前用厦大的也不错），具体的镜像地址见后面的网址。 deb https://mirrors.tuna.tsinghua.edu.cn/CRAN/bin/linux/ubuntu xenial/ https://cran.r-project.org/mirrors.html 而ubuntu xenial则是根据ubuntu版本确定的。我的是16.04，所以是xenial。具体的看官方说明，文末贴链接。 完了之后先更新下软件源。就可以开始安装R了。如果我们需要自行编译R包并且安装的话，就需要在安装r-base-dev。不过笔者测试过，3.3.3版本的r-base自带了r-base-dev。所以不需要进行额外安装。 apt-get update apt-get install r-base apt-get install r-base-dev 完了之后，官方推荐还可以再加个软件源，是关于R的拓展包的。这里贴出命令的通用格式，可以根据需求替换&lt;&gt;的内容。也可以添加下载的公共秘钥。 apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 51716619E084DAB9 deb https://&lt;my.favorite.ubuntu.mirror&gt;/ trusty-backports main restricted universe 完了之后，在命令行里敲入r，出现下面的页面说明安装成功。 2.基于新立得软件管理包新立得软件管理包是Linux下的神器，可以很方便的管理各类软件和依赖库等（上篇提到的WRF-DA模块编译依赖库有些是用这个安装的，具体过程等介绍WRF安装时补充）。当然一开始我没在我的Ubuntu软件里找到新立得。后面仔细翻了下软件列表。发现了这个软件——Synaptic Package Manager，这个就是新立得软件管理包了。启动它，搜索r-base，如图，右击标记安装，然后应用。 3.基于自行编译的方法自行编译的方法，笔者没有具体尝试。但是看了下官方文档。大致的流程如下：官方推荐是组织一个文件夹进行安装，一级文件夹为R_Home，然后把源码解压到R_Home下面，并在下面建立src, doc等多个二级文件夹。然后回到R_Home文件夹。以管理员身份进入。 ./configure make make check make check-all make check-all是针对全部的编译的（可选），最后在安装即可。 make install 可以改变安装路径 ./configure --prefix=/where/you/want/R/to/go make prefix=/path/to/here install 具体可以见官方文档（链接见文末）在R装好的情况下，为了写代码方便，推荐安装R最好的IDE，Rstudio。这边Rstudio的安装就不展开讲了。下载好deb安装文件，直接加命令行安装即可。 dpkg -i rstudio-1.0.136-amd64.deb 在Linux中用Rstudio简单画个散点图。 R语言linux安装官方文档： https://cran.r-project.org/bin/linux/ubuntu/README R语言镜像地址： https://cran.r-project.org/mirrors.html R语言linux编译安装官方文档： https://cran.r-project.org/doc/manuals/r-release/R-admin.html#Installation]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>R</tag>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[WRF-DA代码编译与安装（二）——WRF-DA模块的编译与安装]]></title>
    <url>%2F2017%2F04%2F04%2FWRF-DA%E4%BB%A3%E7%A0%81%E7%BC%96%E8%AF%91%E4%B8%8E%E5%AE%89%E8%A3%85(%E4%BA%8C%EF%BC%89%E2%80%94%E2%80%94WRF-DA%E6%A8%A1%E5%9D%97%E7%9A%84%E7%BC%96%E8%AF%91%E4%B8%8E%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[上一篇已经将所有WRF-DA模块所需要的依赖库都编译安装成功。接下来的步骤就是WRF-DA模块的编译与安装。 笔者已经事先从WRF官网下载了该模块的源码（版本为最新的3.8.1）。首先在设置个目录专门来存放WRF的主程序。选择在Home下面新建一个mode。命令如下： $ sudo mkdir mode 先进入管理员模式（sudo su命令），然后将WRFDA的压缩包全部复制到刚刚建好的文件夹中。 cp -r WRFDA_V3.8.1.tar.gz /home/mode/ 到刚刚建好的WRF文件夹里，同样进入管理员模式，并解压文件夹，到WRFDA目录中，配置环境变量，并设置编译类型。其中，rttov看是否需要，也可以不考虑安装。如若要安装，环境变量配置的路径为可以找到lib/librttov11.*.a的文件目录。 tar zxf WRFDA_V3.8.1.tar.gz cd WRFDA export NETCDF=/usr/local/NETCDF/ export hdf5=/usr/local/hdf5/ export rttov=/usr/rttov/ ./configure wrfda 然后出现了很多选项。选择 x86_64 Linux, gfortran compiler with gcc (serial)，键入32，回车。32到35分别代表32为serial 表示串行计算； 33为smpar 表示内存共享并行计算(shared memory option)，即使用openMP，大部分多核电脑都支持这项功能； 34为dmpar 表示分布式并行计算(distributed memory option)，即使用MPI 进行并行计算，主要用在计算集群，单个电脑就没必要用了； 35为dm+sm 表示同时使用openMP与MPI两种并行方式. 根据实际需要选择即可，最保险的方法就是选择 serial，不过这样编译出来的程序运行最慢（引自xg1990的博客）。笔者初步测试，选择串行计算的版本，而且根据官方文档和编译结果，其他模式还需要有其他相关的依赖库。选择完编译选项后，会出现提示选择嵌套选项，一般就选 basic 选项即可。当然，这边编译器不同的话，序号也有所不同。同时官方文档已声明3.8.1版本不支持dm和dm+sm版本。 搞定之后，看到一条振奋人心的消息。 接下来，就输入如下命令： ./compile all_wrfvar&gt;&amp;checkwrfda.log 然后等它编译完成就好了。 当然，到这一步我还是有问题，因为我只编译安装了43个exe，完全成功应该有44个exe。并且发现这个缺少的exe是主程序，da_wfrda.exe。查看生成exe的命令。 ls -l var/build/*exe var/obsproc/src/obsproc.exe 接着就回头去看log文件以及官方编译要求。发现大部分是路径错误。于是重新配置安装依赖库，并将WRF所需的其他库一并安装，重新编译。终于成功。 以上就是WRF-DA模块的编译与安装。后面会更新WRF主程序的编译与安装方面的内容（具体时间待定）。最后再次感谢以下博客文档的帮助。 https://wenku.baidu.com/view/58851bc269eae009591bec0a.htmlhttps://nwpsaf.eu/site/software/rttov/rttov-v12/http://www2.mmm.ucar.edu/wrf/users/wrfda/updates-3.8.1.htmlhttps://xg1990.com/blog/archives/190 http://blog.csdn.net/luoying_1993/article/details/53228473 https://wenku.baidu.com/view/57e27fd14a7302768e9939f4.html?re=view http://www2.mmm.ucar.edu/wrf/users/wrfda/Docs/user_guide_V3.8.1/users_guide_chap6.htm#_Installing_WRF-Var]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>WRF</tag>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[WRF-DA代码编译与安装（一）——依赖库的编译与安装]]></title>
    <url>%2F2017%2F04%2F02%2FWRF-DA%E4%BB%A3%E7%A0%81%E7%BC%96%E8%AF%91%E4%B8%8E%E5%AE%89%E8%A3%85(%E4%B8%80%EF%BC%89%E2%80%94%E2%80%94%E4%BE%9D%E8%B5%96%E5%BA%93%E7%9A%84%E7%BC%96%E8%AF%91%E4%B8%8E%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[由于笔者的研究需要用到数据同化技术，所以开始学习WRF相关内容（主要是WRF-DA模块）。这里先解释下WRF是什么东西。 WRF全称Weather Research and Forecasting Model, 是一个天气研究与预报模型.可以用来进行精细尺度的天气模拟与预报。 二战后，由于计算机技术的迅猛发展，气象预报技术也随之突飞猛进。短短的几十年里，世界各地的气象研究机关开发出了各自的相对独立的气象模式。这些模式之间缺少互换性，对科研及业务上的交流极其不便。从上世纪90年代后半开始，美国对这种乱立的模式状况进行反省。最后由美国环境预测中心（NCEP），美国国家大气研究中心（NCAR）等美国的科研机构为中心开始着手开发一种统一的气象模式。终于于2000 年开发出了WRF模式。同时，为使研究成果能够迅速地应用到现实的天气预报当中去，WRF模式分为ARW(the Advanced Research WRF)和NMM(the Nonhydrostatic Mesoscale Model)两种，即研究用和业务用两种形式，分别由NCEP和NCAR管理维持着。具体的可以见官网： http://www2.mmm.ucar.edu/wrf/users/ WRF模拟系统主要包含WPS和WRF两部分模块： WPS模块全称为WRF Pre-processing System，即WRF预处理系统，用来为WRF模型准备输入数据；如果只是做理想实验(idealized modeling)，就不需要用WPS处理真实数据。但是理想实验不在本文介绍范围内，本文介绍的是进行真实数据模拟的操作。 WRF模块就是数值求解的模块，它有两个版本：ARW(Advanced Research WRF) 和 NMM(Nonhydrostatic Mesoscale Model)。大多数研究者主要用的都是ARW版本，本文所有的介绍也都基于ARW版本。 除了WPS与WRF两大核心模块外，WRF系统还有很多附加模块：比如用于数据同化的WRF-DA，用于化学传输的WRF-chem，用于林火模拟的WRF-fire（该段文字引自xg1990的博客，具体地址文末贴出，感谢该位大神的分享）。安装运行WRF模拟系统必须在Linux系统。而笔者又无法放弃windows系统，同时目前工作还处于前期测试阶段，故决定选择用VMware虚拟机搭建一个Linux系统来测试。选用的VMware版本：12.5.2。Linux系统：Ubuntu 16.04具体安装过程不是本文重点。详情可见 https://jingyan.baidu.com/article/c275f6ba07e269e33d756714.html 此外附上Ubuntu官网链接 https://www.ubuntu.com/download/desktop WRF-DA编译与安装主要参照官方提供的ppt和文档（地址文末会贴出）。 首先看下WRF-DA编译与安装的需求。 上面提到了需求如下：1.Linux/Mac系统，基于Unix或Linux的系统2.（3DVAR）三维变分的案例内存占用不大，大的（4DVAR）四维变分内存消耗较大。3.支持C和Fortran的编译器（ifort/icc, gfortran/gcc,pgf90/pgcc）4..需要的一些库，类似于WRF。包括：Zlib，netCDF C/Fortran，MPI（MPICH），BUFR，CRTM，RTTOV，HDF5。系统已经安装完毕，而内存部分目前暂时不考虑。接下来看C和Fortran的编译器。Ubuntu内置了gcc的编译器。可以通过命令来查看。 ~$ gcc -v 结果如下： 接下来安装gfortran，也是通过命令进行安装。 ~$ sudo apt-get install gfortran 通过命令查看是否安装成功。 ~$ gfortran -v 接下来是几个库的下载与安装。zlib： http://www.zlib.net/ netCDF C/Fortran： http://www.unidata.ucar.edu/downloads/netcdf/index.jsp MPI（MPICH）： http://www.mpich.org/downloads/ BUFR：包含在WRF源代码中 CRTM：包含在WRF源代码中 RTTOV： https://nwpsaf.eu/site/software/rttov/ 需注册，最好自备梯子。 HDF5： https://support.hdfgroup.org/HDF5/ 将如上的几个库的安装包通过共享文件夹放入虚拟机中（mnt/hgfs/Share)。 zlib和hdf5和netCDF 4相关。具体安装步骤和教程借鉴了官方文档 http://www.unidata.ucar.edu/software/netcdf/docs/getting_and_building_netcdf.html#build_nc4_dap_from_source 1.zlib的安装：解压到/usr/下 $ cp -r zlib-1.2.11.tar.gz /usr/ $ tar zvf zlib-1.2.11.tar.gz 然后进入解压文件夹，并安装 $ ./configure --prefix=/usr/local/zlib $ make check $ make install 修改环境变量。 gedit ~/.bashrc # for zlib export ZLIB_HOME=/usr/local/zlib export LD_LIBRARY_PATH=$ZLIB_HOME/lib:$LD_LIBRARY_PATH 2.HDF5的安装：解压到/usr/下 $ tar -xvf hdf5-1.8.18.tar 然后进入解压文件夹，并安装 $ ./configure --with-zlib=/usr/local --prefix=/usr/local/hdf5 $ make $ make check $ make install HDF5的安装和检验参照： ./configure --prefix=/usr/local/hdf5 --with-zlib=/usr/local/zlib http://blog.csdn.net/luoying_1993/article/details/53228473 HDF5还需配置一个环境变量，避免下面的netCDF C安装报错。 $ gedit ~/.bashrc #for hd5 export CPPFLAGS=-I$PRO_PATH/usr/local/hdf5/include export LDFLAGS=-L$PRO_PATH/usr/local/hdf5/lib export LD_LIBRARY_PATH=$PRO_PATH/usr/local/hdf5/lib $ source ~/.bashrc 3.netCDF C/Fortran安装先装netCDF C： $ export CPPFLAGS=-I$PRO_PATH/usr/local/hdf5/include $ export LDFLAGS=-L$PRO_PATH/usr/local/hdf5/lib $ export LD_LIBRARY_PATH=$PRO_PATH/usr/local/hdf5/lib $ ./configure --prefix=/usr/local/NETCDF --enable-netcdf-4 $ make $ make check $ make install 接着装netCDF Fortran：先声明环境变量： $ export CPPFLAGS=-I/usr/local/NETCDF/include $ export LDFLAGS=-L/usr/local/NETCDF/lib 然后进行下一步编译。 $ ./configure --prefix=/usr/local/NETCDF FC=gfortran 4.mpich的安装：解压之类的步骤同上，同样放到usr下面。解压到指定路径。 $ tar zxf mpich-3.2.tar.gz $ ./configure -prefix=/usr/local/mpi/ 5.rttov的安装：rttov解压出来东西较多，同样新建个path来存放。 $ tar zxf rttov121.tar.gz $ cd src $ ../build/rttov_compile.sh 打完收工。目前应该就完成了WRF-DA编译安装前所有需要的依赖库的编译及安装。下一篇更新WRF-DA具体的编译与安装。由于对Linux系统不熟悉，加上坑爹的rttov，博客写了两三天。从内心坚持要提醒大家的一点，Linux编译环境一定要注意环境变量！！！ 最后重点鸣谢几位主要参考大神的博客以及相关文档： https://wenku.baidu.com/view/58851bc269eae009591bec0a.htmlhttps://nwpsaf.eu/site/software/rttov/rttov-v12/http://www2.mmm.ucar.edu/wrf/users/wrfda/updates-3.8.1.htmlhttps://xg1990.com/blog/archives/190 http://blog.csdn.net/luoying_1993/article/details/53228473]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>WRF</tag>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一行代码更新R语言]]></title>
    <url>%2F2017%2F03%2F23%2F%E4%B8%80%E8%A1%8C%E4%BB%A3%E7%A0%81%E6%9B%B4%E6%96%B0R%E8%AF%AD%E8%A8%80%2F</url>
    <content type="text"><![CDATA[博客中已经陆续更新了两篇关于R语言的文章（相关系数矩阵可视化和读取Excel），按照上一篇挖的坑，这一期讲的是如何只用一行代码更新R语言。这里还是重新认真介绍下R语言（我真的只是凑个字数） 好了，这里安利大家一本书。卡巴科弗. R语言实战[M]. 人民邮电出版社, 2016. 事实上，我放的截图是2013年第一版，2016年有再版，建议大家可以购买纸质版。在第一版的时候，附录里提到了这么一件事。 可以看到当时的2.13.0的版本R仍然没有什么可以自动更新R的方法。不过时至今日，R的版本已经到了3.3.3，在这三年间，R在编程语言排行榜上不断前行。已经有了长久的进步，当然，也出现了可以自动更新R的方法啦。这里介绍的就是R的一个包：installr。 installr {installr} R Documentation Installing software from RDescriptionGives the user the option to download software from within R. 上面是installr的官方文档介绍。接下来来讲所谓的一行代码更新R语言。这里有两个注意点：1.你的installr必须跟你的R版本对应，因为R语言默认安装的包都是适配最新的R语言版本。2.使用installr更新R语言必须在原生R里面，Rstudio里面无法进行（笔者没有尝试过其他R的IDE，有童鞋若有尝试也可以进行指正）。这里第一步先改下默认R的镜像（相信有很多童鞋应该改过了）。原生R更改设定为：程序包→设定CRAN镜像无论Python或者R，镜像统统选清华！。 1234#安装installrinstall.packages（installr)library(installr)updater()#就是这句。真得劲。一键更新 后面只要一路确定就好了。这个方法的好处在于，你可以不用重新安装你已经有的包。可以完整保留。注意的是这个包还依赖于stringr,stringi,magrittr。最后贴下这个包的官方文档航和新增的函数（super强大，还可以一键安装Python，RStudio等)。 NEW FUNCTIONS: install.python - Downloads and installs python 2 or 3UPDATED FUNCTIONS: install.URL now gives warning if there is suspicion that the user is not connected to the internet. updateR - added cran_mirror option]]></content>
      <categories>
        <category>Coding</category>
      </categories>
      <tags>
        <tag>R</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[R语言读取Excel的神器——openxlsx]]></title>
    <url>%2F2017%2F03%2F22%2FR%E8%AF%AD%E8%A8%80%E8%AF%BB%E5%8F%96Excel%E7%9A%84%E7%A5%9E%E5%99%A8%E2%80%94%E2%80%94openxlsx%2F</url>
    <content type="text"><![CDATA[这篇文章讲得是如何用R语言优雅地读取excel，当然前提是用R语言花式读excel，然后最优雅。作为非程序猿的各位同志们，可能最擅长的数据整理软件或者统计软件就是——嗯，没有错，它就是集万千宠爱于一身的E~~X~~O。 咳咳咳，好了。隆重推出我们的主角——Excel 事实上，Excel是个super强大的软件。基本上用它已经能完成大量的统计分析了。For example各类数理统计 线性规划（LINGO表示欲哭无泪，你丫的抢我饭碗）。 当然，很久很久之前有这门本神书：陈彦光. 基于Excel的地理数据分析[M]. 科学出版社, 2010. 当然，作为新时代的研究生，我们怎么能仅用Excel来完成一切的科研任务呢？用老师的话说，你们用Excel做的图，人家审稿都嫌low。这个时候R就登场了。关于R的简介我就不提了。欢迎各种度娘，扯了这么久的淡。终于要进入正题了。今天讲的是R语言的第一步，读数据——读Excel的数据。以下有三种方法:1.将Excel转存为csv格式文件，读csv文件。 a&lt;-read.csv(&quot;exercise1.csv&quot;,header = T) 2.用RODBC包读取Excel。 ab&lt;-odbcConnectExcel2007(&quot;exercise1.xls&quot;)#连接excel，32位系统使用odbcConnectExcel函数 sqlTables(ab) 根据需求读取对应的sheet1 a&lt;-sqlFetch(ab,&quot;Sheet1$&quot;) odbcClose(ab)#关闭句柄，此句是必须。 3.用openxlsx包读取Excel a&lt;-read.xlsx(&quot;exercise1.xlsx&quot;,sheet=1)#文件名+sheet的序号，简单粗暴 综合来看，openxlsx的方法简单粗暴，而且经多名骨灰级玩家证明，罕有bug出现。乃R语言和Excel读取的绝对神器。不过笔者也发现，openxlsx包仅适用于.xlsx格式文件。前期的xls格式文件可能还需要前两种方法来读取。除了以上三种方法，还有类似的包如xlsx、readxl。此处依旧强推神器openxlsx。首先，.xlsx文件存储行数大大提升，从65536行数据提升到了104万条数据。其次，它十分便捷，函数所需参数较少。当然最后的最后，它可能需要的R的版本比较的新，下一篇的预告：如何通过一行代码升级R。最后贴出全文的代码。 1234567891011121314151617181920#设置工作路径setwd("F:/R/applicationstatics")#第一种方法：读取csva&lt;-read.csv("exercise1.csv",header = T)#第二种方法：RODBC包#安装载入RODBC包，如果已安装，请跳过第一句语句install.packages(RODBC)library(RODBC)ab&lt;-odbcConnectExcel2007("exercise1.xls")#连接excel，32位系统使用odbcConnectExcel函数sqlTables(ab)a&lt;-sqlFetch(ab,"Sheet1$")odbcClose(ab)#关闭句柄，此句是必须。#第三种方法：openxlsxinstall.packages(openxlsx)library(openxlsx)a&lt;-read.xlsx("exercise1.xlsx",sheet=1)#文件名+sheet的序号，简单粗暴 当然文末小福利：《基于Excel的地理数据分析》的电子版。需要的童鞋可以在评论区留邮箱或在我的主页（友情链接里面）搜索下我的邮箱。。]]></content>
      <categories>
        <category>Coding</category>
      </categories>
      <tags>
        <tag>R</tag>
        <tag>Excel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Fortran语言初探及Win7 64位下Fortran开发环境配置]]></title>
    <url>%2F2017%2F01%2F16%2FFortran%E8%AF%AD%E8%A8%80%E5%88%9D%E6%8E%A2%E5%8F%8AWin7%2064%E4%BD%8D%E4%B8%8BFortran%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[笔者作为一只游走在生态、遥感、GIS与计算机的学生狗，最近终于因缘际会各种巧合下开始学习Fortran。 还记得遥感物理课上牛柳两位老师（真是一个折磨萌萌哒台湾腔南方银口音的老师组合）的辐射传输方程、几何光学模型时时出现Fortran的身影。 好了，扯淡完毕，首先先来简介下Fortran语言。Fortran源自于“公式翻译”（英语：FormulaTranslation）的缩写，是一种编程语言。它是世界上最早出现的计算机高级程序设计语言，广泛应用于科学和工程计算领域。FORTRAN语言以其特有的功能在数值、科学和工程计算领域发挥着重要作用。Fortran 90之前的版本是人们所知晓的FORTRAN（全部字母大写），从Fortran 90以及以后的版本都写成Fortran（仅有第一个字母大写）（ps，来自度娘百科）。可以说Fortran是属于计算机编程语言中的老古董了，但是另一个重要特点就是在科学和工程计算领域应用广泛，主要是其编程语言本身在数组计算上的一些优点决定的。从TIOBE 2017年1月的编程语言排行榜来看Fortran排在第28位，仍居前30之列，说明该语言仍旧具有广泛适用人群。 那么Fortran在地理学、生态学与遥感方面的应用典型有哪些呢？事实上，在地理学、生态学与遥感领域，Fortran可以说有大量的学者使用并建立开发了大量的模型。比如遥感方面，大气辐射传输6S模型、MODTRAN辐射传输模型；生态学方面，WOFOST作物生长模型、DSSAT作物生长模型、景观中性模型模拟软件RULE等。同时Fortran对数组处理的优势使得它能在遥感数据的处理方面担当举足轻重的角色（类比语言IDL、Matlab、Python的numpy），这也是笔者学习的初衷。当然，正如前面提到了，Fortran是个典型的老古董语言，应用广泛的相关模型基于的Fortran版本的编译器在Win 7及以上系统中基本无法正常安装，故Win 7 64位系统如何配置Fortran开发环境是Fortran语言学习的第一步。由于传统的Visual Fortran 6.6.0及以下版本在Win 7 64位无法兼容，网上虽有帖子提出了相关解决法方法，但笔者亲自尝试的结果是hello world无法运行，故这边介绍其他方法。这里有两种配置方法是可以的：第一种，安装Visual Studio。作为微软主推的IDE，VS在诸多IDE中确实功能突出，优点颇多，作为商业软件，简单的开发环境配置方法也是一大优势。只需勾选Fortran相关编译器安装，即可配置成功。第二种，安装其他IDE，由于VS的简便性导致将其分为一类，其他IDE只需有Fortran编译器即可。VS在简便性上确实很优秀，但是相对而言，VS是个典型的重量级IDE。相对而言，笔者最近喜欢轻量级IDE，故搜索了其他IDE，以Code::Blocks为例，偏爱它的另一个原因就是因为它是免费开源软件（开源大法好）。1.首先下载带有Fortran编译器的Code::Blocks软件。 http://www.codeblocks.org/ 选择最后一个2.直接安装即可，确认安装所有部分 3.安装完毕后，打开IDE在菜单栏中找到“Setting”→“Compiler” 复制一个编译器，自定义名字接着点“Toolchain executables”将画框部分的文件全部改成gfortran.exe 点击ok即可。4.Hello World 编写在菜单栏找到”File”→”New”→”Project”，建立一个Fortran工程文件。 工程命名 选择自定义的编译器 添加hello world项目的Fortran文件 编写如下的hello world进行测试。 1234program helloworld implicit none write(*,*) 'Hello world'end program 5.生成exe文件无法打开的处理方法某些时候生成的exe文件打开会报错。类似“找不到*.dll”“这个应用程序安装/配置不正确，重新安装…”这样的错误。这样的情况下，只需在系统变量里面PATH加上对应的路径即可。]]></content>
      <categories>
        <category>Coding</category>
      </categories>
      <tags>
        <tag>Fortran</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何做出相关系数矩阵可视化图]]></title>
    <url>%2F2016%2F12%2F11%2F%E5%A6%82%E4%BD%95%E5%81%9A%E5%87%BA%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0%E7%9F%A9%E9%98%B5%E5%8F%AF%E8%A7%86%E5%8C%96%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[如何做出相关系数矩阵可视化图 12345678910install.packages("psych")install.packages("corrplot")#安装包，如果已安装，请略过library(psych)library(corrplot)#载入两个包data(iris)#机器学习常用神奇数据集——鸢尾花数据集head(iris)#查看下数据集前五行irisnew&lt;-iris[,-5]#去除第五列种类变量cormat&lt;-corr.test(irisnew)#相关系数分析及显著性检验#最简单的相关系数矩阵可视化corrplot(cormat$r) corrplot(cormat$r,method=&quot;square&quot;) corrplot(cormat$r,method = &quot;number&quot;) corrplot(cormat$r,method = &quot;shade&quot;) corrplot(cormat$r,method=&quot;ellipse&quot;) corrplot(cormat$r,method = &quot;pie&quot;) corrplot(cormat$r,method=&quot;square&quot;,type=&quot;lower&quot;,title = &quot;Correlation of iris&quot;) #含显著性检验的相关系数矩阵可视化 cormatp&lt;-cormat$p#单独取出p值矩阵 cormatp[upper.tri(cormatp)]=0#设置p值矩阵上三角等于0 corrplot(cormat$r,method=&quot;square&quot;,type=&quot;lower&quot;,title = &quot;Correlation of iris&quot;,tl.cex=1.5,tl.pos = &quot;lt&quot;,number.cex=1,p.mat=cormatp,sig.level=0.05,insig=c(&quot;pch&quot;)) corrplot(cormat$r,method=&quot;square&quot;,type=&quot;full&quot;,title = &quot;Correlation of iris&quot;,tl.cex=1.5,tl.pos = &quot;lt&quot;,number.cex=1,p.mat=cormatp,sig.level=0.05,insig=c(&quot;pch&quot;)) corrplot.mixed(cormat$r,upper = &quot;square&quot;,lower = &quot;number&quot;,diag = &quot;u&quot;,tl.cex=1.5,tl.pos = &quot;lt&quot;,number.cex=1,p.mat=cormatp,sig.level=0.05,insig=c(&quot;pch&quot;))]]></content>
      <categories>
        <category>Coding</category>
      </categories>
      <tags>
        <tag>R</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于ArcGIS Pro的二三维一体化]]></title>
    <url>%2F2016%2F12%2F07%2Farcgispro%2F</url>
    <content type="text"><![CDATA[最近尝试了下ArcGIS Pro的二三维一体化管理功能。感觉相当不错，记录一下使用过程与操作。ArcGIS Pro是一款全新的桌面应用程序，它改变了桌面GIS的工作方式，以满足新一代WebGIS应用模式。ArcGIS Pro采用Ribbon界面风格，给人全新的用户体验。它作为一个高级的应用程序，可以对来自本地、ArcGIS Online、或者Portal for ArcGIS的数据进行可视化、编辑、分析。同时，实现了二三维一体化的数据可视化、管理、分析和发布。此外，ArcGIS Pro原生64位应用，支持多线程处理，极大提高软件性能。关于ArcGIS Pro的安装与使用请参考如下的网址（ps，可以无限试用）。 http://blog.csdn.net/kikitamoon/article/details/44102383 从GIS数据的种类来说，主要是两种：矢量数据和栅格数据。三维数据也可以基于这两种分别完成。介绍下这两类的三维化。（一）栅格的三维化栅格数据的三维化主要是类似于DEM拉伸成三维的山体。首先打开ArcGIS Pro 新建一个二维和三维窗口 右击三维场景属性，如下图，设置要三维化的栅格，此外可以根据需求做拉伸 效果如下 点击二三维联动按钮 二三维联动效果： （二）矢量操作矢量的数据可以通过字段拉伸或者rpk生成。ArcGIS Pro在这方面无缝集成了City Engine的规则建模。因此首先在City Engine中写好CGA，通过City Engine生成规则包rpk。 123@StartRulelot--&gt;extrude(rand(3, 50)) 接着点击工具 生成三维体图层 二三维联动效果如下 ArcGIS Pro的整体界面非常友好，而且功能强大，也是目前esri主推的新软件，不仅是二三维一体化，在今年esri用户大会上，还演示了基于ArcGIS Pro的各类大数据应用。大数据时代，让我们拥抱ArcGIS Pro。]]></content>
      <categories>
        <category>GIS</category>
      </categories>
      <tags>
        <tag>ArcGIS Pro</tag>
        <tag>3D-GIS</tag>
        <tag>CGA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[桌面GIS连接Postgresql总结]]></title>
    <url>%2F2016%2F08%2F14%2F%E6%A1%8C%E9%9D%A2GIS%E8%BF%9E%E6%8E%A5Postgresql%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[对于非开发人员的GISer而言，数据库这东西更多停留在mdb，gdb的层面，相对而言这些数据的使用无论是在处理还是管理上，门槛相对较低。但是目前所处的信息爆炸的大数据时代，仅仅依靠桌面GIS本身的数据存储远远不够，在存储大量数据的时候，仍然需要专门的数据库管理。所以桌面GIS如何在关系型数据库中写入空间数据也是一个重要的过程。 此文是在阅读了网上的部分博客及自己的亲身经验写成。主要介绍桌面GIS中两大代表——Esri的ArcGIS以及开源的QGIS。使用的关系型数据库是Postgresql，它的空间扩展是PostGIS。桌面GIS：Esri ArcGIS 10.2Esri ArcSDE 10.2QGIS 2.8.2关系型数据库及空间扩展:Postgresql 9.5.0_x64PostGIS 2.2以上软件的安装略过了，网上均有教程。 （一）QGIS连接Postgresql个人最喜爱QGIS的一点就是它与PostGIS以及其他各类数据库的无缝衔接，确实可以说是直连数据库。 主要是通过这个数据库的操作 先新建一个连接，输入名称、主机、数据库、调整SSL模式、用户名、密码，最后测试连接。 如果跳出这个页面，就证明你成功啦。 接下来按确定之后，只要在最开始的页面点击“连接”，就已经愉快地连上了。如果你打开Postgresql，会发现全局架构是对应的，所以确认是连接成功的。 这边选择了一个2008年2月3日北京市的一辆出租车轨迹数据来做测试 QGIS中，基于出租车轨迹生成的热图 （二）ArcGIS Desktop 连接PostgresqlArcGIS Desktop 10.2之后提供了Postgresql直连的功能，当然这里的直连，我认为可以叫伪直连，因为它仍然需要ArcSDE的支持，而不像QGIS可以直接连接。当然直连的的方法还是相对简单的，不过我也遇到了一个问题，我的Postgresql是64位。但是ArcGIS Desktop目前只有32位。所以即使安装了ArcSDE，也无法直接连接。需要Postgresql32位里面的一些dll文件。 将这些Postgresql对应版本32位的dll文件复制粘贴到ArcGIS安装目录下面的”/ArcGIS/Desktop 10.2/bin的文件夹里，接着可以打开ArcGIS进行连接了。 选择同一个测试数据导入PostGIS 基于ArcGIS连接Postgresql里面的数据制作的核密度图]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>ArcGIS</tag>
        <tag>PostGIS</tag>
        <tag>QGIS</tag>
      </tags>
  </entry>
</search>