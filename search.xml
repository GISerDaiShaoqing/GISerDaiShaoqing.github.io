<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[应用统计学与R语言实现学习笔记（四）——抽样方法与抽样分布]]></title>
    <url>%2F2017%2F05%2F06%2F%E5%BA%94%E7%94%A8%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B8%8ER%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89%E2%80%94%E2%80%94%E6%8A%BD%E6%A0%B7%E6%96%B9%E6%B3%95%E4%B8%8E%E6%8A%BD%E6%A0%B7%E5%88%86%E5%B8%83%2F</url>
    <content type="text"><![CDATA[Chapter 4 Sampling And Sample Distribution本篇是第四章，内容主要是抽样方法与抽样分布。这一章内容比较多（从抽样方法一直到许多分布函数，尤其是介绍了四个重要分布——正态分布、卡方分布、t分布、F分布，以及部分统计推断的内容）。 1.抽样方法抽样调查的概念前面已经有所涉及到，这里就不详述了。大部分情况下，普查是不太可能的，所以抽样调查是科学研究中应用最为广泛的收集数据的方法。但是正如前面在谈论precision和accuracy问题的时候说的，我们希望数据的质量是Low Bias and Low Variance，抽样调查的样本既能很好地代表总体（非抽样误差小），同时多次抽样的话，也希望抽样的样本大致都接近，降低抽样误差。所以从统计学诞生至今，已经提出了很多的抽样方法。可以说并没有任何一种方法能完全避免这些误差，这些方法需要根据具体情境具体使用。总的来说，抽样方法可以分为两大类：概率抽样与非概率抽样。概率抽样包括了： 简单随机抽样 系统抽样 分层抽样 整群抽样 多阶段抽样 概率抽样是根据一个已知的概率来抽取样本单位（也称为随机抽样），概率抽样要求按照一定的概率随机抽取样本，也就是说每个样本都有一定的机会被抽中，同时每个样本被抽中的概率是可以已知或计算出来的，而当运用概率抽样的样本进行参数估计的时候必须考虑样本被抽中的概率（某种程度来说感觉类似贝叶斯，先验概率和后验概率的问题）。简单随机抽样——从总体N个单位里抽出n个单位作为样本（可以重复抽样，也可以不重复抽样），最常用的抽样方式，参数估计和假设检验主要依据的就是简单随机样本。系统抽样——将总体中的所有单位(抽样单位)按一定顺序排列， 在规定的范围内随机地抽取一个单位作为初始单位， 然后按事先规定好的规则确定其他样本单位（先从数字1到k之间随机抽取一个数字r作为初始单位，以后依次取r+k， r+2k…等单位）。分层抽样——将总体单位按某种特征或某种规则划分为不同的层(Strata)， 然后从不同的层中独立、 随机地抽取样本。整群抽样——将总体中若干个单位合并为组(群)， 抽样时直接抽取群， 然后对中选群中的所有单位全部实施调查。多阶段抽样——先抽取群， 但并不是调查群内的所有单位， 而是再进行一步抽样，从选中的群中抽取出若干个单位进行调查（群是初级抽样单位，第二阶段抽取的是最终抽样单位。将该方法推广， 使抽样的段数增多， 就称为多阶段抽样）非概率抽样包括了： 方便抽样 判断抽样 自愿样本 滚雪球抽样 配额抽样 非概率抽样则不是按照随机的原则选取样本，而是根据研究的具体需求选取调查样本。方便抽样——研究员依据方便的原则选取对应的样本。判断抽样——研究员根据自己的判断选择样本。自愿样本——被调查者自愿参加调查提供信息。举个跟地学相关的例子——志愿地理信息（Volunteer Geographcial Information,VGI），是指利用工具创建、组装和传播个人资源提供的地理数据，像社交媒体中的签到。滚雪球抽样——首先选择一组进行调查，让调查者提供另外一些属于调查总体的调查对象，然后持续下去。配额抽样——先将体中的所有单位按一定的标志（变量） 分为若干类， 然后在每个类中采用方便抽样或判断抽样的方式选取样本单位。总的来说，各种抽样方式各有各有的优缺点，根据研究具体情况进行选择。而实际研究中简单随机抽样的应用更多些，这边提供R语言中做简单随机抽样的代码示例。 #N表示总体的数据，n为抽样单位，replace=FALSE代表不重复抽样，replace=TRUE代表重复抽样。 n&lt;-sample(N,n,replace = FALSE) 2.正态分布正态分布由高斯作为描述误差相对频数分布的模型而提出的： 描述连续型随机变量的最重要的分布 许多现象都可以由正态分布来描述 可用于近似离散型随机变量的分布 经典统计推断的基础 正态分布的意义，多多少少大家都有了解，这里就不再详述了。随机变量服从$$ X\sim N (\mu,\sigma^2) $$则X的概率密度函数为$$ f(x)=\frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{1}{2}(\frac{x-\mu}{\sigma})^2} -\infty&lt;x&lt;\infty $$这就是正态分布的概率密度函数。正态分布具有如下性质： 关于x=μ的钟形对称性质，峰值在x=μ处。 均值和标准差一旦决定，该分布形式也就决定了。 均值决定分布函数位置，标准差决定函数的扁平程度。 X轴两侧无限延伸，f(x)无限逼近x轴,但理论上不可能相交。 正态随机变量在特定区间上的取值概率由正态曲线下的面积给出，而且其曲线下的总面积等于1 下图给出了两个图（一个是用核密度生成的曲线，一个是正态分布概率密度函数）来说明以上的部分性质（具体实现的R语言代码会在笔记写完后给出）。 标准正态分布就是指均值为0，标准差为1的正态分布。通过标准正态分布可以很方便地求算各种概率，所以实际应用中，往往将正态分布数据通过标准化的方式转化为标准正态分布求解具体概率。即令$$ Z=\frac{x-\mu}{\sigma} $$则Z服从标准正态分布。那么如何检验数据的正态性呢？一般有以下几种方法： 对数据画出频数分布的直方图或茎叶图（若数据近似服从正态分布， 则图形的形状与上面给出的正态曲线应该相似）。 求出样本数据的四分位差和标准差， 然后二者计算比值。 若数据近似服从正态分布，则有$$ Q_d/s\approx1/3 $$ 拟合优度检验 一般可以通过画这个图来进行检验（代码同在笔记写完后给出）。 或者计算四分位差和标准差比值。这里给出这个方法的R语言实现(用户自编函数）。 Normaltestindex&lt;-function(x) { q=fivenum(x) Qd=q[4]-q[2] s=sd(x) Normaltestindex=Qd/s cat(&quot;The Qd/s&quot;, Normaltestindex) } 拟合优度检验是后面章节内容，这里不详述。正态分布在各样本相互前提下存在线性可加性。$$ x_i\sim N(\mu_i,\sigma_i)，且x_i相互独立，则\Sigma a_ix_i\sim N(\Sigma a_i\mu_i,\Sigma a_i^2\sigma_i^2)$$同时样本量够大情况下，n个独立随机变量之和服从正态分布。 3.三种不同性质的分布统计量(statistic)——样本来自总体，必然携带有反映总体性质的各种信息。统计的基本任务就是通过对样本的研究来对总体的未知参数或分布类型作出估计，对有关总体的假设作出推断。样本是进行统计推断的依据。但在实际应用时，一般不是直接使用样本本身，而是对样本进行整理和加工, 即针对具体问题构造适当的函数—统计量， 利用这些函数来进行统计推断，揭示总体的统计特性。事实上统计量把分散在样本中的总体信息按需要集中在一个函数上，使该函数能反映总体方面的信息。概念很拗口，总结起来就是，我懒得分析（也没法分析，因为有些总体无法穷尽）总体的分布，我就偷懒地先抽样，并且认为样本能够代表总体特征，再偷懒地计算某些指标，这些指标可以反映样本数据分布特征，这些指标就叫统计量，然后再用统计量去推出（猜）总体的分布特征（第一章提到了，应该叫参数）——果然“懒”才是人类进步的动力。当然这里要区分两个概念——统计量与观察值。$$ 假设X_1,X_2, \cdots ,X_n是来自总体X的样本, x_1,x_2,\cdots ,x_n为其样本值, $$$$则称不含任何总体分布中未知参数的函数g(X_1,X_2,\cdots,X_n)为统计量，相应实数g(x_1,x_2,\cdots,x_n)为观察值 $$如何理解这二者区别呢？其实这里把样本看成了一组随机变量，因为在未抽样前，样本观察值未知，样本就是个随机变量（所以一般来说统计推断的基础是简单随机抽样），但是抽样之后，样本就是一组确定的观察值，这也可以说是样本的二重性。常用的统计量包括了样本均值、样本方差、样本标准差、样本k阶原点矩、样本k阶中心距（具体公式的话，文末附录给出）。从前面提到的统计推断基础是简单随机抽样，也就是要求样本是简单随机样本，那么简单随机样本又是什么呢？首先随机样本的概念：$$ 随机抽取的n个个体的集合(X_1,X_2, \cdots ,X_n),n为样本容量。 $$而简单随机样本则需要在随机样本的前提上满足以下两个条件： 随机性：总体中每个个体都有同等机会被选到样本中,即$$ X_i 与X同分布$$ 独立性：样本中每个个体的选取不影响其他个体的选取，即$$ X_1,X_2, \cdots ,X_n是相互独立的随机变量 $$ 接下来是标题提到的三种不同性质的分布：总体分布、样本分布、抽样分布。 总体分布——总体中各元素的观察值所形成的分布，分布通常是未知的，可以假定它服从某种分布。 样本分布——一个样本中各观察值的分布，也称经验分布，当样本容量 n 逐渐增大时，样本分布逐渐接近总体的分布。 抽样分布——样本统计量的概率分布， 是一种理论分布，又称为诱导分布，在重复选取容量为n 的样本时，由该统计量的所有可能取值形成的相对频数分布，随机变量是样本统计量（样本函数，如样本均值，样本比例，样本方差等），结果来自容量相同的所有可能样本，提供了样本统计量长远而稳定的信息，是进行推断的理论基础，也是抽样推断科学性的重要依据（ 点估计、 置信区间、假设推断等）。 用一个简单的例子来说明三者的区别。假设总体N=4，随机变量X=年龄。总体分布如下，均值为21，方差为2.236。这里提醒用R语言做统计的同学，R语言默认的var和sd都是求样本的标准差（分母是n-1和n的差别），当你的数据是总体时，建议另外计算，或者可以使用我下面的自编函数（给了个标准差的样例，方差的会在笔记写完后给出）。 Populationsd&lt;-function(x){ n=length(x) m=mean(x) Psd=sqrt(sum((x-m)^2)/n) cat(&quot;The Standard deviation of Population : &quot;,Psd) } 建立n=2的抽样分布，样本均值分布如下，均值为21，方差为1.58 可以发现总体分布是均匀分布，而样本均值的抽样分布却呈现了近似正态分布，均值是相同的，但是方差却有差异。根据总体分布以及样本容量可以将抽样分布分为以下三类： 精确抽样分布：当总体分布已知时，如果对任一自然数都能导出统计量分布的显示表达式，这样的抽样分布称为精确抽样分布（对小样本的统计推断特别有用，大多数是在正态总体下得到的， t分布、 F分布等）。 渐近抽样分布：样本量无限大时统计量的极限分布（大样本问题）。 近似抽样分布：注意获得近似分布的条件（用统计量的前二阶矩当作正态分布的前二阶矩获得正态近似，随机模拟法获得统计量的近似分布）。 4.一个总体样本统计量的抽样分布样本均值的抽样分布——在重复选取容量为 n 的样本时，由样本均值的所有可能取值形成的相对频数分布（一种理论概率分布，推断总体均值的理论基础）。 正态总体均值抽样分布——精确分布（均值无偏）。 样本均值的中心极限定理——渐进分布。中心极限定理：$$设从均值为\mu， 方差为\sigma^2的一个任意总体中抽取容量为n的样本，$$ $$ 当n充分大时，样本均值的抽样分布近似服从均值为\mu、 方差为\sigma^2/n的正态分布 $$ 用一张图来说明这个定理（摘自参考书目1：贾俊平，《统计学》（第五版），中国人民大学出版社，2012.）。 当然也在这里诞生了一个统计学闻名于世的规定，样本容量n一般至少要求&gt;30。因此样本均值的抽样分布中，样本均值的数学期望（也就是均值）和方差就有对应的公式了。样本均值的数学期望和方差：数学期望：$$ E(\bar x) =\mu $$方差：$$ \sigma{\bar x}^2=\frac{\sigma^2}{n} （重复抽样）,$$$$ \sigma{\bar x}^2=\frac{\sigma^2}{n}\frac{N-n}{N-1} （样本总体有限，且n\ge 5\%N不重复抽样）$$总结来说，总体分布为正态分布的话，抽样分布也是正态分布，总体分布为非正态分布的话，大样本情况下也是近似正态分布，小样本则为非正态分布。 除了均值之外，实际生活中比例也是一个很重要的参数。比例——总体（或样本）中具有某种属性的单位与全部单位总数之比（如不同性别的人与全部人数之比，合格品(或不合格品) 与全部产品总数之比）总体比例可表示为$$ p=\frac{N_0}{N},1-p=\frac{N_1}{N} $$样本比例可表示为$$ p=\frac{n_0}{n},1-p=\frac{n_1}{n} $$样本比例的抽样分布——在重复选取容量为n的样本时，由样本比例的所有可能取值形成的相对频数分布。 一种理论概率分布。 当样本容量很大时（满足np≥5, n(1-p)≥5)，样本比例的抽样分布可用正态分布近似。 推断总体比例p的理论基础。 类似于均值的抽样分布我们可以得到样本比例的数学期望和方差：数学期望：$$ E(\bar p) =p $$方差：$$ \sigma{\bar x}^2=\frac{p(1-p)}{n} （重复抽样）,$$$$ \sigma{\bar x}^2=\frac{p(1-p)}{n}\frac{N-n}{N-1} （不重复抽样）$$ 接下来介绍一个重要的分布——卡方分布。$$ 若随机变量\xi_1,\xi_2,\cdots,\xi_n是n个相互独立的标准正态变量（独立同分布于标准正态分布），$$ $$ 则这n个随机变量的平方和Y=\Sigma\xi_i^2构成的随机变量的分布称为自由度为n的\chi^2分布（chi-square distribution），$$ $$ 记为\chi^2(n)分布 $$卡方分布的性质和特点如下： 分布的变量值始终为正 分布的形状取决于其自由度n的大小， 通常为不对称的单峰右偏（ 正偏） 分布， 但随着自由度的增大逐渐趋于对称， 当n&gt;30时， 接近正态分布 期望为：$$ E(\chi^2)=n，$$方差为：$$ D(\chi^2)=2n (n为自由度) $$ 可加性：$$ 若U和V为两个独立的\chi^2分布随机变量，U\sim \chi^2(n_1)， V\sim \chi^2(n_2), $$ $$则U+V这一随机变量服从自由度为n_1+n_2的\chi^2分布$$ 卡方分布的性质可以根据这张图来看。 卡方分布一般用于样本方差的分布的计算。样本方差的分布——在重复选取容量为n的样本时， 由样本方差的所有可能取值形成的相对频数分布。对于来自正态总体的简单随机样本，则比值$$ \frac{(n-1)s^2}{\sigma^2} $$该比值的抽样分布服从$$ 自由度为(n-1)的\chi^2分布，即 \frac{(n-1)s^2}{\sigma^2}\sim \chi^2(n-1) $$ 接着再介绍一个耳熟能详的t分布。t 分布是类似正态分布的一种对称分布， 它通常要比正态分布平坦和分散。t分布的性质和特点如下： 自由度为1的t 分布为柯西分布，期望值不存在。 n&gt;1时，期望值为0。 n&gt;2时，方差存在，为n/(n-2)。 随着自由度的增大，分布也逐渐趋于标准正态分布。（t 分布的极限为标准正态分布，当n&gt;30时， t 分布可用标准正态分布近似） t分布的性质可以根据这张图来看。 t分布的应用是在求样本均值与样本标准差之比上样本均值与样本标准差之比的分布为：$$ t=\frac{\bar x-\mu}{s/\sqrt{n}}\sim t(n-1) $$自由度为(n-1)的t 分布 5.两个总体样本统计量的抽样分布其实从前面第4点内容可以看出，其实实际应用中，均值、比例、方差的估计是比较多的，因此这三个总体样本统计量的抽样分布特别提出来了。而第4点讨论的是一个总体的，两个总体的也可以类比，道理是一样的。两个样本均值之差的抽样分布： 两个总体均为正态分布，即$$ X_1\sim N(\mu_1,\sigma_1^2) ,X_2\sim N(\mu_2,\sigma_2^2)$$ 两个样本均值之差的抽样分布服从正态分布，其分布的数学期望为两个总体均值之差：$$ E(\bar x_1-\bar x_2)=\mu_1-\mu_2 $$ 方差为各自的方差之和：$$ \sigma_{\bar x_1-\bar x_2}^2=\frac{\sigma_1^2}{n_1}+\frac{\sigma_2^2}{n_2} $$ 两个样本比例之差的抽样分布： 两个总体都服从二项分布。 分别从两个总体中抽取容量为$n_1$和$n_2$的独立样本，当两个样本都为大样本时，两个样本比例之差的抽样分布可用正态分布来近似。 分布的数学期望为：$$ E(\bar p_1-\bar p_2)=p_1-p_2 $$ 方差为各自方差之和：$$ \sigma_{\bar p_1-\bar p_2}^2=\frac{p_1(1-p_1)}{n_1}+\frac{p_2(1-p_2)}{n_2} $$ 最后的最后，我们来介绍本片的最后一个重要的分布——F分布。F分布：$$ 设若U为服从自由度为n_1的\chi^2分布，即U\sim \chi^2(n_1), $$ $$ V为服从自由度为n_2的\chi^2分布，即V\sim \chi^2(n_2),且U与V相互独立, $$ $$ F=\frac{U/n_1}{V/n_2},F服从自由度n_1和n_2的F分布, $$ $$记为 F\sim F(n_1,n_2) $$不同自由度下的F分布 两个样本方差比的抽样分布： 两个总体都为正态分布，即$$ X_1\sim N(\mu_1,\sigma_1^2), X_2\sim N (\mu_2,\sigma_2^2） $$ 从两个总体中分别抽取容量为$n_1$和$n_2$的独立样本。 两个样本方差比的抽样分布， 服从分子自由度$(n_1-1)$， 分母自由度为$(n_2-1)$的F分布， 即$$ \frac{s_1^2/\sigma_1^2}{s_2^2/\sigma_2^2}\sim F(n_1-1,n_2-1) $$ 附录常用统计量公式样本均值：$$ \bar X=\frac{1}{n} \sum_{i=1}^n{Xi} $$样本方差：$$ S^2=\frac{1}{n-1} \sum{i=1}^n(Xi-\bar X)^2 $$样本标准差：$$ S=\sqrt{\frac{1}{n-1} \sum{i=1}^n(X_i-\bar X)^2} $$样本k阶原点矩：$$ Ak=\frac{1}{n} \sum{i=1}^nX_i^k(k=1,2,\cdots)$$样本k阶中心矩：$$ Bk=\frac{1}{n} \sum{i=1}^n(Xi-\bar X)^k(k=1,2,\cdots)$$各统计量的观察值：$$ \bar x=\frac{1}{n} \sum{i=1}^n{xi} $$$$ s^2=\frac{1}{n-1} \sum{i=1}^n(x_i-\bar x)^2 $$$$ ak=\frac{1}{n} \sum{i=1}^nx_i^k(k=1,2,\cdots)$$$$ bk=\frac{1}{n} \sum{i=1}^n(x_i-\bar x)^k(k=1,2,\cdots)$$]]></content>
      <categories>
        <category>统计与模型</category>
      </categories>
      <tags>
        <tag>R语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[应用统计学与R语言实现学习笔记（三）——描述性统计]]></title>
    <url>%2F2017%2F05%2F05%2F%E5%BA%94%E7%94%A8%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B8%8ER%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89%E2%80%94%E2%80%94%E6%8F%8F%E8%BF%B0%E6%80%A7%E7%BB%9F%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[Chapter 3 Descriptive Statistics本篇是第三章，内容是描述性统计。同时在这一章会开始渗透R语言的相关内容。但整体还是以理论为主。 1.数据的预处理本章正式进入统计学的一大分支——描述统计。很多人会疑惑做一个Project或者写一篇Paper，最难的是什么？我曾经不止一次说过，最难的是数据。数据收集完成，项目完成了50%。而数据收集完成之后，很多人就会马上开始进行数据处理和分析，事实上这是不对的。因为你不清楚你的数据是否有问题（什么问题都有可能，会导致你的分析出现各种问题）。所以你拿到数据后的第一步，应该是对数据做预处理，或者用大数据时代的话——叫数据清洗或者ETL（Extract-Transform-Load），我想预处理还会占掉Project花费时间的20%吧。那么接下来先介绍下预处理的内容。数据预处理： 数据审核 数据筛选 数据排序 数据透视 数据审核，包括直接数据的完整性审核以及准确性审核（是否客观），间接数据的适用性审核以及时效性审核；数据筛选，就是对于数据里面的异常值（存在错误，不符合调查要求等），在现在来说就是dirty data（脏数据），将这些数据剔除；数据排序，事实上数据排序更多的目的还是为了更方便地发现异常值，是做数据清洗的手段；数据透视，借鉴于Excel里的数据透视表，事实上就是数据的重铸，融合和汇总，从而得到我们需要的数据。总的来说，前期预处理需要对数据进行排序、汇总和观察发现相关的数据异常值等。在这个阶段，不喜编程的同学推荐用Excel来做数据预处理（通过数据透视图、替换数据、排序、Countif等工具和Excel函数高效完成预处理），更高级的一般可以考虑用R、Python等编程语言进行清洗预处理，或者像在数据库里用SQL语句也是可以的。响应一下本部分的标题，R语言实现，交代几个简单的语句进行数据清洗。 #x为数据框、数组或矩阵，通过summary可以获取平均值、中位数、四分位数等，如果有缺失数据，则会显示NAN等。 summary(x) #表示y是按照x的第一行先升序排列，然后再按x的第二列降序排列得到的数据，-表示降序。 y&lt;-x[order(x[1],-x[2)] #去除NA所在行和列 y&lt;-na.omit(x) 2.数据的整理与展示这部分的数据整理是在预处理完毕后，根据我们需要对数据进行整理和简单可视化（多画图，多可视化，你能发现很多事情）。那么第一步就是先把我们的数据类型搞清楚。因为不同类型数据，整理方式不同。对于分类数据和顺序数据主要是分类整理。对于数值数据主要是做分组整理。 分类数据的整理核心就是计算频数、比例、百分比、比率，一般可视化用条形图（柱状图）。此外还可以考虑使用帕累托图。帕累托图（Pareto chart）是以意大利经济学家V.Pareto的名字而命名的。这是一个双坐标轴图，一侧纵坐标是频率，另一侧纵坐标是累计频率。是在条形图基础上加上一条折线图（累计频率曲线）。通常用帕累托图来表示，就是研究事物特征是否存在二八定律（20/80规律，典型案例：20%的人拥有80%的财富）。除此之外，分类型数据还可以用饼图来进行可视化。 顺序数据则一般选用累计频率曲线和环状图进行可视化。 数值型数据的可视化方式是最多的。主要包括了直方图、折线图（频数多边形图）、打点图、茎叶图、箱线图、线图（时间序列数据）、双变量问题（二维散点图与散点图矩阵）、三变量问题（三维散点图或气泡图）、多变量问题（雷达图）。 其中这里面有一个直方图分组使用的经验公式。 $$ K=1+\frac{\lg {n}}{\lg {2}} $$ K为组数，n为样本数。确定组数，通过极差和组数求组距即可分组。这部分有很多可视化内容，暂时就不在这部分讲述了（第14章会重点讲解几个典型的可视化方式的R语言绘制)。最后小结下数据可视化的内容。 品质数据——先制作汇总表，然后可以采用条形图、饼图、环状图可视化； 数值数据中的原始数据——茎叶图、箱线图可视化； 数值数据中的分组数据——直方图、折线图； 数值数据中的时间序列数据——线图； 数值数据中的多元数据——散点图、气泡图、雷达图。 此外对于图表可视化来说，好的图表可视化应当具有如下特征： 显示数据； 让读者把注意力集中在图表的内容上，而不是制作图表的程序上； 强调数据之间的比较； 服务于一个明确的目的； 有对图表的统计描述和文字说明。 鉴别图表优劣的准则： 精心设计、 有助于洞察问题的实质； 使复杂的观点得到简明、 确切、 高效的阐述； 能在最短的时间内以最少的笔墨给读者提供最大量的信息； 表述数据的真实情况， 避免歪曲。 当然图表可视化不仅仅只有R，Excel、SPSS、Tableau都可以使用。 3.数据的概括性度量当你面对一堆数据时，你还是不知道从何下手，因为我们不可能强行记住每个数据，然后在脑海里对各个数据的分布进行比较，所以科学家们在处理数据的时候，都希望用数据规模尽可能小的一个指标去描述数据尽可能多的信息。那么从数据的角度出发，针对数据分布的不同方面，科学家们也都找出了不相同的指标来进行描述。简单来说，数据分布包括了集中趋势、离散程度、分布形状三个方面的内容。 集中趋势：众数、中位数、平均数； 离散程度：异众比率、四分位差、极差、方差或标准差、离散系数； 分布形状：偏态系数、峰态系数。 集中趋势的几个指标想必大家较为清楚，就不展开详述了。而离散程度中极差、方差和标准差也是如此，同上，不过单独解释下自由度的概念（一组数据中可以自由取值的数据的个数，与附加给独立观测值的约束或限制的个数有关，比如三个数据的均值已经知道，知道其中两个数据，第三个数据是固定的，也就是说在添加了均值这个约束之后，观测数据自由取值的个数是n-1=2个）。这里重点解释异众比率，四分位差、离散系数、偏态系数和峰态系数。异众比率——从字面理解即可，非众数的比率。也就是——不是众数的组的频数占总频数的比率。四分位差——上四分位数减去下四分位数。离散系数——也就是标准差系数，即用标准差除以平均值。偏态系数——用来描述数据分布特征（分布偏斜程度）的系数，该系数&gt;0为右偏分布，0为尖峰分布，&lt;0为扁平分布，=0为扁平峰度适中。最后单列出以上部分指标的公式（有数学恐惧症的同学请跳过）： 中位数：$$ x{((n+1)/2)} （n为奇数）$$或$$ (x{(n/2)}+x{(n/2)+1})/2 （n为偶数）$$四分位数：$$ Q{L位置}=\frac{n}{4},Q{U位置}=\frac{3n}{4} $$$$ Q{L位置}=\frac{n+1}{4},Q{U位置}=\frac{3（n+1）}{4} $$$$ Q{位置}=\frac{[\frac{n+1}{2}]+1}{2} $$$$ Q{L位置}=\frac{n+3}{4},Q{U位置}=\frac{3n+1}{4} $$平均数： $$ \bar{x}=\frac{\sum{i=1}^n x{i}}{n}(简单平均数), \bar{x}=\frac{\sum{i=1}^k M{i}f{i}}{n}(加权平均数)$$$$ G{m}=\sqrt[n] {\prod{i=1}^n {(1+x{i})}}-1(几何平均数)$$异众比率：$$ v_r=1-\frac{f_m}{\sum f_i} $$极差： $$ R=max(x_i)-min(x_i) $$四分位差： $$ Q_d=Q_U-Q_L $$平均差： $$ Md=\frac{\sum{i=1}^n \left|{x_i-\bar {x}}\right|}{n} $$或 $$ Md=\frac{\sum{i=1}^k \left|{M_i-\bar {x}}\right|fi}{n} $$总体方差： $$ \sigma^2=\frac{\sum{i=1}^N (xi-\mu)^2}{n} $$ 或 $$ \sigma^2=\frac{\sum{i=1}^k (M_i-\mu)^2fi}{n} $$总体标准差： $$ \sigma=\sqrt {\frac{\sum{i=1}^N (xi-\mu)^2}{n}} $$ 或 $$ \sigma=\sqrt{\frac{\sum{i=1}^k (M_i-\mu)^2fi}{n}} $$样本方差： $$ s^2=\frac{\sum{i=1}^N (xi-\mu)^2}{n-1} $$ 或 $$ s^2=\frac{\sum{i=1}^k (M_i-\mu)^2fi}{n-1} $$样本标准差： $$ s=\sqrt {\frac{\sum{i=1}^N (xi-\mu)^2}{n-1}} $$ 或 $$ s=\sqrt{\frac{\sum{i=1}^k (M_i-\mu)^2f_i}{n-1}} $$标准分数： $$ z_i=\frac{x_i-\bar{x}}{s} $$标准差系数： $$ v_s=\frac{s}{\bar{x}} $$偏态系数： $$ SK=\frac{n\sum(xi-\bar{x})^3}{(n-1)(n-2)s^3} $$或$$ SK=\frac{\sum{i=1}^k(M_i-\bar{x})^3f_i}{ns^3} $$峰态系数： $$ K=\frac{n(n+1)\sum{(x_i-\bar{x})^4}-3[\sum{(xi-\bar{x})^2}]^2(n-1)}{(n-1)(n-2)(n-3)s^4} $$或$$ K=\frac{\sum{i=1}^k{(M_i-\bar{x})^4f_i}}{ns^4}-3 $$]]></content>
      <categories>
        <category>统计与模型</category>
      </categories>
      <tags>
        <tag>R语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[应用统计学与R语言实现学习笔记（二）——数据收集]]></title>
    <url>%2F2017%2F05%2F04%2F%E5%BA%94%E7%94%A8%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B8%8ER%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E6%94%B6%E9%9B%86%2F</url>
    <content type="text"><![CDATA[Chapter 2 Data Collection本篇是第二章，内容是数据收集。 1.数据来源做科学研究离不开数据，而数据的来源有哪些呢？这里比较简单地将数据来源分为两类：直接（一手）数据和间接（二手）数据。直接数据的数据获取来源包括：观测、调查、实验。间接数据的数据获取来源包括：出版物、互联网等。接下来分别谈谈这几个来源。观测——自然科学里有观测，如气象气候、植物生长期等，社会科学同样有观测，譬如像街区人的观测等。观测的数据可以说是纯粹第一手数据，在研究中是很宝贵的数据，但是很容易受到观测记录员主观因素的影响。调查——自然科学里的调查（室外样品采集，环境状况调查）一般是跟室内实验相结合，而社会科学的调查会更丰富，如典型的问卷调查、访谈、座谈会等。实验——实验是自然科学的核心，这里就不详述了（比如：土壤理化性质分析、植物生态生理特性分析）。不过近年来随着学科交叉增多，社会科学也开始更多地引入实验的方法（以笔者另一门公选课《初级社会网络》为例，耶鲁大学的社会心理学家米尔格兰姆(Stanley Milgram)就设计了一个连锁信件实验，这就是著名的六度分割理论的由来）。当然除了以上三种，我认为在现在的大数据时代，还存在一些新的直接数据来源。 物联网（Interest of Thing,IOT),以各类传感器（RFID、红外感应系统、GPS、通量塔等）为代表，代表数据就是如今火热的大数据——如RFID记录数据、浮动车与出租车GPS轨迹数据、通量塔测量的NEE等。 遥感（Remote Sensing，RS），某种程度上，遥感也是靠传感器接收数据，但是它与物联网还是有所差别，故单列出来。作为地学和生态学背景（尤其是GIS和RS相关方向的）的学生，对遥感会非常熟悉。遥感的特征就是，可以大范围快速获取地表信息数据（譬如地形、地表温度、气溶胶、albedo等，当然这些都需要进行反演等）。 总的来说，观测在自然科学和社会科学中都有渗透较多，但是观测往往受到记录人员主观因素影响导致误差。而且观测的数据结构一般来说呈现非结构化的特征。调查在社会科学中有较多应用，自然科学中较少，而实验则是在自然科学中应用广泛，社会科学则应用较少。这两类的实质是类似的，需要提前设计好调查的大纲或者实验方案，然后按照设计好的大纲和方案进行调查和实验。也因此这两类数据结构化特征比较明显。所谓的间接数据就是指已经经过他人整理的相关数据。这边列出来的主要包括：出版物：统计年鉴、书籍、论文等。统计年鉴是大部分社会科学相关研究的重要数据来源，这边就不详述了。书籍对于很多如社会研究的文本分析是重要的数据来源。论文作为数据，是近年来兴起的文献计量学的典型数据。此外对Meta分析，论文里的数据则是重要来源。互联网：百度指数、阿里指数、大众点评等数据。互联网数据可以利用网络爬虫获取。总的来说，间接数据易于获取，作用广泛，但使用的时候需要控制数据质量以及引用。 2.调查设计这边主要介绍的是数据的调查方式、调查方案的结构和设计以及调查问卷设计。（1）数据的调查方式数据的调查方式一般而言是遵循统计学规律的（我们称之为统计调查方式），这里列举了我国统计调查的常用方式：普查（人口普查、农业普查、甚至到最近刚刚发布成果的全国第一次地理国情普查）、抽样调查（概率抽样、非概率抽样，具体后面第三章会详述）、统计报表（统计公报）。而除了以上之外，当我们需要自己收集直接数据的时候又可以分为以下几种：询问调查类： 访问调查 邮寄调查 电话调查 电脑辅助 座谈会 个别深访 观察实验 观察 实验 （2）调查方案的结构和设计如何做调查？是很多人在科学研究中的第一道难关。这里给出一个关于做调查的普遍步骤流程图： 那么调查方案又是什么呢？我认为调查方案就是调查的策划书。明确你调查的一些目的、对象、项目以及调查方法等。一般结构如下： 调查目的 调查对象调查单位 调查项目 其他 （3）调查问卷设计最后这部分是谈谈调查问卷设计的一些内容（包括笔者自己的一些经验）。问卷结构 开头部分（问候语、填写说明、问卷编号 ） 甄别部分 主体部分 背景部分 其他部分就不详述了，甄别部分一般是针对过滤的问题，就是不符合条件的即可跳过部分调查题目。接下来主要针对主体部分简单介绍。主体部分其实就是问卷主要调查的部分。一般来说要注意一下几点。 提问内容尽可能简短 用词准确通俗（可按6W原则推敲：Who,Where,When,Why,What,How） 一项提问只包括一项内容 避免诱导性提问、否定形式提问、敏感性问题 而问题则又可以分为两大类：开放性问题（自由回答型）和封闭性问题（选择回答型）。封闭性问题包括了二项选择、多项选择（单项、多项、限制选择）、顺序选择法、评定尺度法、双向列联表法。 开放性问题——一般就是可以随便答，这类数据一般是问卷者的主观感受，不会受客观影响。但是最大的问题在于数据收集呈现非结构化特征，多以文本形式存在。研究时必须通过重编码、文本分析等方法。 封闭性问题——相当于是选择题或者填空题。二项选择就是，只有两个选项（A或B）；多项选择则是有多个选项，可以选至少一个（一个为单项、一个以上且不限制选择的数量为多项、一个以上且限制选择的数量为限制）；顺序选择法，就是给出多个选项，让你按照自己的认识对选项进行排序；评定尺度法，给出多个选项且是有等级划分的（如很差，差，一般，好，很好）进行选择；双向列联表法，将两类不同问题综合到一起，用表格形式，横向为一类问题，纵向为一类问题。 从笔者的经验来说，在设置问卷的时候，必须要先从自己想研究的问题出发，思索如何用数据分析证明自己的结论，然后大致思索需要用来分析的统计方法与统计指标，然后对应选择问题的形式，因为不同的问题形式对应的数据结构大不相同，而且统计方法也不尽相同。最后的最后安利大家一个软件：Survey123 for ArcGIS这是由esri北京研发中心开发的一款外业数据收集软件——获得“问卷好帮手”称号的application。 http://www.esri.com/products/survey123 主要包括了桌面端Survey123 connect和移动端Survey123 app两大软件。可以简便地建立问卷、分享问卷、搜集数据、分析数据，同时采集时受访者的GPS位置也将被记录。具体教程参照如下网址。 http://doc.arcgis.com/zh-cn/survey123/ 3.数据质量采集数据的时候必须考虑的就是数据的质量，即降低采集数据时产生误差。科学研究中的数据误差无可避免，而误差的来源主要包括：抽样误差、非抽样误差。抽样误差，在抽样方式确定时就无法避免，具体的方法可能还是统计学万能解药———增加样本量。非抽样误差则包括了如下的内容： 抽样框误差 回答误差 无回答误差 调查员误差 抽样框误差——其实就是抽取的样本无法代表总体；回答误差和无回答误差都是由于受访者导致的错误，而调查员误差则无须再介绍，即采集者自身的误差。那么控制误差的方法无非就在于样本大小以及合适的数据框（针对非抽样误差和抽样框误差），靠重访来进行修正（回答误差和无回答误差），调查员误差则需要对调查员进行培训。当然这里还得普及一个概念，在统计学里面，precision（精度）和accuracy（准确性）是不相同的。中文里面往往因为两个单词都翻译成精度，事实上这两个词指的是不一样的内容。二者的区别可以看下面的图。 这里做个简单的解释，事实上就是我们研究事物是个无法穷尽的总体，因此我们只能进行抽样调查，那么多次抽样调查研究之后，我们可以得到每次抽样调查的均值（也可以是其他统计量），在图中就是蓝色的点，那么在靶中心的绿色部分，可以认为是总体的真正均值。那么也就是说高精度一般指的是，我们的样本数据自身的变异性很小，也就是说，我们做了N次抽样调查，而每次抽样调查的样本均值基本是稳定的。我们抽的N次都是相近的数据，也就是说我们的抽样误差尽可能小了（因为抽了N次数据变化不会太大）。而高准确性一般指的是，我们N次抽样的样本数据的平均值与总体数据差异很小。也就是说我们的N次样本的均值与总体均值很接近，也就是说我们的非抽样误差尽可能小了（因为N次数据平均值与总体均值差异较小，说明我们抽的样本能够反映总体均值的特征）。最后，总结下数据质量的控制要求： 精度(precision)： 最低的抽样误差或随机误差 准确性(accuracy)： 最小的非抽样误差或偏差 关联性： 满足用户决策、 管理和研究的需要 及时性： 在最短的时间里取得并公布数据 一致性： 保持时间序列的可比性 最低成本： 以最经济的方式取得数据]]></content>
      <categories>
        <category>统计与模型</category>
      </categories>
      <tags>
        <tag>理论方法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[应用统计学与R语言实现学习笔记（一）——简介]]></title>
    <url>%2F2017%2F05%2F02%2F%E5%BA%94%E7%94%A8%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B8%8ER%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89%E2%80%94%E2%80%94%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[Chapter 1 Introduction本部分内容是我这学期公选课《应用统计学》的学习笔记，主要参考书目为如下两本：贾俊平，《统计学》（第五版），中国人民大学出版社，2012.何晓群，《多元统计分析》（第三版），中国人民大学出版社，2012.本篇为第一章节，也就是Introduction（简介）部分。 1.从问题说起常常听到的一句话，好的科学论文解决一个科学问题，科学的诞生本身就和问题离不开。老生常谈的就是像牛顿被苹果砸了之后，就想到一个问题，为啥苹果不飞上天和太阳肩并肩呢？我答：因为会被烤焦。。。。嗯，幽默一下。总结下来说，科研中有很多问题跟统计学相关（笔者是地学和生态学背景，就提点接地气的问题）。譬如：（1)人口研究当中，我们希望了解65岁以上老年人所占的比例，以便于我们更好地研究老龄化的问题。（2)从几个监测站点的汽车尾气监测推断今天北京市的汽车尾气排放是否达到大气污染物排放标准。（3）影响植物光合作用的因素是什么，各个因素的影响有多大？以及等等等。总结来说，可以分为以下的几类：（1）统计量问题；（2）参数（推断统计）问题；（3）归因问题；（4）预测问题。 2.统计学及其研究过程那么统计学又是什么呢？ statistics: the science of collecting,analyzing, presenting, and interpreting data.Copyright 1994-2000 Encyclopaedia Britannica, In 翻译过来就是 统计学是收集、分析、表述和解释数据的科学（ 不列颠百科全书） 所以统计学包括了： 数据收集：取得数据 数据处理：整理与图表展示 数据分析：利用统计分析方法分析数据 数据解释：结果的说明 得到结论：从数据分析中得出客观结论。 同时跟统计学密切相关的就是概率论。这二者都是研究随机现象数量规律的学科。而二者的区别可以用一张图来形象体现： 也就是说，概率论是——我知道箱子里面是什么样的，我想知道我拿在手里的球是什么样的可能性分别有多大。统计学则是——我不知道箱子里面是什么样的，但是我已经知道我拿在手里的球是什么样的，我想靠我手里的球的样子去推断箱子是什么样的。有兴趣的也可以查看知乎上的回答。 https://www.zhihu.com/question/20269390 总结起来，统计学的研究过程就像下面的流程图。 当然这里面很容易出问题的是解释数据——数学上有意义，并不代表现实中有意义，非常容易出现很多的悖论。比如太阳升起的时间与每个人起床时间相关性很高，但是我不能说因为每个人都起床了，所以太阳升起了。 3.统计方法及其应用领域从前面提到的我们知道，统计方法是通过已知的观测数据去分析随机现象的数量规律。因此统计方法就包括了两大部分：描述统计与推断统计。其实核心就在于我们所观测的样本是否等于总体。样本=总体，那么使用描述统计就能够用来描述我们所研究的现象。样本≠总体，那么使用推断统计才能较为准确地描述我们所研究的现象。事实上，近年来火热的大数据就是因为技术（传感器等）发展，我们足够获取可以近似等于全样本甚至全样本的数据而不是以往的样本数据所引起的一场变革，也就是说是由数据驱动的变革。 统计学应用领域十分广泛，这里就不细谈了。 4.统计数据类型由于应用广泛，所以统计数据类型也是多样化的。不同的划分标准类型也不相同：（1）按照计量层次划分 分类数据 顺序数据 数值数据 （2）按收集方法划分 调查观察数据 试验数据 （3）按时间状况划分 截面数据 时序数据 5.统计学中的几个基本概念统计学中的基本概念分别是： 总体（population） 样本（sample) 参数（parameter) 统计量（statistic) 变量（variable) 总体——研究对象的全体样本——研究对象的部分个体，观测数据参数——用来描述总体的数学度量统计量——用来描述样本的数学度量变量——描述现象的某种特征]]></content>
      <categories>
        <category>统计与模型</category>
      </categories>
      <tags>
        <tag>理论方法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于Git使用的一些心得]]></title>
    <url>%2F2017%2F05%2F01%2F%E5%85%B3%E4%BA%8EGit%E4%BD%BF%E7%94%A8%E7%9A%84%E4%B8%80%E4%BA%9B%E5%BF%83%E5%BE%97%2F</url>
    <content type="text"><![CDATA[本篇稍微记录下Git使用的一些心得。对Git的使用，应该是从搭建自己的博客开始的。当时看到开源中国推荐的一篇基于码云+hexo搭建自己博客的文章。所以就花了一天时间鼓捣了下博客。顺带整理下目前能看到我写的博客文章的几个地址：自己搭建的博客（Hexo）： https://giserdaishaoqing.github.io/ CSDN博客： http://blog.csdn.net/esa_dsq 简书（相比而言，简书少了一篇关于桌面GIS连接Postgresql的文章）： http://www.jianshu.com/u/8bfccfb12c0d 开源中国： https://my.oschina.net/u/2424163、 以上地址均可看到我的博客文章。回到Git上，关于如何搭建hexo的静态博客。这里就不详述了。网上教程太多。我最早看得是下面的博客，当然后面参考了很多简书和各种平台的。 https://my.oschina.net/z707z/blog/824830 尽管最早是想在OSChina上搭建，不过老是出bug，最后还是选择了github。bug总结起来就是，https连接靠不住，git大法好。用github生成ssh秘钥，然后连接，更为方便。具体的过程下面这篇文章讲得已经很详细了。 http://blog.csdn.net/wfdtxz/article/details/8678982 关键的几个命令就是。 #查看是否有秘钥 cd ~/.ssh ls #没有的话就生成一下，引号里填你github账户的邮箱。 ssh-keygen -t rsa -C &quot;your_email@youremail.com&quot; 后面就去本地文件夹搜索下你的秘钥文件id_rsa.pub。复制内容，并打开github，从settings里面找到如下的选项。 接着点击New Key，然后把秘钥文件里的内容复制过去。启用即可。可以用下面的命令测试下是否成功。 ssh -T git@github.com 这个就是之前搭建博客时提交博客老出错的解决方案。顺带记录下hexo博客的典型命令。 hexo clean hexo generate hexo deploy hexo server -p 5000 同时，最近刚好完成了ArcGIS中OLS回归工具结果可视化的R语言版本代码（见上一篇博客），顺带就托管到github上，就尝试了下如何push。在需要托管的本地文件夹右击Git Bash，接着输入如下的命令。这里就每次都输下自己的账户密码吧。比较安全。 #添加需要更新上传的文件 git add . #commit一下 git commit -a -m &quot;备注信息&quot; #最后push上传 git push]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[R语言读取空间数据以及ArcGIS中OLS工具回归结果可视化R语言版]]></title>
    <url>%2F2017%2F04%2F24%2FR%E8%AF%AD%E8%A8%80%E8%AF%BB%E5%8F%96%E7%A9%BA%E9%97%B4%E6%95%B0%E6%8D%AE%E4%BB%A5%E5%8F%8AArcGIS%E4%B8%ADOLS%E5%B7%A5%E5%85%B7%E5%9B%9E%E5%BD%92%E7%BB%93%E6%9E%9C%E5%8F%AF%E8%A7%86%E5%8C%96R%E8%AF%AD%E8%A8%80%E7%89%88%2F</url>
    <content type="text"><![CDATA[前面已经介绍过R语言读取excel的方法了，当然读取数据来说，个人还是推荐csv或txt存储（针对小数据量）。大数据量的数据的话建议还是用数据库，此外也可以考虑data.table包读取，这个包也是个神包，后面学习完可能来谈谈。这个都是题外话，今天主要目的还是来介绍R语言读取空间数据的方法。主要是之前有同学问过读取的方法。我就顺带整理下，另外虾神今天刚发了一篇关于ArcGIS的OLS工具回归结果可视化内容，并贴出了Python版可视化的代码（文末贴链接），所以对应写个R语言版。本文介绍的空间数据类型主要包括了三种：矢量数据（以最普遍的的shapefile为例），栅格（raster，这个格式就比较多了，不过大同小异）,地理数据库（geodatabase也就是.gdb文件，Esri的数据库）。 1.矢量数据矢量数据其实主要包括了三类：点，线和面，能读取的方式有很多种。下面列举几种。先从点线面分别读取的方式来看，主要包括readShapePoints（读取点），readShapeLines（读取线要素），readShapePoly（读取面要素）。这几个函数都是maptools包里面的。所以第一步如果没安装的话请先安装。 install.packages(&apos;maptools&apos;) library(maptools) 接着定位到我们所需读取数据的工作路径上，然后就可以开始读取对应的数据了。 fujian&lt;-readShapePoints(&apos;fujian.shp&apos;) nanhailine&lt;-readShapeLines(&quot;linesnation.shp&quot;) province&lt;-readShapePoly(&quot;province.shp&quot;) 如果不需要什么其他操作，读取数据只需要填入文件名字作为传入的参数即可。这几个函数完整的参数大体差不多，主要包括下面几个。fn——文件名，一般能读的是.shp文件，.shx文件和.dbf文件proj4string = CRS(as.character(NA))——坐标系的CRS字符串，关于坐标系的问题，这里不详讲。其实就是一个坐标系对应一个ID，把对应ID读进去，按照对应坐标系读取，这个是遵循规范的。一般前两个参数用得多。后面这些只介绍这三个函数共有的参数，其他参数就请参照帮助文档。verbose = FALSE——默认为False，这个主要是在读取数据后是否返回读入要素的类型和数量。repair=FALSE——这个参数的话，主要是考虑到.shx索引文件太大，默认False会跳过读取数据，TRUE的话，会进行内部修复，读取这类文件。而maptools同样提供了另外一个函数readShapeSpatial，这个就可以读以上的三类要素。 fujian&lt;-readShapeSpatial(&quot;fujian.shp&quot;) 当然除了maptools，还有其他包可以读取，事实上，maptools提供的函数读取只能传输较差分辨率的空间数据，所以更推荐的是用rgdal包的OGR驱动程序来读取。熟悉开源GIS的同学对GDAL会比较熟悉，事实上rgdal就是GDAL的R接口（当然没装还是要先装，方法同上），读取方式如下，参数也是传入文件名即可简单读取，不过这个参数可以读具体文件也可以读文件夹名。对应上面proj4string也有一个参数p4s，其他参数参照文档。 fujian&lt;-readOGR(&quot;fujian.shp&quot;) 此外还有shapefiles包也可以进行读取。读取方式（可以读取shp和shx，shx读取结果为空间索引）如下： fujian&lt;-read.shp(&quot;fujian.shp&quot;) 矢量数据读取主要通过以上几种方式就可以实现。 2.栅格数据栅格数据的话，格式还是多种多样的。这边主要提供几种不同格式的读取方法（.img文件，.tif文件，ASCII码文件和.asc文件）。栅格数据读取主要是基于rgdal包，读取方式如下，img和tif都可以通过readGDAL直接读取。 co2&lt;-readGDAL(&quot;CO22008.img&quot;) co2&lt;-readGDAL(&quot;CO22008.tif&quot;) 这里面的参数我就不详细介绍了，主要解释几个个人认为比较重要的参数。有兴趣的同学可以去查询官方文档。band——波段数，单纯栅格无所谓。做遥感影像数据处理时就会遇到需要几个波段的问题，如果缺省的话，是全部导入。p4s——等同于上面的proj4stringtype——像素深度：8bit，16bit等除了rgdal之外，也可以通过raster包进行读取.img文件和.tif文件，这个更方便些。读取方式如下 co2&lt;-raster(&quot;CO22008.img&quot;) co2&lt;-raster(&quot;CO22008.tif&quot;) 当然栅格数据还有较为普遍的以ASCII码文件存储的方式。这里也提供下如何读取ASCII码文件，这个方法是基于sp包的，所以需要先安装和载入sp包，这个包是R语言空间数据的基础包，指定了空间数据库的方法和对象。 co2&lt;-read.asciigrid(&quot;co22008.txt&quot;) 当然ASCII码文件可能是以.asc文件存储的，只需把后缀名改成.asc即可读取。栅格的读取大概就如上。 3.地理数据库（Geodatabase）数据读取Geodatabase是Esri在ArcInfo8之后引入的一种全新的面向对象的空间数据模型。具体简介可以自己搜索。也就是说Geodatabase是Esri官方提出的一种数据库，没有ArcGIS是无法创建Geodatabase的。读取的话其实也相对麻烦些。目前看到的只有Esri官方给出的一个R包可以读取Geodatabase数据。R语言与ArcGIS的结合在未来将很有潜力。目前Esri已经在github上开源了部分工具，2015年全球用户大会上也秀出了R-ArcGIS的Sample工具。具体开源地址： https://r-arcgis.github.io/ 本次用来读取Geodatabase的包就是R-ArcGIS中的一个关键包——arcgisbinding。这个包目前没有在cran上，建议下载之后离线安装。下载地址： https://github.com/R-ArcGIS/r-bridge/releases/tag/v1.0.0.125。 这个包的官方文档可以从官网下载，也可以从下面的连接下载。 http://download.csdn.net/detail/esa_dsq/9823403 具体安装，同时安装完之后需要先确认ArcGIS的许可（要求应该是ArcGIS10.4以上的版本或者ArcGIS pro1.1以上），具体代码如下： install.packages(&quot;G:/GIS/Esri/ArcGIS Plugin/arcgisbinding_1.0.0.125.zip&quot;, repos = NULL, type = &quot;win.binary&quot;) arc.check_product() 读取的方式稍微复杂些，用到了arc.open，arc.select，arc.data2sp三个函数，arc.open是打开gdb文件里的featureclass（支持的格式还包括layers等），arc.select是将打开的featureclass按照需要的字段和sql读成R语言中熟悉的数据框，arc.data2sp是将数据框转化成空间要素。使用方式如下。 china&lt;-arc.open(&quot;china.gdb/province&quot;) chinapop&lt;-arc.select(china,fields = c(&apos;Pop_Rural&apos;,&apos;Pop_Urban&apos;,&apos;POPU&apos;)) chinapopsp&lt;-arc.data2sp(chinapop) 当然读取完了我们还是要来可视化一下。用的是spplot函数，这里就不展开讲了，只贴出图（当然只是随手画的，色带啥的都没调）。 4.ArcGIS中OLS工具回归结果可视化（R语言版）最后的最后。对应虾神文章的Python版本ArcGIS中OLS工具回归结果可视化，写个R语言版本。 #载入包 #如果没安装，请先安装，如果已安装，请注释 #install.packages(&quot;.../arcgisbinding_1.0.0.125.zip&quot;, repos = NULL, type = &quot;win.binary&quot;)…表示arcgisbinding离线包的路径 #install.packages(&quot;car&quot;) #install.packages(&quot;GGally&quot;) #install.packages(&quot;ggplot2&quot;) library(arcgisbinding) library(car) library(GGally) library(ggplot2) #设置工作路径 setwd(&quot;F:/R/demo/readdata&quot;) #检查ArcGIS产品许可 arc.check_product() #读取数据并将数据转换为数据框 olsdata&lt;-arc.open(&quot;china.gdb/olstest&quot;) olsdata olsdataframe&lt;-arc.select(olsdata,fields = c(&quot;gdp&quot;,&quot;Index_2000&quot;,&quot;Pop_Urban&quot;,&quot;POPU&quot;,&quot;PRODUCT&quot;,&quot;Estimated&quot;,&quot;Residual&quot;,&quot;StdResid&quot;)) #把因变量和自变量单独分离出来并用car包里的spm函数绘图 variableframe&lt;-olsdataframe[,c(1:5)] spm(variableframe,diagonal=&quot;hist&quot;) 感觉似乎不是很好看，换个方式。 #利用GGally的ggpairs函数画图 ggpairs(variableframe,upper = list(continuous=&quot;cor&quot;),lower = list(continuous=&quot;smooth&quot;),diag = list(continuous=&quot;barDiag&quot;)) #绘制标准残差的分布，用ggplot2画图 a&lt;-ggplot(olsdataframe,aes(x=StdResid))+ geom_histogram(aes(y=..density..),binwidth = 0.5,colour=&quot;white&quot;,fill=&quot;grey&quot;)+ geom_line(stat=&apos;density&apos;,colour=&quot;#FF6666&quot;) a #绘制标准残差和观测值的散点图 opar&lt;-par(no.readonly = T) par(fig=c(0,0.8,0,0.8)) plot(olsdataframe$gdp,olsdataframe$StdResid,col=&quot;grey&quot;,pch=16) par(fig=c(0,0.8,0.7,1),new=T) hist(olsdataframe$gdp,col=&quot;grey&quot;) par(fig=c(0.75,1,0,0.8),new=T) hist(olsdataframe$StdResid,col=&quot;grey&quot;) 主要是为了和虾神最后的效果类似，事实上，在读取完数据框之后，纯属散点图矩阵可视化方面的内容。最后贴出虾神的公众号和博客。 微信公众号：虾神daxialu——以推广空间分析和空间数据挖掘为己任，致力于在GIS界传递分析价值。虾神博客原文地址：《白话空间统计二十三：回归分析番外-ArcGIS中的OLS（三）》 http://blog.csdn.net/allenlu2008/article/details/70456024]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>R语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从定性遥感到定量遥感——大数据时代的空间数据科学]]></title>
    <url>%2F2017%2F04%2F22%2F%E4%BB%8E%E5%AE%9A%E6%80%A7%E9%81%A5%E6%84%9F%E5%88%B0%E5%AE%9A%E9%87%8F%E9%81%A5%E6%84%9F%E2%80%94%E2%80%94%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%97%B6%E4%BB%A3%E7%9A%84%E7%A9%BA%E9%97%B4%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%2F</url>
    <content type="text"><![CDATA[笔者最近一周之内连续听了四场关于定量遥感前沿进展的讲座（内容遍布目前定量遥感的诸多热点领域）。这四场讲座分别从定量遥感信息技术整体的前沿进展、气溶胶（民众最关心的PM2.5）定量遥感、植被生态环境定量遥感（高光谱遥感、多光谱遥感）到最后一个雷达遥感（SAR）。可以说十分丰富，信息量也非常大。所以听完之后，有些想法和思考来谈一谈关于从定性遥感到定量遥感的发展以及必然。首先会有很多人会疑惑什么是定量遥感？和普通的遥感有啥区别？那么我想还是先从遥感的起源和定义说起。遥感，也就是Remote Sensing。最早是由这位美国海军的老太太提出的，具体的故事看下图介绍。 从广义来说，遥感就是以非直接接触形式探测物体的一种方法，最广泛的一种方式就是以电磁波来进行探测。物体之间的差异，造成了对不同波长的电磁波反射特性不尽相同，通过这个特点，通过传感器接收物体反射回来的电磁波信息，就是典型的遥感探测，当然我们也可以称之为被动遥感。而通过传感器主动发射电磁波并接收物体反射回来的电磁波，同样是遥感探测，也可以称之为主动遥感（有点像海豚的超声波定位原理）。被动遥感的典型案例包括目前多数光学卫星遥感，主动遥感则是近年来兴起的微波遥感、激光雷达遥感等。当然从广义角度来说，无人机航拍这类也可以算是遥感的一类，但是从狭义来说，我认为它还算不上遥感。而遥感的狭义定义就是定量遥感的基础，遥感的狭义定义应当是指通过接收记录物体反射电磁波特性来探测物体性质的方法。所以狭义的遥感的关键是物体反射的电磁波特性。嗯，敲黑板、划重点。三个字：电磁波！电磁波！电磁波！重要事情说三遍。遥感的价值就在于遥感探测得到的电磁波信息，那么电磁波信息能带给我们什么呢？初中老师（也有可能是高中老师吧）曾经曰过：“太阳光是白光（其实它五颜六色），物体在人的视觉里呈现不同颜色，就是因为它吸收了部分光，反射了部分光，这一部分信息被人的视觉所接收并生成图像。”事实上，卫星遥感同样是这个道理，卫星遥感大部分接受的电磁波信息就是地物反射的太阳光波谱信息，所以，不了解遥感的人总觉得它就是在给地球拍照。 图片来源：ArcGIS Earth 其实准确说来也没错。人类视觉接收到的也是地物反射的太阳光波谱信息，相机和卫星接收到的也是如此，只不过人类视觉接收的信息可能以某种生物信息或者信号方式记录存在，而相机（RGB值）和卫星则均使用数字来记录。所以我们会觉得卫星遥感影像有时候很直观，看着跟眼睛看到的真实事物或者拍出来的照片一样，三者者事实上也是一样的道理（盗用知乎的一句话：传感器接受到外界光子，要么形成电压信号，要么形成电流信号，然后转换成我们所熟悉的pixel，尽管三者有些许差别，总的来说核心的问题并没有太大差异，文末贴链接）。一个很核心的问题在于，人类视觉可以接受的波谱信息有限制，也就是我们说的可见光部分。但是卫星遥感数据接收的范围则远比这广得多——微波（合成孔径雷达）、热红外等。但是无论是可见光部分或者非可见光部分，卫星所接收的都是用来描述电磁波的信息，而电磁波的信息又是反映物体的物理特性的（前面提到过，物体间的差异导致的反射波谱不同）。所以遥感技术应用的核心就是将电磁波信息转化为对人类有用的Knowlegde。那么如何转化呢？熟悉遥感的同学会知道目视解译这个词。也就是说看图识物。就像前面提到的，由于遥感成像原理与人眼成像原理类似，我们可以把它当地球拍的一系列照片，通过看着一系列照片，我们可以做监测（就像警察叔叔看监控找犯人一样），监测地球发生的变化，也可以监测某种地物的变化（从监控视频中找出犯人）。就像下面的图片。 图片来源：Google Earth Engine 然而一切的发明都是从偷懒开始的，一定会开始想方设法降低自己看照片的工作量。这就出现了计算机上面的一大分支——图像识别与图像分类。正如我上文提到的，卫星遥感的原理跟相机成像原理最核心部分是类似的。那么也就是说卫星遥感影像某种程度上也可以看成是特殊的“图片”。嗯，讲了很久。貌似都是遥感的基础概念。接下来！！！敲黑板，再次划重点。什么是定性遥感？什么是定量遥感？定性遥感就是类似于看图识物，通过将遥感影像当做特殊的“图片”，通过诸如计算机的图像识别、分类的方法去进行分析和处理得到我们所需要的Knowledge。比如简单的土地利用分类、面向对象的分割与分类或者监测变化等，仅仅是定性的划分。 GLC30 m土地覆被 而定量遥感，我就套用一下李传荣老师讲座时的定义：向社会和公众提供有用信息的技术。要精准描述构成地物状态特征的物理化学要素，以及导致地物目标变化的物理化学动力驱动机制。事实上，它的核心就是第一个重点，遥感目前的根本在于电磁波。那么电磁波这么一个物理现象，要做的不仅仅是将电磁波谱映射成普通图像去做解译、分类。既然我们通过卫星接收到了很多人类无法肉眼观测到的电磁波信息，那么我们就希望通过建立具有物理意义的方程以及模型，将电磁波信息转化为对人类更有用的Knowledge。这就是定量遥感所要做的事情。而定量遥感的典型分析方法就是耳熟能详的遥感定量反演。为什么叫反演？其实就是我想知道B的具体值，但是我无法直接观测B的具体值，但是我能观测到A的具体值，而A和B相互之间的关系，可以通过物理学意义的模型或者是其他模型进行表达，那么我就同过A的值去反推出B的值，这就是反演。相信大家就会很清楚，在定量遥感里，A就是传感器接受的波谱信息，而B则可以有很多种东西。比如：1.二氧化碳探测——温室气体 来源：GOSAT卫星反演结果。 https://data2.gosat.nies.go.jp/index_en.html 动图链接：https://pan.baidu.com/s/1hsNyTrY 去年我们国家在12月26日刚刚发射了TanSAT卫星，使得中国成为了第三个发射监测温室气体排放卫星的国家（前两个是美国和日本，分别是OCO-2卫星和GOSAT卫星），这件事对于我们的意义是什么呢？过去我们没有自己的碳卫星，发达国家在气候变化和谈上说中国排放多，我们难以反驳。现在我们有了自己的碳卫星，我们就有了谈判的手段。同时TanSAT卫星尽管有些方面不如前两个卫星，但是有些方面性能远超前两个卫星。2.地表温度地表温度反演，探究城市热环境的影响因素与空间格局分布。探究冷热岛效应成因分布。 MODIS的LST产品 3.气溶胶反演气溶胶，可能如PM2.5，PM10这些更耳熟能详。但是要注意的就是气溶胶光学厚度≠PM2.5，它是介质消光系数在大气垂直方向上的积分（简单说它没有分离PM2.5、PM10等气溶胶物质）。所以不做垂直订正和湿度订正就拿来跟PM2.5建立关系的AOD都是耍流氓。 PM2.5分布图，来源：网络 MODIS气溶胶产品 4.生态环境定量遥感植被动态变化与生态环境相关要素如叶面积指数、NDVI、光合有效辐射、NPP、GPP等。 VPM模型求算的GPP 除了以上四个，还有很多对应的定量遥感产品——水体叶绿素浓度产品、雪深产品等等。那么定量遥感的核心就是如何通过卫星接收的数据和具有实际物理意义的模型去反演得到我们所需要的产品。而从模型来说，主要分为几类：经验模型、半经验模型、物理模型。经验模型可以被认为是统计意义上的模型，即无视具体的物理过程，单纯靠统计方法建立的模型。半经验模型一般是结合了部分的物理意义的统计模型。物理模型则是严格按照电磁波谱和辐射传输特性经过推导的到的机理模型。可以说物理模型才是定量遥感真正的核心，因为前面两个模型建立之后通常无法复制。物理模型其实有两大部分，即包括了辐射传输方程推导的模型以及几何光学模型（普及下，这就是布鞋院士李小文院士从事的研究）。然而，定量遥感的研究已经有一段时间，却依旧处在一个不为人知的和无法广泛应用的时代。主要是由于地表的复杂性、定量遥感反演目前出现的病态反演问题、定量遥感产品缺乏验证和质量控制的多重因素影响。复杂性——地表非朗伯体特性、地形起伏等影响；病态反演问题——参数求解过程大部分是求解参数大于方程数；缺乏验证和质量控制——不确定性，缺乏统一标准等。当然可以说现在这些问题开始有逐步的改善——毕竟一句话，问题都解决了，还要搞研究的人干什么。但是可以肯定的是，目前计算机技术的发展、卫星载荷的发展、传感器的发展、多颗卫星共同监测、高光谱遥感、激光雷达、合成孔径雷达的普及的情况下，定量遥感的很多问题将会得到改善。所以是时候从定性遥感走向定量遥感，因为这是必然。随着技术的发展和模型精度提高，遥感应用产品也将更加普及。毕竟现在是大数据时代，我们不断强调的是数据即服务和软件即服务，定量遥感作为地球观测的客观载体，将会迸发出更大的潜力。很多人都会这么说，遥感数据是GIS里面的天生大数据，确实遥感数据满足了大数据的4V或者说5V的特征，但是它又跟计算机意义上的大数据有所不同。计算机上的大数据普遍的格式是什么呢？比较典型包括像文本、图片、视频，而甚至像LBS这样的经纬度数据。简而言之，它是高频数据，时间间隔非常短（诸如5min这样的时间间隔）。而遥感数据却不同，卫星的重访周期基本上很难达到5min，所以它非高频数据，那么从这个角度来说，很多大数据算法是否适用呢？同时它具有非常丰富的物理信息，所以就像老师们说的，我们更应该考虑的是这个不太一般的大数据如何去用，不是简单的拿来主义，用这些所谓的机器学习、深度学习去看图识物，可能更值得考虑的事如何将定量遥感的物理模型与大数据的数据挖掘、机器学习等手段相结合。最后的最后，回到主题——大数据时代的空间数据科学。对于空间数据科学来说，这可能是个最好的时代。因为我们不缺数据，但是可能也是个最坏的时代，因为我们多的是黑箱的算法，更缺少的是内在机制的理论研究。毕竟，科学家还是要有梦去追。 关于卫星遥感影像与相机成像原理差异知乎解答： https://www.zhihu.com/question/29835925 后记——从这四场讲座中，了解到很多前沿，对于定量遥感了解可能会更透彻。也了解到自己很多不足。一些简单的想法。就当是学习之后的呓语。最后的最后，推荐两本定量遥感的书吧（京东和当当有满减活动，不用谢，叫我雷锋）。]]></content>
      <categories>
        <category>RS</category>
      </categories>
      <tags>
        <tag>地学思索</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Google Earth网页初探]]></title>
    <url>%2F2017%2F04%2F19%2FGoogle%20Earth%E7%BD%91%E9%A1%B5%E7%89%88%E5%88%9D%E6%8E%A2%2F</url>
    <content type="text"><![CDATA[最近三维GIS界有个比较爆炸性的消息，嗯，没错，Google Earth Enterprise（谷歌地球企业版）宣告开源，47万行代码的大项目就此开放。（深深感觉谷歌就是要搞事情）。概括下GEE开源可以提供些啥。官方github的Readme文档如是写道：1.Fusion（融合）——影像、矢量与地形（或者可以说集成）的多源数据融合，导入三维地球（可以漫游飞行）或者集成的二维地图。2.Server（服务器）——可以通过融合用户自定义的多源数据定制一个私人三维地球服务器（基于Apache或者Tornado）。3.Client（客户端）——谷歌地球企业版客户端和谷歌地图Javascript API V3版用来浏览三维地球和二维地图。可以说这个开源项目强大异常，感觉GEE开源对于GIS和Web三维开发者是个很大的福利。GEE开源地址： https://github.com/google/earthenterprise 接着近日，早前预告过会在世界地球日（4 月 22 日）前发布新版 Google Earth的 Google，今天公布了新消息，各位期待已久的网页版 Google Earth终于来了。现在 Google Earth在电脑端不再是只以应用形式存在，Google 为桌面浏览器推出了专门版本，不过目前只支持 Chrome，未来会增加对其它主流浏览器的支持。移动端方面，则是 Android 版先行，而 iOS 版会在未来得到更新（该段文字引自《Google 地球网页版上线，点击探索者按钮开启环球旅程吧》，文末贴链接）。嗯，终于进入了本篇的正题，虽然跑题的篇幅略长（其实我觉得也不算跑题）。首先贴主页面，感觉整个页面很舒服。 接下来介绍下功能。 主菜单其实包括了下面的几个功能，也可以登录你的谷歌账户。 定义地图样式。 而网页版最主要的两个功能（探索者和知识卡片，貌似官方把知识卡片称之为运气不错）。探索者是实现了在世界知名景点的虚拟旅游，包括嵌入了360°全景、VR以及谷歌街景。ps，给我一个谷歌地球，我能在跑步机上走遍世界。 这里尝试了下BBC的纪录片的这个虚拟旅游（在Youtube上，请自备梯子），这里只放了简单的gif图，后面有详细视频的链接。 知识卡片功能显示（随机到达2万个地点，都有知识卡片和简介） Google Earth在2005年推出之后，引起了全球对GIS、空间科学的新一轮思考与认知。是Google Earth真真正正让GIS、VGI（Volunteer Geographical information，志愿者地理信息）和空间科学的理念普及到了千家万户。而这一次Google Earth网页版的推出，又将驱动VR（Vitrual Reality，虚拟现实技术）与三维GIS的进一步发展。对于地理教学方面，Gooogle Earth真正提供了一个0门槛，高质量的集成。可以期待的是，随着GEE开源，接下来GEE的发展将再次焕发生机。 分享的链接： https://earth.google.com/web/@39.9388838,116.3974589,54.08506769a,142593.39805527d,35y,0h,0t,0r/data=CkwaShJECiUweDM1ZjA1Mjk2ZTcxNDJjYjk6MHhiOTYyNTYyMGFmMGZhOThhGXvXoC-980NAIXNjesISGl1AKgnljJfkuqzluIIYAiAB 谷歌地球网页版： https://earth.google.com/web/ 《Google 地球网页版上线，点击探索者按钮开启环球旅程吧》： http://cn.technode.com/post/2017-04-19/google-earth-voyager/ 体验视频链接： http://v.youku.com/v_show/id_XMjcxNzgyODYzMg==.html?spm=a2hzp.8253869.0.0&amp;from=y1.7-2#pactionhttp://v.youku.com/v_show/id_XMjcxNzgyNjIzMg==.html?spm=a2hzp.8253869.0.0&amp;from=y1.7-2#paction]]></content>
      <categories>
        <category>GIS</category>
      </categories>
      <tags>
        <tag>Google Earth</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MODIS数据的简介和下载（三）——MODIS数据下载方式（基于MODIS Web Service）]]></title>
    <url>%2F2017%2F04%2F15%2FMODIS%E6%95%B0%E6%8D%AE%E7%9A%84%E7%AE%80%E4%BB%8B%E5%92%8C%E4%B8%8B%E8%BD%BD%EF%BC%88%E4%B8%89%EF%BC%89%E2%80%94%E2%80%94MODIS%E6%95%B0%E6%8D%AE%E4%B8%8B%E8%BD%BD%E6%96%B9%E5%BC%8F%EF%BC%88%E5%9F%BA%E4%BA%8EMODIS%20Web%20Service%EF%BC%89%2F</url>
    <content type="text"><![CDATA[这是MODIS数据的简介和下载的最后一篇，下载方式的进阶版——基于MODIS Web Service的下载方式。这篇是笔者课程上机实习内容之一，做些简要总结和整理。事实上MODIS产品系列就如前面提到的，由于搭载在Terra星和Aqua星上，所以产品就包括了Terra星、Aqua星以及二者集成的产品。分别以MOD（Terra星）、MYD（Aqua星）、MCD（二者集成）作区分。具体的产品查询网站除了前面文章简单提到的之外，还可以查看官网。 https://lpdaac.usgs.gov/dataset_discovery/modis/modis_products_table/ 当然这一次进阶版的下载方式是基于Web Service的。那么Web Service是什么呢？这边引用了课程ppt的一段话。 Web service是一个平台独立的，低耦合的，自包含的、基于可编程的web的应用程序，可使用开放的XML（标准通用标记语言下的一个子集）标准来描述、发布、发现、协调和配置这些应用程序，用于开发分布式的互操作的应用程序。 Web Service技术， 能使得运行在不同机器上的不同应用无须借助附加的、专门的第三方软件或硬件， 就可相互交换数据或集成。依据Web Service规范实施的应用之间， 无论它们所使用的语言、 平台或内部协议是什么， 都可以相互交换数据。Web Service是自描述、 自包含的可用网络模块， 可以执行具体的业务功能。Web Service也很容易部署， 因为它们基于一些常规的产业标准以及已有的一些技术，诸如标准通用标记语言下的子集XML、HTTP。Web Service减少了应用接口的花费。Web Service为整个企业甚至多个组织之间的业务流程的集成提供了一个通用机制。 简单说，这是个方便你下载的插件。具体的下载地址就在下面了。官方提供了多种语言的客户端，包括Java，Perl，Python，Kepler，Matlab和R。本篇主要介绍Matlab和R的客户端如何下载MODIS数据。 https://modis.ornl.gov/data/modis_webservice.html 先介绍Matlab的客户端，首先在官网下载Matlab的客户端。 客户端压缩包文件： 客户端在Matlab的部署非常简单。只需要拷贝到Matlab的工作目录即可。当然使用的时候要求位于如图的路径中。 接下来就可以愉快地使用了。当然，由于官方的镜像搬迁的问题，需要更新对应的镜像地址。 对应在Matlab客户端的modisClient.m文件中找到替换的镜像地址，保存后即可开始使用。 在Matlab中调用不含任何参数的modisClient，可以看到可供下载的MODIS产品列表。 modisClient() 用产品名称作为参数，则可以看到该产品下所有数据集。 modisClient(&apos;MOD15A2&apos;) modisClient(&apos;MOD15A2&apos;,&apos;Lai_1km&apos;,36.833,116.567) 加上数据集名称（以1 km的叶面积指数数据为例）以及经纬度坐标。结果为对应的数据集（该数据8天为间隔）所在的时间范围。 在前面的基础上加上时间范围即可用客户端下载对应的MODIS数据。数据的下载格式是一个多元结构体。包括了数据、转换因子、对应时间序列和单位等等。这样我们就用Matlab下载到了对应的MODIS数据。 YC_LAI2009=modisClient(&apos;MOD15A2&apos;,&apos;Lai_1km&apos;,36.833,116.567,2009000,2009365) 接下来我们讲的是R语言的客户端及其下载方式。R语言的客户端有两种配置方法，一个是基础设置（基于SSOAP来进行），一个是高级设置（MODISTools包）。笔者个人使用的是高级设置，基础设置没有配置过。只是对官方给出的例子做了下翻译，具体的demo如下： ##确定你安装了SSOAP包，否则先安装SSOAP，用install.packages(&quot;SSOAP&quot;） ##接着你就可以尝试用命令行的方式来下载裁切你想要的MODIS影像数据了 ## 载入包 library(SSOAP) ## 获取SOAP服务 ornlMODIS = processWSDL(&quot;http://daac.ornl.gov/cgibin/MODIS/GLBVIZ_1_Glb_subset/MODIS_webservice.wsdl&quot;) ## 定义函数设置 ornlMODISFuncs = genSOAPClientInterface(operations=ornlMODIS@operations[[1]], def=ornlMODIS) ## 使用获取裁切影像的函数设定 result = ornlMODISFuncs@functions$getsubset(40.115,-110.025, &quot;MOD11A2&quot;,&quot;LST_Day_1km&quot;,&quot;A2001001&quot;,&quot;A2001025&quot;,1,1) ##打印结果 print(result) 基础设置R语言demo地址： https://modis.ornl.gov/files/modiswebservice/R_getsubset.r 接下来用MODISTools包来做测试，GetProducts函数类似于Matlab的moidsClient（）： GetProducts() 而对应的查看数据集的函数并不是在GetProdcuts函数中填入参数，而是使用GetBands函数。 GetBands(&quot;MOD15A2&quot;) 对应查看数据时间范围的函数为GetDates。 GetDates(36.833,116.567,&quot;MOD15A2&quot;) 而类似于Matlab客户端下载数据的函数则为GetSubset和MODISSubsets。 YC_LAI2009&lt;-GetSubset(36.833,116.567,&quot;MOD15A2&quot;,&quot;Lai_1km&quot;,&quot;A2009001&quot;,&quot;A2009081&quot;,KmAboveBelow = 0,KmLeftRight = 0) GetSubset函数较为简单。但笔者测试时，发现终止时间仅能到达第81天（LAI数据为8天合成产品）。目前尚不清楚具体原因，故最后使用MODISSubsets获取对应的数据。MODISSubsets必须先建立一个数据框作为经纬度（lat,long为字段名)，时间限制范围（start.date，end.date为字段名）的数据。而函数中比较重要的参数还包括了Size和TimeSeriesLength，Size可以用默认值（经纬度位置所处瓦片数量，c(0,0)表示像元中心值），TimeSeriesLength表示时间序列长度，等于1代表从一年的开头到结尾。运行程序，会发现在工作目录下生成了一个.asc文件（即对应MODIS下载下来的数据）。 yclai2009&lt;-data.frame(lat=36.833,long=116.567,start.date=2009,end.date=2009) MODISSubsets(LoadDat = yclai2009,Products = &quot;MOD15A2&quot;,Bands = &quot;Lai_1km&quot;,Size = c(0,0),StartDate = T,TimeSeriesLength = 1) 最后对获取的LAI数据进行绘图可视化。 #Matlab中 Puredata=[YC_LAI2009.data(:,:)] plot([0:(length(Puredata)-1)]*8+1,Puredata*YC_LAI2009.scale,&apos;b-&apos;) ylabel=(YC_LAI2009.units) xlabel=(&apos;day of year&apos;) title=(&apos;禹城站2009年LAI&apos;) #R中 a&lt;-read.table(&quot;Lat36.83300Lon116.56700Start2009-01-01End2009-12-31___MOD15A2.asc&quot;,sep = &quot;,&quot;) lai&lt;-data.frame(day=seq(1,365,8),lai=a$V11*0.1) plot(lai,type=&quot;l&quot;,pch=16,col=&quot;blue&quot;,xlab=&quot;day of year&quot;,ylab=&quot;LAI&quot;,main=&quot;禹城站2009年LAI&quot;) Matlab绘图结果 R绘图结果 总的来说，Matlab和R的客户端下载各有优缺点，而基于MODIS Web Service的下载方式最大好处就是在于它的Subset功能，而不是需要先下载整景影像再处理。在做单点模型的时候是非常快捷的。当然客户端的其它函数还有很多，包括像质量控制。本文没有对数据进行质量控制。实际研究中这个是必须进行的步骤（也可以基于客户端的函数来进行，譬如R里面的QualityCheck函数，Matlab的modisClientGetQC等）。此外地理所也开发了在线平台，研究人员只需填写所需参数即可下载。 http://159.226.110.142/carboncloud/datetool/toolmethod?url=onlinedo&amp;pId=3]]></content>
      <categories>
        <category>RS</category>
      </categories>
      <tags>
        <tag>MODIS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MODIS数据的简介和下载（二）——MODIS数据下载方式（FTP）]]></title>
    <url>%2F2017%2F04%2F14%2FMODIS%E6%95%B0%E6%8D%AE%E7%9A%84%E7%AE%80%E4%BB%8B%E5%92%8C%E4%B8%8B%E8%BD%BD%EF%BC%88%E4%BA%8C%EF%BC%89%E2%80%94%E2%80%94MODIS%E6%95%B0%E6%8D%AE%E4%B8%8B%E8%BD%BD%E6%96%B9%E5%BC%8F%EF%BC%88FTP%EF%BC%89%2F</url>
    <content type="text"><![CDATA[前一篇我们已经介绍了MODIS数据的简介、参数以及相关的典型应用。这一篇我们来介绍下MODIS数据的下载方式。当然这边主要是介绍国外网站的下载方式，国内网站的普遍是在地理空间数据云和遥感集市下载。国外网站（NASA官网）下载方式主要介绍两种。本篇主要针对第一种方式，基于完整的一景影像下载的过程（FTP工具）。后面一篇更新的是基于MODIS Web Service的客户端下载的方式（Matlab和R）。FTP下载工具以及完整影像下载的方法笔者最早也是参照网上某篇博客学习的下载方式，老规矩，文末贴链接，这里先感谢这位写博客的同学。同时NASA官网最近刚刚改版了网站，新版网站的下载方式暂时没有看到其他人整理，故稍作些整理。NASA官方遥感影像数据下载网址（里面不止有MODIS，还有ENVISAT，NPP-VIIRS等）： https://ladsweb.modaps.eosdis.nasa.gov/ 选择DATA DISCOVERY的Search&amp;Order：进入这个页面：找到你要下载的卫星传感器（这里以Terra星做例子）：选择我们需要的产品（这里选了1 km、500 m的二级产品，以及经纬度校正的产品，具体产品介绍看上一篇博客的表格以及列出的链接）：结束后直接点击“TIME”，根据需要选择数据的时间跨度。接着点击下一步，“LOCATION”。有不同选择需要影像范围的方法。Country→按国家的行政边界来选择数据Tiles→按瓦片选择，或者说按照MODIS数据全球逐行逐列划分的格网（也可以说是MODIS观测时的行列号）来选择数据Validation Sites→按全球分布的验证的观测站点或者生态网络观测站点选择（可以结合观测站点数据做研究）Draw Custom Box（Classic）→按照用户自定义画出来的框选选择数据（用过老版网站下载的同学会对这个功能比较熟悉）Enter Coordinates→用经纬度坐标来选择数据（这个也是类似于老版网站的下载功能），其实就是研究区的四至坐标。这里选择了按瓦片选择的方式，点击箭头。下一步，“FILES”。这一步会把符合要求的所有数据列出来，但是由于前面搜索的时间跨度太长，web端无法完全显示，所以我们重新修改下相关的需求数据（仅选择2010年的数据，而且选择下载合成产品）。接下来是新版网站的一个比较不同的地方，这里的”FILES“，可以直接下载数据。老版网站一般需要Order，提交订单之后才能下载。这样使用比原来更自由些。现在选择所有数据，提交订单即可。不过新版网站现在要求要注册账户。所以在下载数据前，记得先申请一个Earthdata的账户（这也就是比较麻烦的点了，目前笔者测试了163和qq邮箱，都没有办法收到激活邮件。目前只有谷歌邮箱能激活，所以必须去注册一个gmail的邮箱）。注意，需要在自己的账户中的“My Application”下面启动“LAADS Web”，最后才能提交订单。FTP的下载必须等到订单出现availlable，才能下载。官方给出的等待时间是5min到10天左右。一般很快就OK了。FTP下载方式的话，需要用FlashFXP这类软件来下载，有需要这个软件的可以在评论区留邮箱或在我的主页（友情链接里面）搜索下我的邮箱。 地址根据你的订单来决定。ftp: ladsweb.modaps.eosdis.nasa.govusername:anoymouspassword:你账户申请用的邮箱（gmail邮箱）anoymous意为FTP里的匿名传输。接下来只需要简单地拖拽就可以将上面的数据拷贝到本地文件夹了。这就是关于MODIS数据下载方式(FTP)的内容。最后附上旧版网站下载方式教程博客网址： http://blog.sina.com.cn/s/blog_8684880b010149ue.html]]></content>
      <categories>
        <category>RS</category>
      </categories>
      <tags>
        <tag>MODIS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MODIS数据的简介和下载（一）——MODIS数据简介]]></title>
    <url>%2F2017%2F04%2F13%2FMODIS%E6%95%B0%E6%8D%AE%E7%9A%84%E7%AE%80%E4%BB%8B%E5%92%8C%E4%B8%8B%E8%BD%BD%EF%BC%88%E4%B8%80%EF%BC%89%E2%80%94%E2%80%94MODIS%E6%95%B0%E6%8D%AE%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[借最近上课实习上机内容，来介绍MODIS数据相关方面内容。本部分主要包括了MODIS数据的简介和下载的问题。本篇是第一部分，MODIS的简介。主要分为三个部分：1.MODIS传感器简介及参数；2.MODIS产品及命名规则；3.MODIS的典型应用。1.MODIS传感器简介及参数首先来纠正件很容易被误解的事，MODIS是传感器而不是卫星，尽管我们平常称呼的时候更习惯叫MODIS数据（以传感器来称呼），Landsata数据（以卫星来称呼）。MODIS传感器的全称为中分辨率成像光谱仪（moderate-resolution imaging spectroradiometer）,主要搭载在Terra和Aqua星上。Terrra的简介如下（摘自百度百科和遥感集市）：EOS（Earth Observation System）卫星是美国地球观测系统计划中一系列卫星的简称。经过长达8年的制造和前期预研究准备工作，第一颗EOS的上午轨道卫星于1999年12月18日发射升空，发射成功的卫星命名为Terra（拉丁语“地球”的意思），主要目的是观测地球表面。它是一个用一系列低轨道卫星对地球进行连续综合观测的计划。它的主要目的是：实现从单系列极轨空间平台上对太阳辐射、大气、海洋和陆地进行综合观测，获取有关海洋、陆地、冰雪圈和太阳动力系统等信息；进行土地利用和土地覆盖研究、气候的季节和年际变化研究、自然灾害监测和分析研究、长期气候变率和变化以及大气臭氧变化研究等；进而实现对大气和地球环境变化的长期观测和研究的总体（战略）目标。EOS卫星轨道高度为距地球705公里，目前的第一颗上午轨道卫星（Terra）过境时间为地方时10:30am左右，一天最多可以获得4条过境轨道资料。Terra卫星于1999年12月18日发射成功，Aqua卫星于2002年5月4日发射成功。Terra为上午星，从北向南于地方时10:30左右通过赤道，Aqua为下午星，从南向北于地方时13：30左右通过赤道。两颗星相互配合每1-2天可重复观测整个地球表面，得到36个波段的观测数据EOS系列卫星上的最主要的仪器是中分辨率成像光谱仪（MODIS），其最大空间分辨率可达250米。对应的MODIS传感器的简介如下（摘自百度百科和遥感集市）：MODIS是当前世界上新一代“图谱合一”的光学遥感仪器，有36个离散光谱波段，光谱范围宽，从0.4微米（可见光）到14.4微米（热红外）全光谱覆盖。MODIS的多波段数据可以同时提供反映陆地表面状况、云边界、云特性、海洋水色、浮游植物、生物地理、化学、大气中水汽、气溶胶、地表温度、云顶温度、大气温度、臭氧和云顶高度等特征的信息。可用于对地表、生物圈、固态地球、大气和海洋进行长期全球观测。中分辨率成像光谱仪（MODIS）最大空间分辨率可达250米，扫描宽度2330公里。MODIS是CZCS、AVHRR、HIRS和TM等仪器的继续。MODIS是被动式成像分光辐射计。共有490个探测器，分布在36个光谱波段，从0.4微米（可见光）到14.4微米（热红外）全光谱覆盖。MODIS仪器的地面分辨率为250m、500m和1000m，扫描宽度为2330km。在对地观测过程中，每秒可同时获得11兆比特的来自大气、海洋和陆地表面信息，日或每两日可获取一次全球观测数据。MODIS参数（摘自百度百科和遥感集市）空间分辨率——250 m (1-2波段)；500 m (3-7波段)；1000 m (8-36波段)扫描宽度——2330km时间分辨率——1天光谱波段——36个离散光谱波段，光谱范围宽，从0.4微米（可见光）到14.4微米（热红外）全光谱覆盖 。轨道——705KM，降轨上午10:30过境，升轨下午1:30过境；太阳同步；近极地圆轨道设计寿命——5年2.MODIS产品及命名规则按处理级别划分，可以分为以下5种：0级产品：也称原始数据;1级产品：指L1A数据，已经被赋予定标参数;2级产品：经过定标定位后数据，本系统产品是国际标准 的EOS-HDF格式。包含所有波段数据，是应用比较广泛的一类数据。;3级产品：在1B数据的基础上，对由遥感器成像过程产生的边缘畸变(Bowtie效应)进行校正，产生L3级产品;4级产品：由参数文件提供的参数，对图像进行几何纠正，辐射校正，使图像的每一点都有精确的地理编码、反射率和辐射率。L4级产品的MODIS图像进行不同时相的匹配时，误差小于1个像元。该级产品是应用级产品不可缺少的基础;5级及以上产品：根据各种应用模型开发L5级产品。MODIS命名规则如下（摘自CSDN博客）：MOD04 是产品名称，表示MODIS气溶胶产品。L2 表示 产品级别，Level2。A2005224 表示产品时间2005年第224天（以每年1月1日为第一天）。0205 表示卫星过境时间，换算成北京时间要加8小时。005表示产品版本，Version005，之前是v004，相比之前版本有很多改进。2006225195920 表示的是产品处理时间。3.MODIS的典型应用MODIS数据的简介大部分是从网上找的资源，链接都附在后面了，已经有很多人做了很多详细介绍，本篇就借花献佛，主要做简单地整理与引用，没有过多赘述。笔者自己写的核心内容主要是MODIS的一些典型应用和相关的一些研究进展。由于MODIS数据是免费获取的，并且具有高时间分辨率，在生态学和地理学研究中有很多广泛的应用。从产品就可以发现它可以监测的相关内容。植被动态监测以及植被生理生态的多种产品遥感反演典型的是NDVI合成产品、NPP（净初级生产力）、LAI（叶面积指数）、植被动态变化。这一部分内容主要应用生态环境监测中，尤其是生态学相关研究。因为NDVI和LAI是宏观尺度上可以反映植物生理生态的两个重要参数，目前演化出来的相关应用非常的多。在农学上，引入这两个参数来进行区域的农作物估产。在林学上，估算森林生物量、NPP、GPP以及光合有效辐射等。通过NDVI和LAI来进行物候变化监测。通过遥感数据去驱动生态模型，生态系统对于全球变化的响应的相关研究上，MODIS的这一系列产品都起到了很大的作用。基于MODIS的LAI产品结合模拟退火算法和DSSAT模型进行玉米估产模型的参数优化（数据同化） 地表温度反演以及相关产品遥感反演运用MODIS的热红外波段，通过劈窗算法（类似AVHRR）可以反演地表温度。包括温度异常和林火产品。在林学上有广泛的应用。基于劈窗算法的MODIS反演地表温度 光学气溶胶厚度反演这部分是近些年来关注的重点，由于PM2.5或者说雾霾的造成的环境问题日益严重，如何从遥感监测PM2.5是一个研究热点，现在比较普遍的使用MODIS产品来进行光学气溶胶（AOD)反演，然后反演PM2.5。基于DDV算法的MODIS光学气溶胶厚度反演 其他应用MODIS的应用还有非常多，比如像海表温度反演——事实上这方面的温度反演精度要高于地表温度反演，主要是海水从性质上说属于近似黑体；叶绿素浓度反演；离水辐射；冰雪覆盖监测（以NDSI为例）等。最后的部分我们用一个简单的知网检索结果、词云可视化以及列出了Web of Science上被引频次最高的10篇文章（MODIS作为keywords，可视化用HistCite）来看看目前MODIS研究的一些进展以及经典文献。遥感集市MODIS简介： http://bbs.rscloudmart.com/forum.php?mod=viewthread&amp;tid=1761&amp;highlight=MODIS MODIS百度百科： http://baike.baidu.com/link?url=IdbXlrWPCG8JX8fUQRmrRSPWjWx4Q7-r_reaPgNTsL88llgGTFPjk_eXrS-5S_bTJwqBCvHJlNIA3MZiV3mbgK MODIS命名规则的CSDN博客： http://blog.csdn.net/xiaoxiang22/article/details/8363469http://blog.csdn.net/rumswell/article/details/9003215 MODIS数据处理相关博客——以ENVI为主，ENVI/IDL官方博客： http://blog.sina.com.cn/s/articlelist_1984634525_0_1.html]]></content>
      <categories>
        <category>RS</category>
      </categories>
      <tags>
        <tag>MODIS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在Ubuntu中安装R的几种方式总结]]></title>
    <url>%2F2017%2F04%2F09%2F%E5%9C%A8Ubuntu%E4%B8%AD%E5%AE%89%E8%A3%85R%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E5%BC%8F%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[近来笔者由于研究需要，开始研究Linux系统，并动手安装了VMware和Ubuntu软件。因缘际会（主要是自己开始入坑Github）发现之前在Windows下安装失败的一个R包bignmf无法安装原因。这个包只能在Ubuntu上测试运行。所以之前在windows上根本无法编译和安装。所以笔者打算在Ubuntu上安装R并安装这个包进行使用。这里简单解释下bignmf包的用处，它是基于Rcpp和RcppEigen两个包，通过底层C++代码调用实现的一个R包，实现的算法是NMF（Nonnegative Matrix Factorization，非负矩阵分解)，作者是爱荷华州立大学的潘岚峰大神。当然R本身自带也有NMF包，不过语法不是很友好的感觉，此外最近笔者也发现了另外的可以在windows上运行的NMF的R包，NMF的理论和应用方面，包括bignmf的编译安装，后面有时间会更新（先挖坑），这里不做详细介绍。回到本篇的主要目的，如何在Ubuntu中安装R。这里提供三个方法：1.Linux安装软件的普遍方法——命令行；2.新立得软件包；3.从官网下载R语言环境源码，自行编译安装。1.基于命令行的方法首先改变先进入/etc/apt/sources.list，变换软件源，同时进入管理员权限 cd /etc/apt/ gedit sources.list 在最下面添加一行，deb后面的网址是镜像，根据你的喜好选一个（反正我推荐清华的，速度快，不过之前用厦大的也不错），具体的镜像地址见后面的网址。 deb https://mirrors.tuna.tsinghua.edu.cn/CRAN/bin/linux/ubuntu xenial/ https://cran.r-project.org/mirrors.html 而ubuntu xenial则是根据ubuntu版本确定的。我的是16.04，所以是xenial。具体的看官方说明，文末贴链接。完了之后先更新下软件源。就可以开始安装R了。如果我们需要自行编译R包并且安装的话，就需要在安装r-base-dev。不过笔者测试过，3.3.3版本的r-base自带了r-base-dev。所以不需要进行额外安装。 apt-get update apt-get install r-base apt-get install r-base-dev 完了之后，官方推荐还可以再加个软件源，是关于R的拓展包的。这里贴出命令的通用格式，可以根据需求替换&lt;&gt;的内容。也可以添加下载的公共秘钥。 apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 51716619E084DAB9 deb https://&lt;my.favorite.ubuntu.mirror&gt;/ trusty-backports main restricted universe 完了之后，在命令行里敲入r，出现下面的页面说明安装成功。2.基于新立得软件管理包新立得软件管理抱是Linux下的神器，可以很方便的管理各类软件和依赖库等（上篇提到的WRF-DA模块编译依赖库有些是用这个安装的，具体过程等介绍WRF安装时补充）。当然一开始我没在我的Ubuntu软件里找到新立得。后面仔细翻了下软件列表。发现了这个软件——Synaptic Package Manager，这个就是新立得软件管理包了。启动它，搜索r-base，如图，右击标记安装，然后应用。3.基于自行编译的方法自行编译的方法，笔者没有具体尝试。但是看了下官方文档。大致的流程如下：官方推荐是组织一个文件夹进行安装，一级文件夹为R_Home，然后把源码解压到R_Home下面，并在下面建立src, doc等多个二级文件夹。然后回到R_Home文件夹。以管理员身份进入。 ./configure make make check make check-all make check-all是针对全部的编译的（可选），最后在安装即可。 make install 可以改变安装路径 ./configure --prefix=/where/you/want/R/to/go make prefix=/path/to/here install 具体可以见官方文档（链接见文末）在R装好的情况下，为了写代码方便，推荐安装R最好的IDE，Rstudio。这边Rstudio的安装就不展开讲了。下载好deb安装文件，直接加命令行安装即可。 dpkg -i rstudio-1.0.136-amd64.deb 在Linux中用Rstudio简单画个散点图。 R语言linux安装官方文档： https://cran.r-project.org/bin/linux/ubuntu/README R语言镜像地址： https://cran.r-project.org/mirrors.html R语言linux编译安装官方文档： https://cran.r-project.org/doc/manuals/r-release/R-admin.html#Installation]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>R语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[WRF-DA代码编译与安装（二）——WRF-DA模块的编译与安装]]></title>
    <url>%2F2017%2F04%2F04%2FWRF-DA%E4%BB%A3%E7%A0%81%E7%BC%96%E8%AF%91%E4%B8%8E%E5%AE%89%E8%A3%85(%E4%BA%8C%EF%BC%89%E2%80%94%E2%80%94WRF-DA%E6%A8%A1%E5%9D%97%E7%9A%84%E7%BC%96%E8%AF%91%E4%B8%8E%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[上一篇已经将所有WRF-DA模块所需要的依赖库都编译安装成功。接下来的步骤就是WRF-DA模块的编译与安装。笔者已经事先从WRF官网下载了该模块的源码（版本为最新的3.8.1）。首先在设置个目录专门来存放WRF的主程序。选择在Home下面新建一个mode。命令如下： $ sudo mkdir mode 先进入管理员模式（sudo su命令），然后将WRFDA的压缩包全部复制到刚刚建好的文件夹中。 cp -r WRFDA_V3.8.1.tar.gz /home/mode/ 到刚刚建好的WRF文件夹里，同样进入管理员模式，并解压文件夹，到WRFDA目录中，配置环境变量，并设置编译类型。其中，rttov看是否需要，也可以不考虑安装。如若要安装，环境变量配置的路径为可以找到lib/librttov11.*.a的文件目录。 tar zxf WRFDA_V3.8.1.tar.gz cd WRFDA export NETCDF=/usr/local/NETCDF/ export hdf5=/usr/local/hdf5/ export rttov=/usr/rttov/ ./configure wrfda 然后出现了很多选项。选择 x86_64 Linux, gfortran compiler with gcc (serial)，键入32，回车。32到35分别代表32为serial 表示串行计算； 33为smpar 表示内存共享并行计算(shared memory option)，即使用openMP，大部分多核电脑都支持这项功能； 34为dmpar 表示分布式并行计算(distributed memory option)，即使用MPI 进行并行计算，主要用在计算集群，单个电脑就没必要用了； 35为dm+sm 表示同时使用openMP与MPI两种并行方式. 根据实际需要选择即可，最保险的方法就是选择 serial，不过这样编译出来的程序运行最慢（引自xg1990的博客）。笔者初步测试，选择串行计算的版本，而且根据官方文档和编译结果，其他模式还需要有其他相关的依赖库。选择完编译选项后，会出现提示选择嵌套选项，一般就选 basic 选项即可。当然，这边编译器不同的话，序号也有所不同。同时官方文档已声明3.8.1版本不支持dm和dm+sm版本。搞定之后，看到一条振奋人心的消息。接下来，就输入如下命令： ./compile all_wrfvar&gt;&amp;checkwrfda.log 然后等它编译完成就好了。当然，到这一步我还是有问题，因为我只编译安装了43个exe，完全成功应该有44个exe。并且发现这个缺少的exe是主程序，da_wfrda.exe。查看生成exe的命令。 ls -l var/build/*exe var/obsproc/src/obsproc.exe 接着就回头去看log文件以及官方编译要求。发现大部分是路径错误。于是重新配置安装依赖库，并将WRF所需的其他库一并安装，重新编译。终于成功。 以上就是WRF-DA模块的编译与安装。后面会更新WRF主程序的编译与安装方面的内容（具体时间待定）。最后再次感谢以下博客文档的帮助。 https://wenku.baidu.com/view/58851bc269eae009591bec0a.htmlhttps://nwpsaf.eu/site/software/rttov/rttov-v12/http://www2.mmm.ucar.edu/wrf/users/wrfda/updates-3.8.1.htmlhttps://xg1990.com/blog/archives/190 http://blog.csdn.net/luoying_1993/article/details/53228473 https://wenku.baidu.com/view/57e27fd14a7302768e9939f4.html?re=view http://www2.mmm.ucar.edu/wrf/users/wrfda/Docs/user_guide_V3.8.1/users_guide_chap6.htm#_Installing_WRF-Var]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>WRF</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[WRF-DA代码编译与安装（一）——依赖库的编译与安装]]></title>
    <url>%2F2017%2F04%2F02%2FWRF-DA%E4%BB%A3%E7%A0%81%E7%BC%96%E8%AF%91%E4%B8%8E%E5%AE%89%E8%A3%85(%E4%B8%80%EF%BC%89%E2%80%94%E2%80%94%E4%BE%9D%E8%B5%96%E5%BA%93%E7%9A%84%E7%BC%96%E8%AF%91%E4%B8%8E%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[由于笔者的研究需要用到数据同化技术，所以开始学习WRF相关内容（主要是WRF-DA模块）。这里先解释下WRF是什么东西。 WRF全称Weather Research and Forecasting Model, 是一个天气研究与预报模型.可以用来进行精细尺度的天气模拟与预报。 二战后，由于计算机技术的迅猛发展，气象预报技术也随之突飞猛进。短短的几十年里，世界各地的气象研究机关开发出了各自的相对独立的气象模式。这些模式之间缺少互换性，对科研及业务上的交流极其不便。从上世纪90年代后半开始，美国对这种乱立的模式状况进行反省。最后由美国环境预测中心（NCEP），美国国家大气研究中心（NCAR）等美国的科研机构为中心开始着手开发一种统一的气象模式。终于于2000 年开发出了WRF模式。同时，为使研究成果能够迅速地应用到现实的天气预报当中去，WRF模式分为ARW(the Advanced Research WRF)和NMM(the Nonhydrostatic Mesoscale Model)两种，即研究用和业务用两种形式，分别由NCEP和NCAR管理维持着。具体的可以见官网： http://www2.mmm.ucar.edu/wrf/users/ WRF模拟系统主要包含WPS和WRF两部分模块： WPS模块全称为WRF Pre-processing System，即WRF预处理系统，用来为WRF模型准备输入数据；如果只是做理想实验(idealized modeling)，就不需要用WPS处理真实数据。但是理想实验不在本文介绍范围内，本文介绍的是进行真实数据模拟的操作。 WRF模块就是数值求解的模块，它有两个版本：ARW(Advanced Research WRF) 和 NMM(Nonhydrostatic Mesoscale Model)。大多数研究者主要用的都是ARW版本，本文所有的介绍也都基于ARW版本。 除了WPS与WRF两大核心模块外，WRF系统还有很多附加模块：比如用于数据同化的WRF-DA，用于化学传输的WRF-chem，用于林火模拟的WRF-fire（该段文字引自xg1990的博客，具体地址文末贴出，感谢该位大神的分享）。安装运行WRF模拟系统必须在Linux系统。而笔者又无法放弃windows系统，同时目前工作还处于前期测试阶段，故决定选择用VMware虚拟机搭建一个Linux系统来测试。选用的VMware版本：12.5.2。Linux系统：Ubuntu 16.04具体安装过程不是本文重点。详情可见 https://jingyan.baidu.com/article/c275f6ba07e269e33d756714.html 此外附上Ubuntu官网链接 https://www.ubuntu.com/download/desktop WRF-DA编译与安装主要参照官方提供的ppt和文档（地址文末会贴出）。 首先看下WRF-DA编译与安装的需求。 上面提到了需求如下：1.Linux/Mac系统，基于Unix或Linux的系统2.（3DVAR）三维变分的案例内存占用不大，大的（4DVAR）四维变分内存消耗较大。3.支持C和Fortran的编译器（ifort/icc, gfortran/gcc,pgf90/pgcc）4..需要的一些库，类似于WRF。包括：Zlib，netCDF C/Fortran，MPI（MPICH），BUFR，CRTM，RTTOV，HDF5。系统已经安装完毕，而内存部分目前暂时不考虑。接下来看C和Fortran的编译器。Ubuntu内置了gcc的编译器。可以通过命令来查看。 ~$ gcc -v 结果如下： 接下来安装gfortran，也是通过命令进行安装。 ~$ sudo apt-get install gfortran 通过命令查看是否安装成功。 ~$ gfortran -v 接下来是几个库的下载与安装。zlib： http://www.zlib.net/ netCDF C/Fortran： http://www.unidata.ucar.edu/downloads/netcdf/index.jsp MPI（MPICH）： http://www.mpich.org/downloads/ BUFR：包含在WRF源代码中 CRTM：包含在WRF源代码中 RTTOV： https://nwpsaf.eu/site/software/rttov/ 需注册，最好自备梯子。 HDF5： https://support.hdfgroup.org/HDF5/ 将如上的几个库的安装包通过共享文件夹放入虚拟机中（mnt/hgfs/Share)。 zlib和hdf5和netCDF 4相关。具体安装步骤和教程借鉴了官方文档 http://www.unidata.ucar.edu/software/netcdf/docs/getting_and_building_netcdf.html#build_nc4_dap_from_source 1.zlib的安装：解压到/usr/下 $ cp -r zlib-1.2.11.tar.gz /usr/ $ tar zvf zlib-1.2.11.tar.gz 然后进入解压文件夹，并安装 $ ./configure --prefix=/usr/local/zlib $ make check $ make install 修改环境变量。 gedit ~/.bashrc # for zlib export ZLIB_HOME=/usr/local/zlib export LD_LIBRARY_PATH=$ZLIB_HOME/lib:$LD_LIBRARY_PATH 2.HDF5的安装：解压到/usr/下 $ tar -xvf hdf5-1.8.18.tar 然后进入解压文件夹，并安装 $ ./configure --with-zlib=/usr/local --prefix=/usr/local/hdf5 $ make $ make check $ make install HDF5的安装和检验参照： ./configure --prefix=/usr/local/hdf5 --with-zlib=/usr/local/zlib http://blog.csdn.net/luoying_1993/article/details/53228473 HDF5还需配置一个环境变量，避免下面的netCDF C安装报错。 $ gedit ~/.bashrc #for hd5 export CPPFLAGS=-I$PRO_PATH/usr/local/hdf5/include export LDFLAGS=-L$PRO_PATH/usr/local/hdf5/lib export LD_LIBRARY_PATH=$PRO_PATH/usr/local/hdf5/lib $ source ~/.bashrc 3.netCDF C/Fortran安装先装netCDF C： $ export CPPFLAGS=-I$PRO_PATH/usr/local/hdf5/include $ export LDFLAGS=-L$PRO_PATH/usr/local/hdf5/lib $ export LD_LIBRARY_PATH=$PRO_PATH/usr/local/hdf5/lib $ ./configure --prefix=/usr/local/NETCDF --enable-netcdf-4 $ make $ make check $ make install 接着装netCDF Fortran：先声明环境变量： $ export CPPFLAGS=-I/usr/local/NETCDF/include $ export LDFLAGS=-L/usr/local/NETCDF/lib 然后进行下一步编译。 $ ./configure --prefix=/usr/local/NETCDF FC=gfortran 4.mpich的安装：解压之类的步骤同上，同样放到usr下面。解压到指定路径。 $ tar zxf mpich-3.2.tar.gz $ ./configure -prefix=/usr/local/mpi/ 5.rttov的安装：rttov解压出来东西较多，同样新建个path来存放。 $ tar zxf rttov121.tar.gz $ cd src $ ../build/rttov_compile.sh 打完收工。目前应该就完成了WRF-DA编译安装前所有需要的依赖库的编译及安装。下一篇更新WRF-DA具体的编译与安装。由于对Linux系统不熟悉，加上坑爹的rttov，博客写了两三天。从内心坚持要提醒大家的一点，Linux编译环境一定要注意环境变量！！！ 最后重点鸣谢几位主要参考大神的博客以及相关文档： https://wenku.baidu.com/view/58851bc269eae009591bec0a.htmlhttps://nwpsaf.eu/site/software/rttov/rttov-v12/http://www2.mmm.ucar.edu/wrf/users/wrfda/updates-3.8.1.htmlhttps://xg1990.com/blog/archives/190 http://blog.csdn.net/luoying_1993/article/details/53228473]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>WRF</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一行代码更新R语言]]></title>
    <url>%2F2017%2F03%2F23%2F%E4%B8%80%E8%A1%8C%E4%BB%A3%E7%A0%81%E6%9B%B4%E6%96%B0R%E8%AF%AD%E8%A8%80%2F</url>
    <content type="text"><![CDATA[博客中已经陆续更新了两篇关于R语言的文章（相关系数矩阵可视化和读取Excel），按照上一篇挖的坑，这一期讲的是如何只用一行代码更新R语言。这里还是重新认真介绍下R语言（我真的只是凑个字数）好了，这里安利大家一本书。卡巴科弗. R语言实战[M]. 人民邮电出版社, 2016.事实上，我放的截图是2013年第一版，2016年有再版，建议大家可以购买纸质版。在第一版的时候，附录里提到了这么一件事。可以看到当时的2.13.0的版本R仍然没有什么可以自动更新R的方法。不过时至今日，R的版本已经到了3.3.3，在这三年间，R在编程语言排行榜上不断前行。已经有了长久的进步，当然，也出现了可以自动更新R的方法啦。这里介绍的就是R的一个包：installr。 installr {installr} R Documentation Installing software from RDescriptionGives the user the option to download software from within R. 上面是installr的官方文档介绍。接下来来讲所谓的一行代码更新R语言。这里有两个注意点：1.你的installr必须跟你的R版本对应，因为R语言默认安装的包都是适配最新的R语言版本。2.使用installr更新R语言必须在原生R里面，Rstudio里面无法进行（笔者没有尝试过其他R的IDE，有童鞋若有尝试也可以进行指正）。这里第一步先改下默认R的镜像（相信有很多童鞋应该改过了）。原生R更改设定为：程序包→设定CRAN镜像无论Python或者R，镜像统统选清华！。 #安装installr install.packages（installr) library(installr) updater()#就是这句。真得劲。一键更新 后面只要一路确定就好了。这个方法的好处在于，你可以不用重新安装你已经有的包。可以完整保留。注意的是这个包还依赖于stringr,stringi,magrittr。最后贴下这个包的官方文档航和新增的函数（super强大，还可以一键安装Python，RStudio等)。 NEW FUNCTIONS: install.python - Downloads and installs python 2 or 3UPDATED FUNCTIONS: install.URL now gives warning if there is suspicion that the user is not connected to the internet. updateR - added cran_mirror option]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>R语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[R语言读取Excel的神器——openxlsx]]></title>
    <url>%2F2017%2F03%2F22%2FR%E8%AF%AD%E8%A8%80%E8%AF%BB%E5%8F%96Excel%E7%9A%84%E7%A5%9E%E5%99%A8%E2%80%94%E2%80%94openxlsx%2F</url>
    <content type="text"><![CDATA[作为非程序猿的各位同志们，可能最擅长的数据整理软件或者统计软件就是——嗯，没有错，它就是集万千宠爱于一身的E~~X~~O。咳咳咳，好了。隆重推出我们的主角——Excel事实上，Excel是个super强大的软件。基本上用它已经能完成大量的统计分析了。For example各类数理统计 线性规划（LINGO表示欲哭无泪，你丫的抢我饭碗）。当然，很久很久之前有这门本神书：陈彦光. 基于Excel的地理数据分析[M]. 科学出版社, 2010.当然，作为新时代的研究生，我们怎么能仅用Excel来完成一切的科研任务呢？用老师的话说，你们用Excel做的图，人家审稿都嫌low。这个时候R就登场了。关于R的简介我就不提了。欢迎各种度娘，扯了这么久的淡。终于要进入正题了。今天讲的是R语言的第一步，读数据——读Excel的数据。以下有三种方法:1.将Excel转存为csv格式文件，读csv文件。 a&lt;-read.csv(&quot;exercise1.csv&quot;,header = T) 2.用RODBC包读取Excel。 ab&lt;-odbcConnectExcel2007(&quot;exercise1.xls&quot;)#连接excel，32位系统使用odbcConnectExcel函数 sqlTables(ab) 根据需求读取对应的sheet1 a&lt;-sqlFetch(ab,&quot;Sheet1$&quot;) odbcClose(ab)#关闭句柄，此句是必须。 3.用openxlsx包读取Excel a&lt;-read.xlsx(&quot;exercise1.xlsx&quot;,sheet=1)#文件名+sheet的序号，简单粗暴 综合来看，openxlsx的方法简单粗暴，而且经多名骨灰级玩家证明，罕有bug出现。乃R语言和Excel读取的绝对神器。不过笔者也发现，openxlsx包仅适用于.xlsx格式文件。前期的xls格式文件可能还需要前两种方法来读取。除了以上三种方法，还有类似的包如xlsx、readxl。此处依旧强推神器openxlsx。首先，.xlsx文件存储行数大大提升，从65536行数据提升到了104万条数据。其次，它十分便捷，函数所需参数较少。当然最后的最后，它可能需要的R的版本比较的新，下一篇的预告：如何通过一行代码升级R。最后贴出全文的代码。 #设置工作路径 setwd(&quot;F:/R/applicationstatics&quot;) #第一种方法：读取csv a&lt;-read.csv(&quot;exercise1.csv&quot;,header = T) #第二种方法：RODBC包 #安装载入RODBC包，如果已安装，请跳过第一句语句 install.packages(RODBC) library(RODBC) ab&lt;-odbcConnectExcel2007(&quot;exercise1.xls&quot;)#连接excel，32位系统使用odbcConnectExcel函数 sqlTables(ab) a&lt;-sqlFetch(ab,&quot;Sheet1$&quot;) odbcClose(ab)#关闭句柄，此句是必须。 #第三种方法：openxlsx install.packages(openxlsx) library(openxlsx) a&lt;-read.xlsx(&quot;exercise1.xlsx&quot;,sheet=1)#文件名+sheet的序号，简单粗暴 当然文末小福利：《基于Excel的地理数据分析》的电子版。需要的童鞋可以在评论区留邮箱或在我的主页（友情链接里面）搜索下我的邮箱。。]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>R语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Fortran语言初探及Win7 64位下Fortran开发环境配置]]></title>
    <url>%2F2017%2F01%2F16%2FFortran%E8%AF%AD%E8%A8%80%E5%88%9D%E6%8E%A2%E5%8F%8AWin7%2064%E4%BD%8D%E4%B8%8BFortran%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[笔者作为一只游走在生态、遥感、GIS与计算机的学生狗，最近终于因缘际会各种巧合下开始学习Fortran。还记得遥感物理课上牛柳两位老师（真是一个折磨萌萌哒台湾腔南方银口音的老师组合）的辐射传输方程、几何光学模型时时出现Fortran的身影。好了，扯淡完毕，首先先来简介下Fortran语言。Fortran源自于“公式翻译”（英语：FormulaTranslation）的缩写，是一种编程语言。它是世界上最早出现的计算机高级程序设计语言，广泛应用于科学和工程计算领域。FORTRAN语言以其特有的功能在数值、科学和工程计算领域发挥着重要作用。Fortran 90之前的版本是人们所知晓的FORTRAN（全部字母大写），从Fortran 90以及以后的版本都写成Fortran（仅有第一个字母大写）（ps，来自度娘百科）。可以说Fortran是属于计算机编程语言中的老古董了，但是另一个重要特点就是在科学和工程计算领域应用广泛，主要是其编程语言本身在数组计算上的一些优点决定的。从TIOBE 2017年1月的编程语言排行榜来看Fortran排在第28位，仍居前30之列，说明该语言仍旧具有广泛适用人群。那么Fortran在地理学、生态学与遥感方面的应用典型有哪些呢？事实上，在地理学、生态学与遥感领域，Fortran可以说有大量的学者使用并建立开发了大量的模型。比如遥感方面，大气辐射传输6S模型、MODTRAN辐射传输模型；生态学方面，WOFOST作物生长模型、DSSAT作物生长模型、景观中性模型模拟软件RULE等。同时Fortran对数组处理的优势使得它能在遥感数据的处理方面担当举足轻重的角色（类比语言IDL、Matlab、Python的numpy），这也是笔者学习的初衷。当然，正如前面提到了，Fortran是个典型的老古董语言，应用广泛的相关模型基于的Fortran版本的编译器在Win 7及以上系统中基本无法正常安装，故Win 7 64位系统如何配置Fortran开发环境是Fortran语言学习的第一步。由于传统的Visual Fortran 6.6.0及以下版本在Win 7 64位无法兼容，网上虽有帖子提出了相关解决法方法，但笔者亲自尝试的结果是hello world无法运行，故这边介绍其他方法。这里有两种配置方法是可以的：第一种，安装Visual Studio。作为微软主推的IDE，VS在诸多IDE中确实功能突出，优点颇多，作为商业软件，简单的开发环境配置方法也是一大优势。只需勾选Fortran相关编译器安装，即可配置成功。第二种，安装其他IDE，由于VS的简便性导致将其分为一类，其他IDE只需有Fortran编译器即可。VS在简便性上确实很优秀，但是相对而言，VS是个典型的重量级IDE。相对而言，笔者最近喜欢轻量级IDE，故搜索了其他IDE，以Code::Blocks为例，偏爱它的另一个原因就是因为它是免费开源软件（开源大法好）。1.首先下载带有Fortran编译器的Code::Blocks软件。 http://www.codeblocks.org/ 选择最后一个2.直接安装即可，确认安装所有部分3.安装完毕后，打开IDE在菜单栏中找到“Setting”→“Compiler”复制一个编译器，自定义名字接着点“Toolchain executables”将画框部分的文件全部改成gfortran.exe点击ok即可。4.Hello World 编写在菜单栏找到”File”→”New”→”Project”，建立一个Fortran工程文件。工程命名选择自定义的编译器添加hello world项目的Fortran文件编写如下的hello world进行测试。 program helloworld implicit none write(*,*) &apos;Hello world&apos; end program 5.生成exe文件无法打开的处理方法某些时候生成的exe文件打开会报错。类似“找不到*.dll”“这个应用程序安装/配置不正确，重新安装…”这样的错误。这样的情况下，只需在系统变量里面PATH加上对应的路径即可。]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>Fortran语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何做出相关系数矩阵可视化图]]></title>
    <url>%2F2016%2F12%2F11%2F%E5%A6%82%E4%BD%95%E5%81%9A%E5%87%BA%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0%E7%9F%A9%E9%98%B5%E5%8F%AF%E8%A7%86%E5%8C%96%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[如何做出相关系数矩阵可视化图 install.packages(&quot;psych&quot;) install.packages(&quot;corrplot&quot;)#安装包，如果已安装，请略过 library(psych) library(corrplot)#载入两个包 data(iris)#机器学习常用神奇数据集——鸢尾花数据集 head(iris)#查看下数据集前五行 irisnew&lt;-iris[,-5]#去除第五列种类变量 cormat&lt;-corr.test(irisnew)#相关系数分析及显著性检验 #最简单的相关系数矩阵可视化 corrplot(cormat$r) corrplot(cormat$r,method=&quot;square&quot;) corrplot(cormat$r,method = &quot;number&quot;) corrplot(cormat$r,method = &quot;shade&quot;) corrplot(cormat$r,method=&quot;ellipse&quot;) corrplot(cormat$r,method = &quot;pie&quot;) corrplot(cormat$r,method=&quot;square&quot;,type=&quot;lower&quot;,title = &quot;Correlation of iris&quot;) #含显著性检验的相关系数矩阵可视化 cormatp&lt;-cormat$p#单独取出p值矩阵 cormatp[upper.tri(cormatp)]=0#设置p值矩阵上三角等于0 corrplot(cormat$r,method=&quot;square&quot;,type=&quot;lower&quot;,title = &quot;Correlation of iris&quot;,tl.cex=1.5,tl.pos = &quot;lt&quot;,number.cex=1,p.mat=cormatp,sig.level=0.05,insig=c(&quot;pch&quot;)) corrplot(cormat$r,method=&quot;square&quot;,type=&quot;full&quot;,title = &quot;Correlation of iris&quot;,tl.cex=1.5,tl.pos = &quot;lt&quot;,number.cex=1,p.mat=cormatp,sig.level=0.05,insig=c(&quot;pch&quot;)) corrplot.mixed(cormat$r,upper = &quot;square&quot;,lower = &quot;number&quot;,diag = &quot;u&quot;,tl.cex=1.5,tl.pos = &quot;lt&quot;,number.cex=1,p.mat=cormatp,sig.level=0.05,insig=c(&quot;pch&quot;))]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>R语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于ArcGIS Pro的二三维一体化]]></title>
    <url>%2F2016%2F12%2F07%2Farcgispro%2F</url>
    <content type="text"><![CDATA[最近尝试了下ArcGIS Pro的二三维一体化管理功能。感觉相当不错，记录一下使用过程与操作。ArcGIS Pro是一款全新的桌面应用程序，它改变了桌面GIS的工作方式，以满足新一代WebGIS应用模式。ArcGIS Pro采用Ribbon界面风格，给人全新的用户体验。它作为一个高级的应用程序，可以对来自本地、ArcGIS Online、或者Portal for ArcGIS的数据进行可视化、编辑、分析。同时，实现了二三维一体化的数据可视化、管理、分析和发布。此外，ArcGIS Pro原生64位应用，支持多线程处理，极大提高软件性能。关于ArcGIS Pro的安装与使用请参考如下的网址（ps，可以无限试用）。 http://blog.csdn.net/kikitamoon/article/details/44102383 从GIS数据的种类来说，主要是两种：矢量数据和栅格数据。三维数据也可以基于这两种分别完成。介绍下这两类的三维化。（一）栅格的三维化栅格数据的三维化主要是类似于DEM拉伸成三维的山体。首先打开ArcGIS Pro新建一个二维和三维窗口右击三维场景属性，如下图，设置要三维化的栅格，此外可以根据需求做拉伸效果如下点击二三维联动按钮二三维联动效果：（二）矢量操作矢量的数据可以通过字段拉伸或者rpk生成。ArcGIS Pro在这方面无缝集成了City Engine的规则建模。因此首先在City Engine中写好CGA，通过City Engine生成规则包rpk。 @StartRule lot--&gt; extrude(rand(3, 50)) 接着点击工具 生成三维体图层 二三维联动效果如下 ArcGIS Pro的整体界面非常友好，而且功能强大，也是目前esri主推的新软件，不仅是二三维一体化，在今年esri用户大会上，还演示了基于ArcGIS Pro的各类大数据应用。大数据时代，让我们拥抱ArcGIS Pro。]]></content>
      <categories>
        <category>GIS</category>
      </categories>
      <tags>
        <tag>ArcGIS Pro</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[桌面GIS连接Postgresql总结]]></title>
    <url>%2F2016%2F08%2F14%2F%E6%A1%8C%E9%9D%A2GIS%E8%BF%9E%E6%8E%A5Postgresql%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[对于非开发人员的GISer而言，数据库这东西更多停留在mdb，gdb的层面，相对而言这些数据的使用无论是在处理还是管理上，门槛相对较低。但是目前所处的信息爆炸的大数据时代，仅仅依靠桌面GIS本身的数据存储远远不够，在存储大量数据的时候，仍然需要专门的数据库管理。所以桌面GIS如何在关系型数据库中写入空间数据也是一个重要的过程。此文是在阅读了网上的部分博客及自己的亲身经验写成。主要介绍桌面GIS中两大代表——Esri的ArcGIS以及开源的QGIS。使用的关系型数据库是Postgresql，它的空间扩展是PostGIS。桌面GIS：Esri ArcGIS 10.2Esri ArcSDE 10.2QGIS 2.8.2关系型数据库及空间扩展:Postgresql 9.5.0_x64PostGIS 2.2以上软件的安装略过了，网上均有教程。 （一）QGIS连接Postgresql个人最喜爱QGIS的一点就是它与PostGIS以及其他各类数据库的无缝衔接，确实可以说是直连数据库。主要是通过这个数据库的操作先新建一个连接，输入名称、主机、数据库、调整SSL模式、用户名、密码，最后测试连接。如果跳出这个页面，就证明你成功啦。接下来按确定之后，只要在最开始的页面点击“连接”，就已经愉快地连上了。如果你打开Postgresql，会发现全局架构是对应的，所以确认是连接成功的。!这边选择了一个2008年2月3日北京市的一辆出租车轨迹数据来做测试QGIS中，基于出租车轨迹生成的热图 （二）ArcGIS Desktop 连接PostgresqlArcGIS Desktop 10.2之后提供了Postgresql直连的功能，当然这里的直连，我认为可以叫伪直连，因为它仍然需要ArcSDE的支持，而不像QGIS可以直接连接。当然直连的的方法还是相对简单的，不过我也遇到了一个问题，我的Postgresql是64位。但是ArcGIS Desktop目前只有32位。所以即使安装了ArcSDE，也无法直接连接。需要Postgresql32位里面的一些dll文件。将这些Postgresql对应版本32位的dll文件复制粘贴到ArcGIS安装目录下面的”/ArcGIS/Desktop 10.2/bin的文件夹里，接着可以打开ArcGIS进行连接了。 选择同一个测试数据导入PostGIS基于ArcGIS连接Postgresql里面的数据制作的核密度图]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>PostGIS</tag>
      </tags>
  </entry>
</search>